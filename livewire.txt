```python
# sxs.py
# Enhanced and Upgraded Scalping Bot Framework
# Derived from xrscalper.py, focusing on robust execution, error handling,
# advanced position management (BE, TSL), and Bybit V5 compatibility.

# Standard Library Imports
import hashlib
import hmac
import json
import logging
import math
import os
import time
from datetime import datetime, timedelta, timezone
from decimal import ROUND_DOWN, ROUND_UP, Decimal, InvalidOperation, getcontext
from logging.handlers import RotatingFileHandler
from typing import Any, Dict, List, Optional, Tuple, Union
from zoneinfo import ZoneInfo # Use zoneinfo for modern timezone handling

# Third-Party Imports
import ccxt # Exchange interaction library
import numpy as np # Numerical operations, used for NaN and jitter
import pandas as pd # Data manipulation and analysis
import pandas_ta as ta # Technical analysis library built on pandas
import requests # Used by ccxt for HTTP requests
from colorama import Fore, Style, init # Colored terminal output
from dotenv import load_dotenv # Loading environment variables

# --- Initialization ---
init(autoreset=True) # Ensure colorama resets styles automatically
load_dotenv() # Load environment variables from .env file (e.g., API keys)

# Set Decimal precision (high precision for financial calculations)
# Trade-off: Higher precision reduces potential rounding errors in complex calculations
# but might slightly impact performance. 36 is generally very high for crypto.
getcontext().prec = 36

# --- Neon Color Scheme (for console logging enhancement) ---
NEON_GREEN = Fore.LIGHTGREEN_EX
NEON_BLUE = Fore.CYAN
NEON_PURPLE = Fore.MAGENTA
NEON_YELLOW = Fore.YELLOW
NEON_RED = Fore.LIGHTRED_EX
NEON_CYAN = Fore.CYAN
RESET = Style.RESET_ALL

# --- Constants ---
# API Keys loaded from environment variables
API_KEY = os.getenv("BYBIT_API_KEY")
API_SECRET = os.getenv("BYBIT_API_SECRET")
# Critical check: Ensure API keys are present before proceeding
if not API_KEY or not API_SECRET:
    # Use a basic logger setup for this critical startup error as full logging isn't ready yet
    logging.basicConfig(level=logging.CRITICAL, format='%(levelname)s: %(message)s')
    logging.critical(f"{NEON_RED}CRITICAL: BYBIT_API_KEY and BYBIT_API_SECRET must be set in .env file.{RESET}")
    raise ValueError("BYBIT_API_KEY and BYBIT_API_SECRET environment variables are not set.")

CONFIG_FILE = "config.json" # Name of the configuration file
LOG_DIRECTORY = "bot_logs" # Directory to store log files
# Ensure the log directory exists early in the script execution
os.makedirs(LOG_DIRECTORY, exist_ok=True)

# Default Timezone (will be overridden by config if specified)
# Using IANA timezone database names (e.g., "America/Chicago", "Europe/London", "UTC")
# https://en.wikipedia.org/wiki/List_of_tz_database_time_zones
DEFAULT_TIMEZONE = ZoneInfo("America/Chicago")
TIMEZONE = DEFAULT_TIMEZONE # Global variable updated by load_config

# API Retry Settings (defaults, can be overridden by config)
MAX_API_RETRIES = 5 # Default maximum number of retries for failed API calls
RETRY_DELAY_SECONDS = 7 # Default base delay between retries (increases exponentially)
# HTTP status codes considered generally retryable for network/server issues
RETRYABLE_HTTP_CODES = [429, 500, 502, 503, 504]

# Valid Timeframes for Data Fetching
VALID_INTERVALS = ["1", "3", "5", "15", "30", "60", "120", "240", "D", "W", "M"]
# Mapping between internal interval notation and CCXT's timeframe notation
CCXT_INTERVAL_MAP = {
    "1": "1m", "3": "3m", "5": "5m", "15": "15m", "30": "30m",
    "60": "1h", "120": "2h", "240": "4h", "D": "1d", "W": "1w", "M": "1M"
}

# Default Indicator Periods (can be overridden by config.json) - Using standardized names
DEFAULT_ATR_PERIOD = 14
DEFAULT_CCI_PERIOD = 20
DEFAULT_WILLIAMS_R_PERIOD = 14
DEFAULT_MFI_PERIOD = 14
DEFAULT_STOCH_RSI_PERIOD = 14
DEFAULT_STOCH_RSI_RSI_PERIOD = 14 # Underlying RSI period for StochRSI
DEFAULT_STOCH_RSI_K_PERIOD = 3
DEFAULT_STOCH_RSI_D_PERIOD = 3
DEFAULT_RSI_PERIOD = 14
DEFAULT_BBANDS_PERIOD = 20
DEFAULT_BBANDS_STDDEV = 2.0
DEFAULT_SMA10_PERIOD = 10
DEFAULT_EMA_SHORT_PERIOD = 9
DEFAULT_EMA_LONG_PERIOD = 21
DEFAULT_MOMENTUM_PERIOD = 7
DEFAULT_VOLUME_MA_PERIOD = 15
DEFAULT_FIB_PERIOD = 50 # Lookback period for Fibonacci High/Low
DEFAULT_PSAR_STEP = 0.02
DEFAULT_PSAR_MAX_STEP = 0.2

FIB_LEVELS = [0.0, 0.236, 0.382, 0.5, 0.618, 0.786, 1.0] # Standard Fibonacci retracement levels
LOOP_DELAY_SECONDS = 10 # Default minimum time between main loop cycles (end of one to start of next)
POSITION_CONFIRM_DELAY_SECONDS = 10 # Default wait time after placing an order before confirming position status

# Global config dictionary, loaded by load_config
config: Dict[str, Any] = {}
# Global default config dictionary, initialized within load_config
default_config: Dict[str, Any] = {}

# --- Configuration Loading & Validation ---
class SensitiveFormatter(logging.Formatter):
    """
    Custom logging formatter to redact sensitive information (like API keys/secrets)
    from log messages before they are written.
    """
    # Store redacted patterns for efficiency
    _patterns = {}
    _sensitive_keys = {"API_KEY": API_KEY, "API_SECRET": API_SECRET}

    def format(self, record: logging.LogRecord) -> str:
        """Formats the log record and redacts sensitive data."""
        msg = super().format(record)

        # Redact sensitive keys found in the message
        for key_name, key_value in self._sensitive_keys.items():
            if key_value: # Only redact if the key has a value
                if key_value not in self._patterns:
                    self._patterns[key_value] = f"***{key_name}***" # e.g., ***API_KEY***
                if key_value in msg: # Simple string replacement is usually sufficient and faster
                    msg = msg.replace(key_value, self._patterns[key_value])
        return msg

def load_config(filepath: str) -> Dict[str, Any]:
    """
    Loads configuration from a JSON file.
    - Creates a default configuration file if it doesn't exist.
    - Merges loaded configuration with defaults to ensure all keys are present.
    - Validates configuration parameters against types, ranges, and allowed values.
    - Resets invalid parameters to their defaults and logs warnings.
    - Saves the updated (merged, validated) configuration back to the file if changes occurred.
    - Updates the global `TIMEZONE` variable based on the validated config.

    Args:
        filepath (str): The path to the configuration JSON file.

    Returns:
        Dict[str, Any]: The validated configuration dictionary.
    """
    global TIMEZONE, default_config # Allow modification of global variables

    # Define the default configuration structure and values
    # This is assigned to the global default_config for reference in validation
    default_config = {
        # --- Trading Pair & Timeframe ---
        "symbol": "BTC/USDT:USDT", # Example for Bybit linear perpetual
        "interval": "5", # Default timeframe (e.g., "5" for 5 minutes)

        # --- API & Bot Behavior ---
        "retry_delay": RETRY_DELAY_SECONDS, # Base delay between API retries (seconds)
        "max_api_retries": MAX_API_RETRIES, # Max retries for API calls
        "enable_trading": False, # CRITICAL SAFETY FEATURE: Must be explicitly True to execute live trades.
        "use_sandbox": True, # CRITICAL SAFETY FEATURE: Connects to exchange testnet by default.
        "max_concurrent_positions": 1, # Max open positions allowed simultaneously for this specific symbol instance.
        "quote_currency": "USDT", # Quote currency (used for balance checks, sizing). Ensure it matches the symbol's quote asset.
        "position_confirm_delay_seconds": POSITION_CONFIRM_DELAY_SECONDS, # Wait time after order placement before checking position status.
        "loop_delay_seconds": LOOP_DELAY_SECONDS, # Minimum delay between main loop cycles.
        "timezone": "America/Chicago", # IANA timezone name for local time display in console logs.

        # --- Risk Management ---
        "risk_per_trade": 0.01, # Fraction of available balance to risk per trade (e.g., 0.01 = 1%).
        "leverage": 20, # Desired leverage multiplier. Ensure it's supported by the exchange/market and within safe limits.
        "stop_loss_multiple": 1.8, # ATR multiple for calculating the initial Stop Loss distance.
        "take_profit_multiple": 0.7, # ATR multiple for calculating the initial Take Profit distance.

        # --- Order Execution ---
        "entry_order_type": "market", # Type of order for entry: "market" or "limit".
        "limit_order_offset_buy": 0.0005, # For limit entries: Percentage offset from the target price for BUY orders (0.0005 = 0.05%). Price = Target * (1 - Offset)
        "limit_order_offset_sell": 0.0005, # For limit entries: Percentage offset from the target price for SELL orders (0.0005 = 0.05%). Price = Target * (1 + Offset)

        # --- Advanced Position Management ---
        "enable_trailing_stop": True, # Enable exchange-native Trailing Stop Loss (Requires exchange support, e.g., Bybit V5).
        # IMPORTANT (Bybit V5 TSL): TSL uses PRICE DISTANCE, not percentage.
        # 'callback_rate' is used here to *calculate* that price distance based on the activation price.
        "trailing_stop_callback_rate": 0.005, # Percentage (0.005 = 0.5%) used to calculate the trail distance from the *activation price*. Distance = ActivationPrice * CallbackRate.
        "trailing_stop_activation_percentage": 0.003, # Profit percentage (0.003 = 0.3%) move from entry price needed to trigger calculation of TSL activation price. ActivationPrice = Entry +/- (Entry * Activation%)
        "enable_break_even": True, # Enable moving Stop Loss to break-even point once profit target is hit.
        "break_even_trigger_atr_multiple": 1.0, # Move SL to break-even when profit reaches (ATR * this multiple).
        "break_even_offset_ticks": 2, # Place the break-even SL slightly beyond the entry price (in number of ticks) to cover potential fees/slippage.

        "time_based_exit_minutes": None, # Optional: Exit position automatically after specified minutes (e.g., 120 for 2 hours). Set to null or None to disable.

        # --- Indicator Periods & Parameters (Defaults defined above) ---
        "atr_period": DEFAULT_ATR_PERIOD,
        "ema_short_period": DEFAULT_EMA_SHORT_PERIOD,
        "ema_long_period": DEFAULT_EMA_LONG_PERIOD,
        "rsi_period": DEFAULT_RSI_PERIOD,
        "bollinger_bands_period": DEFAULT_BBANDS_PERIOD,
        "bollinger_bands_std_dev": DEFAULT_BBANDS_STDDEV,
        "cci_period": DEFAULT_CCI_PERIOD,
        "williams_r_period": DEFAULT_WILLIAMS_R_PERIOD,
        "mfi_period": DEFAULT_MFI_PERIOD,
        "stoch_rsi_period": DEFAULT_STOCH_RSI_PERIOD,
        "stoch_rsi_rsi_period": DEFAULT_STOCH_RSI_RSI_PERIOD,
        "stoch_rsi_k_period": DEFAULT_STOCH_RSI_K_PERIOD,
        "stoch_rsi_d_period": DEFAULT_STOCH_RSI_D_PERIOD,
        "psar_step": DEFAULT_PSAR_STEP,
        "psar_max_step": DEFAULT_PSAR_MAX_STEP,
        "sma_10_period": DEFAULT_SMA10_PERIOD,
        "momentum_period": DEFAULT_MOMENTUM_PERIOD,
        "volume_ma_period": DEFAULT_VOLUME_MA_PERIOD,
        "fibonacci_period": DEFAULT_FIB_PERIOD, # Lookback for Fib High/Low

        # --- Indicator Calculation & Scoring Control ---
        "orderbook_limit": 25, # Number of order book levels to fetch and analyze. Check exchange limits (Bybit V5 linear: up to 200).
        "signal_score_threshold": 1.5, # Minimum absolute weighted score required to trigger a BUY or SELL signal.
        "stoch_rsi_oversold_threshold": 25, # StochRSI level below which it's considered oversold (influences score).
        "stoch_rsi_overbought_threshold": 75, # StochRSI level above which it's considered overbought (influences score).
        "volume_confirmation_multiplier": 1.5, # Minimum ratio of current volume to Volume MA required for positive volume confirmation score.
        "indicators": { # Toggle calculation and scoring contribution for each indicator
            # Key names MUST match _check_<key> methods and weight_sets keys
            "ema_alignment": True, "momentum": True, "volume_confirmation": True,
            "stoch_rsi": True, "rsi": True, "bollinger_bands": True, "vwap": True,
            "cci": True, "wr": True, "psar": True, "sma_10": True, "mfi": True,
            "orderbook": True,
            # Add new indicators here and ensure corresponding _check_ method and weight entries exist
        },
        "weight_sets": { # Define different scoring weights for various strategies
            "scalping": { # Example: Faster signals, momentum-focused
                "ema_alignment": 0.2, "momentum": 0.3, "volume_confirmation": 0.2,
                "stoch_rsi": 0.6, "rsi": 0.2, "bollinger_bands": 0.3, "vwap": 0.4,
                "cci": 0.3, "wr": 0.3, "psar": 0.2, "sma_10": 0.1, "mfi": 0.2, "orderbook": 0.15,
            },
            "default": { # Example: Balanced approach
                "ema_alignment": 0.3, "momentum": 0.2, "volume_confirmation": 0.1,
                "stoch_rsi": 0.4, "rsi": 0.3, "bollinger_bands": 0.2, "vwap": 0.3,
                "cci": 0.2, "wr": 0.2, "psar": 0.3, "sma_10": 0.1, "mfi": 0.2, "orderbook": 0.1,
            }
            # Ensure keys here match keys in "indicators" and correspond to _check_ methods
        },
        "active_weight_set": "default" # Selects which weight set from "weight_sets" to use for scoring.
    }

    current_config = default_config.copy() # Start with default values
    config_loaded_successfully = False
    needs_saving = False # Flag to track if the config file needs to be updated/saved

    # --- Load Existing Config (if exists) ---
    if os.path.exists(filepath):
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                loaded_config = json.load(f)
            # Merge loaded config over defaults, ensuring all default keys exist in the final config
            merged_config = _merge_configs(loaded_config, default_config)
            print(f"{NEON_GREEN}Loaded configuration from {filepath}{RESET}")
            config_loaded_successfully = True
            # Check if merge resulted in changes (e.g., new defaults added)
            if merged_config != loaded_config: # Compare merged vs originally loaded
                needs_saving = True
                print(f"{NEON_YELLOW}Configuration merged with new defaults/structure.{RESET}")
            current_config = merged_config # Use the merged config for validation

        except (json.JSONDecodeError, IOError) as e:
            print(f"{NEON_RED}Error loading config file {filepath}: {e}. Using default config.{RESET}")
            current_config = default_config # Fallback to default
            needs_saving = True # Need to save the default config
        except Exception as e:
             print(f"{NEON_RED}Unexpected error loading config {filepath}: {e}. Using default config.{RESET}")
             current_config = default_config
             needs_saving = True
    else:
        # Config file doesn't exist, create it using defaults
        print(f"{NEON_YELLOW}Config file not found. Creating default config at {filepath}{RESET}")
        current_config = default_config
        needs_saving = True

    # --- Validation Section ---
    # Work with the 'current_config' (which is either loaded+merged or default)
    original_config_before_validation = current_config.copy() # Keep a copy to check if validation modified anything

    # Helper function for validating parameters, logging errors, and resetting to default
    def validate_param(key, validation_func, error_msg_format):
        """Validates a config key, resets to default if invalid, and returns original validity."""
        is_valid = False
        current_value = current_config.get(key)
        default_value = default_config.get(key) # Get default value for this key
        try:
            if key in current_config and validation_func(current_value):
                is_valid = True # Value exists and passes validation
            else:
                # Reset to default if key is missing or validation fails
                current_config[key] = default_value
                # Format error message safely, using repr() for potentially complex values
                value_repr = repr(current_value) if current_value is not None else 'None'
                print(f"{NEON_RED}{error_msg_format.format(key=key, value=value_repr, default=default_value)}{RESET}")
                # Needs saving because we changed the value
                nonlocal needs_saving
                needs_saving = True
        except Exception as validation_err:
            # Catch errors *within* the validation function itself
            print(f"{NEON_RED}Error validating config key '{key}' (Value: {repr(current_value)}): {validation_err}. Resetting to default '{default_value}'.{RESET}")
            current_config[key] = default_value
            needs_saving = True
        return is_valid

    # --- Validate Core Parameters ---
    validate_param("symbol",
                   lambda v: isinstance(v, str) and v.strip(),
                   "CRITICAL: Config key '{key}' is missing, empty, or invalid ({value}). Resetting to default: '{default}'. Check symbol format.")

    validate_param("interval",
                   lambda v: v in VALID_INTERVALS,
                   "Invalid interval '{value}' in config for '{key}'. Resetting to default '{default}'. Valid: " + ", ".join(VALID_INTERVALS) + ".")

    validate_param("entry_order_type",
                   lambda v: v in ["market", "limit"],
                   "Invalid entry_order_type '{value}' for '{key}'. Must be 'market' or 'limit'. Resetting to default '{default}'.")

    validate_param("quote_currency",
                   lambda v: isinstance(v, str) and len(v) >= 3 and v.isupper(), # Basic sanity check
                   "Invalid quote_currency '{value}' for '{key}'. Should be uppercase currency code (e.g., USDT). Resetting to '{default}'.")

    # Validate timezone and update global TIMEZONE constant
    try:
        tz_str = current_config.get("timezone", default_config["timezone"])
        if not isinstance(tz_str, str): raise TypeError("Timezone must be a string")
        tz_info = ZoneInfo(tz_str) # This raises ZoneInfoNotFoundError if invalid
        current_config["timezone"] = tz_str # Store the validated string
        TIMEZONE = tz_info # Update the global constant for use elsewhere
    except Exception as tz_err:
        print(f"{NEON_RED}Invalid timezone '{tz_str}' in config: {tz_err}. Resetting to default '{default_config['timezone']}'.{RESET}")
        current_config["timezone"] = default_config["timezone"]
        TIMEZONE = ZoneInfo(default_config["timezone"]) # Reset global to default
        needs_saving = True

    # Validate active weight set exists in the 'weight_sets' dictionary
    validate_param("active_weight_set",
                   lambda v: isinstance(v, str) and v in current_config.get("weight_sets", {}),
                   "Active weight set '{value}' for '{key}' not found in 'weight_sets' section. Resetting to '{default}'.")

    # --- Validate Numeric Parameters (using Decimal for range checks) ---
    # Format: key: (min_val, max_val, allow_min_equal, allow_max_equal, requires_integer)
    numeric_params = {
        "risk_per_trade": (0, 1, False, False, False), # Exclusive bounds 0-1
        "leverage": (1, 1000, True, True, True), # Realistic max leverage, must be int
        "stop_loss_multiple": (0, float('inf'), False, True, False), # Must be > 0
        "take_profit_multiple": (0, float('inf'), False, True, False), # Must be > 0
        "trailing_stop_callback_rate": (0, 1, False, False, False), # Exclusive bounds 0-1
        "trailing_stop_activation_percentage": (0, 1, True, False, False), # Allow 0%, must be < 1
        "break_even_trigger_atr_multiple": (0, float('inf'), False, True, False), # Must be > 0
        "break_even_offset_ticks": (0, 1000, True, True, True), # Must be int >= 0
        "signal_score_threshold": (0, float('inf'), False, True, False), # Must be > 0
        "atr_period": (2, 1000, True, True, True), # Min 2 for ATR calc
        "ema_short_period": (1, 1000, True, True, True),
        "ema_long_period": (1, 1000, True, True, True),
        "rsi_period": (2, 1000, True, True, True), # Min 2 for RSI calc
        "bollinger_bands_period": (2, 1000, True, True, True),
        "bollinger_bands_std_dev": (0, 10, False, True, False), # Must be > 0
        "cci_period": (2, 1000, True, True, True), # Typical min period
        "williams_r_period": (2, 1000, True, True, True),
        "mfi_period": (2, 1000, True, True, True),
        "stoch_rsi_period": (2, 1000, True, True, True),
        "stoch_rsi_rsi_period": (2, 1000, True, True, True),
        "stoch_rsi_k_period": (1, 1000, True, True, True),
        "stoch_rsi_d_period": (1, 1000, True, True, True),
        "psar_step": (0, 1, False, True, False), # Must be > 0
        "psar_max_step": (0, 1, False, True, False), # Must be > 0
        "sma_10_period": (1, 1000, True, True, True),
        "momentum_period": (1, 1000, True, True, True),
        "volume_ma_period": (1, 1000, True, True, True),
        "fibonacci_period": (2, 1000, True, True, True), # Needs at least 2 bars
        "orderbook_limit": (1, 200, True, True, True), # Bybit V5 linear max is 200
        "position_confirm_delay_seconds": (0, 120, True, True, False), # Allow 0 delay
        "loop_delay_seconds": (1, 300, True, True, False),
        "stoch_rsi_oversold_threshold": (0, 100, True, False, False), # Must be < 100
        "stoch_rsi_overbought_threshold": (0, 100, False, True, False), # Must be > 0
        "volume_confirmation_multiplier": (0, float('inf'), False, True, False), # Must be > 0
        "limit_order_offset_buy": (0, 0.1, True, False, False), # 0% to 10% offset seems reasonable
        "limit_order_offset_sell": (0, 0.1, True, False, False),
        "retry_delay": (1, 120, True, True, False),
        "max_api_retries": (0, 10, True, True, True), # Must be int >= 0
        "max_concurrent_positions": (1, 10, True, True, True), # Must be int >= 1
    }
    for key, (min_val, max_val, allow_min, allow_max, is_integer) in numeric_params.items():
        value = current_config.get(key)
        default_val = default_config.get(key)
        param_is_valid = False
        if value is not None:
            try:
                val_dec = Decimal(str(value)) # Convert to Decimal for reliable checks
                if not val_dec.is_finite(): raise ValueError("Value not finite")

                # Check bounds using Decimal comparison
                min_dec = Decimal(str(min_val))
                max_dec = Decimal(str(max_val))
                lower_bound_ok = (val_dec >= min_dec) if allow_min else (val_dec > min_dec)
                upper_bound_ok = (val_dec <= max_dec) if allow_max else (val_dec < max_dec)

                if lower_bound_ok and upper_bound_ok:
                    # Convert to final type (int or float) after successful validation
                    if is_integer:
                        # Check if it's actually an integer before converting
                        if val_dec == val_dec.to_integral_value():
                            final_value = int(val_dec)
                            current_config[key] = final_value # Store validated integer
                            param_is_valid = True
                        else:
                            raise ValueError("Non-integer value provided for integer parameter")
                    else:
                        final_value = float(val_dec) # Store as float if not integer required
                        current_config[key] = final_value
                        param_is_valid = True
                # else: Bounds check failed, param_is_valid remains False
            except (ValueError, TypeError, InvalidOperation):
                 pass # Invalid format or failed conversion/checks, param_is_valid remains False

        if not param_is_valid:
            # Use validate_param to log error and reset to default
            bound_str = f"{'>' if not allow_min else '>='} {min_val} and {'<' if not allow_max else '<='} {max_val}"
            type_str = 'integer' if is_integer else 'number'
            err_msg = f"Invalid value for '{{key}}' ({{value}}). Must be a {type_str} ({bound_str}). Resetting to default '{{default}}'."
            validate_param(key, lambda v: False, err_msg) # Force reset and log

    # Specific validation for time_based_exit_minutes (allows None or positive number)
    time_exit_key = "time_based_exit_minutes"
    time_exit_value = current_config.get(time_exit_key)
    time_exit_valid = False
    if time_exit_value is None:
        time_exit_valid = True # None is valid
    else:
        try:
            time_exit_float = float(time_exit_value)
            if time_exit_float > 0 and np.isfinite(time_exit_float):
                 current_config[time_exit_key] = time_exit_float # Store validated float
                 time_exit_valid = True
            else: raise ValueError("Must be positive and finite if set")
        except (ValueError, TypeError):
            pass # Invalid format or non-positive/non-finite

    if not time_exit_valid:
         validate_param(time_exit_key, lambda v: False, # Force reset
                        "Invalid value for '{{key}}' ({{value}}). Must be 'None' or a positive number. Resetting to default ('{{default}}').")

    # --- Validate Boolean Parameters ---
    bool_params = ["enable_trading", "use_sandbox", "enable_trailing_stop", "enable_break_even"]
    for key in bool_params:
         validate_param(key, lambda v: isinstance(v, bool),
                        "Invalid value for '{{key}}' ({{value}}). Must be boolean (true/false). Resetting to default '{{default}}'.")

    # --- Validate Indicator Enable Flags (must exist in defaults and be boolean) ---
    indicators_key = 'indicators'
    if indicators_key in current_config and isinstance(current_config[indicators_key], dict):
        indicators_dict = current_config[indicators_key]
        default_indicators_ref = default_config[indicators_key]
        keys_to_remove = [] # Collect unknown keys to remove later
        for ind_key, ind_val in indicators_dict.items():
            # Check if key exists in default config (prevents unknown indicators)
            if ind_key not in default_indicators_ref:
                print(f"{NEON_YELLOW}Warning: Unknown key '{ind_key}' found in '{indicators_key}' section. It will be removed.{RESET}")
                keys_to_remove.append(ind_key)
                needs_saving = True
                continue
            # Validate value is boolean
            if not isinstance(ind_val, bool):
                default_ind_val = default_indicators_ref.get(ind_key, False) # Should exist, but safety fallback
                print(f"{NEON_RED}Invalid value for '{indicators_key}.{ind_key}' ({repr(ind_val)}). Must be boolean (true/false). Resetting to default '{default_ind_val}'.{RESET}")
                indicators_dict[ind_key] = default_ind_val
                needs_saving = True
        # Remove unknown keys outside the loop
        for r_key in keys_to_remove: del indicators_dict[r_key]
        # Ensure all default indicator keys are present
        for def_key, def_val in default_indicators_ref.items():
            if def_key not in indicators_dict:
                print(f"{NEON_YELLOW}Adding missing indicator key '{def_key}' to '{indicators_key}' section with default value '{def_val}'.{RESET}")
                indicators_dict[def_key] = def_val
                needs_saving = True
    else:
        # If 'indicators' key is missing or not a dict, reset to default
        print(f"{NEON_RED}Invalid or missing '{indicators_key}' section in config. Resetting to default.{RESET}")
        current_config[indicators_key] = default_config[indicators_key].copy() # Use copy of default
        needs_saving = True

    # --- Validate Weight Sets Structure and Values ---
    ws_key = "weight_sets"
    if ws_key in current_config and isinstance(current_config[ws_key], dict):
        weight_sets = current_config[ws_key]
        default_indicators_keys = default_config['indicators'].keys() # Get valid indicator keys
        sets_to_remove = []
        for set_name, weights in weight_sets.items():
            if not isinstance(weights, dict):
                 print(f"{NEON_RED}Invalid structure for weight set '{set_name}' (must be a dictionary of indicator:weight pairs). Removing this set.{RESET}")
                 sets_to_remove.append(set_name)
                 needs_saving = True
                 continue

            weights_to_remove = []
            for ind_key, weight_val in weights.items():
                # Ensure weight key matches a known indicator key
                if ind_key not in default_indicators_keys:
                    print(f"{NEON_YELLOW}Warning: Weight defined for unknown/invalid indicator '{ind_key}' in weight set '{set_name}'. Removing this weight entry.{RESET}")
                    weights_to_remove.append(ind_key)
                    needs_saving = True
                    continue

                # Validate weight value is numeric and non-negative
                try:
                    weight_dec = Decimal(str(weight_val))
                    if not weight_dec.is_finite() or weight_dec < 0:
                        raise ValueError("Weight must be non-negative and finite")
                    # Store validated weight as float (common usage in scoring)
                    weights[ind_key] = float(weight_dec)
                except (ValueError, TypeError, InvalidOperation):
                     # Attempt to get default weight, fallback to 0.0
                     default_weight_set = default_config.get(ws_key, {}).get(set_name, {}) # Use global default_config
                     default_weight = default_weight_set.get(ind_key, 0.0)
                     print(f"{NEON_RED}Invalid weight value '{repr(weight_val)}' for indicator '{ind_key}' in weight set '{set_name}'. Must be a non-negative number. Resetting to default '{default_weight}'.{RESET}")
                     weights[ind_key] = float(default_weight) # Reset to float
                     needs_saving = True
            # Remove invalid weights from the current set
            for r_key in weights_to_remove: del weights[r_key]
            # Ensure all default indicator keys are present in the weight set (add with weight 0 if missing)
            for def_ind_key in default_indicators_keys:
                if def_ind_key not in weights:
                    print(f"{NEON_YELLOW}Adding missing indicator key '{def_ind_key}' to weight set '{set_name}' with weight 0.0.{RESET}")
                    weights[def_ind_key] = 0.0
                    needs_saving = True

        # Remove invalid sets
        for r_key in sets_to_remove: del weight_sets[r_key]
    else:
         print(f"{NEON_RED}Invalid or missing '{ws_key}' section in config. Resetting to default.{RESET}")
         current_config[ws_key] = default_config[ws_key].copy() # Use copy of default
         needs_saving = True

    # --- Post-validation Check: Ensure active_weight_set still exists after potential removals ---
    active_set = current_config.get("active_weight_set")
    if active_set not in current_config.get("weight_sets", {}):
         default_active_set = default_config["active_weight_set"]
         print(f"{NEON_RED}Previously selected active_weight_set '{active_set}' is no longer valid (possibly removed during validation). Resetting to default '{default_active_set}'.{RESET}")
         current_config["active_weight_set"] = default_active_set
         needs_saving = True

    # --- Save Updated Config if Necessary ---
    # Needs saving if file was created, merged, or validation caused changes
    if needs_saving or current_config != original_config_before_validation:
        try:
            with open(filepath, "w", encoding="utf-8") as f_write:
                # Dump the validated and potentially corrected config
                json.dump(current_config, f_write, indent=4, ensure_ascii=False, sort_keys=True)
            print(f"{NEON_YELLOW}Saved updated configuration to {filepath}{RESET}")
        except IOError as e:
            print(f"{NEON_RED}Error writing updated config file {filepath}: {e}{RESET}")
        except Exception as e:
             print(f"{NEON_RED}Unexpected error saving config file {filepath}: {e}{RESET}")

    return current_config

def _merge_configs(loaded_config: Dict, default_config: Dict) -> Dict:
    """
    Recursively merges the loaded configuration dictionary onto the default dictionary.
    - Ensures all keys from the default config exist in the final merged config.
    - Prioritizes values from the loaded config if a key exists in both.
    - Handles nested dictionaries recursively.
    - Keys present only in the loaded_config are KEPT (allows user extensions).

    Args:
        loaded_config (Dict): The configuration loaded from the file.
        default_config (Dict): The default configuration structure and values.

    Returns:
        Dict: The merged configuration dictionary.
    """
    merged = default_config.copy() # Start with the default structure

    for key, loaded_value in loaded_config.items():
        if key in merged:
            default_value = merged[key]
            # If both loaded and default values for the key are dictionaries, recurse
            if isinstance(loaded_value, dict) and isinstance(default_value, dict):
                merged[key] = _merge_configs(loaded_value, default_value)
            else:
                # Otherwise, overwrite default with loaded value (validation happens later)
                merged[key] = loaded_value
        else:
            # If key from loaded config doesn't exist in default, add it.
            # This allows users to add custom keys to their config if needed.
            merged[key] = loaded_value

    # Ensure all keys from the default config are present in the merged result.
    # This handles cases where a default key was missing entirely in the loaded config.
    for key, default_value in default_config.items():
        if key not in merged:
            merged[key] = default_value
            # print(f"Debug: Added missing key '{key}' with default value during merge.") # Optional debug log

    return merged

# --- Logging Setup ---
def setup_logger(name: str, config: Dict[str, Any], level: int = logging.INFO) -> logging.Logger:
    """
    Sets up a logger instance with specified name, configuration, and level.
    - Configures a rotating file handler (logs in UTC).
    - Configures a colored console handler (logs in local timezone specified in config).
    - Uses SensitiveFormatter to redact API keys/secrets.
    - Prevents duplicate log messages if called multiple times for the same logger name.

    Args:
        name (str): The name for the logger instance.
        config (Dict[str, Any]): The bot's configuration dictionary (used for timezone).
        level (int): The logging level for the console handler (e.g., logging.INFO, logging.DEBUG).

    Returns:
        logging.Logger: The configured logger instance.
    """
    logger = logging.getLogger(name)
    # Prevent adding multiple handlers if this function is called again for the same logger
    if logger.hasHandlers():
        logger.handlers.clear()

    # Set the logger's base level to DEBUG to capture all messages.
    # Handlers will filter based on their individual levels.
    logger.setLevel(logging.DEBUG)

    # --- File Handler (Rotating, UTC Timestamps) ---
    log_filename = os.path.join(LOG_DIRECTORY, f"{name}.log")
    try:
        # Directory should exist from earlier check, but ensure again just in case.
        os.makedirs(LOG_DIRECTORY, exist_ok=True)
        # Rotate logs: 10MB per file, keep last 5 files
        file_handler = RotatingFileHandler(
            log_filename, maxBytes=10 * 1024 * 1024, backupCount=5, encoding='utf-8'
        )
        # Use UTC timestamps in file logs for consistency across different systems/locations
        # ISO 8601 format with milliseconds and UTC 'Z' indicator
        file_formatter = SensitiveFormatter(
            "%(asctime)s.%(msecs)03dZ %(levelname)-8s [%(name)s:%(lineno)d] %(message)s",
            datefmt='%Y-%m-%dT%H:%M:%S' # ISO 8601 standard date format
        )
        file_formatter.converter = time.gmtime # Force formatter to use UTC time
        file_handler.setFormatter(file_formatter)
        # Log DEBUG level and above to the file
        file_handler.setLevel(logging.DEBUG)
        logger.addHandler(file_handler)
    except Exception as e:
        # Fallback to basic console logging if file handler setup fails
        print(f"{NEON_RED}Error setting up file logger '{log_filename}': {e}. File logging disabled.{RESET}")
        # Ensure there's at least one handler if file logging failed
        if not logger.hasHandlers():
            basic_handler = logging.StreamHandler()
            basic_handler.setFormatter(logging.Formatter('%(levelname)s: %(message)s'))
            logger.addHandler(basic_handler)

    # --- Console Handler (Colored, Local Timestamps) ---
    # Add console handler only if no StreamHandler exists yet (prevents duplicates if file handler failed)
    if not any(isinstance(h, logging.StreamHandler) for h in logger.handlers):
        stream_handler = logging.StreamHandler()
        # Determine local timezone for console display from validated config
        try:
            # Use the globally updated TIMEZONE variable from load_config
            console_tz = TIMEZONE
        except Exception as tz_err: # Should not happen if load_config worked, but safety check
            print(f"{NEON_RED}Error getting configured timezone for console logs: {tz_err}. Using UTC.{RESET}")
            console_tz = ZoneInfo("UTC")

        # Formatter with colors and local time (including timezone abbreviation %Z)
        console_formatter = SensitiveFormatter(
            f"{NEON_BLUE}%(asctime)s{RESET} {NEON_YELLOW}%(levelname)-8s{RESET} {NEON_PURPLE}[%(name)s]{RESET} %(message)s",
            datefmt='%Y-%m-%d %H:%M:%S %Z' # Example: 2023-10-27 15:30:00 CDT
        )

        # Custom time converter function for the console formatter
        def local_time_converter(*args):
            """Returns the current time as a timetuple in the configured local timezone."""
            return datetime.now(console_tz).timetuple()

        console_formatter.converter = local_time_converter # Assign the converter
        stream_handler.setFormatter(console_formatter)
        # Set console log level based on the function argument (e.g., INFO)
        stream_handler.setLevel(level)
        logger.addHandler(stream_handler)

    # Prevent logs from propagating to the root logger (avoids potential duplicate outputs)
    logger.propagate = False
    return logger

# --- CCXT Exchange Setup ---
def initialize_exchange(config: Dict[str, Any], logger: logging.Logger) -> Optional[ccxt.Exchange]:
    """
    Initializes and configures the CCXT Bybit exchange object.
    - Sets API keys, rate limiting, timeouts, and V5-specific options.
    - Handles enabling Sandbox (Testnet) mode with URL verification and fallbacks.
    - Loads exchange markets and validates the configured trading symbol.
    - Performs an initial connection test by fetching balance.
    - Includes robust error handling for common initialization failures.

    Args:
        config (Dict[str, Any]): The bot's configuration dictionary.
        logger (logging.Logger): The logger instance.

    Returns:
        Optional[ccxt.Exchange]: The configured CCXT exchange object, or None if initialization fails.
    """
    lg = logger # Alias for convenience
    try:
        # CCXT Exchange configuration options
        exchange_options = {
            'apiKey': API_KEY,
            'secret': API_SECRET,
            'enableRateLimit': True, # Enable ccxt's built-in rate limiter
            'rateLimit': 150, # Milliseconds between requests (approx 6.6 req/s). Adjust based on Bybit V5 limits and VIP level.
            'options': {
                'defaultType': 'linear', # CRUCIAL for Bybit V5 USDT/USDC perpetuals/futures. Use 'inverse' for inverse contracts.
                'adjustForTimeDifference': True, # Helps mitigate timestamp synchronization errors.
                # Set reasonable network timeouts (in milliseconds) for various API calls
                'fetchTickerTimeout': 15000,      # 15 seconds
                'fetchBalanceTimeout': 20000,     # 20 seconds
                'createOrderTimeout': 25000,      # 25 seconds
                'cancelOrderTimeout': 20000,      # 20 seconds
                'fetchPositionsTimeout': 25000,   # 25 seconds
                'fetchOHLCVTimeout': 20000,       # 20 seconds
                'fetchOrderBookTimeout': 15000,   # 15 seconds
                'setLeverageTimeout': 20000,      # 20 seconds
                'fetchMyTradesTimeout': 20000,    # 20 seconds
                'fetchClosedOrdersTimeout': 25000,# 25 seconds
                # Custom User-Agent can help identify your bot's traffic to the exchange (Optional)
                'user-agent': 'sxsBotFramework/1.0 (+https://github.com/your_repo_here)', # Optional: Update URL if applicable
                # Bybit V5 specific settings (Consult Bybit/CCXT docs if needed)
                # 'recvWindow': 10000, # Optional: Increase if timestamp errors persist despite adjustForTimeDifference
                # 'brokerId': 'YOUR_BROKER_ID', # Optional: If participating in Bybit broker program
                # 'enableUnifiedMargin': False, # Set to True if using Bybit's Unified Trading Account (UTA)
                # 'enableUnifiedAccount': False, # May be an alias for above; check CCXT/Bybit documentation
            }
        }

        # Instantiate the Bybit exchange class from ccxt
        exchange_id = "bybit" # Explicitly target Bybit
        exchange_class = getattr(ccxt, exchange_id)
        exchange = exchange_class(exchange_options)

        # --- Sandbox (Testnet) Mode Setup ---
        if config.get('use_sandbox', True): # Default to sandbox if key is missing
            lg.warning(f"{NEON_YELLOW}INITIALIZING IN SANDBOX MODE (Testnet){RESET}")
            try:
                # Attempt 1: Use CCXT's standard method for enabling sandbox mode
                exchange.set_sandbox_mode(True)
                lg.info(f"Sandbox mode enabled via exchange.set_sandbox_mode(True) for {exchange.id}.")

                # Attempt 2: CRITICAL VERIFICATION - Check if the API URL actually changed
                current_api_url = exchange.urls.get('api', '')
                if isinstance(current_api_url, dict): # URL can sometimes be a dict (public/private)
                    current_api_url = current_api_url.get('public') or current_api_url.get('private') or ''

                if 'testnet' not in current_api_url.lower():
                    lg.warning(f"set_sandbox_mode did not change API URL to testnet! Current URL: '{current_api_url}'")
                    # Attempt 3: Manual override using URLs defined in exchange description
                    lg.info("Attempting manual Testnet URL override based on exchange.describe()...")
                    test_url_info = exchange.describe().get('urls', {}).get('test')
                    api_test_url = None
                    if isinstance(test_url_info, str):
                        api_test_url = test_url_info
                    elif isinstance(test_url_info, dict): # Sometimes 'test' contains a dict of URLs
                        api_test_url = test_url_info.get('public') or test_url_info.get('private') or next((url for url in test_url_info.values() if isinstance(url, str)), None)

                    if api_test_url:
                        exchange.urls['api'] = api_test_url
                        lg.info(f"Manually set API URL to Testnet based on exchange.describe(): {exchange.urls['api']}")
                    else:
                        # Attempt 4: Final hardcoded fallback if describe() didn't provide a usable URL
                        fallback_test_url = 'https://api-testnet.bybit.com' # Bybit V5 Testnet URL
                        lg.warning(f"Could not determine testnet URL from describe(). Hardcoding fallback: {fallback_test_url}")
                        exchange.urls['api'] = fallback_test_url
                else:
                     lg.info(f"Confirmed API URL is set to Testnet: {current_api_url}")

            except AttributeError:
                # Fallback if the ccxt version doesn't support set_sandbox_mode
                lg.warning(f"{exchange.id} ccxt version might lack set_sandbox_mode. Manually setting Testnet API URL.")
                exchange.urls['api'] = 'https://api-testnet.bybit.com' # Ensure this is the correct V5 testnet URL
                lg.info(f"Manually set Bybit API URL to Testnet: {exchange.urls['api']}")
            except Exception as e_sandbox:
                lg.error(f"Error encountered trying to enable sandbox mode: {e_sandbox}. Ensure API keys are for Testnet. Proceeding with potentially incorrect URL.", exc_info=True)
        else:
            # --- Live (Real Money) Environment Setup ---
            lg.info(f"{NEON_GREEN}INITIALIZING IN LIVE (Real Money) Environment.{RESET}")
            # Ensure API URL is set to production if sandbox was somehow enabled previously
            current_api_url = exchange.urls.get('api', '')
            if isinstance(current_api_url, dict): # URL can sometimes be a dict
                 current_api_url = current_api_url.get('public') or current_api_url.get('private') or ''

            if 'testnet' in current_api_url.lower():
                lg.warning("Detected testnet URL while in live mode configuration. Attempting to reset to production URL.")
                # Find the production URL from exchange description
                prod_url_info = exchange.describe().get('urls', {}).get('api')
                api_prod_url = None
                if isinstance(prod_url_info, str):
                     api_prod_url = prod_url_info
                elif isinstance(prod_url_info, dict): # API URL might be nested
                     api_prod_url = prod_url_info.get('public') or prod_url_info.get('private') or next((url for url in prod_url_info.values() if isinstance(url, str)), None)

                if api_prod_url:
                    exchange.urls['api'] = api_prod_url
                    lg.info(f"Reset API URL to Production based on exchange.describe(): {exchange.urls['api']}")
                else:
                    # Fallback to 'www' URL or hardcoded default if 'api' is not found
                    www_url = exchange.describe().get('urls',{}).get('www')
                    if www_url and isinstance(www_url, str):
                         # Assume API is based on www (common pattern)
                         prod_api_guess = www_url.replace('www.', 'api.') if 'www.' in www_url else 'https://api.bybit.com' # Educated guess
                         exchange.urls['api'] = prod_api_guess
                         lg.info(f"Reset API URL to Production using 'www' fallback (Guessed API: {exchange.urls['api']})")
                    else:
                         fallback_prod_url = 'https://api.bybit.com' # Hardcoded V5 production URL
                         lg.error(f"Could not determine production API URL automatically. Hardcoding fallback: {fallback_prod_url}")
                         exchange.urls['api'] = fallback_prod_url

        lg.info(f"Initializing {exchange.id} (API Endpoint: {exchange.urls.get('api', 'URL Not Set')})...")

        # --- Load Markets (Essential for precision, limits, IDs, fees) ---
        lg.info(f"Loading markets for {exchange.id} (this may take a moment)...")
        try:
             # Use safe_api_call for robustness, force reload to ensure freshness
             safe_api_call(exchange.load_markets, lg, reload=True)
             lg.info(f"Markets loaded successfully for {exchange.id}. Found {len(exchange.symbols)} symbols.")

             # --- Validate Target Symbol Existence & Compatibility ---
             target_symbol = config.get("symbol")
             if not target_symbol:
                  lg.critical(f"{NEON_RED}FATAL: 'symbol' not defined in configuration!{RESET}")
                  return None
             if target_symbol not in exchange.markets:
                  lg.critical(f"{NEON_RED}FATAL: Target symbol '{target_symbol}' not found in loaded markets for {exchange.id}!{RESET}")
                  lg.critical(f"{NEON_RED}>> Check symbol spelling, format, and availability on the exchange ({'Testnet' if config.get('use_sandbox') else 'Live'}).{RESET}")
                  # Provide hint for common Bybit V5 linear format
                  if '/' in target_symbol and ':' not in target_symbol and exchange.id == 'bybit':
                       base, quote = target_symbol.split('/')[:2]
                       suggested_symbol = f"{base}/{quote}:{quote}"
                       lg.warning(f"{NEON_YELLOW}Hint: For Bybit V5 linear perpetuals, the format is often like '{suggested_symbol}'.{RESET}")
                  # List available markets if the list is small and potentially helpful
                  if 0 < len(exchange.symbols) < 50:
                       lg.debug(f"Available symbols sample: {sorted(list(exchange.symbols))[:10]}...")
                  elif len(exchange.symbols) == 0:
                       lg.error("No symbols were loaded from the exchange at all.")
                  return None # Fatal error if configured symbol doesn't exist
             else:
                  lg.info(f"Target symbol '{target_symbol}' validated against loaded markets.")
                  # Optional: Add checks here for market type compatibility (e.g., ensure it's linear if expected)
                  market_info_check = exchange.market(target_symbol)
                  market_type = market_info_check.get('type', 'unknown').lower()
                  default_type_cfg = exchange.options.get('defaultType', 'linear').lower()

                  if default_type_cfg == 'linear' and not market_info_check.get('linear', False):
                      lg.warning(f"Target symbol '{target_symbol}' (Type: {market_type}) might not be a linear contract, but defaultType is '{default_type_cfg}'. Verify settings and symbol type.")
                  elif default_type_cfg == 'inverse' and not market_info_check.get('inverse', False):
                      lg.warning(f"Target symbol '{target_symbol}' (Type: {market_type}) might not be an inverse contract, but defaultType is '{default_type_cfg}'. Verify settings and symbol type.")
                  elif default_type_cfg == 'spot' and market_info_check.get('contract', False):
                       lg.warning(f"Target symbol '{target_symbol}' (Type: {market_type}) appears to be a contract, but defaultType is '{default_type_cfg}'. Verify settings.")


        except Exception as market_err:
             lg.critical(f"{NEON_RED}CRITICAL: Failed to load markets after retries: {market_err}. Bot cannot operate without market data. Exiting.{RESET}", exc_info=True)
             return None # Fatal error

        # --- Initial Connection & Permissions Test (Fetch Balance) ---
        # This also helps confirm the correct account type (CONTRACT/UNIFIED) is accessible.
        # Use the dedicated fetch_balance function for robustness
        lg.info(f"Performing initial connection test by fetching balance...")
        quote_curr = config.get("quote_currency", "USDT") # Use configured quote currency
        balance_decimal = fetch_balance(exchange, quote_curr, lg) # Use the dedicated robust function

        if balance_decimal is not None:
             # Balance fetch succeeded, log the result
             lg.info(f"{NEON_GREEN}Successfully connected and fetched initial {quote_curr} balance: {balance_decimal:.4f}{RESET}")
             if balance_decimal <= 0: # Check if balance is zero or negative
                  lg.warning(f"{NEON_YELLOW}Initial available {quote_curr} balance is zero or negative. Ensure funds are in the correct account type (e.g., CONTRACT, UNIFIED) and wallet.{RESET}")
        else:
             # fetch_balance logs detailed errors, add a critical warning here as failure is significant.
             lg.critical(f"{NEON_RED}CRITICAL: Initial balance fetch for {quote_curr} failed.{RESET}")
             lg.critical(f"{NEON_RED}>> Check API key validity, permissions (read access needed), IP whitelisting, account type (CONTRACT/UNIFIED?), and network connectivity.{RESET}")
             # Decide if this is fatal. For a trading bot, inability to fetch balance usually is.
             return None # Make initial balance fetch failure fatal

        lg.info(f"CCXT exchange '{exchange.id}' initialized. Sandbox: {config.get('use_sandbox')}, Default Type: {exchange.options.get('defaultType')}")
        return exchange

    # --- Specific Exception Handling for Initialization ---
    except ccxt.AuthenticationError as e:
        lg.critical(f"{NEON_RED}CCXT Authentication Error during initialization: {e}{RESET}")
        lg.critical(f"{NEON_RED}>> Please check: API Key/Secret correctness, validity (not expired), enabled permissions (read, trade), and IP whitelisting configuration on the Bybit website.{RESET}")
    except ccxt.ExchangeError as e:
        lg.critical(f"{NEON_RED}CCXT Exchange Error during initialization: {e}{RESET}")
        lg.critical(f"{NEON_RED}>> This could be a temporary issue with the exchange API, incorrect exchange settings (e.g., defaultType), or network problems. Check Bybit status pages.{RESET}")
    except ccxt.NetworkError as e:
        lg.critical(f"{NEON_RED}CCXT Network Error during initialization: {e}{RESET}")
        lg.critical(f"{NEON_RED}>> Check your internet connection, DNS resolution, and firewall settings. Ensure api.bybit.com (or testnet) is reachable.{RESET}")
    except Exception as e:
        # Catch any other unexpected errors during the setup process
        lg.critical(f"{NEON_RED}Unexpected critical error initializing CCXT exchange: {e}{RESET}", exc_info=True)

    return None # Return None if any critical error occurred during initialization

# --- API Call Wrapper with Enhanced Retries ---
def safe_api_call(func, logger: logging.Logger, *args, **kwargs):
    """
    Wraps a CCXT API call with robust retry logic for network issues, rate limits,
    and specific transient exchange errors. Uses exponential backoff with jitter.

    Args:
        func: The CCXT exchange method to call (e.g., exchange.fetch_ticker).
        logger: The logger instance for logging retry attempts and errors.
        *args: Positional arguments for the CCXT function.
        **kwargs: Keyword arguments for the CCXT function.

    Returns:
        The result of the API call if successful after retries.

    Raises:
        The original exception if the call fails after all retries or encounters
        a non-retryable error (e.g., AuthenticationError, InvalidOrder).
    """
    lg = logger
    # Get retry parameters from global config if available, else use constants
    global config # Access the globally loaded config dictionary
    max_retries = config.get("max_api_retries", MAX_API_RETRIES)
    base_retry_delay = config.get("retry_delay", RETRY_DELAY_SECONDS)
    attempts = 0
    last_exception = None

    while attempts <= max_retries:
        try:
            # Attempt the API call
            result = func(*args, **kwargs)
            # Optional: Log successful calls at DEBUG level (can be verbose)
            # lg.debug(f"API call '{func.__name__}' successful (Attempt {attempts+1}).")
            return result # Success, return the result

        # --- Retryable Network/Server Availability Errors ---
        except (ccxt.NetworkError, ccxt.RequestTimeout, requests.exceptions.ConnectionError,
                requests.exceptions.Timeout, ccxt.ExchangeNotAvailable, ccxt.DDoSProtection) as e:
            last_exception = e
            # Exponential backoff: delay = base * (1.5 ^ attempts)
            wait_time = base_retry_delay * (1.5 ** attempts)
            # Add random jitter (+/- 10% of wait_time) to prevent simultaneous retries (thundering herd)
            wait_time *= (1 + (np.random.rand() - 0.5) * 0.2)
            wait_time = min(wait_time, 60) # Cap maximum wait time (e.g., 60 seconds)
            lg.warning(f"{NEON_YELLOW}Retryable Network/Availability Error in '{func.__name__}': {type(e).__name__}. "
                       f"Retrying in {wait_time:.1f}s (Attempt {attempts+1}/{max_retries+1}). Details: {e}{RESET}")

        # --- Rate Limit Errors ---
        except ccxt.RateLimitExceeded as e:
            last_exception = e
            retry_after_header = None
            header_wait_seconds = 0
            # Try to extract 'Retry-After' value from headers (can be seconds or ms)
            # Check ccxt standard attribute first
            if hasattr(e, 'http_headers') and isinstance(e.http_headers, dict):
                 retry_after_header = e.http_headers.get('Retry-After') or e.http_headers.get('retry-after')
            # Fallback check on the underlying requests response if available
            elif hasattr(e, 'response') and hasattr(e.response, 'headers'):
                 retry_after_header = e.response.headers.get('Retry-After') or e.response.headers.get('retry-after')

            # Use a stronger exponential backoff for rate limits: base * (2.0 ^ attempts)
            backoff_wait = base_retry_delay * (2.0 ** attempts)
            backoff_wait *= (1 + (np.random.rand() - 0.5) * 0.2) # Add jitter

            # Parse Retry-After header value if found
            if retry_after_header:
                try:
                    header_wait_seconds = float(retry_after_header)
                    # Assume seconds unless value looks like milliseconds (e.g., > 10000)
                    if header_wait_seconds > 1000: header_wait_seconds /= 1000.0
                    header_wait_seconds += 0.5 # Add a small buffer (0.5 seconds)
                    lg.debug(f"Rate limit 'Retry-After' header: {retry_after_header} -> Parsed wait: {header_wait_seconds:.1f}s")
                except (ValueError, TypeError):
                    lg.warning(f"Could not parse Retry-After header value: {retry_after_header}")
                    header_wait_seconds = 0 # Ignore invalid header

            # Use the longer of calculated backoff or header-suggested wait time
            final_wait_time = max(backoff_wait, header_wait_seconds)
            final_wait_time = min(final_wait_time, 90) # Cap rate limit wait time (e.g., 90 seconds)

            lg.warning(f"{NEON_YELLOW}Rate Limit Exceeded in '{func.__name__}'. "
                       f"Retrying in {final_wait_time:.1f}s (Attempt {attempts+1}/{max_retries+1}). Error: {e}{RESET}")
            wait_time = final_wait_time # Use the determined wait time for the sleep

        # --- Authentication Errors (FATAL - Non-Retryable) ---
        except ccxt.AuthenticationError as e:
             lg.error(f"{NEON_RED}Authentication Error in '{func.__name__}': {e}. This is likely NOT retryable.{RESET}")
             lg.error(f"{NEON_RED}>> Check API Key/Secret validity, permissions, IP whitelist, and environment (Live/Testnet). Aborting call.{RESET}")
             raise e # Re-raise immediately, do not retry

        # --- Invalid Order / Input Errors (FATAL - Non-Retryable) ---
        # These usually indicate a problem with parameters (size, price, etc.)
        except (ccxt.InvalidOrder, ccxt.BadSymbol, ccxt.ArgumentsRequired, ccxt.BadRequest, ccxt.InsufficientFunds) as e:
            # Added InsufficientFunds as non-retryable
            lg.error(f"{NEON_RED}{type(e).__name__} Error in '{func.__name__}': {e}. This indicates an issue with order parameters, symbol, or funds. NOT retryable.{RESET}")
            lg.error(f"{NEON_RED}>> Check parameters: {args}, {kwargs}. Aborting call.{RESET}")
            raise e # Re-raise immediately

        # --- Potentially Retryable Exchange-Specific Errors ---
        except ccxt.ExchangeError as e:
            last_exception = e
            err_str = str(e).lower()
            # Try to get HTTP status code and exchange-specific error code
            http_status_code = getattr(e, 'http_status_code', None)
            exchange_code = None # Initialize exchange_code

            # Try to extract standard CCXT parsed 'code' if available
            if hasattr(e, 'code') and e.code is not None:
                 exchange_code = e.code # Use CCXT's parsed code if available
            # If CCXT code is not available, attempt to parse Bybit's 'retCode' from message string
            elif 'bybit' in str(type(e)).lower() and 'retcode' in err_str:
                try:
                     # Example: "bybit {"retCode":10006,"retMsg":"Too many visits!"...}"
                     start_index = err_str.find('"retcode":')
                     if start_index != -1:
                          code_part = err_str[start_index + len('"retcode":'):]
                          end_index = code_part.find(',')
                          code_str = code_part[:end_index].strip()
                          if code_str.isdigit(): exchange_code = int(code_str)
                except Exception as parse_err:
                     lg.debug(f"Minor error parsing Bybit retCode from error string '{err_str}': {parse_err}")


            # List of known Bybit V5 transient/retryable error codes (expand as needed)
            # Ref: https://bybit-exchange.github.io/docs/v5/error_code
            bybit_retry_codes = [
                10001, # Internal server error (sometimes param error, but often transient) - Retry carefully
                10002, # Request parameter error (can be transient if related to timing/state) - Retry carefully
                10004, # Invalid sign (can be transient timing/nonce issue)
                10006, # Too many visits (Rate Limit - should ideally be caught by RateLimitExceeded)
                10010, # Request expired (Timestamp issue, adjustForTimeDifference should help, retry might work)
                10016, # Service error (Temporary issue)
                10017, # Request not supported (Might indicate wrong endpoint/params, but maybe transient during updates)
                10018, # Request timeout (Could be network or server load)
                10020, # Request Too Frequent (Another Rate Limit variant)
                10029, # Websocket Connection Unavailable (If using WS indirectly)
                110001, # Internal error, try again
                110043, # Position idx not match position mode (Can be transient if mode is changing?) - Retry carefully
                130021, # Order cost not match (Can be due to rapid price changes/precision) - Retry carefully
                130106, # Service busy (Classic retryable)
                130150, # Service data error (Temporary issue)
                130151, # Request pending process (Order might be processing, retry query later)
                131204, # Cannot connect to matching engine (Temporary issue)
                131205, # Cannot connect to TAKER order service (Temporary issue)
                170131, # Too many requests (Contract specific?)
                # Add other codes based on observation & documentation
            ]
            # General retryable error messages (case-insensitive)
            retryable_messages = [
                 "internal server error", "service unavailable", "system busy",
                 "matching engine busy", "please try again", "request timeout",
                 "nonce is too small", # Can happen with clock drift, retry might help
                 "order placement optimization", # Occasional Bybit transient message
                 "service data error", "request pending process",
                 "cannot connect to", # Generic connection issues
            ]

            is_retryable = False
            # Check retryable conditions: Bybit code OR HTTP code OR message content
            # Be cautious retrying codes that *could* indicate parameter errors (10001, 10002, 130021, 110043)
            # Only retry these if attempts are low, or consider not retrying them at all if stability is paramount.
            cautious_retry_codes = [10001, 10002, 130021, 110043]
            if exchange_code in bybit_retry_codes:
                 if exchange_code in cautious_retry_codes and attempts > 1: # Don't retry potentially bad params many times
                      lg.warning(f"Cautious retry code {exchange_code} encountered on attempt {attempts+1}. Will not retry further to avoid loop on bad params.")
                      is_retryable = False
                 else:
                      is_retryable = True
            if not is_retryable and http_status_code in RETRYABLE_HTTP_CODES: is_retryable = True
            if not is_retryable and any(msg in err_str for msg in retryable_messages): is_retryable = True

            if is_retryable and attempts < max_retries: # Ensure we don't sleep on the last attempt
                 # Use standard backoff for these transient errors
                 wait_time = base_retry_delay * (1.5 ** attempts)
                 wait_time *= (1 + (np.random.rand() - 0.5) * 0.2) # Add jitter
                 wait_time = min(wait_time, 60) # Cap wait time
                 lg.warning(f"{NEON_YELLOW}Potentially Retryable Exchange Error in '{func.__name__}': {e} (Code: {exchange_code}, HTTP: {http_status_code}). "
                            f"Retrying in {wait_time:.1f}s (Attempt {attempts+1}/{max_retries+1})...{RESET}")
                 time.sleep(wait_time) # Sleep before the next attempt
                 attempts += 1
                 continue # Go to the next iteration of the while loop directly
            elif is_retryable and attempts >= max_retries:
                 # If it was deemed retryable but we're out of retries
                 lg.warning(f"Retryable Exchange Error occurred on final attempt ({attempts+1}/{max_retries+1}). Will now raise: {e}")
                 raise e # Raise the error after logging
            else:
                 # Non-retryable ExchangeError (e.g., insufficient balance, invalid parameters not caught earlier)
                 lg.error(f"{NEON_RED}Non-Retryable Exchange Error in '{func.__name__}': {e} (Code: {exchange_code}, HTTP: {http_status_code}){RESET}")
                 raise e # Re-raise immediately

        # --- Catch any other unexpected error ---
        except Exception as e:
            last_exception = e
            lg.error(f"{NEON_RED}Unexpected Error during API call '{func.__name__}': {e}{RESET}", exc_info=True)
            raise e # Re-raise unexpected errors immediately, do not retry

        # --- Increment Attempt Counter (if a retryable exception occurred and wasn't 'continue'd) ---
        # This block is reached after the warning log for retryable network/rate limit errors (if not continue'd)
        if attempts < max_retries: # Only sleep if more retries are possible
             # Wait time should have been calculated in the corresponding except block
             calculated_wait_time = locals().get('wait_time', 0)
             if calculated_wait_time > 0:
                 time.sleep(calculated_wait_time)
             else:
                 # Fallback sleep if wait_time wasn't set (shouldn't happen with current logic)
                 lg.warning(f"Wait time not calculated for retry attempt {attempts+1}. Using base delay.")
                 time.sleep(base_retry_delay)
             attempts += 1
        else:
            # If we got here without returning or raising, it means max retries are hit for a Network/RateLimit error
            break # Exit the loop, the final error raising block will handle it


    # --- Max Retries Exceeded ---
    # If the loop completes without returning, it means max retries were hit
    lg.error(f"{NEON_RED}Max retries ({max_retries}) exceeded for API call '{func.__name__}'. Aborting call.{RESET}")
    if last_exception:
        lg.error(f"Last encountered error: {type(last_exception).__name__}: {last_exception}")
        raise last_exception # Raise the last captured exception
    else:
        # Fallback if no exception was captured (shouldn't normally happen)
        raise ccxt.RequestTimeout(f"Max retries exceeded for {func.__name__} but no specific exception was captured during retry loop.")


# --- CCXT Data Fetching Functions (using safe_api_call) ---

def fetch_current_price_ccxt(exchange: ccxt.Exchange, symbol: str, logger: logging.Logger) -> Optional[Decimal]:
    """
    Fetches the current market price for a symbol using CCXT's fetch_ticker.
    - Uses safe_api_call for robust fetching with retries.
    - Implements a priority order for selecting the price (mark > last > close > avg > mid > ask > bid).
    - Calculates mid-price and checks spread.
    - Converts the selected price to Decimal for precision.
    - Performs validation to ensure the price is positive and finite.

    Args:
        exchange (ccxt.Exchange): The initialized CCXT exchange object.
        symbol (str): The trading symbol (e.g., 'BTC/USDT:USDT').
        logger (logging.Logger): The logger instance.

    Returns:
        Optional[Decimal]: The current price as a Decimal, or None if fetching/parsing fails.
    """
    lg = logger
    try:
        # Fetch ticker data using the robust wrapper
        ticker = safe_api_call(exchange.fetch_ticker, lg, symbol)

        if not ticker or not isinstance(ticker, dict):
            lg.error(f"Failed to fetch valid ticker data for {symbol} after retries.")
            # safe_api_call should have logged the root cause if retries failed
            return None

        lg.debug(f"Raw Ticker data for {symbol}: {json.dumps(ticker, indent=2, default=str)}") # Log full ticker for debug

        # --- Helper for Safe Decimal Conversion ---
        def to_decimal(value, context_str: str = "price") -> Optional[Decimal]:
            """Safely converts a value to a positive, finite Decimal. Returns None on failure."""
            if value is None: return None
            try:
                # Convert via string to handle floats/ints consistently
                d = Decimal(str(value))
                # Ensure the price is valid (finite number greater than zero)
                if d.is_finite() and d > 0:
                    return d
                else:
                    lg.debug(f"Invalid {context_str} value from ticker (non-finite or non-positive): {value}. Discarding.")
                    return None
            except (InvalidOperation, ValueError, TypeError):
                lg.debug(f"Invalid {context_str} format, cannot convert to Decimal: {value}. Discarding.")
                return None

        # --- Extract Potential Price Candidates ---
        p_last = to_decimal(ticker.get('last'), 'last price')
        p_mark = to_decimal(ticker.get('mark'), 'mark price') # Important for futures/swaps
        p_close = to_decimal(ticker.get('close', ticker.get('last')), 'close price') # Use 'close', fallback to 'last' if close is missing
        p_bid = to_decimal(ticker.get('bid'), 'bid price')
        p_ask = to_decimal(ticker.get('ask'), 'ask price')
        p_avg = to_decimal(ticker.get('average'), 'average price') # Often (High+Low+Close)/3 or VWAP-like

        # Calculate Mid Price if Bid and Ask are valid and spread is reasonable
        p_mid = None
        if p_bid is not None and p_ask is not None:
             if p_ask > p_bid: # Ensure ask is higher than bid
                 spread = p_ask - p_bid
                 spread_pct = (spread / p_ask) * 100 if p_ask > 0 else Decimal('0')
                 # Warn if spread is excessive (e.g., > 1%) - might indicate illiquid market or bad data
                 if spread_pct > Decimal('1.0'):
                      lg.debug(f"Ticker spread for {symbol} is > 1% ({spread_pct:.2f}%). Mid price calculation may be less reliable.")
                 p_mid = (p_bid + p_ask) / Decimal('2')
                 if not p_mid.is_finite(): p_mid = None # Ensure calculation didn't result in non-finite
             else:
                 lg.debug(f"Bid ({p_bid}) is not less than Ask ({p_ask}) for {symbol}. Cannot calculate Mid price.")

        # --- Determine Market Type for Price Priority ---
        # Use get_market_info to leverage its caching and flags
        market_info = get_market_info(exchange, symbol, lg)
        is_contract = market_info.get('is_contract', False) if market_info else False

        # --- Select Price Based on Priority ---
        # Priority Order: mark (for contracts) > last > close > average > mid > ask > bid
        selected_price: Optional[Decimal] = None
        price_source: str = "N/A"

        if is_contract and p_mark:
            selected_price, price_source = p_mark, "Mark Price"
        elif p_last:
            selected_price, price_source = p_last, "Last Price"
        elif p_close: # Close is often same as Last, but good fallback
            selected_price, price_source = p_close, "Close Price"
        elif p_avg:
            selected_price, price_source = p_avg, "Average Price"
        elif p_mid:
            selected_price, price_source = p_mid, "Mid Price (Bid/Ask)"
        elif p_ask:
            # Using only Ask or Bid is less ideal due to spread
            if p_bid: # Log spread if using Ask as fallback
                 spread_pct = ((p_ask - p_bid) / p_ask) * 100 if p_ask > 0 else Decimal('0')
                 if spread_pct > Decimal('2.0'): # Higher warning threshold if using Ask directly
                      lg.warning(f"{NEON_YELLOW}Using 'ask' price ({p_ask}) as fallback for {symbol}, but spread seems large ({spread_pct:.2f}%, Bid: {p_bid}).{RESET}")
            selected_price, price_source = p_ask, "Ask Price (Fallback)"
        elif p_bid:
            # Last resort
            selected_price, price_source = p_bid, "Bid Price (Last Resort Fallback)"

        # --- Final Validation and Return ---
        if selected_price is not None and selected_price.is_finite() and selected_price > 0:
            lg.info(f"Current price ({symbol}): {selected_price} (Source: {price_source})")
            return selected_price
        else:
            lg.error(f"{NEON_RED}Failed to extract a valid positive price from ticker data for {symbol}. Ticker: {ticker}{RESET}")
            return None

    except Exception as e:
        # Catch errors raised by safe_api_call or during price processing
        lg.error(f"{NEON_RED}Error fetching/processing current price for {symbol}: {e}{RESET}", exc_info=False) # Keep log concise on error
        return None


def fetch_klines_ccxt(exchange: ccxt.Exchange, symbol: str, timeframe: str, limit: int = 250, logger: Optional[logging.Logger] = None) -> pd.DataFrame:
    """
    Fetches OHLCV kline data using CCXT with retries and robust processing.
    - Uses safe_api_call for fetching.
    - Converts internal timeframe format (e.g., "5") to CCXT format (e.g., "5m").
    - Creates a pandas DataFrame.
    - Performs data cleaning:
        - Converts timestamps to UTC datetime objects.
        - Converts OHLCV columns to Decimal, handling NaNs and invalid values robustly.
        - Drops rows with invalid timestamps or NaN in essential price columns.
        - Checks for and drops rows with inconsistent OHLC values (e.g., High < Low).
        - Sorts by timestamp and removes duplicates.
    - Returns an empty DataFrame on failure or if no valid data remains after cleaning.

    Args:
        exchange (ccxt.Exchange): Initialized CCXT exchange object.
        symbol (str): Trading symbol.
        timeframe (str): Internal timeframe string (e.g., "1", "5", "60", "D").
        limit (int): Maximum number of klines to fetch.
        logger (Optional[logging.Logger]): Logger instance. Uses default if None.

    Returns:
        pd.DataFrame: DataFrame with OHLCV data (Decimal type) indexed by UTC timestamp,
                      or an empty DataFrame if fetching/processing fails.
    """
    lg = logger or logging.getLogger(__name__) # Use provided logger or get a default one
    empty_df = pd.DataFrame(columns=['open', 'high', 'low', 'close', 'volume']) # Define columns for empty DF
    empty_df.index.name = 'timestamp'

    # Check if exchange supports fetching OHLCV data
    if not exchange.has.get('fetchOHLCV'):
        lg.error(f"Exchange {exchange.id} does not support fetchOHLCV according to ccxt 'has' attribute.")
        return empty_df

    try:
        # Convert internal timeframe to CCXT's format
        ccxt_timeframe = CCXT_INTERVAL_MAP.get(timeframe)
        if not ccxt_timeframe:
            lg.error(f"Invalid internal timeframe '{timeframe}' provided. Valid map keys: {list(CCXT_INTERVAL_MAP.keys())}. Cannot fetch klines.")
            return empty_df

        lg.debug(f"Fetching up to {limit} klines for {symbol} with timeframe {ccxt_timeframe} (Internal: {timeframe})...")
        # Fetch data using the safe API call wrapper
        ohlcv_data = safe_api_call(exchange.fetch_ohlcv, lg, symbol, timeframe=ccxt_timeframe, limit=limit)

        # Validate the raw data structure
        if ohlcv_data is None or not isinstance(ohlcv_data, list) or len(ohlcv_data) == 0:
            # safe_api_call logs error if it failed after retries. Log warning if it just returned empty.
            if ohlcv_data is not None:
                lg.warning(f"{NEON_YELLOW}No kline data returned by {exchange.id}.fetch_ohlcv for {symbol} {ccxt_timeframe}. Check symbol/interval/exchange status.{RESET}")
            return empty_df

        # Convert raw list of lists into a pandas DataFrame
        df = pd.DataFrame(ohlcv_data, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])

        if df.empty:
            lg.warning(f"Kline data DataFrame is empty after initial creation for {symbol} {ccxt_timeframe}.")
            return empty_df

        # --- Data Cleaning and Type Conversion ---
        # 1. Convert timestamp to datetime (UTC) and set as index
        try:
            # pd.to_datetime handles various timestamp formats; 'ms' unit is standard for ccxt
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms', errors='coerce', utc=True)
            initial_len_ts = len(df)
            # Drop rows where timestamp conversion failed (resulted in NaT)
            df.dropna(subset=['timestamp'], inplace=True)
            if len(df) < initial_len_ts:
                lg.debug(f"Dropped {initial_len_ts - len(df)} rows with invalid timestamps for {symbol}.")
            if df.empty:
                lg.warning(f"DataFrame became empty after dropping invalid timestamps for {symbol}.")
                return empty_df
            # Set the valid timestamp column as the DataFrame index
            df.set_index('timestamp', inplace=True)
        except Exception as ts_err:
             lg.error(f"Critical error processing timestamps for {symbol}: {ts_err}. Returning empty DataFrame.", exc_info=True)
             return empty_df

        # 2. Convert OHLCV columns to Decimal with robust error handling
        cols_to_convert = ['open', 'high', 'low', 'close', 'volume']
        for col in cols_to_convert:
            if col not in df.columns:
                lg.warning(f"Required column '{col}' missing in fetched kline data for {symbol}. Skipping conversion.")
                continue
            try:
                # Helper function for safe conversion to Decimal, returns Decimal('NaN') on failure
                def safe_to_decimal(x, col_name) -> Decimal:
                    """Converts input to Decimal, returns Decimal('NaN') on failure, NaN, non-finite, or invalid value."""
                    if pd.isna(x) or str(x).strip() == '': return Decimal('NaN')
                    try:
                        d = Decimal(str(x)) # Convert via string representation
                        # Check conditions: must be finite. Prices must be > 0, Volume >= 0.
                        is_price = col_name in ['open', 'high', 'low', 'close']
                        is_valid = d.is_finite() and (d > 0 if is_price else d >= 0)
                        if is_valid:
                            return d
                        else:
                            # lg.debug(f"Invalid Decimal value in '{col_name}': {x} (Non-finite or non-positive price/negative volume)")
                            return Decimal('NaN')
                    except (InvalidOperation, TypeError, ValueError):
                        # lg.debug(f"Conversion error to Decimal for '{x}' in column '{col_name}', returning NaN.")
                        return Decimal('NaN')

                # Apply the safe conversion function to the column
                df[col] = df[col].apply(lambda x: safe_to_decimal(x, col))

            except Exception as conv_err: # Catch unexpected errors during the apply step
                 lg.error(f"Unexpected error converting column '{col}' to Decimal for {symbol}: {conv_err}. Attempting float conversion as fallback.", exc_info=True)
                 # Fallback: try converting to float, coercing errors to standard float NaN
                 df[col] = pd.to_numeric(df[col], errors='coerce')
                 # Ensure any remaining non-finite floats (inf, -inf) are also treated as NaN
                 if pd.api.types.is_float_dtype(df[col]):
                     df[col] = df[col].replace([np.inf, -np.inf], np.nan)


        # 3. Drop rows with NaN in essential price columns (Open, High, Low, Close)
        initial_len_nan = len(df)
        essential_price_cols = ['open', 'high', 'low', 'close']
        df.dropna(subset=essential_price_cols, how='any', inplace=True)
        rows_dropped_nan = initial_len_nan - len(df)
        if rows_dropped_nan > 0:
            lg.debug(f"Dropped {rows_dropped_nan} rows with NaN price data for {symbol}.")

        if df.empty:
            lg.warning(f"DataFrame became empty after dropping NaN price data for {symbol}.")
            return empty_df

        # 4. Additional Sanity Check: Ensure OHLC consistency (e.g., High >= Low, High >= Open, etc.)
        # Ensure columns are suitable for comparison (should be Decimal or numeric after step 2)
        for col in essential_price_cols:
            if col not in df.columns or not (isinstance(df[col].iloc[0], Decimal) or pd.api.types.is_numeric_dtype(df[col])):
                 lg.warning(f"Cannot perform OHLC consistency check: Column '{col}' is not Decimal or numeric for {symbol}.")
                 # Skip check if types are wrong
                 invalid_ohlc_mask = pd.Series(False, index=df.index) # Assume all are valid if check can't run
                 break
        else: # Only run if all essential columns seem valid
            try:
                # Create boolean mask for rows where OHLC logic is violated
                # Handles Decimal or numeric comparison automatically
                invalid_ohlc_mask = (df['high'] < df['low']) | \
                                    (df['high'] < df['open']) | \
                                    (df['high'] < df['close']) | \
                                    (df['low'] > df['open']) | \
                                    (df['low'] > df['close'])
                invalid_count = invalid_ohlc_mask.sum()
                if invalid_count > 0:
                    lg.warning(f"{NEON_YELLOW}Found {invalid_count} klines with inconsistent OHLC data (e.g., High < Low) for {symbol}. Dropping these rows.{RESET}")
                    df = df[~invalid_ohlc_mask] # Keep only rows where the mask is False
            except TypeError as cmp_err:
                lg.warning(f"Could not perform OHLC consistency check for {symbol} due to type error: {cmp_err}. Skipping check.")
            except Exception as cmp_err:
                 lg.warning(f"Unexpected error during OHLC consistency check for {symbol}: {cmp_err}. Skipping check.")

        if df.empty:
            lg.warning(f"Kline data for {symbol} {ccxt_timeframe} became empty after cleaning (OHLC check).")
            return empty_df

        # 5. Sort by timestamp index (should already be sorted, but ensures) and remove duplicates
        if not df.index.is_monotonic_increasing:
            lg.debug(f"Sorting kline index for {symbol}...")
            df.sort_index(inplace=True)
        if df.index.has_duplicates:
            num_duplicates = df.index.duplicated().sum()
            lg.debug(f"Found {num_duplicates} duplicate timestamps in kline data for {symbol}. Keeping the last entry for each duplicate.")
            # Keep the last occurrence of each duplicated timestamp
            df = df[~df.index.duplicated(keep='last')]

        # --- Final Log and Return ---
        lg.info(f"Successfully fetched and processed {len(df)} valid klines for {symbol} {ccxt_timeframe} (requested limit: {limit})")
        # Log head/tail only if DEBUG level is enabled and DataFrame is not empty
        if lg.isEnabledFor(logging.DEBUG) and not df.empty:
             lg.debug(f"Kline check ({symbol}): First row:\n{df.head(1)}\nLast row:\n{df.tail(1)}")
        return df

    except ValueError as ve: # Catch specific validation errors raised within the function
        lg.error(f"{NEON_RED}Kline fetch/processing error for {symbol}: {ve}{RESET}")
        return empty_df
    except Exception as e:
        # Catch errors from safe_api_call or unexpected errors during processing
        lg.error(f"{NEON_RED}Unexpected error fetching or processing klines for {symbol}: {e}{RESET}", exc_info=True)
        return empty_df


def fetch_orderbook_ccxt(exchange: ccxt.Exchange, symbol: str, limit: int, logger: logging.Logger) -> Optional[Dict]:
    """
    Fetches order book data using CCXT with retries, validation, and Decimal conversion.
    - Uses safe_api_call for fetching.
    - Validates the structure of the returned order book data.
    - Converts bid/ask prices and amounts to Decimal, ensuring they are finite and positive.
    - Logs warnings for invalid entries but attempts to return partial data if possible.
    - Returns a dictionary containing 'bids' and 'asks' lists (each entry is [Decimal(price), Decimal(amount)]),
      along with original metadata, or None on failure.

    Args:
        exchange (ccxt.Exchange): Initialized CCXT exchange object.
        symbol (str): Trading symbol.
        limit (int): Number of order book levels to fetch (depth).
        logger (logging.Logger): Logger instance.

    Returns:
        Optional[Dict]: Order book dictionary with Decimal values, or None if fetching/processing fails.
                        Structure: {'bids': [[price, amount], ...], 'asks': [[price, amount], ...], 'timestamp': ..., ...}
    """
    lg = logger
    # Check if exchange supports fetching the order book
    if not exchange.has.get('fetchOrderBook'):
        lg.error(f"Exchange {exchange.id} does not support fetchOrderBook according to ccxt 'has' attribute.")
        return None

    try:
        lg.debug(f"Fetching order book for {symbol} with limit {limit}...")
        # Fetch order book using the safe API call wrapper
        orderbook_raw = safe_api_call(exchange.fetch_order_book, lg, symbol, limit=limit)

        # Validate the raw response
        if not orderbook_raw: # safe_api_call logs error if retries failed
            lg.warning(f"fetch_order_book for {symbol} returned None or empty after retries.")
            return None
        if not isinstance(orderbook_raw, dict) or \
           'bids' not in orderbook_raw or 'asks' not in orderbook_raw or \
           not isinstance(orderbook_raw['bids'], list) or not isinstance(orderbook_raw['asks'], list):
            lg.warning(f"Invalid order book structure received for {symbol}. Data: {str(orderbook_raw)[:200]}...") # Log snippet
            return None

        # --- Process bids and asks, converting to Decimal ---
        cleaned_book = {
            'bids': [],
            'asks': [],
            # Preserve original metadata if available
            'timestamp': orderbook_raw.get('timestamp'),
            'datetime': orderbook_raw.get('datetime'),
            'nonce': orderbook_raw.get('nonce')
        }
        conversion_errors = 0
        invalid_format_count = 0

        for side in ['bids', 'asks']:
            raw_side_data = orderbook_raw.get(side, [])
            for entry in raw_side_data:
                # Ensure entry is a list/tuple with exactly two elements (price, amount)
                if isinstance(entry, (list, tuple)) and len(entry) == 2:
                    try:
                        # Convert price and amount to Decimal via string representation
                        price = Decimal(str(entry[0]))
                        amount = Decimal(str(entry[1]))

                        # Validate: Price must be > 0, Amount must be >= 0, both must be finite
                        if price.is_finite() and price > 0 and amount.is_finite() and amount >= 0:
                            cleaned_book[side].append([price, amount])
                        else:
                            lg.debug(f"Invalid Decimal price/amount in {side} entry for {symbol}: P={price}, A={amount}") # Can be verbose
                            conversion_errors += 1
                    except (InvalidOperation, ValueError, TypeError):
                        lg.debug(f"Conversion error for {side} entry: {entry} in {symbol}") # Can be verbose
                        conversion_errors += 1
                else:
                    # Log entries with unexpected format
                    lg.warning(f"Invalid {side[:-1]} entry format in orderbook for {symbol}: {entry}")
                    invalid_format_count += 1

        # Log summary of cleaning issues if any occurred
        if conversion_errors > 0:
            lg.debug(f"Orderbook ({symbol}): Encountered {conversion_errors} entries with invalid/non-finite/non-positive values during Decimal conversion.")
        if invalid_format_count > 0:
            lg.warning(f"{NEON_YELLOW}Orderbook ({symbol}): Encountered {invalid_format_count} entries with unexpected format (expected [price, amount]).{RESET}")

        # Ensure bids are sorted descending by price and asks ascending by price
        # CCXT usually provides sorted data, but this ensures consistency. Use Decimal comparison.
        try:
            # Sort only if there are entries to sort to avoid errors on empty lists
            if cleaned_book['bids']:
                cleaned_book['bids'].sort(key=lambda x: x[0], reverse=True)
            if cleaned_book['asks']:
                cleaned_book['asks'].sort(key=lambda x: x[0])
        except Exception as sort_err:
             lg.warning(f"Could not sort order book entries for {symbol}: {sort_err}. Data might be unsorted.")

        # Check if the cleaned book is empty
        if not cleaned_book['bids'] and not cleaned_book['asks']:
            lg.warning(f"Orderbook for {symbol} is empty after cleaning/conversion (originally had {len(orderbook_raw.get('bids',[]))} bids, {len(orderbook_raw.get('asks',[]))} asks).")
            # Still return the structure, as the fetch itself might have succeeded
            return cleaned_book
        elif not cleaned_book['bids']:
             lg.warning(f"Orderbook ({symbol}) contains no valid bids after cleaning.")
        elif not cleaned_book['asks']:
             lg.warning(f"Orderbook ({symbol}) contains no valid asks after cleaning.")

        lg.debug(f"Successfully fetched and processed order book for {symbol} ({len(cleaned_book['bids'])} valid bids, {len(cleaned_book['asks'])} valid asks).")
        return cleaned_book

    except Exception as e:
        # Catch errors raised by safe_api_call or during other processing steps
        lg.error(f"{NEON_RED}Error fetching or processing order book for {symbol}: {e}{RESET}", exc_info=False)
        return None

# --- Trading Analyzer Class ---
class TradingAnalyzer:
    """
    Analyzes market data (OHLCV, order book) to generate trading signals.
    - Calculates technical indicators using pandas_ta.
    - Handles Decimal/float type conversions between raw data, TA library, and internal use.
    - Provides helper methods for market precision, limits, and SL/TP calculation.
    - Generates weighted trading signals based on configured indicators and weights.
    """

    def __init__(
        self,
        df: pd.DataFrame, # Expects OHLCV columns with Decimal type from fetch_klines
        logger: logging.Logger,
        config: Dict[str, Any],
        market_info: Dict[str, Any],
    ) -> None:
        """
        Initializes the TradingAnalyzer.

        Args:
            df (pd.DataFrame): Pandas DataFrame containing OHLCV data (expects Decimal values)
                               indexed by timestamp (UTC).
            logger (logging.Logger): Logger instance for logging messages.
            config (Dict[str, Any]): The bot's configuration dictionary.
            market_info (Dict[str, Any]): Dictionary containing details for the specific market
                                          (precision, limits, symbol, etc.) obtained from CCXT.
        """
        if not isinstance(df, pd.DataFrame):
             raise ValueError("TradingAnalyzer requires a pandas DataFrame.")
        if not isinstance(logger, logging.Logger):
             raise ValueError("TradingAnalyzer requires a valid Logger instance.")
        if not isinstance(config, dict) or not config:
             raise ValueError("TradingAnalyzer requires a valid configuration dictionary.")
        if not isinstance(market_info, dict) or not market_info:
             raise ValueError("TradingAnalyzer requires valid market information.")

        self.df = df.copy() # Work on a copy to avoid modifying the original DataFrame passed in
        self.logger = logger
        self.config = config
        self.market_info = market_info
        self.symbol = market_info.get('symbol', 'UNKNOWN_SYMBOL')
        self.interval = config.get("interval", "N/A") # Internal interval string
        self.ccxt_interval = CCXT_INTERVAL_MAP.get(self.interval) # CCXT timeframe string

        # Dictionary to store the latest calculated indicator values.
        # Uses Decimal for price-based values (OHLC, ATR, Bands, EMAs, PSAR, VWAP, SMA)
        # Uses float for oscillators/ratios (Momentum, CCI, W%R, MFI, StochRSI, RSI, Volume_MA)
        self.indicator_values: Dict[str, Union[Decimal, float, datetime, None]] = {}
        # Dictionary to map internal indicator keys (e.g., "EMA_Short") to the actual
        # column names generated by pandas_ta in the DataFrame (e.g., "EMA_9").
        self.ta_column_names: Dict[str, Optional[str]] = {}
        # Dictionary to store calculated Fibonacci retracement levels (Decimal prices).
        self.fib_levels_data: Dict[str, Decimal] = {}

        # Load the active weight set configuration for signal scoring
        self.active_weight_set_name = config.get("active_weight_set", "default")
        self.weights = config.get("weight_sets", {}).get(self.active_weight_set_name, {})
        if not self.weights:
            logger.warning(f"{NEON_YELLOW}Active weight set '{self.active_weight_set_name}' not found or is empty in config for {self.symbol}. Signal scores may be zero.{RESET}")
            self.weights = {} # Use empty dict to prevent errors if weights are missing

        # --- Caches for Precision/Limits (populated by getter methods) ---
        # Avoid recalculating these frequently within a single analysis cycle
        self._cached_price_precision: Optional[int] = None
        self._cached_min_tick_size: Optional[Decimal] = None
        self._cached_amount_precision: Optional[int] = None
        self._cached_min_amount_step: Optional[Decimal] = None

        # Perform initial validation and calculations upon instantiation
        self._initialize_analysis()

    def _initialize_analysis(self) -> None:
        """Performs initial checks and calculations when the analyzer is created."""
        if self.df.empty:
             self.logger.warning(f"TradingAnalyzer initialized with an empty DataFrame for {self.symbol}. No calculations will be performed.")
             return

        # Verify required columns exist
        required_cols = ['open', 'high', 'low', 'close', 'volume']
        missing_cols = [col for col in required_cols if col not in self.df.columns]
        if missing_cols:
            self.logger.error(f"DataFrame for {self.symbol} is missing required columns: {', '.join(missing_cols)}. Cannot perform analysis.")
            self.df = pd.DataFrame() # Clear DF to prevent errors in subsequent methods
            return

        # Verify data types (expecting Decimal from fetch_klines)
        essential_price_cols = ['open', 'high', 'low', 'close']
        first_valid_idx = self.df[essential_price_cols].first_valid_index()
        if first_valid_idx is None:
            self.logger.error(f"DataFrame for {self.symbol} contains no valid (non-NaN) price data. Cannot perform analysis.")
            self.df = pd.DataFrame() # Clear DF
            return
        # Check type of the first valid 'close' value
        if not isinstance(self.df.loc[first_valid_idx, 'close'], Decimal):
             self.logger.warning(f"DataFrame 'close' column for {self.symbol} does not appear to contain Decimal values as expected. Calculations might proceed but precision could be affected.")

        # Verify DataFrame contains some non-NaN data in essential columns (already covered by first_valid_idx check)
        # if self.df[essential_price_cols].isnull().all().all():
        #      self.logger.error(f"DataFrame for {self.symbol} contains all NaN values in required price columns. Cannot perform analysis.")
        #      self.df = pd.DataFrame() # Clear DF
        #      return

        # --- Proceed with Initial Calculations ---
        try:
            self._calculate_all_indicators()
            # Update latest values *after* indicators are calculated and potentially back-converted
            self._update_latest_indicator_values()
            # Calculate initial Fibonacci levels
            self.calculate_fibonacci_levels()
        except Exception as init_calc_err:
             # Catch any unexpected errors during the initial calculation phase
             self.logger.error(f"Error during TradingAnalyzer initial indicator/Fibonacci calculation for {self.symbol}: {init_calc_err}", exc_info=True)
             # Consider clearing the DataFrame or setting a 'failed' state depending on severity
             # self.df = pd.DataFrame()

    def _get_ta_col_name(self, base_name: str, result_df_columns: List[str]) -> Optional[str]:
        """
        Helper method to robustly find the actual column name generated by pandas_ta
        for a given internal indicator base name. Searches using multiple strategies.

        Args:
            base_name (str): Internal identifier for the indicator (e.g., "ATR", "EMA_Short").
            result_df_columns (List[str]): List of column names present in the DataFrame after
                                           TA calculations have been run.

        Returns:
            Optional[str]: The matched column name string, or None if no unambiguous match is found.
        """
        if not result_df_columns: return None # Cannot search if no columns exist

        # --- Dynamically Define Expected Patterns Based on Config ---
        # Use float representation matching pandas_ta common output (e.g., '2.0' for std dev)
        # Use try-except for robustness in case config values are invalid types at this stage
        try: bb_std_dev_str = f"{float(self.config.get('bollinger_bands_std_dev', DEFAULT_BBANDS_STDDEV)):.1f}"
        except (ValueError, TypeError): bb_std_dev_str = f"{DEFAULT_BBANDS_STDDEV:.1f}"
        try: psar_step_str = f"{float(self.config.get('psar_step', DEFAULT_PSAR_STEP)):g}"
        except (ValueError, TypeError): psar_step_str = f"{DEFAULT_PSAR_STEP:g}"
        try: psar_max_str = f"{float(self.config.get('psar_max_step', DEFAULT_PSAR_MAX_STEP)):g}"
        except (ValueError, TypeError): psar_max_str = f"{DEFAULT_PSAR_MAX_STEP:g}"

        # Get relevant period parameters from config or defaults, ensuring integers
        param_keys = [
            ('atr_period', DEFAULT_ATR_PERIOD), ('ema_short_period', DEFAULT_EMA_SHORT_PERIOD),
            ('ema_long_period', DEFAULT_EMA_LONG_PERIOD), ('momentum_period', DEFAULT_MOMENTUM_PERIOD),
            ('cci_period', DEFAULT_CCI_PERIOD), ('williams_r_period', DEFAULT_WILLIAMS_R_PERIOD),
            ('mfi_period', DEFAULT_MFI_PERIOD), ('rsi_period', DEFAULT_RSI_PERIOD),
            ('bollinger_bands_period', DEFAULT_BBANDS_PERIOD), ('sma_10_period', DEFAULT_SMA10_PERIOD),
            ('volume_ma_period', DEFAULT_VOLUME_MA_PERIOD),
            ('stoch_rsi_period', DEFAULT_STOCH_RSI_PERIOD), ('stoch_rsi_rsi_period', DEFAULT_STOCH_RSI_RSI_PERIOD),
            ('stoch_rsi_k_period', DEFAULT_STOCH_RSI_K_PERIOD), ('stoch_rsi_d_period', DEFAULT_STOCH_RSI_D_PERIOD)
        ]
        params = {}
        for key, default in param_keys:
            try: params[key] = int(self.config.get(key, default))
            except (ValueError, TypeError): params[key] = int(default) # Fallback if config value is bad

        # Map internal base names to lists of potential pandas_ta column name patterns
        # These patterns should match the typical output of pandas_ta functions
        expected_patterns = {
            "ATR": [f"ATRr_{params['atr_period']}"], # 'r' suffix often means 'real' or result
            "EMA_Short": [f"EMA_{params['ema_short_period']}"],
            "EMA_Long": [f"EMA_{params['ema_long_period']}"],
            "Momentum": [f"MOM_{params['momentum_period']}"],
            "CCI": [f"CCI_{params['cci_period']}_0.015"], # Common suffix for constant, check without suffix too
            "Williams_R": [f"WILLR_{params['williams_r_period']}"],
            "MFI": [f"MFI_{params['mfi_period']}"],
            "VWAP": ["VWAP_D", "VWAP"], # pandas_ta default VWAP often daily anchored ('_D'), check without too
            "PSAR_long": [f"PSARl_{psar_step_str}_{psar_max_str}"], # 'l' for long trend signal
            "PSAR_short": [f"PSARs_{psar_step_str}_{psar_max_str}"], # 's' for short trend signal
            "PSAR_af": [f"PSARaf_{psar_step_str}_{psar_max_str}"], # Acceleration factor
            "PSAR_rev": [f"PSARr_{psar_step_str}_{psar_max_str}"], # Reversal points
            "SMA_10": [f"SMA_{params['sma_10_period']}"],
            "StochRSI_K": [f"STOCHRSIk_{params['stoch_rsi_period']}_{params['stoch_rsi_rsi_period']}_{params['stoch_rsi_k_period']}"],
            "StochRSI_D": [f"STOCHRSId_{params['stoch_rsi_period']}_{params['stoch_rsi_rsi_period']}_{params['stoch_rsi_k_period']}_{params['stoch_rsi_d_period']}"],
            "RSI": [f"RSI_{params['rsi_period']}"],
            "BB_Lower": [f"BBL_{params['bollinger_bands_period']}_{bb_std_dev_str}"],
            "BB_Middle": [f"BBM_{params['bollinger_bands_period']}_{bb_std_dev_str}"],
            "BB_Upper": [f"BBU_{params['bollinger_bands_period']}_{bb_std_dev_str}"],
            "BB_Bandwidth": [f"BBB_{params['bollinger_bands_period']}_{bb_std_dev_str}"],
            "BB_Percent": [f"BBP_{params['bollinger_bands_period']}_{bb_std_dev_str}"],
            # Custom name used for Volume MA calculation
            "Volume_MA": [f"VOL_SMA_{params['volume_ma_period']}"]
        }
        # Add pattern variations (e.g., CCI without suffix)
        if 'CCI' in params: expected_patterns["CCI"].append(f"CCI_{params['cci_period']}")

        patterns_to_check = expected_patterns.get(base_name)
        if not patterns_to_check:
            self.logger.debug(f"No expected column pattern defined for indicator base name: '{base_name}'")
            return None

        # --- Search Strategy (from most specific to least specific) ---
        # 1. Exact Match (Case-Sensitive) - Most reliable
        for pattern in patterns_to_check:
            if pattern in result_df_columns:
                self.logger.debug(f"Mapped '{base_name}' to column '{pattern}' (Exact Match)")
                return pattern

        # 2. Case-Insensitive Exact Match
        patterns_lower = [p.lower() for p in patterns_to_check]
        # Create mapping from lower-case column name to original case for efficient lookup
        cols_lower_map = {col.lower(): col for col in result_df_columns}
        for i, pattern_lower in enumerate(patterns_lower):
             if pattern_lower in cols_lower_map:
                  original_col_name = cols_lower_map[pattern_lower]
                  self.logger.debug(f"Mapped '{base_name}' to column '{original_col_name}' (Case-Insensitive Exact Match)")
                  return original_col_name

        # 3. Starts With Match (Case-Insensitive) - Handles potential suffixes added by TA lib
        # This is slightly riskier, use with caution
        for pattern in patterns_to_check:
            pattern_lower = pattern.lower()
            possible_matches = [col for col in result_df_columns if col.lower().startswith(pattern_lower)]
            if len(possible_matches) == 1: # Only accept if it's the *only* match starting with this pattern
                 match = possible_matches[0]
                 self.logger.debug(f"Mapped '{base_name}' to column '{match}' (Unique StartsWith Match: '{pattern}')")
                 return match
            # If multiple columns start with the same pattern, it's ambiguous, don't use this method for this pattern.

        # 4. Fallback: Simple base name substring check (use with caution)
        # Example: base_name 'StochRSI_K' -> simple_base 'stochrsi'
        # This is less reliable and might yield false positives
        simple_base = base_name.split('_')[0].lower()
        potential_matches = [col for col in result_df_columns if simple_base in col.lower()]

        if len(potential_matches) == 1:
             match = potential_matches[0]
             self.logger.debug(f"Mapped '{base_name}' to '{match}' via unique simple substring search ('{simple_base}'). Verify.")
             return match
        elif len(potential_matches) > 1:
              # Ambiguous: Multiple columns contain the simple base name.
              # Try to resolve by checking if one of the full expected patterns is among the matches.
              resolved_match = None
              for pattern in patterns_to_check:
                   if pattern in potential_matches: # Check exact expected pattern
                        resolved_match = pattern
                        self.logger.debug(f"Resolved ambiguous substring match for '{base_name}' to exact expected pattern '{pattern}'.")
                        break
                   if pattern.lower() in [p.lower() for p in potential_matches]: # Check case-insensitive expected pattern
                        # Find the original case match
                        original_case_match = next((p for p in potential_matches if p.lower() == pattern.lower()), None)
                        if original_case_match:
                             resolved_match = original_case_match
                             self.logger.debug(f"Resolved ambiguous substring match for '{base_name}' to case-insensitive expected pattern '{original_case_match}'.")
                             break
              if resolved_match: return resolved_match

              # If still ambiguous after checking expected patterns, it's safer to return None
              self.logger.warning(f"{NEON_YELLOW}Ambiguous substring match for '{base_name}' ('{simple_base}'): Found {potential_matches}. Could not resolve clearly based on expected patterns: {patterns_to_check}. No column mapped.{RESET}")
              return None

        # If no match found by any method
        self.logger.debug(f"Could not find matching column name for indicator '{base_name}' (Expected patterns: {patterns_to_check}) in DataFrame columns.")
        return None


    def _calculate_all_indicators(self):
        """
        Calculates all technical indicators specified and enabled in the configuration
        using the pandas_ta library. Handles data type conversions for compatibility.
        Updates the internal DataFrame with the calculated indicator columns.
        Converts price-based indicators back to Decimal for precision.
        """
        if self.df.empty:
            self.logger.warning(f"DataFrame is empty for {self.symbol}, cannot calculate indicators.")
            return

        # --- Determine Minimum Required Data Length ---
        # Estimate required length based on the longest period among enabled & weighted indicators
        required_periods = []
        indicators_config = self.config.get("indicators", {})
        active_weights = self.weights # Use weights loaded during init

        # Helper to add period requirement if indicator is active
        def add_req_if_active(indicator_key, config_period_key, default_period):
            """Adds period requirement if indicator is enabled and has non-zero weight."""
            is_enabled = indicators_config.get(indicator_key, False)
            try: weight = float(active_weights.get(indicator_key, 0.0))
            except (ValueError, TypeError): weight = 0.0

            if is_enabled and weight > 1e-9: # Check weight > small tolerance
                try:
                    period = int(self.config.get(config_period_key, default_period))
                    if period > 0: required_periods.append(period)
                    else: self.logger.warning(f"Invalid zero/negative period configured for {config_period_key} ({period}). Ignoring for length check.")
                except (ValueError, TypeError):
                     self.logger.warning(f"Invalid period format for {config_period_key} ('{self.config.get(config_period_key)}'). Ignoring for length check.")

        # Add requirements for indicators with standard periods
        add_req_if_active("atr", "atr_period", DEFAULT_ATR_PERIOD) # Use dummy key 'atr' for ATR check
        add_req_if_active("momentum", "momentum_period", DEFAULT_MOMENTUM_PERIOD)
        add_req_if_active("cci", "cci_period", DEFAULT_CCI_PERIOD)
        add_req_if_active("wr", "williams_r_period", DEFAULT_WILLIAMS_R_PERIOD)
        add_req_if_active("mfi", "mfi_period", DEFAULT_MFI_PERIOD)
        add_req_if_active("sma_10", "sma_10_period", DEFAULT_SMA10_PERIOD)
        add_req_if_active("rsi", "rsi_period", DEFAULT_RSI_PERIOD)
        add_req_if_active("bollinger_bands", "bollinger_bands_period", DEFAULT_BBANDS_PERIOD)
        add_req_if_active("volume_confirmation", "volume_ma_period", DEFAULT_VOLUME_MA_PERIOD)

        # Fibonacci period is a lookback window, include it
        try: fib_period = int(self.config.get("fibonacci_period", DEFAULT_FIB_PERIOD))
        except (ValueError, TypeError): fib_period = DEFAULT_FIB_PERIOD
        if fib_period > 0: required_periods.append(fib_period)

        # Compound indicators: EMA Alignment requires both short and long EMAs
        if indicators_config.get("ema_alignment", False) and float(active_weights.get("ema_alignment", 0.0)) > 1e-9:
             add_req_if_active("ema_alignment", "ema_short_period", DEFAULT_EMA_SHORT_PERIOD) # Use proxy key
             add_req_if_active("ema_alignment", "ema_long_period", DEFAULT_EMA_LONG_PERIOD)

        # StochRSI requires its main period and the underlying RSI period
        if indicators_config.get("stoch_rsi", False) and float(active_weights.get("stoch_rsi", 0.0)) > 1e-9:
             add_req_if_active("stoch_rsi", "stoch_rsi_period", DEFAULT_STOCH_RSI_PERIOD)
             add_req_if_active("stoch_rsi", "stoch_rsi_rsi_period", DEFAULT_STOCH_RSI_RSI_PERIOD)

        # Calculate minimum required length, add a buffer (e.g., 30 bars) for indicator stabilization
        min_required_data = max(required_periods) + 30 if required_periods else 50 # Default buffer if no periods found

        if len(self.df) < min_required_data:
             self.logger.warning(f"{NEON_YELLOW}Insufficient kline data ({len(self.df)} points) for {self.symbol} {self.ccxt_interval} "
                                f"to reliably calculate all active indicators (min recommended: {min_required_data} based on max period: {max(required_periods) if required_periods else 'N/A'}). "
                                f"Results may contain NaNs or be inaccurate.{RESET}")
             # Proceed with calculation, but be aware of potential issues in results

        try:
            # --- Prepare DataFrame for pandas_ta ---
            # pandas_ta generally works best with float types for OHLCV.
            # Convert Decimal columns to float temporarily, storing original types.
            df_calc = self.df # Work on the instance's copy
            original_types = {}
            cols_to_float = ['open', 'high', 'low', 'close', 'volume']

            for col in cols_to_float:
                 if col in df_calc.columns:
                     # Check type of first non-NaN value to determine original type
                     first_valid_idx = df_calc[col].first_valid_index()
                     if first_valid_idx is not None:
                          col_type = type(df_calc.loc[first_valid_idx, col])
                          original_types[col] = col_type
                          # Only convert if the original type was Decimal
                          if col_type == Decimal:
                               self.logger.debug(f"Converting Decimal column '{col}' to float for TA calculation.")
                               # Apply conversion robustly: finite Decimals -> float, non-finite -> np.nan
                               df_calc[col] = df_calc[col].apply(
                                   lambda x: float(x) if isinstance(x, Decimal) and x.is_finite() else np.nan
                               )
                          elif not pd.api.types.is_numeric_dtype(df_calc[col]):
                              # If original type wasn't Decimal and isn't numeric, attempt conversion
                              self.logger.debug(f"Column '{col}' is not Decimal or numeric ({col_type}), attempting conversion to float.")
                              df_calc[col] = pd.to_numeric(df_calc[col], errors='coerce')
                              df_calc[col] = df_calc[col].replace([np.inf, -np.inf], np.nan) # Ensure finite
                     else: # Column is all NaN
                          original_types[col] = None # Mark as unknown original type
                          self.logger.debug(f"Column '{col}' contains only NaN values, skipping conversion.")

            # --- Dynamically Create pandas_ta Strategy ---
            ta_strategy = ta.Strategy(
                name="SXS_Dynamic_Strategy",
                description="Calculates indicators based on sxsBot config file",
                ta=[] # Initialize empty list of indicators to add
            )

            # --- Map internal keys to pandas_ta function names and parameters ---
            # Use lambda functions to fetch parameters from self.config at the time of calculation
            # Ensure parameters are cast to the types expected by pandas_ta (int for lengths, float for std/step)
            ta_map = {
                 # Indicator Key : { pandas_ta_function_name, parameter_name: lambda: type_cast(self.config.get(...)), ... }
                 "atr": {"kind": "atr", "length": lambda: int(self.config.get("atr_period", DEFAULT_ATR_PERIOD))},
                 "ema_short": {"kind": "ema", "length": lambda: int(self.config.get("ema_short_period", DEFAULT_EMA_SHORT_PERIOD))},
                 "ema_long": {"kind": "ema", "length": lambda: int(self.config.get("ema_long_period", DEFAULT_EMA_LONG_PERIOD))},
                 "momentum": {"kind": "mom", "length": lambda: int(self.config.get("momentum_period", DEFAULT_MOMENTUM_PERIOD))},
                 "cci": {"kind": "cci", "length": lambda: int(self.config.get("cci_period", DEFAULT_CCI_PERIOD))},
                 "wr": {"kind": "willr", "length": lambda: int(self.config.get("williams_r_period", DEFAULT_WILLIAMS_R_PERIOD))},
                 "mfi": {"kind": "mfi", "length": lambda: int(self.config.get("mfi_period", DEFAULT_MFI_PERIOD))},
                 "sma_10": {"kind": "sma", "length": lambda: int(self.config.get("sma_10_period", DEFAULT_SMA10_PERIOD))},
                 "rsi": {"kind": "rsi", "length": lambda: int(self.config.get("rsi_period", DEFAULT_RSI_PERIOD))},
                 "vwap": {"kind": "vwap"}, # VWAP typically uses default daily anchoring in pandas_ta
                 "psar": {"kind": "psar",
                          "step": lambda: float(self.config.get("psar_step", DEFAULT_PSAR_STEP)),
                          "max_step": lambda: float(self.config.get("psar_max_step", DEFAULT_PSAR_MAX_STEP))},
                 "stoch_rsi": {"kind": "stochrsi",
                               "length": lambda: int(self.config.get("stoch_rsi_period", DEFAULT_STOCH_RSI_PERIOD)),
                               "rsi_length": lambda: int(self.config.get("stoch_rsi_rsi_period", DEFAULT_STOCH_RSI_RSI_PERIOD)),
                               "k": lambda: int(self.config.get("stoch_rsi_k_period", DEFAULT_STOCH_RSI_K_PERIOD)),
                               "d": lambda: int(self.config.get("stoch_rsi_d_period", DEFAULT_STOCH_RSI_D_PERIOD))},
                 "bollinger_bands": {"kind": "bbands",
                                     "length": lambda: int(self.config.get("bollinger_bands_period", DEFAULT_BBANDS_PERIOD)),
                                     "std": lambda: float(self.config.get("bollinger_bands_std_dev", DEFAULT_BBANDS_STDDEV))},
                 # Note: Volume MA is calculated separately below, not added to ta_map
            }

            # --- Add Indicators to Strategy Based on Config/Weights ---
            calculated_indicator_keys = set() # Track which base indicators are added to avoid duplicates

            # Always calculate ATR if possible, as it's needed for SL/TP/BE sizing, even if not weighted for signals
            if "atr" in ta_map:
                 try:
                     params = {k: v() for k, v in ta_map["atr"].items() if k != 'kind'} # Extract params using lambdas
                     ta_strategy.ta.append(ta.Indicator(ta_map["atr"]["kind"], **params))
                     calculated_indicator_keys.add("atr")
                     self.logger.debug(f"Adding ATR to TA strategy with params: {params}")
                 except Exception as e: self.logger.error(f"Error preparing ATR indicator for strategy: {e}")

            # Add other indicators only if they are enabled AND have a non-zero weight in the active set
            for key, is_enabled in indicators_config.items():
                 if key == "atr": continue # Already handled

                 # Check if check method exists (implies indicator is supported)
                 if not hasattr(self, f'_check_{key}'): continue

                 try: weight = float(active_weights.get(key, 0.0))
                 except (ValueError, TypeError): weight = 0.0

                 # Skip if disabled in config OR has zero weight in the active set
                 if not is_enabled or weight < 1e-9: continue

                 # Handle compound indicators or indicators needing special logic
                 if key == "ema_alignment":
                      # Requires both short and long EMAs to be calculated
                      for ema_key in ["ema_short", "ema_long"]:
                          if ema_key not in calculated_indicator_keys and ema_key in ta_map:
                               try:
                                   params = {k: v() for k, v in ta_map[ema_key].items() if k != 'kind'}
                                   ta_strategy.ta.append(ta.Indicator(ta_map[ema_key]["kind"], **params))
                                   calculated_indicator_keys.add(ema_key)
                                   self.logger.debug(f"Adding {ema_key} (for ema_alignment) to TA strategy with params: {params}")
                               except Exception as e: self.logger.error(f"Error preparing {ema_key} indicator for strategy: {e}")
                 elif key == "volume_confirmation":
                      # Volume MA is calculated separately after the main strategy run
                      pass
                 elif key == "orderbook":
                      # Order book analysis doesn't use pandas_ta
                      pass
                 elif key in ta_map:
                      # Check if this base indicator was already added (e.g., if EMA was added via ema_alignment)
                      if key not in calculated_indicator_keys:
                           try:
                               indicator_def = ta_map[key]
                               params = {k: v() for k, v in indicator_def.items() if k != 'kind'}
                               ta_strategy.ta.append(ta.Indicator(indicator_def["kind"], **params))
                               calculated_indicator_keys.add(key) # Mark base key as calculated
                               self.logger.debug(f"Adding {key} to TA strategy with params: {params}")
                           except Exception as e: self.logger.error(f"Error preparing {key} indicator for strategy: {e}")
                 else:
                      # This indicates a mismatch between config['indicators'], config['weights'], and ta_map/special handling
                      self.logger.warning(f"Indicator '{key}' is enabled and weighted but has no calculation definition in ta_map or special handling. It will be ignored.")

            # --- Execute the TA Strategy ---
            if ta_strategy.ta: # Only run if indicators were actually added
                 self.logger.info(f"Running pandas_ta strategy '{ta_strategy.name}' with {len(ta_strategy.ta)} indicators for {self.symbol}...")
                 try:
                     # df.ta.strategy() applies the indicators and appends columns to df_calc inplace
                     # Use suppress_warnings=True to silence potential TA-Lib warnings if desired
                     df_calc.ta.strategy(ta_strategy, append=True, suppress_warnings=True)
                     self.logger.info(f"Pandas_ta strategy calculation complete for {self.symbol}.")
                 except Exception as ta_err:
                      self.logger.error(f"{NEON_RED}Error running pandas_ta strategy for {self.symbol}: {ta_err}{RESET}", exc_info=True)
                      # Allow continuation, but subsequent steps might fail if indicators are missing
            else:
                 self.logger.info(f"No pandas_ta indicators added to the strategy based on config and weights for {self.symbol}.")

            # --- Calculate Volume Moving Average Separately ---
            vol_key = "volume_confirmation"
            vol_ma_p = 0
            try: vol_ma_p = int(self.config.get("volume_ma_period", DEFAULT_VOLUME_MA_PERIOD))
            except (ValueError, TypeError): pass

            # Calculate only if enabled, weighted, and period is valid
            if indicators_config.get(vol_key, False) and float(active_weights.get(vol_key, 0.0)) > 1e-9 and vol_ma_p > 0:
                 try:
                     vol_ma_col = f"VOL_SMA_{vol_ma_p}" # Define a unique column name
                     # Ensure 'volume' column exists and is numeric (should be float after conversion)
                     if 'volume' in df_calc.columns and pd.api.types.is_numeric_dtype(df_calc['volume']):
                          # Use pandas_ta directly for SMA on the volume column
                          # Fill potential NaNs in volume with 0 before calculating SMA to avoid propagation
                          df_calc[vol_ma_col] = ta.sma(df_calc['volume'].fillna(0), length=vol_ma_p, append=False) # append=False returns Series
                          self.logger.debug(f"Calculated Volume MA ({vol_ma_col}) for {self.symbol}.")
                          calculated_indicator_keys.add("volume_ma") # Mark for column mapping
                     else:
                          self.logger.warning(f"Volume column missing or not numeric in DataFrame for {self.symbol}, cannot calculate Volume MA.")
                 except Exception as vol_ma_err:
                      self.logger.error(f"Error calculating Volume MA for {self.symbol}: {vol_ma_err}")

            # --- Map Internal Names to Actual DataFrame Column Names ---
            # Get all column names present after calculations
            final_df_columns = df_calc.columns.tolist()
            # Define the mapping from internal keys (used in checks/scoring) to the base names used in _get_ta_col_name
            indicator_mapping = {
                # Internal Name : TA Indicator Base Name (used in _get_ta_col_name patterns)
                "ATR": "ATR", "EMA_Short": "EMA_Short", "EMA_Long": "EMA_Long",
                "Momentum": "Momentum", "CCI": "CCI", "Williams_R": "Williams_R", "MFI": "MFI",
                "SMA_10": "SMA_10", "RSI": "RSI", "VWAP": "VWAP",
                # PSAR generates multiple columns; map the specific ones needed by checks
                "PSAR_long": "PSAR_long", "PSAR_short": "PSAR_short",
                # StochRSI generates K and D; map both if used
                "StochRSI_K": "StochRSI_K", "StochRSI_D": "StochRSI_D",
                # BBands generates multiple; map components needed by checks
                "BB_Lower": "BB_Lower", "BB_Middle": "BB_Middle", "BB_Upper": "BB_Upper",
                "Volume_MA": "Volume_MA" # Use the custom name defined above
            }
            self.ta_column_names = {} # Clear previous mapping
            for internal_name, ta_base_name in indicator_mapping.items():
                 # Find the actual column name using the robust helper method
                 mapped_col = self._get_ta_col_name(ta_base_name, final_df_columns)
                 if mapped_col:
                     self.ta_column_names[internal_name] = mapped_col
                 # else: Warning logged by _get_ta_col_name if not found

            # --- Convert Selected Columns Back to Decimal (if original was Decimal) ---
            # Prioritize converting indicators used in precise calculations (ATR, price-based levels)
            # Check if original 'close' price was Decimal as a proxy for whether conversion is needed/meaningful
            if original_types.get('close') == Decimal:
                cols_to_decimalize = ["ATR", "BB_Lower", "BB_Middle", "BB_Upper", "PSAR_long",
                                      "PSAR_short", "VWAP", "SMA_10", "EMA_Short", "EMA_Long"]
                # Also include base OHLC columns if they were converted
                for base_col in ['open', 'high', 'low', 'close']:
                     if original_types.get(base_col) == Decimal: cols_to_decimalize.append(base_col.capitalize())

                # Helper for safe Decimal conversion from float column
                def safe_float_to_decimal(x):
                     if pd.notna(x) and np.isfinite(x):
                          try: return Decimal(str(x))
                          except InvalidOperation: return Decimal('NaN')
                     return Decimal('NaN')

                for key in cols_to_decimalize:
                    # Handle base OHLC columns directly
                    if key.lower() in ['open', 'high', 'low', 'close']:
                         col_name = key.lower()
                    else: # Handle TA indicator columns via mapping
                         col_name = self.ta_column_names.get(key)

                    # Check if column name found and column exists
                    if col_name and col_name in df_calc.columns:
                         # Check if the column actually contains float data (might be object/int if errors occurred)
                         if pd.api.types.is_float_dtype(df_calc[col_name]):
                             try:
                                 self.logger.debug(f"Converting calculated column '{col_name}' (for '{key}') back to Decimal.")
                                 df_calc[col_name] = df_calc[col_name].apply(safe_float_to_decimal)
                             except Exception as conv_err: # Catch unexpected errors during apply
                                  self.logger.error(f"Failed to convert TA column '{col_name}' back to Decimal: {conv_err}. Leaving as float.")
                         # else: Column is not float, likely already Decimal or couldn't be calculated properly
            else:
                 self.logger.debug("Original OHLCV data was not Decimal, skipping Decimal reconversion for TA columns.")

            self.logger.debug(f"Finished indicator calculations for {self.symbol}. Final DF columns sample: {self.df.columns.tolist()[:15]}...")
            self.logger.debug(f"Mapped TA column names for {self.symbol}: {self.ta_column_names}")

        except Exception as e:
            self.logger.error(f"{NEON_RED}Critical error during indicator calculation setup or execution for {self.symbol}: {e}{RESET}", exc_info=True)
            # Consider clearing the DataFrame or setting flags to prevent further use
            # self.df = pd.DataFrame()

    def _update_latest_indicator_values(self):
        """
        Extracts the latest values for OHLCV and all calculated indicators from the
        DataFrame and stores them in the `self.indicator_values` dictionary.
        Handles type consistency (Decimal for price/ATR/etc., float for others) and NaNs.
        """
        self.indicator_values = {} # Reset dictionary

        if self.df.empty:
            self.logger.warning(f"Cannot update latest indicator values: DataFrame empty for {self.symbol}.")
            return
        try:
            # Ensure index is sorted chronologically to get the truly latest row
            if not self.df.index.is_monotonic_increasing:
                 self.logger.warning(f"DataFrame index for {self.symbol} is not sorted. Sorting before extracting latest values.")
                 self.df.sort_index(inplace=True)

            # Get the last row of the DataFrame
            latest_row = self.df.iloc[-1]
            latest_timestamp = latest_row.name # Get timestamp from the index
            self.indicator_values["Timestamp"] = latest_timestamp # Store timestamp as datetime object

        except IndexError:
            self.logger.error(f"Error accessing latest row (iloc[-1]) for {self.symbol}. DataFrame might be empty or calculations failed.")
            return
        except Exception as e:
             self.logger.error(f"Unexpected error getting latest row for {self.symbol}: {e}", exc_info=True)
             return

        # --- Define Expected Types for Indicators ---
        decimal_keys = ["Open", "High", "Low", "Close", "ATR", "BB_Lower", "BB_Middle", "BB_Upper",
                        "PSAR_long", "PSAR_short", "VWAP", "SMA_10", "EMA_Short", "EMA_Long", "Volume"]
        float_keys = ["Momentum", "CCI", "Williams_R", "MFI", "StochRSI_K", "StochRSI_D", "RSI", "Volume_MA"]

        # --- Process Base OHLCV Columns ---
        for base_col in ['open', 'high', 'low', 'close', 'volume']:
            key_name = base_col.capitalize() # e.g., 'Open'
            nan_value = Decimal('NaN')
            value = nan_value # Default to Decimal NaN
            if base_col in latest_row.index:
                 raw_value = latest_row[base_col]
                 if isinstance(raw_value, Decimal):
                      value = raw_value if raw_value.is_finite() else nan_value
                 elif pd.notna(raw_value) and np.isfinite(raw_value): # Handle case where it might be float/int after fallback
                      try:
                           dec_val = Decimal(str(raw_value))
                           value = dec_val if dec_val.is_finite() else nan_value
                      except (InvalidOperation, ValueError, TypeError): pass # Failed conversion, remains NaN
                 # else: raw_value was None or NaN, value remains Decimal('NaN')
            self.indicator_values[key_name] = value

        # --- Process TA Indicators Using Mapped Column Names ---
        for key, col_name in self.ta_column_names.items():
            # Determine expected type
            is_decimal_expected = key in decimal_keys or key.capitalize() in decimal_keys
            is_float_expected = key in float_keys

            target_type = Decimal if is_decimal_expected else float if is_float_expected else None
            nan_value = Decimal('NaN') if is_decimal_expected else np.nan if is_float_expected else None
            value = nan_value # Default to appropriate NaN

            if col_name and col_name in latest_row.index and target_type is not None:
                raw_value = latest_row[col_name]
                # Check if the value is valid (not None, not pd.NA, etc.)
                if pd.notna(raw_value):
                    try:
                        # Attempt conversion to the target type
                        if target_type == Decimal:
                             # Handle both Decimal and potential float/int inputs robustly
                             if isinstance(raw_value, Decimal):
                                  converted_value = raw_value
                             elif np.isfinite(raw_value): # Check finiteness if it's potentially float/int
                                  converted_value = Decimal(str(raw_value))
                             else: # Non-finite float/int
                                  converted_value = Decimal('NaN')
                             value = converted_value if converted_value.is_finite() else nan_value
                        else: # Target is float
                             converted_value = float(raw_value)
                             value = converted_value if np.isfinite(converted_value) else nan_value
                    except (ValueError, TypeError, InvalidOperation):
                        # self.logger.debug(f"Could not convert TA value {key} ('{col_name}': {raw_value}) to {target_type}. Storing NaN.")
                        value = nan_value # Use appropriate NaN on conversion failure
                # else: raw_value is already NaN/None, value remains default NaN

            # Store the processed value or the appropriate NaN type
            self.indicator_values[key] = value

        # --- Log Summary of Latest Values (formatted, DEBUG level) ---
        if self.logger.isEnabledFor(logging.DEBUG):
            log_vals = {}
            price_prec = self.get_price_precision_places() # Use helper for precision
            amount_prec = self.get_amount_precision_places() # Use helper

            # Combine known keys for formatting
            price_keys = ["Open", "High", "Low", "Close", "ATR", "BB_Lower", "BB_Middle", "BB_Upper",
                          "PSAR_long", "PSAR_short", "VWAP", "SMA_10", "EMA_Short", "EMA_Long"]
            amount_keys = ["Volume"] # Base volume
            float_indicator_keys = ["Momentum", "CCI", "Williams_R", "MFI", "StochRSI_K", "StochRSI_D", "RSI", "Volume_MA"]

            for k, v in self.indicator_values.items():
                if k == "Timestamp":
                    log_vals[k] = v.strftime('%Y-%m-%d %H:%M:%S %Z') if isinstance(v, datetime) else str(v)
                    continue

                formatted_val = "NaN" # Default for None or NaN types
                try:
                    if isinstance(v, Decimal) and v.is_finite():
                         prec = price_prec if k in price_keys else amount_prec if k in amount_keys else 8 # Default precision for other Decimals
                         formatted_val = f"{v:.{prec}f}"
                    elif isinstance(v, float) and np.isfinite(v):
                         prec = 4 if k in float_indicator_keys else 8 # Use 4dp for typical float indicators, more for others
                         formatted_val = f"{v:.{prec}f}"
                    elif isinstance(v, int): # Handle integers directly
                         formatted_val = str(v)
                except (ValueError, TypeError): # Handle invalid precision or other format issues
                    formatted_val = str(v)

                # Include non-NaN finite values in the log summary
                if formatted_val != "NaN":
                     log_vals[k] = formatted_val

            if log_vals:
                 # Sort keys for consistent log output: Timestamp, Prices, Amounts, Others alphabetically
                 sort_order = {'Timestamp': -1} # Timestamp first
                 sort_order.update({k: 0 for k in price_keys})
                 sort_order.update({k: 1 for k in amount_keys})
                 sorted_keys = sorted(log_vals.keys(), key=lambda x: (sort_order.get(x, 2), x)) # Prices, amounts, others
                 sorted_log_vals = {k: log_vals[k] for k in sorted_keys}
                 self.logger.debug(f"Latest indicator values updated ({self.symbol}): {json.dumps(sorted_log_vals)}")
            else:
                 self.logger.warning(f"No valid latest indicator values could be determined for {self.symbol} after processing.")


    def calculate_fibonacci_levels(self, window: Optional[int] = None) -> Dict[str, Decimal]:
        """
        Calculates Fibonacci retracement levels based on the High/Low range over a specified window.
        - Uses Decimal precision for calculations.
        - Quantizes results based on market's minimum tick size.
        - Stores results in `self.fib_levels_data`.

        Args:
            window (Optional[int]): The lookback period (number of bars) for finding High/Low.
                                    Uses 'fibonacci_period' from config if None.

        Returns:
            Dict[str, Decimal]: Dictionary of Fibonacci levels, e.g., {"Fib_38.2%": Decimal("...")}.
                                Returns empty dict if calculation fails.
        """
        # Use window from config if not provided, ensure it's an integer > 0
        if window is None:
            try: window = int(self.config.get("fibonacci_period", DEFAULT_FIB_PERIOD))
            except (ValueError, TypeError): window = DEFAULT_FIB_PERIOD
        if not isinstance(window, int) or window <= 1:
            self.logger.warning(f"Invalid window ({window}) for Fibonacci calculation on {self.symbol}. Needs integer > 1. Using default {DEFAULT_FIB_PERIOD}.")
            window = DEFAULT_FIB_PERIOD

        self.fib_levels_data = {} # Clear previous calculation results

        # Basic validation checks
        if self.df.empty or 'high' not in self.df.columns or 'low' not in self.df.columns:
             self.logger.debug(f"Fibonacci calc skipped for {self.symbol}: DataFrame empty or missing high/low columns.")
             return {}
        if len(self.df) < window:
            self.logger.debug(f"Not enough data ({len(self.df)} bars) for Fibonacci calculation (requires {window} bars) on {self.symbol}.")
            return {}

        # Get the relevant slice of the DataFrame
        df_slice = self.df.tail(window)

        try:
            # Extract high/low series, drop NaNs, find max/min (should be Decimal type)
            high_series = df_slice["high"].dropna()
            low_series = df_slice["low"].dropna()

            if high_series.empty or low_series.empty:
                 self.logger.warning(f"No valid high/low data points found in the last {window} bars for Fibonacci calculation on {self.symbol}.")
                 return {}

            # Find the highest high and lowest low within the window
            high_price = high_series.max()
            low_price = low_series.min()

            # Ensure we obtained valid, finite Decimal prices
            if not isinstance(high_price, Decimal) or not high_price.is_finite() or \
               not isinstance(low_price, Decimal) or not low_price.is_finite():
                self.logger.warning(f"Could not find valid finite high/low Decimal prices for Fibonacci (Window: {window}) on {self.symbol}. High: {high_price}, Low: {low_price}")
                return {}

            # --- Calculate Fibonacci Levels using Decimal Arithmetic ---
            price_range = high_price - low_price

            # Get market tick size for quantization
            min_tick = self.get_min_tick_size() # Should be valid positive Decimal
            quantizer = min_tick

            calculated_levels = {}
            if price_range < quantizer: # Handle very small or zero range
                # If range is smaller than tick size, all levels effectively collapse
                if price_range <= 0:
                    self.logger.debug(f"Fibonacci range is zero or negative (High={high_price}, Low={low_price}) for {self.symbol}. Setting all levels to High price.")
                    level_price_quantized = high_price.quantize(quantizer, rounding=ROUND_DOWN)
                else: # Range is positive but smaller than one tick
                     self.logger.debug(f"Fibonacci range ({price_range}) is smaller than tick size ({quantizer}) for {self.symbol}. Levels will likely collapse.")
                     # Treat high/low as the effective levels, use high for consistency
                     level_price_quantized = high_price.quantize(quantizer, rounding=ROUND_DOWN)

                # Assign the single price to all standard levels
                calculated_levels = {f"Fib_{level_pct * 100:.1f}%": level_price_quantized for level_pct in FIB_LEVELS}
            else:
                # Calculate normal levels based on the range
                for level_pct_str in map(str, FIB_LEVELS): # Iterate through standard levels
                    level_pct = Decimal(level_pct_str)
                    level_name = f"Fib_{level_pct * 100:.1f}%" # e.g., "Fib_38.2%"

                    # Standard Retracement Level price = High - (Range * Percentage)
                    level_price_raw = high_price - (price_range * level_pct)

                    # Quantize the calculated level price based on market tick size
                    # Round DOWN for levels calculated from High (ensures level <= raw calculation)
                    calculated_levels[level_name] = level_price_raw.quantize(quantizer, rounding=ROUND_DOWN)

            # Store the calculated levels and log them
            self.fib_levels_data = calculated_levels
            price_prec = self.get_price_precision_places()
            # Format levels for logging
            log_levels = {k: f"{v:.{price_prec}f}" for k, v in calculated_levels.items()}
            self.logger.debug(f"Calculated Fibonacci levels for {self.symbol} (Window: {window}, High: {high_price:.{price_prec}f}, Low: {low_price:.{price_prec}f}, Tick: {min_tick}): {log_levels}")
            return calculated_levels

        except KeyError as e:
            self.logger.error(f"{NEON_RED}Fibonacci calc error for {self.symbol}: DataFrame missing column '{e}'. Ensure OHLCV data is present.{RESET}")
            return {}
        except (ValueError, TypeError, InvalidOperation) as e:
             self.logger.error(f"{NEON_RED}Fibonacci calc error for {self.symbol}: Invalid data type or operation during calculation. {e}{RESET}")
             return {}
        except Exception as e:
            self.logger.error(f"{NEON_RED}Unexpected Fibonacci calculation error for {self.symbol}: {e}{RESET}", exc_info=True)
            return {}

    # --- Precision and Limit Helper Methods ---
    # These methods extract precision and limit information from the market_info dictionary,
    # providing fallbacks and caching results for efficiency within an analysis cycle.

    def get_price_precision_places(self) -> int:
        """Determines price precision (number of decimal places) from market info."""
        # Return cached value if already calculated for this instance
        if self._cached_price_precision is not None:
            return self._cached_price_precision

        precision = None
        source = "Unknown"
        try:
            precision_info = self.market_info.get('precision', {})
            price_precision_val = precision_info.get('price') # This can be int (places) or float/str (tick size)

            if price_precision_val is not None:
                # Case 1: Integer value represents decimal places directly
                if isinstance(price_precision_val, int) and price_precision_val >= 0:
                    precision, source = price_precision_val, "market.precision.price (int)"
                # Case 2: Float/String value represents tick size; calculate places from it
                else:
                    try:
                        tick_size = Decimal(str(price_precision_val))
                        if tick_size.is_finite() and tick_size > 0:
                            # Number of decimal places is the negative of the exponent of the normalized tick size
                            precision = abs(tick_size.normalize().as_tuple().exponent)
                            source = f"market.precision.price (tick: {tick_size})"
                        else: pass # Invalid tick size value, proceed to fallbacks
                    except (TypeError, ValueError, InvalidOperation): pass # Error converting tick size

            # Fallback 1: Infer from limits.price.min (if it resembles a tick size)
            if precision is None:
                min_price_val = self.market_info.get('limits', {}).get('price', {}).get('min')
                if min_price_val is not None:
                    try:
                        min_price_tick = Decimal(str(min_price_val))
                        # Heuristic: if min price is > 0 and looks like a power of 10 (common for ticks)
                        if min_price_tick.is_finite() and min_price_tick > 0 and (min_price_tick.log10() % 1 == 0 or str(min_price_tick).rstrip('0').endswith('1')):
                            precision = abs(min_price_tick.normalize().as_tuple().exponent)
                            source = f"market.limits.price.min (tick: {min_price_tick})"
                    except (TypeError, ValueError, InvalidOperation): pass

            # Fallback 2: Infer from last close price's decimal places (least reliable)
            if precision is None:
                last_close = self.indicator_values.get("Close") # Assumes latest values updated
                if isinstance(last_close, Decimal) and last_close.is_finite() and last_close > 0:
                    try:
                        # Get decimal places from the normalized exponent
                        p = abs(last_close.normalize().as_tuple().exponent)
                        # Set a reasonable range for crypto price decimal places (e.g., 0 to 12)
                        if 0 <= p <= 12:
                            precision = p
                            source = f"Inferred from Last Close Price ({last_close})"
                    except Exception: pass # Ignore potential errors during inference

        except Exception as e:
            self.logger.warning(f"Error determining price precision places for {self.symbol}: {e}. Using default.")

        # --- Final Default Fallback ---
        if precision is None:
            default_precision = 4 # A common default for many USDT pairs
            precision = default_precision
            source = f"Default ({default_precision})"
            self.logger.warning(f"{NEON_YELLOW}Could not determine price precision places for {self.symbol}. Using default: {precision}. Verify market info.{RESET}")

        # Cache and return the determined precision
        self._cached_price_precision = precision
        self.logger.debug(f"Price precision places for {self.symbol}: {precision} (Source: {source})")
        return precision

    def get_min_tick_size(self) -> Decimal:
        """Gets the minimum price increment (tick size) from market info as Decimal."""
        if self._cached_min_tick_size is not None:
            return self._cached_min_tick_size

        tick_size = None
        source = "Unknown"
        try:
            # 1. Try precision.price directly if it's not an integer (interpreted as tick size)
            precision_info = self.market_info.get('precision', {})
            price_precision_val = precision_info.get('price')
            if price_precision_val is not None and not isinstance(price_precision_val, int):
                try:
                    tick = Decimal(str(price_precision_val))
                    if tick.is_finite() and tick > 0:
                        tick_size, source = tick, "market.precision.price (value)"
                    else: raise ValueError("Invalid tick size value")
                except (TypeError, ValueError, InvalidOperation): pass

            # 2. Fallback: Try limits.price.min (often represents tick size)
            if tick_size is None:
                min_price_val = self.market_info.get('limits', {}).get('price', {}).get('min')
                if min_price_val is not None:
                    try:
                        min_tick = Decimal(str(min_price_val))
                        if min_tick.is_finite() and min_tick > 0:
                            tick_size, source = min_tick, "market.limits.price.min"
                        else: raise ValueError("Invalid min price value")
                    except (TypeError, ValueError, InvalidOperation): pass

            # 3. Fallback: Calculate from integer precision.price (number of decimal places)
            if tick_size is None and price_precision_val is not None and isinstance(price_precision_val, int) and price_precision_val >= 0:
                 tick_size = Decimal('1e-' + str(price_precision_val))
                 source = f"Calculated from market.precision.price (int: {price_precision_val})"

        except Exception as e:
            self.logger.warning(f"Could not determine min tick size for {self.symbol} from market info: {e}. Using fallback.")

        # --- Final Fallback: Calculate from derived decimal places ---
        if tick_size is None:
            price_precision_places = self.get_price_precision_places() # Call the robust getter
            tick_size = Decimal('1e-' + str(price_precision_places))
            source = f"Calculated from Derived Precision ({price_precision_places})"
            self.logger.warning(f"{NEON_YELLOW}Using fallback tick size based on derived precision for {self.symbol}: {tick_size}. Verify market info.{RESET}")

        # Emergency fallback if all methods failed to produce a valid positive Decimal
        if not isinstance(tick_size, Decimal) or not tick_size.is_finite() or tick_size <= 0:
             fallback_tick = Decimal('0.00000001') # Arbitrary small positive value
             self.logger.error(f"{NEON_RED}Failed to determine a valid tick size for {self.symbol}! Using emergency fallback: {fallback_tick}. Orders may fail.{RESET}")
             tick_size = fallback_tick
             source = "Emergency Fallback"

        self._cached_min_tick_size = tick_size
        self.logger.debug(f"Min Tick Size for {self.symbol}: {tick_size} (Source: {source})")
        return tick_size

    def get_amount_precision_places(self) -> int:
        """Determines amount precision (number of decimal places) from market info."""
        if self._cached_amount_precision is not None:
            return self._cached_amount_precision

        precision = None
        source = "Unknown"
        try:
            precision_info = self.market_info.get('precision', {})
            amount_precision_val = precision_info.get('amount') # Can be int (places) or float/str (step size)

            if amount_precision_val is not None:
                # Case 1: Integer value represents decimal places
                if isinstance(amount_precision_val, int) and amount_precision_val >= 0:
                    precision, source = amount_precision_val, "market.precision.amount (int)"
                # Case 2: Float/String value represents step size; infer places
                else:
                     try:
                          step_size = Decimal(str(amount_precision_val))
                          if step_size.is_finite() and step_size > 0:
                               precision = abs(step_size.normalize().as_tuple().exponent)
                               source = f"market.precision.amount (step: {step_size})"
                          else: pass
                     except (TypeError, ValueError, InvalidOperation): pass

            # Fallback 1: Infer from limits.amount.min (if it looks like a step size)
            if precision is None:
                min_amount_val = self.market_info.get('limits', {}).get('amount', {}).get('min')
                if min_amount_val is not None:
                    try:
                        min_amount_step = Decimal(str(min_amount_val))
                        if min_amount_step.is_finite() and min_amount_step > 0:
                            # If step size is fractional or has decimals, infer places
                            if min_amount_step < 1 or '.' in str(min_amount_val):
                               precision = abs(min_amount_step.normalize().as_tuple().exponent)
                               source = f"market.limits.amount.min (step: {min_amount_step})"
                            # If step size is a whole number (e.g., 1), precision is 0
                            elif min_amount_step >= 1 and min_amount_step == min_amount_step.to_integral_value():
                               precision = 0
                               source = f"market.limits.amount.min (int step: {min_amount_step})"
                        else: pass
                    except (TypeError, ValueError, InvalidOperation): pass

        except Exception as e:
            self.logger.warning(f"Error determining amount precision places for {self.symbol}: {e}. Using default.")

        # --- Final Default Fallback ---
        if precision is None:
            # Look at base currency for hint - BTC/ETH often 8dp, others vary. Default to a higher value.
            base_currency = self.market_info.get('base', '').upper()
            default_precision = 8 if base_currency in ['BTC', 'ETH'] else 6 # Default to 6 or 8
            precision = default_precision
            source = f"Default ({default_precision})"
            self.logger.warning(f"{NEON_YELLOW}Could not determine amount precision places for {self.symbol} (Base: {base_currency}). Using default: {precision}. Verify market info.{RESET}")

        self._cached_amount_precision = precision
        self.logger.debug(f"Amount precision places for {self.symbol}: {precision} (Source: {source})")
        return precision

    def get_min_amount_step(self) -> Decimal:
        """Gets the minimum amount increment (step size) from market info as Decimal."""
        if self._cached_min_amount_step is not None:
            return self._cached_min_amount_step

        step_size = None
        source = "Unknown"
        try:
            # 1. Try precision.amount directly if not integer (interpreted as step size)
            precision_info = self.market_info.get('precision', {})
            amount_precision_val = precision_info.get('amount')
            if amount_precision_val is not None and not isinstance(amount_precision_val, int):
                try:
                    step = Decimal(str(amount_precision_val))
                    if step.is_finite() and step > 0:
                        step_size, source = step, "market.precision.amount (value)"
                    else: raise ValueError("Invalid step size value")
                except (TypeError, ValueError, InvalidOperation): pass

            # 2. Fallback: Try limits.amount.min (often is the step size)
            if step_size is None:
                min_amount_val = self.market_info.get('limits', {}).get('amount', {}).get('min')
                if min_amount_val is not None:
                    try:
                        min_step = Decimal(str(min_amount_val))
                        if min_step.is_finite() and min_step > 0:
                            step_size, source = min_step, "market.limits.amount.min"
                        else: raise ValueError("Invalid min amount value")
                    except (TypeError, ValueError, InvalidOperation): pass

            # 3. Fallback: Calculate from integer precision.amount (decimal places)
            if step_size is None and amount_precision_val is not None and isinstance(amount_precision_val, int) and amount_precision_val >= 0:
                 step_size = Decimal('1e-' + str(amount_precision_val))
                 source = f"Calculated from market.precision.amount (int: {amount_precision_val})"

        except Exception as e:
            self.logger.warning(f"Could not determine min amount step for {self.symbol} from market info: {e}. Using fallback.")

        # --- Final Fallback: Calculate from derived decimal places ---
        if step_size is None:
            amount_precision_places = self.get_amount_precision_places() # Use robust getter
            step_size = Decimal('1e-' + str(amount_precision_places))
            source = f"Calculated from Derived Precision ({amount_precision_places})"
            self.logger.warning(f"{NEON_YELLOW}Using fallback amount step based on derived precision for {self.symbol}: {step_size}. Verify market info.{RESET}")

        # Emergency fallback
        if not isinstance(step_size, Decimal) or not step_size.is_finite() or step_size <= 0:
             fallback_step = Decimal('0.00000001') # Arbitrary small positive value
             self.logger.error(f"{NEON_RED}Failed to determine a valid amount step size for {self.symbol}! Using emergency fallback: {fallback_step}. Orders may fail.{RESET}")
             step_size = fallback_step
             source = "Emergency Fallback"

        self._cached_min_amount_step = step_size
        self.logger.debug(f"Min Amount Step for {self.symbol}: {step_size} (Source: {source})")
        return step_size

    def get_nearest_fibonacci_levels(self, current_price: Decimal, num_levels: int = 5) -> List[Tuple[str, Decimal]]:
        """
        Finds the N nearest calculated Fibonacci levels to the given current price.

        Args:
            current_price (Decimal): The current market price to compare against.
            num_levels (int): The number of nearest levels to return.

        Returns:
            List[Tuple[str, Decimal]]: A list of tuples, where each tuple contains the
                                       Fibonacci level name (str) and its price (Decimal),
                                       sorted by distance to the current price (nearest first).
                                       Returns an empty list if no valid levels or price provided.
        """
        if not self.fib_levels_data:
            self.logger.debug(f"Fibonacci levels not calculated or empty for {self.symbol}. Cannot find nearest.")
            return []
        if not isinstance(current_price, Decimal) or not current_price.is_finite() or current_price <= 0:
            self.logger.warning(f"Invalid current price ({current_price}) provided for Fibonacci comparison on {self.symbol}.")
            return []

        try:
            level_distances = []
            # Calculate distance from current price to each valid Fibonacci level
            for name, level_price in self.fib_levels_data.items():
                # Ensure the stored level price is a valid Decimal before calculating distance
                if isinstance(level_price, Decimal) and level_price.is_finite() and level_price > 0:
                    distance = abs(current_price - level_price)
                    level_distances.append({'name': name, 'level': level_price, 'distance': distance})
                else:
                    self.logger.debug(f"Skipping invalid or non-finite Fib level during distance calculation: {name}={level_price}.")
                    pass # Skip invalid levels

            if not level_distances:
                self.logger.debug(f"No valid Fibonacci levels found to compare distance against for {self.symbol}.")
                return []

            # Sort the levels based on their distance to the current price (ascending)
            level_distances.sort(key=lambda item: item['distance'])

            # Return the name and level price for the nearest N levels requested
            return [(item['name'], item['level']) for item in level_distances[:num_levels]]

        except Exception as e:
            self.logger.error(f"{NEON_RED}Error finding nearest Fibonacci levels for {self.symbol}: {e}{RESET}", exc_info=True)
            return []

    # --- Signal Generation and Indicator Check Methods ---

    def generate_trading_signal(self, current_price: Decimal, orderbook_data: Optional[Dict]) -> str:
        """
        Generates the final trading signal ('BUY', 'SELL', or 'HOLD') based on a
        weighted score derived from enabled indicator check methods.
        - Uses Decimal for score aggregation to maintain precision.
        - Compares the final score against the configured threshold.
        - Logs the signal decision and contributing factors.

        Args:
            current_price (Decimal): The current market price (used for logging and potentially some checks).
            orderbook_data (Optional[Dict]): Processed order book data (needed for '_check_orderbook').

        Returns:
            str: The final trading signal: 'BUY', 'SELL', or 'HOLD'.
        """
        final_score = Decimal("0.0") # Initialize score as Decimal
        total_weight = Decimal("0.0") # Sum of weights for indicators that provided a valid score
        active_indicator_count = 0 # Count of indicators contributing to the score
        contributing_indicators = {} # Dictionary to store scores of contributing indicators {indicator_key: score_str}

        # --- Basic Input Validation ---
        if not self.indicator_values or "Timestamp" not in self.indicator_values: # Check if values were updated
            self.logger.warning(f"Signal Generation Skipped for {self.symbol}: Indicator values not calculated or available.")
            return "HOLD"
        if not isinstance(current_price, Decimal) or not current_price.is_finite() or current_price <= 0:
            self.logger.warning(f"Signal Generation Skipped for {self.symbol}: Invalid current price ({current_price}).")
            return "HOLD"
        if not self.weights:
            self.logger.warning(f"Signal Generation Warning for {self.symbol}: Active weight set ('{self.active_weight_set_name}') is missing or empty. Score will be zero.")
            # No weights means no score can be generated, default to HOLD
            return "HOLD"

        # --- Iterate Through Configured Indicators ---
        # Find available check methods in this class (methods starting with _check_)
        available_check_methods = {m.replace('_check_', '') for m in dir(self) if m.startswith('_check_') and callable(getattr(self, m))}

        for indicator_key, is_enabled in self.config.get("indicators", {}).items():
            # Skip if indicator is explicitly disabled in the config
            if not is_enabled: continue

            # Check if a corresponding check method exists for this enabled indicator
            if indicator_key not in available_check_methods:
                 # Warn only if it's enabled AND has a non-zero weight defined (otherwise it's harmless)
                 if float(self.weights.get(indicator_key, 0.0)) > 1e-9:
                     self.logger.warning(f"No check method '_check_{indicator_key}' found for enabled and weighted indicator '{indicator_key}' in TradingAnalyzer. Skipping.")
                 continue # Skip processing this indicator

            # Get the weight for this indicator from the active weight set
            weight_val = self.weights.get(indicator_key)
            # Skip if no weight is defined for this indicator in the active set
            if weight_val is None: continue

            # Validate and convert weight to Decimal, ensuring it's non-negative
            try:
                weight = Decimal(str(weight_val))
                if not weight.is_finite() or weight < 0:
                    raise ValueError("Weight must be non-negative and finite")
                # Skip efficiently if weight is zero (or extremely close to it)
                if weight < Decimal('1e-9'): continue
            except (ValueError, TypeError, InvalidOperation):
                self.logger.warning(f"Invalid weight value '{weight_val}' configured for indicator '{indicator_key}' in weight set '{self.active_weight_set_name}'. Skipping this indicator.")
                continue

            # --- Execute the Indicator Check Method ---
            check_method_name = f"_check_{indicator_key}"
            score_float = np.nan # Default score is NaN (indicating no signal or error)

            try:
                method = getattr(self, check_method_name)
                # Special handling for orderbook check which requires extra data arguments
                if indicator_key == "orderbook":
                    if orderbook_data:
                        # Pass the orderbook dictionary and current price (Decimal)
                        score_float = method(orderbook_data=orderbook_data, current_price=current_price)
                    else:
                        self.logger.debug(f"Orderbook check skipped for {self.symbol}: No orderbook data provided.")
                        score_float = np.nan # Cannot score without data
                else:
                    # Call the standard check method without extra arguments
                    score_float = method()

            except Exception as e:
                self.logger.error(f"Error executing indicator check '{check_method_name}' for {self.symbol}: {e}", exc_info=True)
                score_float = np.nan # Ensure score is NaN if the check method itself fails

            # --- Aggregate Score (using Decimal) ---
            # Process the score only if it's a valid, finite float number
            if pd.notna(score_float) and np.isfinite(score_float):
                try:
                    # Convert the float score [-1.0, 1.0] returned by check method to Decimal
                    score_dec = Decimal(str(score_float))
                    # Clamp score to the expected range [-1, 1] just in case a check method returned slightly out of bounds
                    clamped_score = max(Decimal("-1.0"), min(Decimal("1.0"), score_dec))

                    # Add the weighted score to the final aggregate score
                    final_score += clamped_score * weight
                    # Add the weight of this contributing indicator to the total weight sum
                    total_weight += weight
                    active_indicator_count += 1
                    # Store the clamped score (as string for JSON logging) for debugging
                    contributing_indicators[indicator_key] = f"{clamped_score:.3f}"

                except (ValueError, TypeError, InvalidOperation) as calc_err:
                    self.logger.error(f"Error processing score for indicator '{indicator_key}' (Raw Score: {score_float}, Weight: {weight}): {calc_err}")
            # else: Score was NaN or infinite from the check method; it does not contribute to the final score or total weight.

        # --- Determine Final Signal Based on Aggregated Score ---
        final_signal = "HOLD" # Default signal
        threshold = Decimal('1.5') # Default threshold
        # Only generate BUY/SELL if there was meaningful contribution (total weight > 0)
        if total_weight > Decimal('1e-9'): # Use a small tolerance
            # Get the signal threshold from config, validate, use Decimal
            try:
                threshold_str = self.config.get("signal_score_threshold", "1.5")
                threshold = Decimal(str(threshold_str))
                # Ensure threshold is positive and finite
                if not threshold.is_finite() or threshold <= 0:
                    raise ValueError("Signal score threshold must be positive and finite")
            except (ValueError, TypeError, InvalidOperation):
                # Fallback to default threshold if config value is invalid
                default_threshold_val = default_config.get("signal_score_threshold", 1.5) # Get from global default
                threshold = Decimal(str(default_threshold_val))
                self.logger.warning(f"{NEON_YELLOW}Invalid 'signal_score_threshold' ('{threshold_str}') in config. Using default: {threshold}.{RESET}")

            # Compare the final aggregated score against the positive/negative threshold
            if final_score >= threshold:
                final_signal = "BUY"
            elif final_score <= -threshold:
                final_signal = "SELL"
            # else: Score is within the neutral zone (-threshold < score < threshold), signal remains "HOLD"
        else:
            # Log if no indicators contributed significantly
            self.logger.debug(f"No indicators provided valid scores or had non-zero weights for {self.symbol} (Total Weight: {total_weight:.4f}). Defaulting signal to HOLD.")

        # --- Log the Signal Generation Summary ---
        price_prec = self.get_price_precision_places()
        # Choose color based on the final signal
        sig_color = NEON_GREEN if final_signal == "BUY" else NEON_RED if final_signal == "SELL" else NEON_YELLOW
        log_msg = (
            f"Signal ({self.symbol} @ {current_price:.{price_prec}f}): "
            f"Strategy='{self.active_weight_set_name}', ActiveInd={active_indicator_count}, "
            f"TotalWeight={total_weight:.2f}, FinalScore={final_score:.4f} (Threshold: +/-{threshold:.2f}) "
            f"==> {sig_color}{final_signal}{RESET}"
        )
        self.logger.info(log_msg)

        # Log the scores of contributing indicators only if logger level is DEBUG
        if self.logger.isEnabledFor(logging.DEBUG) and contributing_indicators:
             # Sort scores by indicator key for consistent log output
             sorted_scores = dict(sorted(contributing_indicators.items()))
             self.logger.debug(f"  Contributing Scores ({self.symbol}): {json.dumps(sorted_scores)}")

        return final_signal

    # --- Indicator Check Methods ---
    # Each method should:
    # 1. Fetch required latest values from `self.indicator_values`.
    # 2. Validate that the fetched values are usable (not NaN, correct type expected).
    # 3. Perform the specific indicator logic.
    # 4. Return a float score between -1.0 (strong sell) and 1.0 (strong buy),
    #    or np.nan if the check cannot be performed (e.g., due to missing data).

    def _check_ema_alignment(self) -> float:
        """Checks EMA alignment (Short vs Long) and price position relative to EMAs.
           Returns float score [-1.0, 1.0] or np.nan."""
        ema_s = self.indicator_values.get("EMA_Short") # Expect Decimal or NaN
        ema_l = self.indicator_values.get("EMA_Long")  # Expect Decimal or NaN
        close = self.indicator_values.get("Close")     # Expect Decimal or NaN

        # Validate inputs: ensure all are finite Decimals
        if not isinstance(ema_s, Decimal) or not ema_s.is_finite() or \
           not isinstance(ema_l, Decimal) or not ema_l.is_finite() or \
           not isinstance(close, Decimal) or not close.is_finite():
            return np.nan # Cannot perform check if any value is missing or invalid

        try:
            # Determine relative positions
            price_above_short = close > ema_s
            short_above_long = ema_s > ema_l # Bullish EMA cross/alignment

            # --- Scoring Logic ---
            if short_above_long: # EMAs indicate uptrend bias
                if price_above_short: return 1.0   # Strongest Bullish: Close > Short > Long
                else: return -0.2 # Weaker Bullish: Short > Long, but Close < Short (potential pullback/weakness)
            else: # EMAs indicate downtrend bias (Long >= Short)
                if not price_above_short: return -1.0 # Strongest Bearish: Close < Short <= Long
                else: return 0.2 # Weaker Bearish: Long >= Short, but Close > Short (potential pullback/weakness)

        except TypeError: # Should not happen if validation passes, but safety check
            self.logger.warning(f"Type error during EMA alignment check for {self.symbol}.", exc_info=False)
            return np.nan

    def _check_momentum(self) -> float:
        """Scores based on the Momentum indicator value relative to zero.
           Returns float score [-1.0, 1.0] or np.nan."""
        momentum = self.indicator_values.get("Momentum") # Expect float or np.nan

        # Validate input: ensure it's a finite float/int
        if not isinstance(momentum, (float, int)) or not np.isfinite(momentum):
            return np.nan

        # Scoring based on sign and magnitude relative to zero
        # Positive momentum -> Buy bias, Negative momentum -> Sell bias
        # Scale the score: simple linear scaling for now, could use std dev or ATR scaling
        # For now, treat any positive as 0.5, any negative as -0.5 for simplicity.
        # TODO: Potentially refine scaling based on typical momentum range for the asset/timeframe.
        if momentum > 0:
             # Scale positive momentum (e.g., 0 to 1.0 based on magnitude)
             # Simple example: Clamp score between 0.1 and 1.0 based on some reference value
             # ref_momentum = 0.5 # Needs context - related to price change typical magnitude
             # score = min(1.0, 0.1 + 0.9 * (abs(momentum) / ref_momentum))
             return 0.5 # Simplified: Moderate buy signal
        elif momentum < 0:
             # Scale negative momentum
             # score = max(-1.0, -0.1 - 0.9 * (abs(momentum) / ref_momentum))
             return -0.5 # Simplified: Moderate sell signal
        else: # Momentum is exactly zero
             return 0.0

    def _check_volume_confirmation(self) -> float:
        """Scores based on current volume relative to its moving average. High volume confirms trend strength.
           Returns float score [-0.4, 1.0] or np.nan."""
        current_volume = self.indicator_values.get("Volume") # Expect Decimal or NaN
        volume_ma = self.indicator_values.get("Volume_MA") # Expect float or np.nan

        # Validate inputs
        if not isinstance(current_volume, Decimal) or not current_volume.is_finite() or current_volume < 0:
            return np.nan # Invalid current volume
        if not isinstance(volume_ma, (float, int)) or not np.isfinite(volume_ma) or volume_ma <= 1e-12: # Check against very small value
            # If MA is zero or negligible, comparison is meaningless
            return np.nan

        try:
            # Convert MA float to Decimal for accurate comparison
            volume_ma_dec = Decimal(str(volume_ma))
            # Get multiplier from config, ensure it's a valid Decimal > 0
            try:
                multiplier = Decimal(str(self.config.get("volume_confirmation_multiplier", 1.5)))
                if not multiplier.is_finite() or multiplier <= 0: raise ValueError
            except (ValueError, TypeError, InvalidOperation):
                 multiplier = Decimal('1.5') # Fallback to default if invalid

            # Calculate ratio of current volume to its moving average
            ratio = current_volume / volume_ma_dec

            # --- Scoring Logic ---
            # Score positive if volume is significantly above average (confirms move)
            if ratio >= multiplier * Decimal('1.5'): return 1.0 # Very high volume confirmation (strong signal)
            if ratio >= multiplier: return 0.6                 # High volume confirmation (moderate signal)

            # Score slightly negative if volume is significantly below average (lack of interest/conviction)
            if ratio <= (Decimal('1') / (multiplier * Decimal('1.5'))): return -0.4 # Unusually low volume
            if ratio <= (Decimal('1') / multiplier): return -0.2                 # Low volume

            # Volume is within the 'normal' range (between low and high thresholds)
            return 0.0

        except (InvalidOperation, ZeroDivisionError, TypeError) as e:
             self.logger.warning(f"Error during volume confirmation calculation for {self.symbol}: {e}")
             return np.nan

    def _check_stoch_rsi(self) -> float:
        """Scores based on Stochastic RSI K and D values relative to overbought/oversold thresholds and their crossover.
           Returns float score [-1.0, 1.0] or np.nan."""
        k_val = self.indicator_values.get("StochRSI_K") # Expect float or np.nan
        d_val = self.indicator_values.get("StochRSI_D") # Expect float or np.nan

        # Validate inputs: ensure K and D are finite floats/ints
        if not isinstance(k_val, (float, int)) or not np.isfinite(k_val) or \
           not isinstance(d_val, (float, int)) or not np.isfinite(d_val):
            return np.nan

        # Get thresholds from config, ensuring they are valid floats within 0-100
        try:
            oversold = float(self.config.get("stoch_rsi_oversold_threshold", 25))
            overbought = float(self.config.get("stoch_rsi_overbought_threshold", 75))
            # Basic validation: thresholds must be within range and oversold < overbought
            if not (0 <= oversold < 100 and 0 < overbought <= 100 and oversold < overbought):
                raise ValueError("Invalid StochRSI thresholds")
        except (ValueError, TypeError):
             oversold, overbought = 25.0, 75.0 # Fallback to safe defaults
             self.logger.warning(f"{NEON_YELLOW}Invalid StochRSI thresholds in config, using defaults ({oversold}/{overbought}) for {self.symbol}.{RESET}")

        score = 0.0 # Initialize score to neutral

        # --- Scoring Logic ---
        # 1. Extreme Conditions (Strongest Signal): Both K and D in overbought/oversold zones
        k_is_oversold = k_val < oversold
        d_is_oversold = d_val < oversold
        k_is_overbought = k_val > overbought
        d_is_overbought = d_val > overbought

        if k_is_oversold and d_is_oversold:
            score = 1.0 # Strong Buy Signal (Deeply Oversold)
        elif k_is_overbought and d_is_overbought:
            score = -1.0 # Strong Sell Signal (Deeply Overbought)

        # 2. Crossover Signals (Moderate Signal): K crossing D adds confirmation
        # Use a small tolerance for crossover to avoid noise around exact equality
        cross_tolerance = 0.5 # Use a small tolerance
        is_bullish_cross = k_val > d_val + cross_tolerance # K crosses above D
        is_bearish_cross = d_val > k_val + cross_tolerance # D crosses above K (K crosses below D)

        # Check previous K/D values if available for confirmed cross (more robust) - Not implemented here yet
        # Simplified: Check current relative position

        if is_bullish_cross:
             # Give bullish cross positive score, more significant if crossing up from oversold
             score = max(score, 0.6 if k_is_oversold else 0.3) # Max ensures we don't weaken a stronger signal (e.g., deep OS = 1.0)
        elif is_bearish_cross:
             # Give bearish cross negative score, more significant if crossing down from overbought
             score = min(score, -0.6 if k_is_overbought else -0.3) # Min ensures we don't weaken a stronger signal (e.g., deep OB = -1.0)

        # 3. General Position Bias (Weakest Signal): Position relative to 50 midpoint if not in extreme zones
        mid_point = 50.0
        # Apply only if the current score is still weak (e.g., abs(score) < 0.3)
        if abs(score) < 0.3:
            if k_val > mid_point and d_val > mid_point:
                 score = max(score, 0.1) # Minor bullish bias reinforcement
            elif k_val < mid_point and d_val < mid_point:
                 score = min(score, -0.1) # Minor bearish bias reinforcement

        # Final clamp score to ensure it's strictly within [-1.0, 1.0]
        return max(-1.0, min(1.0, score))

    def _check_rsi(self) -> float:
        """Scores based on RSI value relative to standard overbought (70) / oversold (30) levels, with extremes (80/20).
           Returns float score [-1.0, 1.0] or np.nan."""
        rsi = self.indicator_values.get("RSI") # Expect float or np.nan

        # Validate input: ensure RSI is a finite float/int (typically 0-100)
        if not isinstance(rsi, (float, int)) or not np.isfinite(rsi):
            return np.nan

        # --- Graded Scoring based on RSI Level ---
        if rsi >= 80: return -1.0 # Extreme Overbought (Strong Sell Signal)
        if rsi >= 70: return -0.7 # Standard Overbought (Moderate Sell Signal)
        if rsi > 60: return -0.3  # Approaching Overbought (Weak Sell Signal)

        if rsi <= 20: return 1.0 # Extreme Oversold (Strong Buy Signal)
        if rsi <= 30: return 0.7 # Standard Oversold (Moderate Buy Signal)
        if rsi < 40: return 0.3  # Approaching Oversold (Weak Buy Signal)

        # Neutral zone (typically 40-60)
        return 0.0

    def _check_cci(self) -> float:
        """Scores based on CCI value relative to standard levels (+/-100) and extremes (+/-200).
           Returns float score [-1.0, 1.0] or np.nan."""
        cci = self.indicator_values.get("CCI") # Expect float or np.nan

        # Validate input: ensure CCI is a finite float/int
        if not isinstance(cci, (float, int)) or not np.isfinite(cci):
            return np.nan

        # --- Scoring based on CCI levels ---
        # CCI > +100 suggests overbought (potential sell)
        # CCI < -100 suggests oversold (potential buy)
        if cci >= 200: return -1.0 # Extreme Overbought/Sell Signal
        if cci >= 100: return -0.7 # Standard Overbought/Sell Signal
        if cci > 0: return -0.1   # Mild bearish momentum bias (above zero line)

        if cci <= -200: return 1.0 # Extreme Oversold/Buy Signal
        if cci <= -100: return 0.7 # Standard Oversold/Buy Signal
        if cci < 0: return 0.1   # Mild bullish momentum bias (below zero line)

        # Exactly zero
        return 0.0

    def _check_wr(self) -> float:
        """Scores based on Williams %R value. Note W%R ranges from -100 (least oversold) to 0 (most overbought).
           Standard levels are -20 (Overbought threshold) and -80 (Oversold threshold).
           Returns float score [-1.0, 1.0] or np.nan."""
        wr = self.indicator_values.get("Williams_R") # Expect float (range -100 to 0) or np.nan

        # Validate input: ensure W%R is a finite float/int within expected range
        if not isinstance(wr, (float, int)) or not np.isfinite(wr) or not (-100 <= wr <= 0):
             # Log if value is outside expected range, might indicate calculation issue
             if isinstance(wr, (float, int)) and np.isfinite(wr):
                  self.logger.warning(f"Williams %R value ({wr}) is outside expected range [-100, 0] for {self.symbol}.")
             return np.nan

        # --- Scoring based on W%R levels (remembering inverse relationship) ---
        # W%R near 0 = Overbought (Sell signal)
        # W%R near -100 = Oversold (Buy signal)
        if wr >= -10: return -1.0 # Extreme Overbought (Strong Sell)
        if wr >= -20: return -0.7 # Standard Overbought (Moderate Sell)
        if wr > -50: return -0.2  # In upper half (closer to OB, slight sell bias)

        if wr <= -90: return 1.0 # Extreme Oversold (Strong Buy)
        if wr <= -80: return 0.7 # Standard Oversold (Moderate Buy)
        if wr < -50: return 0.2  # In lower half (closer to OS, slight buy bias)

        # Exactly -50 (midpoint)
        return 0.0

    def _check_psar(self) -> float:
        """Scores based on Parabolic SAR position relative to price (indicated by which PSAR value is active).
           PSAR below price = Uptrend (+1.0). PSAR above price = Downtrend (-1.0).
           Returns float score [-1.0, 1.0] or np.nan."""
        # pandas_ta PSAR calculation typically returns NaN for the non-active direction
        psar_l = self.indicator_values.get("PSAR_long")  # Value below price (uptrend) if active (Decimal or NaN)
        psar_s = self.indicator_values.get("PSAR_short") # Value above price (downtrend) if active (Decimal or NaN)

        # Check which PSAR value is finite (and implicitly non-NaN)
        # Assumes Decimal('NaN') or np.nan is used for invalid/inactive states
        l_active = isinstance(psar_l, Decimal) and psar_l.is_finite()
        s_active = isinstance(psar_s, Decimal) and psar_s.is_finite()

        if l_active and not s_active:
            return 1.0  # Uptrend Signal: PSAR Long is active (plotting below price)
        elif s_active and not l_active:
            return -1.0 # Downtrend Signal: PSAR Short is active (plotting above price)
        elif not l_active and not s_active:
            self.logger.debug(f"PSAR check ({self.symbol}): Neither long nor short PSAR value is active/valid.")
            return np.nan # Indeterminate state or insufficient data for PSAR calculation
        else:
             # This state (both L and S are finite Decimals) shouldn't normally happen with standard PSAR.
             # It might indicate an issue with the TA calculation or data interpretation.
             self.logger.warning(f"PSAR check ({self.symbol}) encountered unusual state: Both Long ({psar_l}) and Short ({psar_s}) seem active/valid. Returning neutral (0.0).")
             return 0.0

    def _check_sma_10(self) -> float:
        """Scores based on current price position relative to the 10-period Simple Moving Average.
           Returns float score [-0.6, 0.6] or np.nan."""
        sma = self.indicator_values.get("SMA_10")   # Expect Decimal or NaN
        close = self.indicator_values.get("Close") # Expect Decimal or NaN

        # Validate inputs: ensure both are finite Decimals
        if not isinstance(sma, Decimal) or not sma.is_finite() or \
           not isinstance(close, Decimal) or not close.is_finite():
           return np.nan

        try:
            # Basic check: Price above SMA suggests bullish bias, below suggests bearish.
            if close > sma: return 0.6  # Moderate Buy Signal (Price > SMA)
            if close < sma: return -0.6 # Moderate Sell Signal (Price < SMA)
            # else: Price is exactly on SMA
            return 0.0
        except TypeError: # Safety net for comparison errors
             self.logger.warning(f"Type error during SMA_10 check for {self.symbol}.", exc_info=False)
             return np.nan

    def _check_vwap(self) -> float:
        """Scores based on current price position relative to the Volume Weighted Average Price (VWAP).
           VWAP often acts as a session mean or support/resistance.
           Returns float score [-0.7, 0.7] or np.nan."""
        vwap = self.indicator_values.get("VWAP")   # Expect Decimal or NaN
        close = self.indicator_values.get("Close") # Expect Decimal or NaN

        # Validate inputs: ensure both are finite Decimals
        if not isinstance(vwap, Decimal) or not vwap.is_finite() or \
           not isinstance(close, Decimal) or not close.is_finite():
           return np.nan

        # Scoring Logic: Price relative to VWAP indicates intraday trend/strength
        try:
            if close > vwap: return 0.7  # Moderate Buy Signal (Price trading above VWAP)
            if close < vwap: return -0.7 # Moderate Sell Signal (Price trading below VWAP)
            # else: Price is exactly on VWAP
            return 0.0
        except TypeError:
             self.logger.warning(f"Type error during VWAP check for {self.symbol}.", exc_info=False)
             return np.nan

    def _check_mfi(self) -> float:
        """Scores based on Money Flow Index (MFI) relative to standard overbought (80) / oversold (20) levels, with extremes (90/10).
           Returns float score [-1.0, 1.0] or np.nan."""
        mfi = self.indicator_values.get("MFI") # Expect float or np.nan

        # Validate input: ensure MFI is a finite float/int (typically 0-100)
        if not isinstance(mfi, (float, int)) or not np.isfinite(mfi):
            return np.nan

        # --- Graded Scoring based on MFI Level ---
        if mfi >= 90: return -1.0 # Extreme Overbought (Strong Sell Signal - potential exhaustion)
        if mfi >= 80: return -0.7 # Standard Overbought (Moderate Sell Signal)
        if mfi > 70: return -0.3  # Approaching Overbought (Weak Sell Signal)

        if mfi <= 10: return 1.0 # Extreme Oversold (Strong Buy Signal - potential exhaustion)
        if mfi <= 20: return 0.7 # Standard Oversold (Moderate Buy Signal)
        if mfi < 30: return 0.3  # Approaching Oversold (Weak Buy Signal)

        # Neutral zone (e.g., 30-70)
        return 0.0

    def _check_bollinger_bands(self) -> float:
        """Scores based on price position relative to Bollinger Bands (Lower, Middle, Upper).
           Touching bands suggests reversal potential (-/+ 1.0). Position vs middle band suggests trend continuation/mean reversion bias (-/+ 0.5).
           Returns float score [-1.0, 1.0] or np.nan."""
        bbl = self.indicator_values.get("BB_Lower")   # Expect Decimal or NaN
        bbm = self.indicator_values.get("BB_Middle")  # Expect Decimal or NaN
        bbu = self.indicator_values.get("BB_Upper")   # Expect Decimal or NaN
        close = self.indicator_values.get("Close")    # Expect Decimal or NaN

        # Validate inputs: ensure all are finite Decimals
        if not all(isinstance(v, Decimal) and v.is_finite() for v in [bbl, bbm, bbu, close]):
            return np.nan

        # Validate band structure: Upper band must be greater than Lower band
        band_width = bbu - bbl
        if band_width <= 0:
            self.logger.debug(f"BBands check skipped for {self.symbol}: Upper band ({bbu}) <= Lower band ({bbl}).")
            return np.nan # Invalid bands

        try:
            # --- Scoring Logic ---
            # 1. Price Touching or Exceeding Bands (Strong Reversal/Fade Signal)
            # Use a small tolerance (e.g., 0.1% of band width) for "touching"
            tolerance = band_width * Decimal('0.001')
            if close <= bbl + tolerance: return 1.0 # Strong Buy Signal (at/below lower band)
            if close >= bbu - tolerance: return -1.0 # Strong Sell Signal (at/above upper band)

            # 2. Price Between Bands: Position relative to Middle Band (Mean Reversion / Trend Bias)
            # Ensure middle band is between upper and lower
            if not (bbl < bbm < bbu):
                 self.logger.warning(f"BBands check issue for {self.symbol}: Middle band ({bbm}) not between Lower ({bbl}) and Upper ({bbu}).")
                 return np.nan # Invalid band structure for middle band check

            # If price is above middle band, suggests potential reversion lower (slight sell bias)
            if close > bbm:
                 # Scale score from 0 (at BBM) towards -0.5 (approaching BBU)
                 # Normalize position within the upper half of the band: (Close - Mid) / (Upper - Mid)
                 position_in_upper_band = (close - bbm) / (bbu - bbm) # Range approx 0 to 1
                 score = float(position_in_upper_band) * -0.5 # Scale to 0 to -0.5
                 return max(-0.5, score) # Limit score
            # If price is below middle band, suggests potential reversion higher (slight buy bias)
            elif close < bbm:
                 # Scale score from 0 (at BBM) towards +0.5 (approaching BBL)
                 # Normalize position within the lower half: (Mid - Close) / (Mid - Lower)
                 position_in_lower_band = (bbm - close) / (bbm - bbl) # Range approx 0 to 1
                 score = float(position_in_lower_band) * 0.5 # Scale to 0 to +0.5
                 return min(0.5, score) # Limit score
            else: # close == bbm
                 return 0.0 # Exactly on the middle band is neutral

        except (TypeError, ZeroDivisionError, InvalidOperation) as e: # Handle comparison errors or division by zero if bands collapse
             self.logger.warning(f"Error during Bollinger Bands check for {self.symbol}: {e}")
             return np.nan

    def _check_orderbook(self, orderbook_data: Optional[Dict], current_price: Decimal) -> float:
        """
        Analyzes Order Book Imbalance based on the volume within configured levels.
        Compares cumulative bid volume vs. cumulative ask volume.
        Returns float score [-1.0 (ask heavy), 1.0 (bid heavy)] or np.nan.
        """
        # Validate input data
        if not orderbook_data or not isinstance(orderbook_data.get('bids'), list) or not isinstance(orderbook_data.get('asks'), list):
            self.logger.debug(f"Orderbook check skipped for {self.symbol}: Invalid or missing orderbook data.")
            return np.nan

        bids = orderbook_data['bids'] # List of [Decimal(price), Decimal(amount)], sorted high to low
        asks = orderbook_data['asks'] # List of [Decimal(price), Decimal(amount)], sorted low to high

        # Ensure bids and asks lists are not empty
        if not bids or not asks:
            self.logger.debug(f"Orderbook check skipped for {self.symbol}: Bids or asks list is empty.")
            return np.nan

        try:
            # Use the number of levels specified in the config
            levels_to_analyze = int(self.config.get("orderbook_limit", 10))
            # Clamp levels to the actual available data depth
            levels_to_analyze = min(len(bids), len(asks), levels_to_analyze)
            if levels_to_analyze <= 0:
                self.logger.debug(f"Orderbook check ({self.symbol}): No levels to analyze ({levels_to_analyze}). Returning neutral.")
                return 0.0

            # --- Calculate Cumulative Volume within the specified levels ---
            # Ensure amounts are Decimal before summing
            total_bid_volume = sum(b[1] for b in bids[:levels_to_analyze] if isinstance(b[1], Decimal) and b[1].is_finite())
            total_ask_volume = sum(a[1] for a in asks[:levels_to_analyze] if isinstance(a[1], Decimal) and a[1].is_finite())

            # Calculate total volume in the analyzed range
            total_volume = total_bid_volume + total_ask_volume

            # Avoid division by zero if total volume is negligible
            if total_volume < Decimal('1e-12'):
                self.logger.debug(f"Orderbook check ({self.symbol}): Zero total volume in analyzed {levels_to_analyze} levels.")
                return 0.0 # Return neutral if no significant volume

            # --- Calculate Order Book Imbalance (OBI) ---
            # Simple difference ratio: (Bids - Asks) / Total
            # Ranges from -1.0 (all asks) to +1.0 (all bids). 0.0 indicates perfect balance.
            obi_diff_ratio = (total_bid_volume - total_ask_volume) / total_volume

            # Convert the Decimal ratio to float for the score, clamping just in case
            score = float(max(Decimal("-1.0"), min(Decimal("1.0"), obi_diff_ratio)))

            self.logger.debug(f"OB Check ({self.symbol}, {levels_to_analyze} levels): BidVol={total_bid_volume:.4f}, AskVol={total_ask_volume:.4f}, OBI_Diff={obi_diff_ratio:.4f} -> Score={score:.4f}")
            return score

        except (IndexError, ValueError, TypeError, InvalidOperation, ZeroDivisionError) as e:
             self.logger.warning(f"Orderbook analysis calculation failed for {self.symbol}: {e}", exc_info=False)
             return np.nan
        except Exception as e:
             self.logger.error(f"Unexpected error during order book analysis for {self.symbol}: {e}", exc_info=True)
             return np.nan

    # --- TP/SL Calculation Method ---

    def calculate_entry_tp_sl(
        self, entry_price_estimate: Decimal, signal: str
    ) -> Tuple[Optional[Decimal], Optional[Decimal], Optional[Decimal]]:
        """
        Calculates potential initial Take Profit (TP) and Stop Loss (SL) prices
        based on an estimated entry price, the trading signal ('BUY'/'SELL'), and ATR.
        - Uses Decimal precision throughout.
        - Applies market tick size for quantization.
        - Ensures TP/SL are valid prices and appropriately positioned relative to entry.

        Args:
            entry_price_estimate (Decimal): The estimated or target entry price.
            signal (str): The trading signal ('BUY' or 'SELL').

        Returns:
            Tuple[Optional[Decimal], Optional[Decimal], Optional[Decimal]]:
                - Validated Entry Price Estimate (currently just passed through, could be refined)
                - Calculated Take Profit Price (Decimal), or None if invalid/not calculable.
                - Calculated Stop Loss Price (Decimal), or None if invalid/not calculable.
        """
        final_tp: Optional[Decimal] = None
        final_sl: Optional[Decimal] = None

        # --- Validate Inputs ---
        if signal not in ["BUY", "SELL"]:
            self.logger.debug(f"TP/SL Calc skipped for {self.symbol}: Invalid signal '{signal}'.")
            return entry_price_estimate, None, None

        # Fetch latest ATR value (should be Decimal or NaN)
        atr_val = self.indicator_values.get("ATR")
        if not isinstance(atr_val, Decimal) or not atr_val.is_finite() or atr_val <= 0:
            self.logger.warning(f"{NEON_YELLOW}TP/SL Calc Fail ({self.symbol} {signal}): Invalid or non-positive ATR value ({atr_val}). Cannot calculate TP/SL.{RESET}")
            return entry_price_estimate, None, None

        if not isinstance(entry_price_estimate, Decimal) or not entry_price_estimate.is_finite() or entry_price_estimate <= 0:
            self.logger.warning(f"{NEON_YELLOW}TP/SL Calc Fail ({self.symbol} {signal}): Invalid entry price estimate ({entry_price_estimate}).{RESET}")
            return entry_price_estimate, None, None

        try:
            # --- Get Parameters as Decimals ---
            try:
                tp_mult_cfg = self.config.get("take_profit_multiple", default_config["take_profit_multiple"])
                sl_mult_cfg = self.config.get("stop_loss_multiple", default_config["stop_loss_multiple"])
                tp_mult = Decimal(str(tp_mult_cfg))
                sl_mult = Decimal(str(sl_mult_cfg))
                if not tp_mult.is_finite() or tp_mult <= 0 or not sl_mult.is_finite() or sl_mult <= 0:
                     raise ValueError("Multipliers must be positive and finite")
            except (ValueError, TypeError, InvalidOperation):
                 def_tp = default_config["take_profit_multiple"]
                 def_sl = default_config["stop_loss_multiple"]
                 self.logger.warning(f"Invalid TP/SL multipliers in config ({tp_mult_cfg}/{sl_mult_cfg}). Using defaults ({def_tp}/{def_sl}).")
                 tp_mult = Decimal(str(def_tp))
                 sl_mult = Decimal(str(def_sl))

            # Get market tick size for quantization
            min_tick = self.get_min_tick_size() # Should be a valid positive Decimal
            quantizer = min_tick

            # --- Calculate Raw Price Offsets based on ATR ---
            tp_offset = atr_val * tp_mult
            sl_offset = atr_val * sl_mult

            # --- Calculate Raw TP/SL Prices ---
            if signal == "BUY":
                tp_raw = entry_price_estimate + tp_offset
                sl_raw = entry_price_estimate - sl_offset
            else: # SELL signal
                tp_raw = entry_price_estimate - tp_offset
                sl_raw = entry_price_estimate + sl_offset

            # --- Quantize TP/SL Prices using Market Tick Size ---
            # Apply rounding logic:
            # - TP: Round towards neutral (less profit) to increase chance of execution.
            #       BUY TP -> Round Down; SELL TP -> Round Up.
            # - SL: Round away from entry (more loss potential) to avoid premature stops due to rounding.
            #       BUY SL -> Round Down; SELL SL -> Round Up.
            if tp_raw.is_finite():
                rounding_mode_tp = ROUND_DOWN if signal == "BUY" else ROUND_UP
                final_tp = tp_raw.quantize(quantizer, rounding=rounding_mode_tp)
            else: final_tp = None

            if sl_raw.is_finite():
                rounding_mode_sl = ROUND_DOWN if signal == "BUY" else ROUND_UP
                final_sl = sl_raw.quantize(quantizer, rounding=rounding_mode_sl)
            else: final_sl = None

            # --- Validation and Refinement ---
            # 1. Ensure SL is strictly further from entry than the tick size allows after rounding
            if final_sl is not None:
                if signal == "BUY" and final_sl >= entry_price_estimate:
                    # If BUY SL ended up >= entry, move it one tick below entry
                    corrected_sl = (entry_price_estimate - min_tick).quantize(quantizer, rounding=ROUND_DOWN)
                    if corrected_sl < entry_price_estimate: # Ensure adjustment is possible
                        self.logger.debug(f"Adjusted BUY SL ({final_sl}) to be below entry: {corrected_sl}")
                        final_sl = corrected_sl
                    else: # Cannot adjust below entry (entry price too close to zero or tick size too large)
                        self.logger.warning(f"Could not adjust BUY SL ({final_sl}) below entry ({entry_price_estimate}) due to tick size. Nullifying SL.")
                        final_sl = None
                elif signal == "SELL" and final_sl <= entry_price_estimate:
                    # If SELL SL ended up <= entry, move it one tick above entry
                    corrected_sl = (entry_price_estimate + min_tick).quantize(quantizer, rounding=ROUND_UP)
                    if corrected_sl > entry_price_estimate: # Ensure adjustment is possible
                        self.logger.debug(f"Adjusted SELL SL ({final_sl}) to be above entry: {corrected_sl}")
                        final_sl = corrected_sl
                    else: # Cannot adjust above entry
                        self.logger.warning(f"Could not adjust SELL SL ({final_sl}) above entry ({entry_price_estimate}) due to tick size. Nullifying SL.")
                        final_sl = None
                # Ensure SL didn't become invalid (e.g., negative) after adjustment
                if final_sl is not None and final_sl <= 0:
                     self.logger.error(f"{NEON_RED}Calculated {signal} SL became zero or negative ({final_sl}) after adjustments. Nullifying SL.{RESET}")
                     final_sl = None

            # 2. Ensure TP offers potential profit (strictly beyond entry after rounding)
            if final_tp is not None:
                 if signal == "BUY" and final_tp <= entry_price_estimate:
                     self.logger.warning(f"{NEON_YELLOW}Calculated BUY TP ({final_tp}) is not above entry price ({entry_price_estimate}) after rounding. Nullifying TP.{RESET}")
                     final_tp = None
                 elif signal == "SELL" and final_tp >= entry_price_estimate:
                     self.logger.warning(f"{NEON_YELLOW}Calculated SELL TP ({final_tp}) is not below entry price ({entry_price_estimate}) after rounding. Nullifying TP.{RESET}")
                     final_tp = None
                 # Ensure TP didn't become invalid (e.g., negative)
                 if final_tp is not None and final_tp <= 0:
                      self.logger.warning(f"{NEON_YELLOW}Calculated {signal} TP is zero or negative ({final_tp}). Nullifying TP.{RESET}")
                      final_tp = None

            # 3. Final check: If SL or TP calculation failed, ensure they are None
            if final_sl is not None and (not final_sl.is_finite() or final_sl <= 0): final_sl = None
            if final_tp is not None and (not final_tp.is_finite() or final_tp <= 0): final_tp = None


            # --- Log Results ---
            price_prec = self.get_price_precision_places()
            tp_str = f"{final_tp:.{price_prec}f}" if final_tp else "None"
            sl_str = f"{final_sl:.{price_prec}f}" if final_sl else "None"
            self.logger.info(f"Calculated TP/SL for {signal} {self.symbol}: "
                             f"EntryEst={entry_price_estimate:.{price_prec}f}, ATR={atr_val:.{price_prec+2}f}, "
                             f"Tick={min_tick}, TP={tp_str}, SL={sl_str}")

            return entry_price_estimate, final_tp, final_sl

        except Exception as e:
            self.logger.error(f"{NEON_RED}Unexpected error calculating TP/SL for {signal} {self.symbol}: {e}{RESET}", exc_info=True)
            return entry_price_estimate, None, None

# --- Trading Logic Helper Functions ---

def fetch_balance(exchange: ccxt.Exchange, currency: str, logger: logging.Logger) -> Optional[Decimal]:
    """
    Fetches the *available* balance for a specific currency using CCXT.
    - Handles Bybit V5 account types (prioritizes 'CONTRACT', could be adapted for 'UNIFIED').
    - Parses various possible balance response structures from CCXT.
    - Falls back to using 'total' balance if 'free'/'available' cannot be found (with warning).
    - Converts the balance to Decimal, ensuring it's non-negative and finite.
    - Returns the available balance as Decimal, or None if fetching/parsing fails.

    Args:
        exchange (ccxt.Exchange): Initialized CCXT exchange object.
        currency (str): The currency code (e.g., 'USDT', 'BTC').
        logger (logging.Logger): Logger instance.

    Returns:
        Optional[Decimal]: Available balance as Decimal, or None on failure.
    """
    lg = logger
    balance_info = None
    account_type_tried = "N/A" # Track which account type was queried

    # --- Attempt 1: Fetch with Specific Account Type (Bybit V5 Optimization) ---
    if exchange.id == 'bybit':
        # Determine preferred account type based on exchange's defaultType setting
        # TODO: Add logic to check config for unified account preference if needed (e.g., config['use_unified_account'])
        use_unified = False # Placeholder for unified account config check
        preferred_account_type = 'UNIFIED' if use_unified else 'CONTRACT'
        lg.debug(f"Attempting Bybit V5 balance fetch for {currency} (Account Type: {preferred_account_type})...")
        try:
            params = {'accountType': preferred_account_type}
            balance_info = safe_api_call(exchange.fetch_balance, lg, params=params)
            account_type_tried = preferred_account_type
            lg.debug(f"Raw balance response (Type: {account_type_tried}): {json.dumps(balance_info, default=str, indent=2)}")
        except ccxt.ExchangeError as e:
            err_str = str(e).lower()
            # Handle specific errors indicating the account type might be wrong/unused
            # Bybit code 10001 can sometimes mean wrong account type; 34036 for UTA not enabled
            if "account type does not exist" in err_str or "unified account" in err_str or getattr(e, 'code', None) in [10001, 34036]:
                lg.info(f"Account type '{preferred_account_type}' may not be applicable or enabled. Falling back to default balance fetch for {currency}.")
            else:
                # Log other exchange errors but still try fallback
                lg.warning(f"Exchange error fetching balance with type '{preferred_account_type}' for {currency}: {e}. Falling back.")
            balance_info = None # Ensure fallback is triggered
        except Exception as e: # Catch other potential errors from safe_api_call
             lg.warning(f"Failed fetching balance with type '{preferred_account_type}' for {currency}: {e}. Falling back.")
             balance_info = None

    # --- Attempt 2: Fallback to Default Fetch (if specific type failed or not Bybit) ---
    if balance_info is None:
        lg.debug(f"Fetching balance for {currency} using default parameters...")
        try:
            balance_info = safe_api_call(exchange.fetch_balance, lg)
            account_type_tried = "Default" # Indicate default fetch was used
            lg.debug(f"Raw balance response (Type: {account_type_tried}): {json.dumps(balance_info, default=str, indent=2)}")
        except Exception as e:
            lg.error(f"{NEON_RED}Failed to fetch balance info for {currency} even with default parameters: {e}{RESET}")
            return None # Both attempts failed

    # --- Parse the Balance Information ---
    if not balance_info:
         lg.error(f"Balance fetch (Type: {account_type_tried}) returned empty or None response for {currency}.")
         return None

    free_balance_str = None
    parse_source = "Unknown"

    # --- Parsing Logic (tries various common structures) ---
    # Structure 1: Standard CCXT `balance[currency]['free']` or `balance[currency]['available']`
    if currency in balance_info and isinstance(balance_info.get(currency), dict):
        currency_data = balance_info[currency]
        if currency_data.get('free') is not None:
            free_balance_str = str(currency_data['free'])
            parse_source = f"Standard ['{currency}']['free']"
        elif currency_data.get('available') is not None: # Some exchanges use 'available'
            free_balance_str = str(currency_data['available'])
            parse_source = f"Standard ['{currency}']['available']"

    # Structure 2: Top-level `balance['free'][currency]` or `balance['available'][currency]`
    elif free_balance_str is None and isinstance(balance_info.get('free'), dict) and balance_info['free'].get(currency) is not None:
         free_balance_str = str(balance_info['free'][currency])
         parse_source = f"Top-level ['free']['{currency}']"
    elif free_balance_str is None and isinstance(balance_info.get('available'), dict) and balance_info['available'].get(currency) is not None:
         free_balance_str = str(balance_info['available'][currency])
         parse_source = f"Top-level ['available']['{currency}']"

    # Structure 3: Bybit V5 Specific Parsing (from `info` field) - Often more reliable for V5 details
    elif free_balance_str is None and exchange.id == 'bybit' and isinstance(balance_info.get('info'), dict):
         info_data = balance_info['info']
         # V5 responses often nest results under 'result'
         result_data = info_data.get('result', info_data) # Use result if present, else info itself

         # Check for V5 list structure (common for balance endpoints)
         if isinstance(result_data.get('list'), list) and result_data['list']:
             account_list = result_data['list']
             found_in_list = False
             for account_details in account_list:
                 if not isinstance(account_details, dict): continue # Skip invalid entries

                 # --- Unified Account Parsing (Type: UNIFIED) ---
                 # Unified accounts contain a 'coin' list within the single account entry
                 if account_details.get('accountType') == 'UNIFIED':
                     if isinstance(account_details.get('coin'), list):
                         for coin_data in account_details['coin']:
                             if isinstance(coin_data, dict) and coin_data.get('coin') == currency:
                                  # Prefer availableToWithdraw > availableBalance > walletBalance for usable funds
                                  free = coin_data.get('availableToWithdraw') or coin_data.get('availableBalance') or coin_data.get('walletBalance')
                                  if free is not None:
                                      free_balance_str = str(free)
                                      parse_source = f"Bybit V5 info.result.list[UNIFIED][coin='{currency}']"
                                      found_in_list = True; break # Found currency in unified list
                         if found_in_list: break # Exit outer loop if found

                 # --- Contract Account Parsing (Type: CONTRACT) ---
                 # Contract accounts have balance directly under the account entry, filtered by coin
                 elif account_details.get('accountType') == 'CONTRACT':
                     # Check if the account entry itself has the target currency
                     if account_details.get('coin') == currency:
                          # Prefer availableBalance > walletBalance
                          free = account_details.get('availableBalance') or account_details.get('walletBalance')
                          if free is not None:
                                free_balance_str = str(free)
                                parse_source = f"Bybit V5 info.result.list[CONTRACT][coin='{currency}']"
                                found_in_list = True; break

             # Fallback: If not found via specific type checks, look generically (less reliable)
             if not found_in_list and account_list and isinstance(account_list[0], dict):
                  first_acc = account_list[0]
                  # Check coin list if present in first entry (might be UTA)
                  if isinstance(first_acc.get('coin'), list):
                       for coin_data in first_acc['coin']:
                            if isinstance(coin_data, dict) and coin_data.get('coin') == currency:
                                 free = coin_data.get('availableToWithdraw') or coin_data.get('availableBalance') or coin_data.get('walletBalance')
                                 if free is not None:
                                     free_balance_str = str(free)
                                     parse_source = f"Bybit V5 info.result.list[0][coin='{currency}'] (Fallback Guess)"
                                     found_in_list = True; break
                  # Check direct keys if not in coin list (might be Contract)
                  if not found_in_list and first_acc.get('coin') == currency:
                       free = first_acc.get('availableBalance') or first_acc.get('walletBalance')
                       if free is not None:
                            free_balance_str = str(free)
                            parse_source = f"Bybit V5 info.result.list[0][direct coin='{currency}'] (Fallback Guess)"


         # Alternative V5 Structure: Check if currency is a direct key under 'info' or 'info.result'
         elif free_balance_str is None and isinstance(result_data.get(currency), dict):
              currency_data = result_data[currency]
              # Look for common available balance keys
              free = currency_data.get('available') or currency_data.get('free') or currency_data.get('availableBalance') or currency_data.get('walletBalance')
              if free is not None:
                  free_balance_str = str(free)
                  parse_source = f"Bybit V5 info[.result]['{currency}']"


    # --- Fallback: Use 'total' balance if 'free'/'available' couldn't be found ---
    if free_balance_str is None:
         total_balance_str = None
         parse_source_total = "Unknown Total"
         # Check standard structures for 'total'
         if currency in balance_info and isinstance(balance_info.get(currency), dict) and balance_info[currency].get('total') is not None:
             total_balance_str = str(balance_info[currency]['total'])
             parse_source_total = f"Standard ['{currency}']['total']"
         elif isinstance(balance_info.get('total'), dict) and balance_info['total'].get(currency) is not None:
             total_balance_str = str(balance_info['total'][currency])
             parse_source_total = f"Top-level ['total']['{currency}']"
         # Add V5 'total' parsing from info if needed (e.g., check 'walletBalance')
         elif exchange.id == 'bybit' and isinstance(balance_info.get('info'), dict):
             info_data = balance_info['info']
             result_data = info_data.get('result', info_data)
             if isinstance(result_data.get('list'), list) and result_data['list']:
                 for account_details in result_data['list']:
                     if not isinstance(account_details, dict): continue
                     # Unified
                     if account_details.get('accountType') == 'UNIFIED' and isinstance(account_details.get('coin'), list):
                         for coin_data in account_details['coin']:
                             if isinstance(coin_data, dict) and coin_data.get('coin') == currency and coin_data.get('walletBalance') is not None:
                                 total_balance_str = str(coin_data['walletBalance'])
                                 parse_source_total = f"Bybit V5 info.result.list[UNIFIED][coin='{currency}']['walletBalance']"
                                 break
                     # Contract
                     elif account_details.get('accountType') == 'CONTRACT' and account_details.get('coin') == currency and account_details.get('walletBalance') is not None:
                         total_balance_str = str(account_details['walletBalance'])
                         parse_source_total = f"Bybit V5 info.result.list[CONTRACT][coin='{currency}']['walletBalance']"
                         break
                     if total_balance_str: break

         if total_balance_str is not None:
              lg.warning(f"{NEON_YELLOW}Could not find 'free' or 'available' balance for {currency}. Using 'total' balance ({total_balance_str}) as fallback ({parse_source_total})."
                         f" Note: 'total' may include collateral or unrealized PNL and might not be fully available for new trades.{RESET}")
              free_balance_str = total_balance_str
              parse_source = parse_source_total + " (Fallback)"
         else:
              # If even 'total' couldn't be found, log error and return None
              lg.error(f"{NEON_RED}Could not determine any balance ('free', 'available', or 'total') for {currency} after checking known structures (Account Type Searched: {account_type_tried}).{RESET}")
              lg.debug(f"Full balance_info structure: {json.dumps(balance_info, default=str)}")
              return None

    # --- Convert the Found Balance String to Decimal ---
    try:
        # Handle potential empty string if parsing failed somehow
        if not free_balance_str:
            raise ValueError("Parsed balance string is empty")
        final_balance = Decimal(free_balance_str)
        # Validate the converted Decimal value
        if not final_balance.is_finite():
             lg.warning(f"Parsed balance for {currency} ('{free_balance_str}' from {parse_source}) resulted in a non-finite Decimal. Treating as zero.")
             final_balance = Decimal('0')
        # Treat negative available balance as zero for trading decisions
        if final_balance < 0:
             lg.warning(f"Parsed available balance for {currency} ('{free_balance_str}' from {parse_source}) is negative. Treating as zero available.")
             final_balance = Decimal('0')

        lg.info(f"Available {currency} balance determined (Source: {parse_source}, AccType Searched: {account_type_tried}): {final_balance:.4f}") # Adjust precision as needed
        return final_balance
    except (ValueError, TypeError, InvalidOperation) as e:
        lg.error(f"{NEON_RED}Failed to convert final balance string '{free_balance_str}' (from {parse_source}) to Decimal for {currency}: {e}{RESET}")
        return None


def get_market_info(exchange: ccxt.Exchange, symbol: str, logger: logging.Logger) -> Optional[Dict]:
    """
    Retrieves the market information dictionary for a specific symbol from CCXT.
    - Ensures exchange markets are loaded first.
    - Handles cases where the symbol is not found.
    - Adds convenient boolean flags (is_contract, is_linear, is_inverse, is_spot)
      to the returned dictionary for easier logic elsewhere.
    - Infers linear/inverse status if not explicitly provided, based on defaultType and quote currency.
    - Logs key market details and checks if the market is active.

    Args:
        exchange (ccxt.Exchange): Initialized CCXT exchange object.
        symbol (str): The trading symbol (e.g., 'BTC/USDT:USDT').
        logger (logging.Logger): Logger instance.

    Returns:
        Optional[Dict]: The CCXT market dictionary augmented with convenience flags,
                        or None if market info cannot be retrieved or is invalid.
    """
    lg = logger
    try:
        # --- Ensure Markets Are Loaded ---
        # Crucial step, as market info is needed for almost all operations
        if not exchange.markets or not exchange.markets_by_id: # Check both for robustness
             lg.info(f"Markets not loaded for {exchange.id}. Attempting explicit load...")
             try:
                 # Use safe_api_call to load markets robustly
                 safe_api_call(exchange.load_markets, lg, reload=True) # Force reload
                 lg.info(f"Markets reloaded successfully ({len(exchange.symbols)} symbols found).")
                 # Double-check if markets are populated now
                 if not exchange.markets:
                      lg.error(f"{NEON_RED}Market loading appeared successful but exchange.markets is still empty! Cannot proceed.{RESET}")
                      return None
             except Exception as load_err:
                  lg.error(f"{NEON_RED}Failed to load markets after retries: {load_err}. Cannot get market info for {symbol}.{RESET}")
                  return None # Market loading failed, cannot proceed

        # --- Retrieve Market Dictionary ---
        # Use exchange.market() which handles lookup by symbol, id, etc.
        market = exchange.market(symbol)
        if not market or not isinstance(market, dict):
             lg.error(f"{NEON_RED}Market '{symbol}' not found in CCXT's loaded markets for {exchange.id}.{RESET}")
             # Provide hint for common Bybit V5 linear format if applicable
             if '/' in symbol and ':' not in symbol and exchange.id == 'bybit':
                  base, quote = symbol.split('/')[:2]
                  suggested_symbol = f"{base}/{quote}:{quote}"
                  lg.warning(f"{NEON_YELLOW}Hint: For Bybit V5 linear perpetuals, check format like '{suggested_symbol}'.{RESET}")
             return None

        # --- Add Convenience Flags for Easier Logic ---
        # Create a copy to avoid modifying the cached market object
        market_copy = market.copy()

        # Use .get() with defaults for safety in case keys are missing
        market_type = market_copy.get('type', '').lower() # e.g., 'spot', 'swap', 'future'
        is_spot = (market_type == 'spot')
        is_swap = (market_type == 'swap') # Typically perpetual swaps
        is_future = (market_type == 'future') # Typically dated futures
        # General contract flag (covers swap, future, or explicit 'contract' flag)
        is_contract = is_swap or is_future or market_copy.get('contract', False)

        # Determine Linear vs. Inverse (Crucial for contract sizing and PNL)
        # Check explicit flags first
        is_linear = market_copy.get('linear', False)
        is_inverse = market_copy.get('inverse', False)
        # Check settle currency type for confirmation (Bybit V5)
        settle_id = market_copy.get('settleId', '').upper()
        if settle_id in ['USDT', 'USDC', 'USD']: is_linear = True
        elif settle_id and settle_id != 'USD': is_inverse = True # If settle is crypto (BTC, ETH), it's inverse

        # --- Infer Linear/Inverse if still unclear ---
        if is_contract and not is_linear and not is_inverse:
            lg.debug(f"Market {symbol} is contract but linear/inverse flag not explicit or derivable from settleId. Inferring...")
            # 1. Check defaultType set during exchange initialization
            default_type = exchange.options.get('defaultType', '').lower()
            if default_type == 'linear':
                 is_linear = True
                 lg.debug(f" > Inferred Linear based on exchange defaultType.")
            elif default_type == 'inverse':
                 is_inverse = True
                 lg.debug(f" > Inferred Inverse based on exchange defaultType.")
            else:
                 # 2. Fallback: Infer based on quote currency (less reliable but common pattern)
                 quote_id = market_copy.get('quoteId', '').upper()
                 if quote_id in ['USD']: # Typically USD-margined are inverse
                     is_inverse = True
                     lg.debug(f" > Inferred Inverse based on quote currency '{quote_id}'.")
                 elif quote_id in ['USDT', 'USDC', 'BUSD', 'DAI']: # Stablecoin-margined are usually linear
                     is_linear = True
                     lg.
```python
# sxs.py
# Enhanced and Upgraded Scalping Bot Framework
# Derived from xrscalper.py, focusing on robust execution, error handling,
# advanced position management (BE, TSL), and Bybit V5 compatibility.

# Standard Library Imports
import hashlib
import hmac
import json
import logging
import math
import os
import time
from datetime import datetime, timedelta, timezone
from decimal import ROUND_DOWN, ROUND_UP, Decimal, InvalidOperation, getcontext
from logging.handlers import RotatingFileHandler
from typing import Any, Dict, List, Optional, Tuple, Union
from zoneinfo import ZoneInfo # Use zoneinfo for modern timezone handling

# Third-Party Imports
import ccxt # Exchange interaction library
import numpy as np # Numerical operations, used for NaN and jitter
import pandas as pd # Data manipulation and analysis
import pandas_ta as ta # Technical analysis library built on pandas
import requests # Used by ccxt for HTTP requests
from colorama import Fore, Style, init # Colored terminal output
from dotenv import load_dotenv # Loading environment variables

# --- Initialization ---
init(autoreset=True) # Ensure colorama resets styles automatically
load_dotenv() # Load environment variables from .env file (e.g., API keys)

# Set Decimal precision (high precision for financial calculations)
# Trade-off: Higher precision reduces potential rounding errors in complex calculations
# but might slightly impact performance. 36 is generally very high for crypto.
getcontext().prec = 36

# --- Neon Color Scheme (for console logging enhancement) ---
NEON_GREEN = Fore.LIGHTGREEN_EX
NEON_BLUE = Fore.CYAN
NEON_PURPLE = Fore.MAGENTA
NEON_YELLOW = Fore.YELLOW
NEON_RED = Fore.LIGHTRED_EX
NEON_CYAN = Fore.CYAN
RESET = Style.RESET_ALL

# --- Constants ---
# API Keys loaded from environment variables
API_KEY = os.getenv("BYBIT_API_KEY")
API_SECRET = os.getenv("BYBIT_API_SECRET")
# Critical check: Ensure API keys are present before proceeding
if not API_KEY or not API_SECRET:
    # Use a basic logger setup for this critical startup error as full logging isn't ready yet
    logging.basicConfig(level=logging.CRITICAL, format='%(levelname)s: %(message)s')
    logging.critical(f"{NEON_RED}CRITICAL: BYBIT_API_KEY and BYBIT_API_SECRET must be set in .env file.{RESET}")
    raise ValueError("BYBIT_API_KEY and BYBIT_API_SECRET environment variables are not set.")

CONFIG_FILE = "config.json" # Name of the configuration file
LOG_DIRECTORY = "bot_logs" # Directory to store log files
# Ensure the log directory exists early in the script execution
os.makedirs(LOG_DIRECTORY, exist_ok=True)

# Default Timezone (will be overridden by config if specified)
# Using IANA timezone database names (e.g., "America/Chicago", "Europe/London", "UTC")
# https://en.wikipedia.org/wiki/List_of_tz_database_time_zones
DEFAULT_TIMEZONE = ZoneInfo("America/Chicago")
TIMEZONE = DEFAULT_TIMEZONE # Global variable updated by load_config

# API Retry Settings (defaults, can be overridden by config)
MAX_API_RETRIES = 5 # Default maximum number of retries for failed API calls
RETRY_DELAY_SECONDS = 7 # Default base delay between retries (increases exponentially)
# HTTP status codes considered generally retryable for network/server issues
RETRYABLE_HTTP_CODES = [429, 500, 502, 503, 504]

# Valid Timeframes for Data Fetching
VALID_INTERVALS = ["1", "3", "5", "15", "30", "60", "120", "240", "D", "W", "M"]
# Mapping between internal interval notation and CCXT's timeframe notation
CCXT_INTERVAL_MAP = {
    "1": "1m", "3": "3m", "5": "5m", "15": "15m", "30": "30m",
    "60": "1h", "120": "2h", "240": "4h", "D": "1d", "W": "1w", "M": "1M"
}

# Default Indicator Periods (can be overridden by config.json) - Using standardized names
DEFAULT_ATR_PERIOD = 14
DEFAULT_CCI_PERIOD = 20
DEFAULT_WILLIAMS_R_PERIOD = 14
DEFAULT_MFI_PERIOD = 14
DEFAULT_STOCH_RSI_PERIOD = 14
DEFAULT_STOCH_RSI_RSI_PERIOD = 14 # Underlying RSI period for StochRSI
DEFAULT_STOCH_RSI_K_PERIOD = 3
DEFAULT_STOCH_RSI_D_PERIOD = 3
DEFAULT_RSI_PERIOD = 14
DEFAULT_BBANDS_PERIOD = 20
DEFAULT_BBANDS_STDDEV = 2.0
DEFAULT_SMA10_PERIOD = 10
DEFAULT_EMA_SHORT_PERIOD = 9
DEFAULT_EMA_LONG_PERIOD = 21
DEFAULT_MOMENTUM_PERIOD = 7
DEFAULT_VOLUME_MA_PERIOD = 15
DEFAULT_FIB_PERIOD = 50 # Lookback period for Fibonacci High/Low
DEFAULT_PSAR_STEP = 0.02
DEFAULT_PSAR_MAX_STEP = 0.2

FIB_LEVELS = [0.0, 0.236, 0.382, 0.5, 0.618, 0.786, 1.0] # Standard Fibonacci retracement levels
LOOP_DELAY_SECONDS = 10 # Default minimum time between main loop cycles (end of one to start of next)
POSITION_CONFIRM_DELAY_SECONDS = 10 # Default wait time after placing an order before confirming position status

# Global config dictionary, loaded by load_config
config: Dict[str, Any] = {}

# --- Configuration Loading & Validation ---
class SensitiveFormatter(logging.Formatter):
    """
    Custom logging formatter to redact sensitive information (like API keys/secrets)
    from log messages before they are written.
    """
    # Cache patterns for a minor performance gain, avoids recompiling regex implicitly
    _patterns = {}

    def format(self, record: logging.LogRecord) -> str:
        """Formats the log record and redacts sensitive data."""
        # Format the original message using the parent class formatter
        msg = super().format(record)

        # Redact API Key if present and pattern cached/created
        if API_KEY:
            if API_KEY not in self._patterns:
                # Simple replacement, not regex needed here
                self._patterns[API_KEY] = "***API_KEY***"
            if API_KEY in msg:
                msg = msg.replace(API_KEY, self._patterns[API_KEY])

        # Redact API Secret if present and pattern cached/created
        if API_SECRET:
            if API_SECRET not in self._patterns:
                self._patterns[API_SECRET] = "***API_SECRET***"
            if API_SECRET in msg:
                msg = msg.replace(API_SECRET, self._patterns[API_SECRET])

        return msg

def load_config(filepath: str) -> Dict[str, Any]:
    """
    Loads configuration from a JSON file.
    - Creates a default configuration file if it doesn't exist.
    - Merges loaded configuration with defaults to ensure all keys are present.
    - Validates configuration parameters against types, ranges, and allowed values.
    - Resets invalid parameters to their defaults and logs warnings.
    - Saves the updated (merged, validated) configuration back to the file if changes occurred.
    - Updates the global `TIMEZONE` variable based on the validated config.

    Args:
        filepath (str): The path to the configuration JSON file.

    Returns:
        Dict[str, Any]: The validated configuration dictionary.
    """
    global TIMEZONE # Allow modification of the global timezone variable

    # Define the default configuration structure and values
    default_config = {
        # --- Trading Pair & Timeframe ---
        "symbol": "BTC/USDT:USDT", # Example for Bybit linear perpetual
        "interval": "5", # Default timeframe (e.g., "5" for 5 minutes)

        # --- API & Bot Behavior ---
        "retry_delay": RETRY_DELAY_SECONDS, # Base delay between API retries (seconds)
        "max_api_retries": MAX_API_RETRIES, # Max retries for API calls
        "enable_trading": False, # CRITICAL SAFETY FEATURE: Must be explicitly True to execute live trades.
        "use_sandbox": True, # CRITICAL SAFETY FEATURE: Connects to exchange testnet by default.
        "max_concurrent_positions": 1, # Max open positions allowed simultaneously for this specific symbol instance.
        "quote_currency": "USDT", # Quote currency (used for balance checks, sizing). Ensure it matches the symbol's quote asset.
        "position_confirm_delay_seconds": POSITION_CONFIRM_DELAY_SECONDS, # Wait time after order placement before checking position status.
        "loop_delay_seconds": LOOP_DELAY_SECONDS, # Minimum delay between main loop cycles.
        "timezone": "America/Chicago", # IANA timezone name for local time display in console logs.

        # --- Risk Management ---
        "risk_per_trade": 0.01, # Fraction of available balance to risk per trade (e.g., 0.01 = 1%).
        "leverage": 20, # Desired leverage multiplier. Ensure it's supported by the exchange/market and within safe limits.
        "stop_loss_multiple": 1.8, # ATR multiple for calculating the initial Stop Loss distance.
        "take_profit_multiple": 0.7, # ATR multiple for calculating the initial Take Profit distance.

        # --- Order Execution ---
        "entry_order_type": "market", # Type of order for entry: "market" or "limit".
        "limit_order_offset_buy": 0.0005, # For limit entries: Percentage offset from the target price for BUY orders (0.0005 = 0.05%). Price = Target * (1 - Offset)
        "limit_order_offset_sell": 0.0005, # For limit entries: Percentage offset from the target price for SELL orders (0.0005 = 0.05%). Price = Target * (1 + Offset)

        # --- Advanced Position Management ---
        "enable_trailing_stop": True, # Enable exchange-native Trailing Stop Loss (Requires exchange support, e.g., Bybit V5).
        # IMPORTANT (Bybit V5 TSL): TSL uses PRICE DISTANCE, not percentage.
        # 'callback_rate' is used here to *calculate* that price distance based on the activation price.
        "trailing_stop_callback_rate": 0.005, # Percentage (0.005 = 0.5%) used to calculate the trail distance from the *activation price*. Distance = ActivationPrice * CallbackRate.
        "trailing_stop_activation_percentage": 0.003, # Profit percentage (0.003 = 0.3%) move from entry price needed to trigger calculation of TSL activation price. ActivationPrice = Entry +/- (Entry * Activation%)
        "enable_break_even": True, # Enable moving Stop Loss to break-even point once profit target is hit.
        "break_even_trigger_atr_multiple": 1.0, # Move SL to break-even when profit reaches (ATR * this multiple).
        "break_even_offset_ticks": 2, # Place the break-even SL slightly beyond the entry price (in number of ticks) to cover potential fees/slippage.

        "time_based_exit_minutes": None, # Optional: Exit position automatically after specified minutes (e.g., 120 for 2 hours). Set to null or None to disable.

        # --- Indicator Periods & Parameters (Defaults defined above) ---
        "atr_period": DEFAULT_ATR_PERIOD,
        "ema_short_period": DEFAULT_EMA_SHORT_PERIOD,
        "ema_long_period": DEFAULT_EMA_LONG_PERIOD,
        "rsi_period": DEFAULT_RSI_PERIOD,
        "bollinger_bands_period": DEFAULT_BBANDS_PERIOD,
        "bollinger_bands_std_dev": DEFAULT_BBANDS_STDDEV,
        "cci_period": DEFAULT_CCI_PERIOD,
        "williams_r_period": DEFAULT_WILLIAMS_R_PERIOD,
        "mfi_period": DEFAULT_MFI_PERIOD,
        "stoch_rsi_period": DEFAULT_STOCH_RSI_PERIOD,
        "stoch_rsi_rsi_period": DEFAULT_STOCH_RSI_RSI_PERIOD,
        "stoch_rsi_k_period": DEFAULT_STOCH_RSI_K_PERIOD,
        "stoch_rsi_d_period": DEFAULT_STOCH_RSI_D_PERIOD,
        "psar_step": DEFAULT_PSAR_STEP,
        "psar_max_step": DEFAULT_PSAR_MAX_STEP,
        "sma_10_period": DEFAULT_SMA10_PERIOD,
        "momentum_period": DEFAULT_MOMENTUM_PERIOD,
        "volume_ma_period": DEFAULT_VOLUME_MA_PERIOD,
        "fibonacci_period": DEFAULT_FIB_PERIOD, # Lookback for Fib High/Low

        # --- Indicator Calculation & Scoring Control ---
        "orderbook_limit": 25, # Number of order book levels to fetch and analyze. Check exchange limits (Bybit V5 linear: up to 200).
        "signal_score_threshold": 1.5, # Minimum absolute weighted score required to trigger a BUY or SELL signal.
        "stoch_rsi_oversold_threshold": 25, # StochRSI level below which it's considered oversold (influences score).
        "stoch_rsi_overbought_threshold": 75, # StochRSI level above which it's considered overbought (influences score).
        "volume_confirmation_multiplier": 1.5, # Minimum ratio of current volume to Volume MA required for positive volume confirmation score.
        "indicators": { # Toggle calculation and scoring contribution for each indicator
            # Key names MUST match _check_<key> methods and weight_sets keys
            "ema_alignment": True, "momentum": True, "volume_confirmation": True,
            "stoch_rsi": True, "rsi": True, "bollinger_bands": True, "vwap": True,
            "cci": True, "wr": True, "psar": True, "sma_10": True, "mfi": True,
            "orderbook": True,
            # Add new indicators here and ensure corresponding _check_ method and weight entries exist
        },
        "weight_sets": { # Define different scoring weights for various strategies
            "scalping": { # Example: Faster signals, momentum-focused
                "ema_alignment": 0.2, "momentum": 0.3, "volume_confirmation": 0.2,
                "stoch_rsi": 0.6, "rsi": 0.2, "bollinger_bands": 0.3, "vwap": 0.4,
                "cci": 0.3, "wr": 0.3, "psar": 0.2, "sma_10": 0.1, "mfi": 0.2, "orderbook": 0.15,
            },
            "default": { # Example: Balanced approach
                "ema_alignment": 0.3, "momentum": 0.2, "volume_confirmation": 0.1,
                "stoch_rsi": 0.4, "rsi": 0.3, "bollinger_bands": 0.2, "vwap": 0.3,
                "cci": 0.2, "wr": 0.2, "psar": 0.3, "sma_10": 0.1, "mfi": 0.2, "orderbook": 0.1,
            }
            # Ensure keys here match keys in "indicators" and correspond to _check_ methods
        },
        "active_weight_set": "default" # Selects which weight set from "weight_sets" to use for scoring.
    }

    current_config = default_config.copy() # Start with default values
    config_loaded_successfully = False
    needs_saving = False # Flag to track if the config file needs to be updated/saved

    # --- Load Existing Config (if exists) ---
    if os.path.exists(filepath):
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                loaded_config = json.load(f)
            # Merge loaded config over defaults, ensuring all default keys exist in the final config
            merged_config = _merge_configs(loaded_config, default_config)
            print(f"{NEON_GREEN}Loaded configuration from {filepath}{RESET}")
            config_loaded_successfully = True
            # Check if merge resulted in changes (e.g., new defaults added)
            if merged_config != loaded_config: # Compare merged vs originally loaded
                needs_saving = True
                print(f"{NEON_YELLOW}Configuration merged with new defaults/structure.{RESET}")
            current_config = merged_config # Use the merged config for validation

        except (json.JSONDecodeError, IOError) as e:
            print(f"{NEON_RED}Error loading config file {filepath}: {e}. Using default config.{RESET}")
            current_config = default_config # Fallback to default
            needs_saving = True # Need to save the default config
        except Exception as e:
             print(f"{NEON_RED}Unexpected error loading config {filepath}: {e}. Using default config.{RESET}")
             current_config = default_config
             needs_saving = True
    else:
        # Config file doesn't exist, create it using defaults
        print(f"{NEON_YELLOW}Config file not found. Creating default config at {filepath}{RESET}")
        current_config = default_config
        needs_saving = True

    # --- Validation Section ---
    # Work with the 'current_config' (which is either loaded+merged or default)
    original_config_before_validation = current_config.copy() # Keep a copy to check if validation modified anything

    # Helper function for validating parameters, logging errors, and resetting to default
    def validate_param(key, default_value, validation_func, error_msg_format):
        """Validates a config key, resets to default if invalid, and returns original validity."""
        is_valid = False
        current_value = current_config.get(key)
        try:
            if key in current_config and validation_func(current_value):
                is_valid = True # Value exists and passes validation
            else:
                # Reset to default if key is missing or validation fails
                current_config[key] = default_value
                # Format error message safely, using repr() for potentially complex values
                value_repr = repr(current_value) if current_value is not None else 'None'
                print(f"{NEON_RED}{error_msg_format.format(key=key, value=value_repr, default=default_value)}{RESET}")
                # Needs saving because we changed the value
                nonlocal needs_saving
                needs_saving = True
        except Exception as validation_err:
            # Catch errors *within* the validation function itself
            print(f"{NEON_RED}Error validating config key '{key}' (Value: {repr(current_value)}): {validation_err}. Resetting to default '{default_value}'.{RESET}")
            current_config[key] = default_value
            needs_saving = True
        return is_valid

    # --- Validate Core Parameters ---
    validate_param("symbol", default_config["symbol"],
                   lambda v: isinstance(v, str) and v.strip(),
                   "CRITICAL: Config key '{key}' is missing, empty, or invalid ({value}). Resetting to default: '{default}'. Check symbol format.")

    validate_param("interval", default_config["interval"],
                   lambda v: v in VALID_INTERVALS,
                   "Invalid interval '{value}' in config for '{key}'. Resetting to default '{default}'. Valid: " + ", ".join(VALID_INTERVALS) + ".")

    validate_param("entry_order_type", default_config["entry_order_type"],
                   lambda v: v in ["market", "limit"],
                   "Invalid entry_order_type '{value}' for '{key}'. Must be 'market' or 'limit'. Resetting to default '{default}'.")

    validate_param("quote_currency", default_config["quote_currency"],
                   lambda v: isinstance(v, str) and len(v) >= 3 and v.isupper(), # Basic sanity check
                   "Invalid quote_currency '{value}' for '{key}'. Should be uppercase currency code (e.g., USDT). Resetting to '{default}'.")

    # Validate timezone and update global TIMEZONE constant
    try:
        tz_str = current_config.get("timezone", default_config["timezone"])
        if not isinstance(tz_str, str): raise TypeError("Timezone must be a string")
        tz_info = ZoneInfo(tz_str) # This raises ZoneInfoNotFoundError if invalid
        current_config["timezone"] = tz_str # Store the validated string
        TIMEZONE = tz_info # Update the global constant for use elsewhere
    except Exception as tz_err:
        print(f"{NEON_RED}Invalid timezone '{tz_str}' in config: {tz_err}. Resetting to default '{default_config['timezone']}'.{RESET}")
        current_config["timezone"] = default_config["timezone"]
        TIMEZONE = ZoneInfo(default_config["timezone"]) # Reset global to default
        needs_saving = True

    # Validate active weight set exists in the 'weight_sets' dictionary
    validate_param("active_weight_set", default_config["active_weight_set"],
                   lambda v: isinstance(v, str) and v in current_config.get("weight_sets", {}),
                   "Active weight set '{value}' for '{key}' not found in 'weight_sets' section. Resetting to '{default}'.")

    # --- Validate Numeric Parameters (using Decimal for range checks) ---
    # Format: key: (min_val, max_val, allow_min_equal, allow_max_equal, requires_integer, default_val)
    numeric_params = {
        "risk_per_trade": (0, 1, False, False, False, default_config["risk_per_trade"]), # Exclusive bounds 0-1
        "leverage": (1, 1000, True, True, True, default_config["leverage"]), # Realistic max leverage, must be int
        "stop_loss_multiple": (0, float('inf'), False, True, False, default_config["stop_loss_multiple"]), # Must be > 0
        "take_profit_multiple": (0, float('inf'), False, True, False, default_config["take_profit_multiple"]), # Must be > 0
        "trailing_stop_callback_rate": (0, 1, False, False, False, default_config["trailing_stop_callback_rate"]), # Exclusive bounds 0-1
        "trailing_stop_activation_percentage": (0, 1, True, False, False, default_config["trailing_stop_activation_percentage"]), # Allow 0%, must be < 1
        "break_even_trigger_atr_multiple": (0, float('inf'), False, True, False, default_config["break_even_trigger_atr_multiple"]), # Must be > 0
        "break_even_offset_ticks": (0, 1000, True, True, True, default_config["break_even_offset_ticks"]), # Must be int >= 0
        "signal_score_threshold": (0, float('inf'), False, True, False, default_config["signal_score_threshold"]), # Must be > 0
        "atr_period": (2, 1000, True, True, True, default_config["atr_period"]), # Min 2 for ATR calc
        "ema_short_period": (1, 1000, True, True, True, default_config["ema_short_period"]),
        "ema_long_period": (1, 1000, True, True, True, default_config["ema_long_period"]),
        "rsi_period": (2, 1000, True, True, True, default_config["rsi_period"]), # Min 2 for RSI calc
        "bollinger_bands_period": (2, 1000, True, True, True, default_config["bollinger_bands_period"]),
        "bollinger_bands_std_dev": (0, 10, False, True, False, default_config["bollinger_bands_std_dev"]), # Must be > 0
        "cci_period": (2, 1000, True, True, True, default_config["cci_period"]), # Typical min period
        "williams_r_period": (2, 1000, True, True, True, default_config["williams_r_period"]),
        "mfi_period": (2, 1000, True, True, True, default_config["mfi_period"]),
        "stoch_rsi_period": (2, 1000, True, True, True, default_config["stoch_rsi_period"]),
        "stoch_rsi_rsi_period": (2, 1000, True, True, True, default_config["stoch_rsi_rsi_period"]),
        "stoch_rsi_k_period": (1, 1000, True, True, True, default_config["stoch_rsi_k_period"]),
        "stoch_rsi_d_period": (1, 1000, True, True, True, default_config["stoch_rsi_d_period"]),
        "psar_step": (0, 1, False, True, False, default_config["psar_step"]), # Must be > 0
        "psar_max_step": (0, 1, False, True, False, default_config["psar_max_step"]), # Must be > 0
        "sma_10_period": (1, 1000, True, True, True, default_config["sma_10_period"]),
        "momentum_period": (1, 1000, True, True, True, default_config["momentum_period"]),
        "volume_ma_period": (1, 1000, True, True, True, default_config["volume_ma_period"]),
        "fibonacci_period": (2, 1000, True, True, True, default_config["fibonacci_period"]), # Needs at least 2 bars
        "orderbook_limit": (1, 200, True, True, True, default_config["orderbook_limit"]), # Bybit V5 linear max is 200
        "position_confirm_delay_seconds": (0, 120, True, True, False, default_config["position_confirm_delay_seconds"]), # Allow 0 delay
        "loop_delay_seconds": (1, 300, True, True, False, default_config["loop_delay_seconds"]),
        "stoch_rsi_oversold_threshold": (0, 100, True, False, False, default_config["stoch_rsi_oversold_threshold"]), # Must be < 100
        "stoch_rsi_overbought_threshold": (0, 100, False, True, False, default_config["stoch_rsi_overbought_threshold"]), # Must be > 0
        "volume_confirmation_multiplier": (0, float('inf'), False, True, False, default_config["volume_confirmation_multiplier"]), # Must be > 0
        "limit_order_offset_buy": (0, 0.1, True, False, False, default_config["limit_order_offset_buy"]), # 0% to 10% offset seems reasonable
        "limit_order_offset_sell": (0, 0.1, True, False, False, default_config["limit_order_offset_sell"]),
        "retry_delay": (1, 120, True, True, False, default_config["retry_delay"]),
        "max_api_retries": (0, 10, True, True, True, default_config["max_api_retries"]), # Must be int >= 0
        "max_concurrent_positions": (1, 10, True, True, True, default_config["max_concurrent_positions"]), # Must be int >= 1
    }
    for key, (min_val, max_val, allow_min, allow_max, is_integer, default_val) in numeric_params.items():
        value = current_config.get(key)
        param_is_valid = False
        if value is not None:
            try:
                val_dec = Decimal(str(value)) # Convert to Decimal for reliable checks
                if not val_dec.is_finite(): raise ValueError("Value not finite")

                # Check bounds using Decimal comparison
                min_dec = Decimal(str(min_val))
                max_dec = Decimal(str(max_val))
                lower_bound_ok = (val_dec >= min_dec) if allow_min else (val_dec > min_dec)
                upper_bound_ok = (val_dec <= max_dec) if allow_max else (val_dec < max_dec)

                if lower_bound_ok and upper_bound_ok:
                    # Convert to final type (int or float) after successful validation
                    if is_integer:
                        # Check if it's actually an integer before converting
                        if val_dec == val_dec.to_integral_value():
                            final_value = int(val_dec)
                            current_config[key] = final_value # Store validated integer
                            param_is_valid = True
                        else:
                            raise ValueError("Non-integer value provided for integer parameter")
                    else:
                        final_value = float(val_dec) # Store as float if not integer required
                        current_config[key] = final_value
                        param_is_valid = True
                # else: Bounds check failed, param_is_valid remains False
            except (ValueError, TypeError, InvalidOperation):
                 pass # Invalid format or failed conversion/checks, param_is_valid remains False

        if not param_is_valid:
            # Use validate_param to log error and reset to default
            bound_str = f"{'>' if not allow_min else '>='} {min_val} and {'<' if not allow_max else '<='} {max_val}"
            type_str = 'integer' if is_integer else 'number'
            err_msg = f"Invalid value for '{{key}}' ({{value}}). Must be a {type_str} ({bound_str}). Resetting to default '{{default}}'."
            validate_param(key, default_val, lambda v: False, err_msg) # Force reset and log

    # Specific validation for time_based_exit_minutes (allows None or positive number)
    time_exit_key = "time_based_exit_minutes"
    time_exit_value = current_config.get(time_exit_key)
    time_exit_valid = False
    if time_exit_value is None:
        time_exit_valid = True # None is valid
    else:
        try:
            time_exit_float = float(time_exit_value)
            if time_exit_float > 0 and np.isfinite(time_exit_float):
                 current_config[time_exit_key] = time_exit_float # Store validated float
                 time_exit_valid = True
            else: raise ValueError("Must be positive and finite if set")
        except (ValueError, TypeError):
            pass # Invalid format or non-positive/non-finite

    if not time_exit_valid:
         validate_param(time_exit_key, default_config[time_exit_key], lambda v: False, # Force reset
                        "Invalid value for '{{key}}' ({{value}}). Must be 'None' or a positive number. Resetting to default ('{{default}}').")

    # --- Validate Boolean Parameters ---
    bool_params = ["enable_trading", "use_sandbox", "enable_trailing_stop", "enable_break_even"]
    for key in bool_params:
         validate_param(key, default_config[key], lambda v: isinstance(v, bool),
                        "Invalid value for '{{key}}' ({{value}}). Must be boolean (true/false). Resetting to default '{{default}}'.")

    # --- Validate Indicator Enable Flags (must exist in defaults and be boolean) ---
    indicators_key = 'indicators'
    if indicators_key in current_config and isinstance(current_config[indicators_key], dict):
        indicators_dict = current_config[indicators_key]
        default_indicators = default_config[indicators_key]
        keys_to_remove = [] # Collect unknown keys to remove later
        for ind_key, ind_val in indicators_dict.items():
            # Check if key exists in default config (prevents unknown indicators)
            if ind_key not in default_indicators:
                print(f"{NEON_YELLOW}Warning: Unknown key '{ind_key}' found in '{indicators_key}' section. It will be removed.{RESET}")
                keys_to_remove.append(ind_key)
                needs_saving = True
                continue
            # Validate value is boolean
            if not isinstance(ind_val, bool):
                default_ind_val = default_indicators.get(ind_key, False) # Should exist, but safety fallback
                print(f"{NEON_RED}Invalid value for '{indicators_key}.{ind_key}' ({repr(ind_val)}). Must be boolean (true/false). Resetting to default '{default_ind_val}'.{RESET}")
                indicators_dict[ind_key] = default_ind_val
                needs_saving = True
        # Remove unknown keys outside the loop
        for r_key in keys_to_remove: del indicators_dict[r_key]
    else:
        # If 'indicators' key is missing or not a dict, reset to default
        print(f"{NEON_RED}Invalid or missing '{indicators_key}' section in config. Resetting to default.{RESET}")
        current_config[indicators_key] = default_config[indicators_key].copy() # Use copy of default
        needs_saving = True

    # --- Validate Weight Sets Structure and Values ---
    ws_key = "weight_sets"
    if ws_key in current_config and isinstance(current_config[ws_key], dict):
        weight_sets = current_config[ws_key]
        default_indicators_keys = default_config['indicators'].keys() # Get valid indicator keys
        sets_to_remove = []
        for set_name, weights in weight_sets.items():
            if not isinstance(weights, dict):
                 print(f"{NEON_RED}Invalid structure for weight set '{set_name}' (must be a dictionary of indicator:weight pairs). Removing this set.{RESET}")
                 sets_to_remove.append(set_name)
                 needs_saving = True
                 continue

            weights_to_remove = []
            for ind_key, weight_val in weights.items():
                # Ensure weight key matches a known indicator key
                if ind_key not in default_indicators_keys:
                    print(f"{NEON_YELLOW}Warning: Weight defined for unknown/invalid indicator '{ind_key}' in weight set '{set_name}'. Removing this weight entry.{RESET}")
                    weights_to_remove.append(ind_key)
                    needs_saving = True
                    continue

                # Validate weight value is numeric and non-negative
                try:
                    weight_dec = Decimal(str(weight_val))
                    if not weight_dec.is_finite() or weight_dec < 0:
                        raise ValueError("Weight must be non-negative and finite")
                    # Store validated weight as float (common usage in scoring)
                    weights[ind_key] = float(weight_dec)
                except (ValueError, TypeError, InvalidOperation):
                     # Attempt to get default weight, fallback to 0.0
                     default_weight_set = default_config[ws_key].get(set_name, {})
                     default_weight = default_weight_set.get(ind_key, 0.0)
                     print(f"{NEON_RED}Invalid weight value '{repr(weight_val)}' for indicator '{ind_key}' in weight set '{set_name}'. Must be a non-negative number. Resetting to default '{default_weight}'.{RESET}")
                     weights[ind_key] = float(default_weight) # Reset to float
                     needs_saving = True
            # Remove invalid weights from the current set
            for r_key in weights_to_remove: del weights[r_key]
        # Remove invalid sets
        for r_key in sets_to_remove: del weight_sets[r_key]
    else:
         print(f"{NEON_RED}Invalid or missing '{ws_key}' section in config. Resetting to default.{RESET}")
         current_config[ws_key] = default_config[ws_key].copy() # Use copy of default
         needs_saving = True

    # --- Post-validation Check: Ensure active_weight_set still exists after potential removals ---
    active_set = current_config.get("active_weight_set")
    if active_set not in current_config.get("weight_sets", {}):
         default_active_set = default_config["active_weight_set"]
         print(f"{NEON_RED}Previously selected active_weight_set '{active_set}' is no longer valid (possibly removed during validation). Resetting to default '{default_active_set}'.{RESET}")
         current_config["active_weight_set"] = default_active_set
         needs_saving = True

    # --- Save Updated Config if Necessary ---
    # Needs saving if file was created, merged, or validation caused changes
    if needs_saving or current_config != original_config_before_validation:
        try:
            with open(filepath, "w", encoding="utf-8") as f_write:
                # Dump the validated and potentially corrected config
                json.dump(current_config, f_write, indent=4, ensure_ascii=False, sort_keys=True)
            print(f"{NEON_YELLOW}Saved updated configuration to {filepath}{RESET}")
        except IOError as e:
            print(f"{NEON_RED}Error writing updated config file {filepath}: {e}{RESET}")
        except Exception as e:
             print(f"{NEON_RED}Unexpected error saving config file {filepath}: {e}{RESET}")

    return current_config

def _merge_configs(loaded_config: Dict, default_config: Dict) -> Dict:
    """
    Recursively merges the loaded configuration dictionary onto the default dictionary.
    - Ensures all keys from the default config exist in the final merged config.
    - Prioritizes values from the loaded config if a key exists in both.
    - Handles nested dictionaries recursively.
    - Adds keys present only in the loaded_config (allows user extensions).

    Args:
        loaded_config (Dict): The configuration loaded from the file.
        default_config (Dict): The default configuration structure and values.

    Returns:
        Dict: The merged configuration dictionary.
    """
    merged = default_config.copy() # Start with the default structure

    for key, loaded_value in loaded_config.items():
        if key in merged:
            default_value = merged[key]
            # If both loaded and default values for the key are dictionaries, recurse
            if isinstance(loaded_value, dict) and isinstance(default_value, dict):
                merged[key] = _merge_configs(loaded_value, default_value)
            else:
                # Otherwise, overwrite default with loaded value (validation happens later)
                merged[key] = loaded_value
        else:
            # If key from loaded config doesn't exist in default, add it.
            # This allows users to add custom keys to their config if needed.
            merged[key] = loaded_value

    # Ensure all keys from the default config are present in the merged result.
    # This handles cases where a default key was missing entirely in the loaded config.
    for key, default_value in default_config.items():
        if key not in merged:
            merged[key] = default_value
            # print(f"Debug: Added missing key '{key}' with default value during merge.") # Optional debug log

    return merged

# --- Logging Setup ---
def setup_logger(name: str, config: Dict[str, Any], level: int = logging.INFO) -> logging.Logger:
    """
    Sets up a logger instance with specified name, configuration, and level.
    - Configures a rotating file handler (logs in UTC).
    - Configures a colored console handler (logs in local timezone specified in config).
    - Uses SensitiveFormatter to redact API keys/secrets.
    - Prevents duplicate log messages if called multiple times for the same logger name.

    Args:
        name (str): The name for the logger instance.
        config (Dict[str, Any]): The bot's configuration dictionary (used for timezone).
        level (int): The logging level for the console handler (e.g., logging.INFO, logging.DEBUG).

    Returns:
        logging.Logger: The configured logger instance.
    """
    logger = logging.getLogger(name)
    # Prevent adding multiple handlers if this function is called again for the same logger
    if logger.hasHandlers():
        logger.handlers.clear()

    # Set the logger's base level to DEBUG to capture all messages.
    # Handlers will filter based on their individual levels.
    logger.setLevel(logging.DEBUG)

    # --- File Handler (Rotating, UTC Timestamps) ---
    log_filename = os.path.join(LOG_DIRECTORY, f"{name}.log")
    try:
        # Directory should exist from earlier check, but ensure again just in case.
        os.makedirs(LOG_DIRECTORY, exist_ok=True)
        # Rotate logs: 10MB per file, keep last 5 files
        file_handler = RotatingFileHandler(
            log_filename, maxBytes=10 * 1024 * 1024, backupCount=5, encoding='utf-8'
        )
        # Use UTC timestamps in file logs for consistency across different systems/locations
        # ISO 8601 format with milliseconds and UTC 'Z' indicator
        file_formatter = SensitiveFormatter(
            "%(asctime)s.%(msecs)03dZ %(levelname)-8s [%(name)s:%(lineno)d] %(message)s",
            datefmt='%Y-%m-%dT%H:%M:%S' # ISO 8601 standard date format
        )
        file_formatter.converter = time.gmtime # Force formatter to use UTC time
        file_handler.setFormatter(file_formatter)
        # Log DEBUG level and above to the file
        file_handler.setLevel(logging.DEBUG)
        logger.addHandler(file_handler)
    except Exception as e:
        # Fallback to basic console logging if file handler setup fails
        print(f"{NEON_RED}Error setting up file logger '{log_filename}': {e}. File logging disabled.{RESET}")
        # Ensure there's at least one handler if file logging failed
        if not logger.hasHandlers():
            basic_handler = logging.StreamHandler()
            basic_handler.setFormatter(logging.Formatter('%(levelname)s: %(message)s'))
            logger.addHandler(basic_handler)

    # --- Console Handler (Colored, Local Timestamps) ---
    # Add console handler only if no StreamHandler exists yet (prevents duplicates if file handler failed)
    if not any(isinstance(h, logging.StreamHandler) for h in logger.handlers):
        stream_handler = logging.StreamHandler()
        # Determine local timezone for console display from validated config
        try:
            # Use the globally updated TIMEZONE variable from load_config
            console_tz = TIMEZONE
        except Exception as tz_err: # Should not happen if load_config worked, but safety check
            print(f"{NEON_RED}Error getting configured timezone for console logs: {tz_err}. Using UTC.{RESET}")
            console_tz = ZoneInfo("UTC")

        # Formatter with colors and local time (including timezone abbreviation %Z)
        console_formatter = SensitiveFormatter(
            f"{NEON_BLUE}%(asctime)s{RESET} {NEON_YELLOW}%(levelname)-8s{RESET} {NEON_PURPLE}[%(name)s]{RESET} %(message)s",
            datefmt='%Y-%m-%d %H:%M:%S %Z' # Example: 2023-10-27 15:30:00 CDT
        )

        # Custom time converter function for the console formatter
        def local_time_converter(*args):
            """Returns the current time as a timetuple in the configured local timezone."""
            return datetime.now(console_tz).timetuple()

        console_formatter.converter = local_time_converter # Assign the converter
        stream_handler.setFormatter(console_formatter)
        # Set console log level based on the function argument (e.g., INFO)
        stream_handler.setLevel(level)
        logger.addHandler(stream_handler)

    # Prevent logs from propagating to the root logger (avoids potential duplicate outputs)
    logger.propagate = False
    return logger

# --- CCXT Exchange Setup ---
def initialize_exchange(config: Dict[str, Any], logger: logging.Logger) -> Optional[ccxt.Exchange]:
    """
    Initializes and configures the CCXT Bybit exchange object.
    - Sets API keys, rate limiting, timeouts, and V5-specific options.
    - Handles enabling Sandbox (Testnet) mode with URL verification and fallbacks.
    - Loads exchange markets and validates the configured trading symbol.
    - Performs an initial connection test by fetching balance.
    - Includes robust error handling for common initialization failures.

    Args:
        config (Dict[str, Any]): The bot's configuration dictionary.
        logger (logging.Logger): The logger instance.

    Returns:
        Optional[ccxt.Exchange]: The configured CCXT exchange object, or None if initialization fails.
    """
    lg = logger # Alias for convenience
    try:
        # CCXT Exchange configuration options
        exchange_options = {
            'apiKey': API_KEY,
            'secret': API_SECRET,
            'enableRateLimit': True, # Enable ccxt's built-in rate limiter
            'rateLimit': 150, # Milliseconds between requests (approx 6.6 req/s). Adjust based on Bybit V5 limits and VIP level.
            'options': {
                'defaultType': 'linear', # CRUCIAL for Bybit V5 USDT/USDC perpetuals/futures. Use 'inverse' for inverse contracts.
                'adjustForTimeDifference': True, # Helps mitigate timestamp synchronization errors.
                # Set reasonable network timeouts (in milliseconds) for various API calls
                'fetchTickerTimeout': 15000,      # 15 seconds
                'fetchBalanceTimeout': 20000,     # 20 seconds
                'createOrderTimeout': 25000,      # 25 seconds
                'cancelOrderTimeout': 20000,      # 20 seconds
                'fetchPositionsTimeout': 25000,   # 25 seconds
                'fetchOHLCVTimeout': 20000,       # 20 seconds
                'fetchOrderBookTimeout': 15000,   # 15 seconds
                'setLeverageTimeout': 20000,      # 20 seconds
                'fetchMyTradesTimeout': 20000,    # 20 seconds (Added)
                'fetchClosedOrdersTimeout': 25000,# 25 seconds (Added)
                # Custom User-Agent can help identify your bot's traffic to the exchange (Optional)
                'user-agent': 'sxsBot/1.2 (+https://github.com/your_repo)', # Optional: Update URL if applicable
                # Bybit V5 specific settings (Consult Bybit/CCXT docs if needed)
                # 'recvWindow': 10000, # Optional: Increase if timestamp errors persist despite adjustForTimeDifference
                # 'brokerId': 'YOUR_BROKER_ID', # Optional: If participating in Bybit broker program
                # 'enableUnifiedMargin': False, # Set to True if using Bybit's Unified Trading Account (UTA)
                # 'enableUnifiedAccount': False, # May be an alias for above; check CCXT/Bybit documentation
            }
        }

        # Instantiate the Bybit exchange class from ccxt
        exchange_id = "bybit" # Explicitly target Bybit
        exchange_class = getattr(ccxt, exchange_id)
        exchange = exchange_class(exchange_options)

        # --- Sandbox (Testnet) Mode Setup ---
        if config.get('use_sandbox', True): # Default to sandbox if key is missing
            lg.warning(f"{NEON_YELLOW}INITIALIZING IN SANDBOX MODE (Testnet){RESET}")
            try:
                # Attempt to use CCXT's standard method for enabling sandbox mode
                exchange.set_sandbox_mode(True)
                lg.info(f"Sandbox mode enabled via exchange.set_sandbox_mode(True) for {exchange.id}.")

                # --- CRITICAL VERIFICATION: Check if the API URL actually changed ---
                current_api_url = exchange.urls.get('api', '')
                if 'testnet' not in current_api_url.lower():
                    lg.warning(f"set_sandbox_mode did not change API URL to testnet! Current URL: {current_api_url}")
                    # Attempt manual override using URLs defined in exchange description
                    test_url_info = exchange.describe().get('urls', {}).get('test')
                    api_test_url = None
                    if isinstance(test_url_info, str):
                        api_test_url = test_url_info
                    elif isinstance(test_url_info, dict): # Sometimes 'test' contains a dict of URLs
                        # Prioritize public/private keys if they exist
                        api_test_url = test_url_info.get('public') or test_url_info.get('private') or next((url for url in test_url_info.values() if isinstance(url, str)), None)

                    if api_test_url:
                        exchange.urls['api'] = api_test_url
                        lg.info(f"Manually set API URL to Testnet based on exchange.describe(): {exchange.urls['api']}")
                    else:
                        # Final hardcoded fallback if describe() didn't provide a usable URL
                        fallback_test_url = 'https://api-testnet.bybit.com'
                        lg.warning(f"Could not reliably determine testnet URL from describe(). Hardcoding fallback: {fallback_test_url}")
                        exchange.urls['api'] = fallback_test_url
                else:
                     lg.info(f"Confirmed API URL is set to Testnet: {current_api_url}")

            except AttributeError:
                # Fallback if the ccxt version doesn't support set_sandbox_mode
                lg.warning(f"{exchange.id} ccxt version might lack set_sandbox_mode. Manually setting Testnet API URL.")
                exchange.urls['api'] = 'https://api-testnet.bybit.com' # Ensure this is the correct V5 testnet URL
                lg.info(f"Manually set Bybit API URL to Testnet: {exchange.urls['api']}")
            except Exception as e_sandbox:
                lg.error(f"Error encountered trying to enable sandbox mode: {e_sandbox}. Ensure API keys are for Testnet. Proceeding with potentially incorrect URL.", exc_info=True)
        else:
            # --- Live (Real Money) Environment Setup ---
            lg.info(f"{NEON_GREEN}INITIALIZING IN LIVE (Real Money) Environment.{RESET}")
            # Ensure API URL is set to production if sandbox was somehow enabled previously
            current_api_url = exchange.urls.get('api', '')
            if 'testnet' in current_api_url.lower():
                lg.warning("Detected testnet URL while in live mode configuration. Attempting to reset to production URL.")
                # Find the production URL from exchange description
                prod_url_info = exchange.describe().get('urls', {}).get('api')
                api_prod_url = None
                if isinstance(prod_url_info, str):
                     api_prod_url = prod_url_info
                elif isinstance(prod_url_info, dict): # API URL might be nested
                     api_prod_url = prod_url_info.get('public') or prod_url_info.get('private') or next((url for url in prod_url_info.values() if isinstance(url, str)), None)

                if api_prod_url:
                    exchange.urls['api'] = api_prod_url
                    lg.info(f"Reset API URL to Production based on exchange.describe(): {exchange.urls['api']}")
                else:
                    # Fallback to 'www' URL or hardcoded default if 'api' is not found
                    www_url = exchange.describe().get('urls',{}).get('www')
                    if www_url and isinstance(www_url, str):
                         exchange.urls['api'] = www_url # Less ideal, but better than testnet
                         lg.info(f"Reset API URL to Production using 'www' fallback: {exchange.urls['api']}")
                    else:
                         fallback_prod_url = 'https://api.bybit.com' # Hardcoded V5 production URL
                         lg.error(f"Could not determine production API URL automatically. Hardcoding fallback: {fallback_prod_url}")
                         exchange.urls['api'] = fallback_prod_url

        lg.info(f"Initializing {exchange.id} (API Endpoint: {exchange.urls.get('api', 'URL Not Set')})...")

        # --- Load Markets (Essential for precision, limits, IDs, fees) ---
        lg.info(f"Loading markets for {exchange.id} (this may take a moment)...")
        try:
             # Use safe_api_call for robustness, force reload to ensure freshness
             safe_api_call(exchange.load_markets, lg, reload=True)
             lg.info(f"Markets loaded successfully for {exchange.id}. Found {len(exchange.symbols)} symbols.")

             # --- Validate Target Symbol Existence & Compatibility ---
             target_symbol = config.get("symbol")
             if not target_symbol:
                  lg.critical(f"{NEON_RED}FATAL: 'symbol' not defined in configuration!{RESET}")
                  return None
             if target_symbol not in exchange.markets:
                  lg.critical(f"{NEON_RED}FATAL: Target symbol '{target_symbol}' not found in loaded markets for {exchange.id}!{RESET}")
                  lg.critical(f"{NEON_RED}>> Check symbol spelling, format, and availability on the exchange ({'Testnet' if config.get('use_sandbox') else 'Live'}).{RESET}")
                  # Provide hint for common Bybit V5 linear format
                  if '/' in target_symbol and ':' not in target_symbol and exchange.id == 'bybit':
                       base, quote = target_symbol.split('/')[:2]
                       suggested_symbol = f"{base}/{quote}:{quote}"
                       lg.warning(f"{NEON_YELLOW}Hint: For Bybit V5 linear perpetuals, the format is often like '{suggested_symbol}'.{RESET}")
                  # List available markets if the list is small and potentially helpful
                  if 0 < len(exchange.symbols) < 50:
                       lg.debug(f"Available symbols sample: {sorted(list(exchange.symbols))[:10]}...")
                  elif len(exchange.symbols) == 0:
                       lg.error("No symbols were loaded from the exchange at all.")
                  return None # Fatal error if configured symbol doesn't exist
             else:
                  lg.info(f"Target symbol '{target_symbol}' validated against loaded markets.")
                  # Optional: Add checks here for market type compatibility (e.g., ensure it's linear if expected)
                  market_info_check = exchange.market(target_symbol)
                  if market_info_check.get('linear') is not True and exchange.options.get('defaultType') == 'linear':
                       lg.warning(f"Target symbol '{target_symbol}' might not be a linear contract, but defaultType is linear. Verify settings.")


        except Exception as market_err:
             lg.critical(f"{NEON_RED}CRITICAL: Failed to load markets after retries: {market_err}. Bot cannot operate without market data. Exiting.{RESET}", exc_info=True)
             return None # Fatal error

        # --- Initial Connection & Permissions Test (Fetch Balance) ---
        # This also helps confirm the correct account type (CONTRACT/UNIFIED) is accessible.
        account_type_hint = exchange.options.get('defaultType', 'linear').upper() # e.g., LINEAR -> check CONTRACT
        account_type_to_test = 'CONTRACT' if account_type_hint != 'INVERSE' else 'CONTRACT' # Or potentially 'UNIFIED'
        lg.info(f"Performing initial connection test by fetching balance (Account Type Hint based on defaultType: {account_type_to_test})...")
        quote_curr = config.get("quote_currency", "USDT") # Use configured quote currency
        balance_decimal = fetch_balance(exchange, quote_curr, lg) # Use the dedicated robust function

        if balance_decimal is not None:
             # Balance fetch succeeded, log the result
             lg.info(f"{NEON_GREEN}Successfully connected and fetched initial {quote_curr} balance: {balance_decimal:.4f}{RESET}")
             if balance_decimal == Decimal('0'):
                  lg.warning(f"{NEON_YELLOW}Initial available {quote_curr} balance is zero. Ensure funds are in the correct account type (e.g., CONTRACT, UNIFIED) and wallet.{RESET}")
        else:
             # fetch_balance logs detailed errors, add a critical warning here as failure is significant.
             lg.critical(f"{NEON_RED}CRITICAL: Initial balance fetch for {quote_curr} failed.{RESET}")
             lg.critical(f"{NEON_RED}>> Check API key validity, permissions (read access needed), IP whitelisting, account type (CONTRACT/UNIFIED?), and network connectivity.{RESET}")
             # Decide if this is fatal. For a trading bot, inability to fetch balance usually is.
             # return None # Uncomment to make initial balance fetch failure fatal

        lg.info(f"CCXT exchange '{exchange.id}' initialized. Sandbox: {config.get('use_sandbox')}, Default Type: {exchange.options.get('defaultType')}")
        return exchange

    # --- Specific Exception Handling for Initialization ---
    except ccxt.AuthenticationError as e:
        lg.critical(f"{NEON_RED}CCXT Authentication Error during initialization: {e}{RESET}")
        lg.critical(f"{NEON_RED}>> Please check: API Key/Secret correctness, validity (not expired), enabled permissions (read, trade), and IP whitelisting configuration on the Bybit website.{RESET}")
    except ccxt.ExchangeError as e:
        lg.critical(f"{NEON_RED}CCXT Exchange Error during initialization: {e}{RESET}")
        lg.critical(f"{NEON_RED}>> This could be a temporary issue with the exchange API, incorrect exchange settings (e.g., defaultType), or network problems. Check Bybit status pages.{RESET}")
    except ccxt.NetworkError as e:
        lg.critical(f"{NEON_RED}CCXT Network Error during initialization: {e}{RESET}")
        lg.critical(f"{NEON_RED}>> Check your internet connection, DNS resolution, and firewall settings. Ensure api.bybit.com (or testnet) is reachable.{RESET}")
    except Exception as e:
        # Catch any other unexpected errors during the setup process
        lg.critical(f"{NEON_RED}Unexpected critical error initializing CCXT exchange: {e}{RESET}", exc_info=True)

    return None # Return None if any critical error occurred during initialization

# --- API Call Wrapper with Enhanced Retries ---
def safe_api_call(func, logger: logging.Logger, *args, **kwargs):
    """
    Wraps a CCXT API call with robust retry logic for network issues, rate limits,
    and specific transient exchange errors. Uses exponential backoff with jitter.

    Args:
        func: The CCXT exchange method to call (e.g., exchange.fetch_ticker).
        logger: The logger instance for logging retry attempts and errors.
        *args: Positional arguments for the CCXT function.
        **kwargs: Keyword arguments for the CCXT function.

    Returns:
        The result of the API call if successful after retries.

    Raises:
        The original exception if the call fails after all retries or encounters
        a non-retryable error (e.g., AuthenticationError, InvalidOrder).
    """
    lg = logger
    # Get retry parameters from global config if available, else use constants
    # Using globals() is generally okay for script-level config, but passing config explicitly would be cleaner
    global config
    max_retries = config.get("max_api_retries", MAX_API_RETRIES) if config else MAX_API_RETRIES
    base_retry_delay = config.get("retry_delay", RETRY_DELAY_SECONDS) if config else RETRY_DELAY_SECONDS
    attempts = 0
    last_exception = None

    while attempts <= max_retries:
        try:
            # Attempt the API call
            result = func(*args, **kwargs)
            # Optional: Log successful calls at DEBUG level (can be verbose)
            # lg.debug(f"API call '{func.__name__}' successful (Attempt {attempts+1}).")
            return result # Success, return the result

        # --- Retryable Network/Server Availability Errors ---
        except (ccxt.NetworkError, ccxt.RequestTimeout, requests.exceptions.ConnectionError,
                requests.exceptions.Timeout, ccxt.ExchangeNotAvailable, ccxt.DDoSProtection) as e:
            last_exception = e
            # Exponential backoff: delay = base * (1.5 ^ attempts)
            wait_time = base_retry_delay * (1.5 ** attempts)
            # Add random jitter (+/- 10% of wait_time) to prevent simultaneous retries (thundering herd)
            wait_time *= (1 + (np.random.rand() - 0.5) * 0.2)
            wait_time = min(wait_time, 60) # Cap maximum wait time (e.g., 60 seconds)
            lg.warning(f"{NEON_YELLOW}Retryable Network/Availability Error in '{func.__name__}': {type(e).__name__}. "
                       f"Retrying in {wait_time:.1f}s (Attempt {attempts+1}/{max_retries+1}). Details: {e}{RESET}")

        # --- Rate Limit Errors ---
        except ccxt.RateLimitExceeded as e:
            last_exception = e
            retry_after_header = None
            header_wait_seconds = 0
            # Try to extract 'Retry-After' value from headers (can be seconds or ms)
            # Check ccxt standard attribute first
            if hasattr(e, 'http_headers') and isinstance(e.http_headers, dict):
                 retry_after_header = e.http_headers.get('Retry-After') or e.http_headers.get('retry-after')
            # Fallback check on the underlying requests response if available
            elif hasattr(e, 'response') and hasattr(e.response, 'headers'):
                 retry_after_header = e.response.headers.get('Retry-After') or e.response.headers.get('retry-after')

            # Use a stronger exponential backoff for rate limits: base * (2.0 ^ attempts)
            backoff_wait = base_retry_delay * (2.0 ** attempts)
            backoff_wait *= (1 + (np.random.rand() - 0.5) * 0.2) # Add jitter

            # Parse Retry-After header value if found
            if retry_after_header:
                try:
                    header_wait_seconds = float(retry_after_header)
                    # Assume seconds unless value looks like milliseconds (e.g., > 10000)
                    if header_wait_seconds > 1000: header_wait_seconds /= 1000.0
                    header_wait_seconds += 0.5 # Add a small buffer (0.5 seconds)
                    lg.debug(f"Rate limit 'Retry-After' header: {retry_after_header} -> Parsed wait: {header_wait_seconds:.1f}s")
                except (ValueError, TypeError):
                    lg.warning(f"Could not parse Retry-After header value: {retry_after_header}")
                    header_wait_seconds = 0 # Ignore invalid header

            # Use the longer of calculated backoff or header-suggested wait time
            final_wait_time = max(backoff_wait, header_wait_seconds)
            final_wait_time = min(final_wait_time, 90) # Cap rate limit wait time (e.g., 90 seconds)

            lg.warning(f"{NEON_YELLOW}Rate Limit Exceeded in '{func.__name__}'. "
                       f"Retrying in {final_wait_time:.1f}s (Attempt {attempts+1}/{max_retries+1}). Error: {e}{RESET}")
            wait_time = final_wait_time # Use the determined wait time for the sleep

        # --- Authentication Errors (FATAL - Non-Retryable) ---
        except ccxt.AuthenticationError as e:
             lg.error(f"{NEON_RED}Authentication Error in '{func.__name__}': {e}. This is likely NOT retryable.{RESET}")
             lg.error(f"{NEON_RED}>> Check API Key/Secret validity, permissions, IP whitelist, and environment (Live/Testnet). Aborting call.{RESET}")
             raise e # Re-raise immediately, do not retry

        # --- Invalid Order / Input Errors (FATAL - Non-Retryable) ---
        # These usually indicate a problem with parameters (size, price, etc.)
        except (ccxt.InvalidOrder, ccxt.BadSymbol, ccxt.ArgumentsRequired, ccxt.BadRequest) as e:
            lg.error(f"{NEON_RED}Invalid Request Error in '{func.__name__}': {e}. This indicates an issue with order parameters or symbol. NOT retryable.{RESET}")
            lg.error(f"{NEON_RED}>> Check parameters: {args}, {kwargs}. Aborting call.{RESET}")
            raise e # Re-raise immediately

        # --- Potentially Retryable Exchange-Specific Errors ---
        except ccxt.ExchangeError as e:
            last_exception = e
            err_str = str(e).lower()
            # Try to get HTTP status code and exchange-specific error code
            http_status_code = getattr(e, 'http_status_code', None)
            exchange_code = getattr(e, 'code', None) # CCXT often parses this

            # Try extracting Bybit's 'retCode' from the message string if ccxt didn't parse it
            if exchange_code is None and 'bybit' in str(type(e)).lower() and 'retcode' in err_str:
                try:
                     # Example: "bybit {"retCode":10006,"retMsg":"Too many visits!"...}"
                     start_index = err_str.find('"retcode":')
                     if start_index != -1:
                          code_part = err_str[start_index + len('"retcode":'):]
                          end_index = code_part.find(',')
                          code_str = code_part[:end_index].strip()
                          if code_str.isdigit(): exchange_code = int(code_str)
                except Exception: pass # Ignore parsing errors

            # List of known Bybit V5 transient/retryable error codes (expand as needed)
            # Ref: https://bybit-exchange.github.io/docs/v5/error_code
            bybit_retry_codes = [
                10001, # Internal server error (param error or server issue)
                10002, # Service unavailable / Server error
                10004, # Sign check error (can be transient timing)
                10006, # Too many requests (might also be caught by RateLimitExceeded)
                10010, # Request expired (timestamp issue, maybe retryable with adjustForTimeDifference)
                10016, # Service temporarily unavailable (maintenance/upgrade)
                # 10018, # Request validation failed (sometimes transient) - Risky to retry blindly
                110001, # Internal error, try again
                130021, # Order qty error (sometimes transient precision/price issue)
                130150, # System busy
                131204, # Cannot connect to matching engine
                170131, # Too many requests (contract specific?)
                170146, # Risk limit cannot be adjusted when the symbol has active order
                # Add other codes based on observation
            ]
            # General retryable error messages (case-insensitive)
            retryable_messages = [
                 "internal server error", "service unavailable", "system busy",
                 "matching engine busy", "please try again", "request timeout",
                 "nonce is too small", # Can happen with clock drift, retry might help
                 "order placement optimization", # Occasional Bybit transient message
            ]

            is_retryable = False
            # Check retryable conditions: Bybit code OR HTTP code OR message content
            if exchange_code in bybit_retry_codes: is_retryable = True
            if not is_retryable and http_status_code in RETRYABLE_HTTP_CODES: is_retryable = True
            if not is_retryable and any(msg in err_str for msg in retryable_messages): is_retryable = True

            if is_retryable:
                 # Use standard backoff for these transient errors
                 wait_time = base_retry_delay * (1.5 ** attempts)
                 wait_time *= (1 + (np.random.rand() - 0.5) * 0.2) # Add jitter
                 wait_time = min(wait_time, 60) # Cap wait time
                 lg.warning(f"{NEON_YELLOW}Potentially Retryable Exchange Error in '{func.__name__}': {e} (Code: {exchange_code}, HTTP: {http_status_code}). "
                            f"Retrying in {wait_time:.1f}s (Attempt {attempts+1}/{max_retries+1})...{RESET}")
                 time.sleep(wait_time) # Sleep before the next attempt
                 attempts += 1
                 continue # Go to the next iteration of the while loop directly
            else:
                 # Non-retryable ExchangeError (e.g., insufficient balance, invalid parameters not caught earlier)
                 lg.error(f"{NEON_RED}Non-Retryable Exchange Error in '{func.__name__}': {e} (Code: {exchange_code}, HTTP: {http_status_code}){RESET}")
                 raise e # Re-raise immediately

        # --- Catch any other unexpected error ---
        except Exception as e:
            last_exception = e
            lg.error(f"{NEON_RED}Unexpected Error during API call '{func.__name__}': {e}{RESET}", exc_info=True)
            raise e # Re-raise unexpected errors immediately, do not retry

        # --- Increment Attempt Counter (if a retryable exception occurred and wasn't 'continue'd) ---
        # This block is reached after the sleep for retryable network/rate limit errors
        if attempts <= max_retries:
             # Wait time should have been calculated in the corresponding except block
             calculated_wait_time = locals().get('wait_time', 0)
             if calculated_wait_time > 0:
                 time.sleep(calculated_wait_time)
             else:
                 # Fallback sleep if wait_time wasn't set (shouldn't happen with current logic)
                 lg.warning(f"Wait time not calculated for retry attempt {attempts+1}. Using base delay.")
                 time.sleep(base_retry_delay)
             attempts += 1
        else:
            # Should be handled by the loop condition, but as a safety break
            break

    # --- Max Retries Exceeded ---
    # If the loop completes without returning, it means max retries were hit
    lg.error(f"{NEON_RED}Max retries ({max_retries}) exceeded for API call '{func.__name__}'. Aborting call.{RESET}")
    if last_exception:
        lg.error(f"Last encountered error: {type(last_exception).__name__}: {last_exception}")
        raise last_exception # Raise the last captured exception
    else:
        # Fallback if no exception was captured (shouldn't normally happen)
        raise ccxt.RequestTimeout(f"Max retries exceeded for {func.__name__} but no specific exception was captured during retry loop.")


# --- CCXT Data Fetching Functions (using safe_api_call) ---

def fetch_current_price_ccxt(exchange: ccxt.Exchange, symbol: str, logger: logging.Logger) -> Optional[Decimal]:
    """
    Fetches the current market price for a symbol using CCXT's fetch_ticker.
    - Uses safe_api_call for robust fetching with retries.
    - Implements a priority order for selecting the price (e.g., last, mark, close).
    - Converts the selected price to Decimal for precision.
    - Performs validation to ensure the price is positive and finite.

    Args:
        exchange (ccxt.Exchange): The initialized CCXT exchange object.
        symbol (str): The trading symbol (e.g., 'BTC/USDT:USDT').
        logger (logging.Logger): The logger instance.

    Returns:
        Optional[Decimal]: The current price as a Decimal, or None if fetching/parsing fails.
    """
    lg = logger
    try:
        # Fetch ticker data using the robust wrapper
        ticker = safe_api_call(exchange.fetch_ticker, lg, symbol)

        if not ticker or not isinstance(ticker, dict):
            lg.error(f"Failed to fetch valid ticker data for {symbol} after retries.")
            # safe_api_call should have logged the root cause if retries failed
            return None

        lg.debug(f"Raw Ticker data for {symbol}: {json.dumps(ticker, indent=2, default=str)}") # Log full ticker for debug

        # --- Helper for Safe Decimal Conversion ---
        def to_decimal(value, context_str: str = "price") -> Optional[Decimal]:
            """Safely converts a value to a positive, finite Decimal. Returns None on failure."""
            if value is None: return None
            try:
                # Convert via string to handle floats/ints consistently
                d = Decimal(str(value))
                # Ensure the price is valid (finite number greater than zero)
                if d.is_finite() and d > 0:
                    return d
                else:
                    lg.debug(f"Invalid {context_str} value from ticker (non-finite or non-positive): {value}. Discarding.")
                    return None
            except (InvalidOperation, ValueError, TypeError):
                lg.debug(f"Invalid {context_str} format, cannot convert to Decimal: {value}. Discarding.")
                return None

        # --- Extract Potential Price Candidates ---
        p_last = to_decimal(ticker.get('last'), 'last price')
        p_mark = to_decimal(ticker.get('mark'), 'mark price') # Important for futures/swaps
        p_close = to_decimal(ticker.get('close', ticker.get('last')), 'close price') # Use 'close', fallback to 'last' if close is missing
        p_bid = to_decimal(ticker.get('bid'), 'bid price')
        p_ask = to_decimal(ticker.get('ask'), 'ask price')
        p_avg = to_decimal(ticker.get('average'), 'average price') # Often (High+Low+Close)/3 or VWAP-like

        # Calculate Mid Price if Bid and Ask are valid and spread is reasonable
        p_mid = None
        if p_bid is not None and p_ask is not None:
             if p_ask > p_bid: # Ensure ask is higher than bid
                 spread = p_ask - p_bid
                 spread_pct = (spread / p_ask) * 100 if p_ask > 0 else Decimal('0')
                 # Warn if spread is excessive (e.g., > 1%) - might indicate illiquid market or bad data
                 if spread_pct > Decimal('1.0'):
                      lg.debug(f"Ticker spread for {symbol} is > 1% ({spread_pct:.2f}%). Mid price calculation may be less reliable.")
                 p_mid = (p_bid + p_ask) / Decimal('2')
                 if not p_mid.is_finite(): p_mid = None # Ensure calculation didn't result in non-finite
             else:
                 lg.debug(f"Bid ({p_bid}) is not less than Ask ({p_ask}) for {symbol}. Cannot calculate Mid price.")

        # --- Determine Market Type for Price Priority ---
        market_info = exchange.market(symbol) if symbol in exchange.markets else {}
        is_contract = market_info.get('contract', False) or market_info.get('type') in ['swap', 'future']

        # --- Select Price Based on Priority ---
        # Priority Order: mark (for contracts) > last > close > average > mid > ask > bid
        selected_price: Optional[Decimal] = None
        price_source: str = "N/A"

        if is_contract and p_mark:
            selected_price, price_source = p_mark, "Mark Price"
        elif p_last:
            selected_price, price_source = p_last, "Last Price"
        elif p_close: # Close is often same as Last, but good fallback
            selected_price, price_source = p_close, "Close Price"
        elif p_avg:
            selected_price, price_source = p_avg, "Average Price"
        elif p_mid:
            selected_price, price_source = p_mid, "Mid Price (Bid/Ask)"
        elif p_ask:
            # Using only Ask or Bid is less ideal due to spread
            if p_bid: # Log spread if using Ask as fallback
                 spread_pct = ((p_ask - p_bid) / p_ask) * 100 if p_ask > 0 else Decimal('0')
                 if spread_pct > Decimal('2.0'): # Higher warning threshold if using Ask directly
                      lg.warning(f"Using 'ask' price ({p_ask}) as fallback for {symbol}, but spread seems large ({spread_pct:.2f}%, Bid: {p_bid}).")
            selected_price, price_source = p_ask, "Ask Price (Fallback)"
        elif p_bid:
            # Last resort
            selected_price, price_source = p_bid, "Bid Price (Last Resort Fallback)"

        # --- Final Validation and Return ---
        if selected_price is not None and selected_price.is_finite() and selected_price > 0:
            lg.info(f"Current price ({symbol}): {selected_price} (Source: {price_source})")
            return selected_price
        else:
            lg.error(f"{NEON_RED}Failed to extract a valid positive price from ticker data for {symbol}. Ticker: {ticker}{RESET}")
            return None

    except Exception as e:
        # Catch errors raised by safe_api_call or during price processing
        lg.error(f"{NEON_RED}Error fetching/processing current price for {symbol}: {e}{RESET}", exc_info=False) # Keep log concise on error
        return None


def fetch_klines_ccxt(exchange: ccxt.Exchange, symbol: str, timeframe: str, limit: int = 250, logger: Optional[logging.Logger] = None) -> pd.DataFrame:
    """
    Fetches OHLCV kline data using CCXT with retries and robust processing.
    - Uses safe_api_call for fetching.
    - Converts internal timeframe format (e.g., "5") to CCXT format (e.g., "5m").
    - Creates a pandas DataFrame.
    - Performs data cleaning:
        - Converts timestamps to UTC datetime objects.
        - Converts OHLCV columns to Decimal, handling NaNs and invalid values robustly.
        - Drops rows with invalid timestamps or NaN in essential price columns.
        - Checks for and drops rows with inconsistent OHLC values (e.g., High < Low).
        - Sorts by timestamp and removes duplicates.
    - Returns an empty DataFrame on failure or if no valid data remains after cleaning.

    Args:
        exchange (ccxt.Exchange): Initialized CCXT exchange object.
        symbol (str): Trading symbol.
        timeframe (str): Internal timeframe string (e.g., "1", "5", "60", "D").
        limit (int): Maximum number of klines to fetch.
        logger (Optional[logging.Logger]): Logger instance. Uses default if None.

    Returns:
        pd.DataFrame: DataFrame with OHLCV data (Decimal type) indexed by UTC timestamp,
                      or an empty DataFrame if fetching/processing fails.
    """
    lg = logger or logging.getLogger(__name__) # Use provided logger or get a default one
    empty_df = pd.DataFrame() # Standard empty DataFrame to return on failure

    # Check if exchange supports fetching OHLCV data
    if not exchange.has.get('fetchOHLCV'):
        lg.error(f"Exchange {exchange.id} does not support fetchOHLCV according to ccxt 'has' attribute.")
        return empty_df

    try:
        # Convert internal timeframe to CCXT's format
        ccxt_timeframe = CCXT_INTERVAL_MAP.get(timeframe)
        if not ccxt_timeframe:
            lg.error(f"Invalid internal timeframe '{timeframe}' provided. Valid map keys: {list(CCXT_INTERVAL_MAP.keys())}. Cannot fetch klines.")
            return empty_df

        lg.debug(f"Fetching up to {limit} klines for {symbol} with timeframe {ccxt_timeframe} (Internal: {timeframe})...")
        # Fetch data using the safe API call wrapper
        ohlcv_data = safe_api_call(exchange.fetch_ohlcv, lg, symbol, timeframe=ccxt_timeframe, limit=limit)

        # Validate the raw data structure
        if ohlcv_data is None or not isinstance(ohlcv_data, list) or len(ohlcv_data) == 0:
            # safe_api_call logs error if it failed after retries. Log warning if it just returned empty.
            if ohlcv_data is not None:
                lg.warning(f"{NEON_YELLOW}No kline data returned by {exchange.id}.fetch_ohlcv for {symbol} {ccxt_timeframe}. Check symbol/interval/exchange status.{RESET}")
            return empty_df

        # Convert raw list of lists into a pandas DataFrame
        df = pd.DataFrame(ohlcv_data, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])

        if df.empty:
            lg.warning(f"Kline data DataFrame is empty after initial creation for {symbol} {ccxt_timeframe}.")
            return empty_df

        # --- Data Cleaning and Type Conversion ---
        # 1. Convert timestamp to datetime (UTC) and set as index
        try:
            # pd.to_datetime handles various timestamp formats; 'ms' unit is standard for ccxt
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms', errors='coerce', utc=True)
            initial_len_ts = len(df)
            # Drop rows where timestamp conversion failed (resulted in NaT)
            df.dropna(subset=['timestamp'], inplace=True)
            if len(df) < initial_len_ts:
                lg.debug(f"Dropped {initial_len_ts - len(df)} rows with invalid timestamps for {symbol}.")
            if df.empty:
                lg.warning(f"DataFrame became empty after dropping invalid timestamps for {symbol}.")
                return empty_df
            # Set the valid timestamp column as the DataFrame index
            df.set_index('timestamp', inplace=True)
        except Exception as ts_err:
             lg.error(f"Critical error processing timestamps for {symbol}: {ts_err}. Returning empty DataFrame.", exc_info=True)
             return empty_df

        # 2. Convert OHLCV columns to Decimal with robust error handling
        cols_to_convert = ['open', 'high', 'low', 'close', 'volume']
        for col in cols_to_convert:
            if col not in df.columns:
                lg.warning(f"Required column '{col}' missing in fetched kline data for {symbol}. Skipping conversion.")
                continue
            try:
                # Helper function for safe conversion to Decimal, returns Decimal('NaN') on failure
                def safe_to_decimal(x, col_name) -> Decimal:
                    """Converts input to Decimal, returns Decimal('NaN') on failure, NaN, non-finite, or non-positive (for price)."""
                    if pd.isna(x) or str(x).strip() == '': return Decimal('NaN')
                    try:
                        d = Decimal(str(x)) # Convert via string representation
                        # Check conditions: must be finite. Prices must be > 0, Volume >= 0.
                        is_price = col_name in ['open', 'high', 'low', 'close']
                        is_valid = d.is_finite() and (d > 0 if is_price else d >= 0)
                        if is_valid:
                            return d
                        else:
                            # lg.debug(f"Invalid Decimal value in '{col_name}': {x} (Non-finite or non-positive price/negative volume)")
                            return Decimal('NaN')
                    except (InvalidOperation, TypeError, ValueError):
                        # lg.debug(f"Conversion error to Decimal for '{x}' in column '{col_name}', returning NaN.")
                        return Decimal('NaN')

                # Apply the safe conversion function to the column
                df[col] = df[col].apply(lambda x: safe_to_decimal(x, col))

            except Exception as conv_err: # Catch unexpected errors during the apply step
                 lg.error(f"Unexpected error converting column '{col}' to Decimal for {symbol}: {conv_err}. Attempting float conversion as fallback.", exc_info=True)
                 # Fallback: try converting to float, coercing errors to standard float NaN
                 df[col] = pd.to_numeric(df[col], errors='coerce')
                 # Ensure any remaining non-finite floats (inf, -inf) are also treated as NaN
                 if pd.api.types.is_float_dtype(df[col]):
                     df[col] = df[col].apply(lambda x: x if np.isfinite(x) else np.nan)


        # 3. Drop rows with NaN in essential price columns (Open, High, Low, Close)
        initial_len_nan = len(df)
        essential_price_cols = ['open', 'high', 'low', 'close']
        df.dropna(subset=essential_price_cols, how='any', inplace=True)
        rows_dropped_nan = initial_len_nan - len(df)
        if rows_dropped_nan > 0:
            lg.debug(f"Dropped {rows_dropped_nan} rows with NaN price data for {symbol}.")

        # 4. Additional Sanity Check: Ensure OHLC consistency (e.g., High >= Low, High >= Open, etc.)
        # Convert columns to numeric temporarily if they aren't Decimal (due to fallback)
        for col in essential_price_cols:
            if col in df.columns and not isinstance(df[col].iloc[0], Decimal) and not pd.api.types.is_numeric_dtype(df[col]):
                 df[col] = pd.to_numeric(df[col], errors='coerce')
        # Re-check for NaNs introduced by coercion before comparison
        df.dropna(subset=essential_price_cols, how='any', inplace=True)

        if not df.empty: # Proceed only if DF still has data
            try:
                # Create boolean mask for rows where OHLC logic is violated
                # Uses Decimal comparison if types are correct, otherwise numeric comparison
                invalid_ohlc_mask = (df['high'] < df['low']) | \
                                    (df['high'] < df['open']) | \
                                    (df['high'] < df['close']) | \
                                    (df['low'] > df['open']) | \
                                    (df['low'] > df['close'])
                invalid_count = invalid_ohlc_mask.sum()
                if invalid_count > 0:
                    lg.warning(f"{NEON_YELLOW}Found {invalid_count} klines with inconsistent OHLC data (e.g., High < Low) for {symbol}. Dropping these rows.{RESET}")
                    df = df[~invalid_ohlc_mask] # Keep only rows where the mask is False
            except TypeError as cmp_err:
                # This might happen if data conversion failed unexpectedly, leading to mixed types
                lg.warning(f"Could not perform OHLC consistency check for {symbol} due to type error: {cmp_err}. Skipping check.")
            except Exception as cmp_err:
                 lg.warning(f"Unexpected error during OHLC consistency check for {symbol}: {cmp_err}. Skipping check.")

        if df.empty:
            lg.warning(f"Kline data for {symbol} {ccxt_timeframe} became empty after cleaning (NaN drop or OHLC check).")
            return empty_df

        # 5. Sort by timestamp index (should already be sorted, but ensures) and remove duplicates
        df.sort_index(inplace=True)
        if df.index.has_duplicates:
            num_duplicates = df.index.duplicated().sum()
            lg.debug(f"Found {num_duplicates} duplicate timestamps in kline data for {symbol}. Keeping the last entry for each duplicate.")
            # Keep the last occurrence of each duplicated timestamp
            df = df[~df.index.duplicated(keep='last')]

        # --- Final Log and Return ---
        lg.info(f"Successfully fetched and processed {len(df)} valid klines for {symbol} {ccxt_timeframe} (requested limit: {limit})")
        # Log head/tail only if DEBUG level is enabled and DataFrame is not empty
        if lg.isEnabledFor(logging.DEBUG) and not df.empty:
             lg.debug(f"Kline check ({symbol}): First row:\n{df.head(1)}\nLast row:\n{df.tail(1)}")
        return df

    except ValueError as ve: # Catch specific validation errors raised within the function
        lg.error(f"{NEON_RED}Kline fetch/processing error for {symbol}: {ve}{RESET}")
        return empty_df
    except Exception as e:
        # Catch errors from safe_api_call or unexpected errors during processing
        lg.error(f"{NEON_RED}Unexpected error fetching or processing klines for {symbol}: {e}{RESET}", exc_info=True)
        return empty_df


def fetch_orderbook_ccxt(exchange: ccxt.Exchange, symbol: str, limit: int, logger: logging.Logger) -> Optional[Dict]:
    """
    Fetches order book data using CCXT with retries, validation, and Decimal conversion.
    - Uses safe_api_call for fetching.
    - Validates the structure of the returned order book data.
    - Converts bid/ask prices and amounts to Decimal, ensuring they are finite and positive.
    - Logs warnings for invalid entries but attempts to return partial data if possible.
    - Returns a dictionary containing 'bids' and 'asks' lists (each entry is [Decimal(price), Decimal(amount)]),
      along with original metadata, or None on failure.

    Args:
        exchange (ccxt.Exchange): Initialized CCXT exchange object.
        symbol (str): Trading symbol.
        limit (int): Number of order book levels to fetch (depth).
        logger (logging.Logger): Logger instance.

    Returns:
        Optional[Dict]: Order book dictionary with Decimal values, or None if fetching/processing fails.
                        Structure: {'bids': [[price, amount], ...], 'asks': [[price, amount], ...], 'timestamp': ..., ...}
    """
    lg = logger
    # Check if exchange supports fetching the order book
    if not exchange.has.get('fetchOrderBook'):
        lg.error(f"Exchange {exchange.id} does not support fetchOrderBook according to ccxt 'has' attribute.")
        return None

    try:
        lg.debug(f"Fetching order book for {symbol} with limit {limit}...")
        # Fetch order book using the safe API call wrapper
        orderbook_raw = safe_api_call(exchange.fetch_order_book, lg, symbol, limit=limit)

        # Validate the raw response
        if not orderbook_raw: # safe_api_call logs error if retries failed
            lg.warning(f"fetch_order_book for {symbol} returned None or empty after retries.")
            return None
        if not isinstance(orderbook_raw, dict) or \
           'bids' not in orderbook_raw or 'asks' not in orderbook_raw or \
           not isinstance(orderbook_raw['bids'], list) or not isinstance(orderbook_raw['asks'], list):
            lg.warning(f"Invalid order book structure received for {symbol}. Data: {str(orderbook_raw)[:200]}...") # Log snippet
            return None

        # --- Process bids and asks, converting to Decimal ---
        cleaned_book = {
            'bids': [],
            'asks': [],
            # Preserve original metadata if available
            'timestamp': orderbook_raw.get('timestamp'),
            'datetime': orderbook_raw.get('datetime'),
            'nonce': orderbook_raw.get('nonce')
        }
        conversion_errors = 0
        invalid_format_count = 0

        for side in ['bids', 'asks']:
            for entry in orderbook_raw[side]:
                # Ensure entry is a list/tuple with exactly two elements (price, amount)
                if isinstance(entry, (list, tuple)) and len(entry) == 2:
                    try:
                        # Convert price and amount to Decimal via string representation
                        price = Decimal(str(entry[0]))
                        amount = Decimal(str(entry[1]))

                        # Validate: Price must be > 0, Amount must be >= 0, both must be finite
                        if price.is_finite() and price > 0 and amount.is_finite() and amount >= 0:
                            cleaned_book[side].append([price, amount])
                        else:
                            # lg.debug(f"Invalid Decimal price/amount in {side} entry for {symbol}: P={price}, A={amount}") # Can be verbose
                            conversion_errors += 1
                    except (InvalidOperation, ValueError, TypeError):
                        # lg.debug(f"Conversion error for {side} entry: {entry} in {symbol}") # Can be verbose
                        conversion_errors += 1
                else:
                    # Log entries with unexpected format
                    # lg.warning(f"Invalid {side[:-1]} entry format in orderbook for {symbol}: {entry}")
                    invalid_format_count += 1

        # Log summary of cleaning issues if any occurred
        if conversion_errors > 0:
            lg.debug(f"Orderbook ({symbol}): Encountered {conversion_errors} entries with invalid/non-finite/non-positive values during Decimal conversion.")
        if invalid_format_count > 0:
            lg.warning(f"{NEON_YELLOW}Orderbook ({symbol}): Encountered {invalid_format_count} entries with unexpected format (expected [price, amount]).{RESET}")

        # Ensure bids are sorted descending by price and asks ascending by price
        # CCXT usually provides sorted data, but this ensures consistency. Use Decimal comparison.
        try:
            cleaned_book['bids'].sort(key=lambda x: x[0], reverse=True)
            cleaned_book['asks'].sort(key=lambda x: x[0])
        except Exception as sort_err:
             lg.warning(f"Could not sort order book entries for {symbol}: {sort_err}. Data might be unsorted.")

        # Check if the cleaned book is empty
        if not cleaned_book['bids'] and not cleaned_book['asks']:
            lg.warning(f"Orderbook for {symbol} is empty after cleaning/conversion (originally had {len(orderbook_raw['bids'])} bids, {len(orderbook_raw['asks'])} asks).")
            # Still return the structure, as the fetch itself might have succeeded
            return cleaned_book
        elif not cleaned_book['bids']:
             lg.warning(f"Orderbook ({symbol}) contains no valid bids after cleaning.")
        elif not cleaned_book['asks']:
             lg.warning(f"Orderbook ({symbol}) contains no valid asks after cleaning.")

        lg.debug(f"Successfully fetched and processed order book for {symbol} ({len(cleaned_book['bids'])} valid bids, {len(cleaned_book['asks'])} valid asks).")
        return cleaned_book

    except Exception as e:
        # Catch errors raised by safe_api_call or during other processing steps
        lg.error(f"{NEON_RED}Error fetching or processing order book for {symbol}: {e}{RESET}", exc_info=False)
        return None

# --- Trading Analyzer Class ---
class TradingAnalyzer:
    """
    Analyzes market data (OHLCV, order book) to generate trading signals.
    - Calculates technical indicators using pandas_ta.
    - Handles Decimal/float type conversions between raw data, TA library, and internal use.
    - Provides helper methods for market precision, limits, and SL/TP calculation.
    - Generates weighted trading signals based on configured indicators and weights.
    """

    def __init__(
        self,
        df: pd.DataFrame, # Expects OHLCV columns with Decimal type from fetch_klines
        logger: logging.Logger,
        config: Dict[str, Any],
        market_info: Dict[str, Any],
    ) -> None:
        """
        Initializes the TradingAnalyzer.

        Args:
            df (pd.DataFrame): Pandas DataFrame containing OHLCV data (expects Decimal values)
                               indexed by timestamp (UTC).
            logger (logging.Logger): Logger instance for logging messages.
            config (Dict[str, Any]): The bot's configuration dictionary.
            market_info (Dict[str, Any]): Dictionary containing details for the specific market
                                          (precision, limits, symbol, etc.) obtained from CCXT.
        """
        if not isinstance(df, pd.DataFrame):
             raise ValueError("TradingAnalyzer requires a pandas DataFrame.")
        self.df = df.copy() # Work on a copy to avoid modifying the original DataFrame passed in
        self.logger = logger
        self.config = config
        self.market_info = market_info
        self.symbol = market_info.get('symbol', 'UNKNOWN_SYMBOL')
        self.interval = config.get("interval", "N/A") # Internal interval string
        self.ccxt_interval = CCXT_INTERVAL_MAP.get(self.interval) # CCXT timeframe string

        # Dictionary to store the latest calculated indicator values.
        # Uses Decimal for price-based values (OHLC, ATR, Bands, EMAs, PSAR, VWAP) and float for others.
        self.indicator_values: Dict[str, Union[Decimal, float, datetime, None]] = {}
        # Dictionary to map internal indicator keys (e.g., "EMA_Short") to the actual
        # column names generated by pandas_ta in the DataFrame (e.g., "EMA_9").
        self.ta_column_names: Dict[str, Optional[str]] = {}
        # Dictionary to store calculated Fibonacci retracement levels (Decimal prices).
        self.fib_levels_data: Dict[str, Decimal] = {}

        # Load the active weight set configuration for signal scoring
        self.active_weight_set_name = config.get("active_weight_set", "default")
        self.weights = config.get("weight_sets", {}).get(self.active_weight_set_name, {})
        if not self.weights:
            logger.warning(f"{NEON_YELLOW}Active weight set '{self.active_weight_set_name}' not found or is empty in config for {self.symbol}. Signal scores may be zero.{RESET}")
            self.weights = {} # Use empty dict to prevent errors if weights are missing

        # --- Caches for Precision/Limits (populated by getter methods) ---
        # Avoid recalculating these frequently within a single analysis cycle
        self._cached_price_precision: Optional[int] = None
        self._cached_min_tick_size: Optional[Decimal] = None
        self._cached_amount_precision: Optional[int] = None
        self._cached_min_amount_step: Optional[Decimal] = None

        # Perform initial validation and calculations upon instantiation
        self._initialize_analysis()

    def _initialize_analysis(self) -> None:
        """Performs initial checks and calculations when the analyzer is created."""
        if self.df.empty:
             self.logger.warning(f"TradingAnalyzer initialized with an empty DataFrame for {self.symbol}. No calculations will be performed.")
             return

        # Verify required columns exist
        required_cols = ['open', 'high', 'low', 'close', 'volume']
        missing_cols = [col for col in required_cols if col not in self.df.columns]
        if missing_cols:
            self.logger.error(f"DataFrame for {self.symbol} is missing required columns: {', '.join(missing_cols)}. Cannot perform analysis.")
            self.df = pd.DataFrame() # Clear DF to prevent errors in subsequent methods
            return

        # Verify data types (expecting Decimal from fetch_klines)
        first_valid_idx = self.df['close'].first_valid_index()
        if first_valid_idx is None or not isinstance(self.df.loc[first_valid_idx, 'close'], Decimal):
             self.logger.warning(f"DataFrame 'close' column for {self.symbol} does not appear to contain Decimal values as expected. Calculations might proceed but precision could be affected.")

        # Verify DataFrame contains some non-NaN data in essential columns
        if self.df[essential_price_cols].isnull().all().all():
             self.logger.error(f"DataFrame for {self.symbol} contains all NaN values in required price columns. Cannot perform analysis.")
             self.df = pd.DataFrame() # Clear DF
             return

        # --- Proceed with Initial Calculations ---
        try:
            self._calculate_all_indicators()
            # Update latest values *after* indicators are calculated and potentially back-converted
            self._update_latest_indicator_values()
            # Calculate initial Fibonacci levels
            self.calculate_fibonacci_levels()
        except Exception as init_calc_err:
             # Catch any unexpected errors during the initial calculation phase
             self.logger.error(f"Error during TradingAnalyzer initial indicator/Fibonacci calculation for {self.symbol}: {init_calc_err}", exc_info=True)
             # Consider clearing the DataFrame or setting a 'failed' state depending on severity
             # self.df = pd.DataFrame()

    def _get_ta_col_name(self, base_name: str, result_df_columns: List[str]) -> Optional[str]:
        """
        Helper method to robustly find the actual column name generated by pandas_ta
        for a given internal indicator base name.

        Args:
            base_name (str): Internal identifier for the indicator (e.g., "ATR", "EMA_Short").
            result_df_columns (List[str]): List of column names present in the DataFrame after
                                           TA calculations have been run.

        Returns:
            Optional[str]: The matched column name string, or None if no unambiguous match is found.
        """
        if not result_df_columns: return None # Cannot search if no columns exist

        # --- Dynamically Define Expected Patterns Based on Config ---
        # Use float representation matching pandas_ta common output (e.g., '2.0' for std dev)
        bb_std_dev_str = f"{float(self.config.get('bollinger_bands_std_dev', DEFAULT_BBANDS_STDDEV)):.1f}"
        psar_step_str = f"{float(self.config.get('psar_step', DEFAULT_PSAR_STEP)):g}" # Use 'g' for general format (avoids trailing zeros like 0.020)
        psar_max_str = f"{float(self.config.get('psar_max_step', DEFAULT_PSAR_MAX_STEP)):g}"

        # Get relevant period parameters from config or defaults
        param_keys = [
            ('atr_period', DEFAULT_ATR_PERIOD), ('ema_short_period', DEFAULT_EMA_SHORT_PERIOD),
            ('ema_long_period', DEFAULT_EMA_LONG_PERIOD), ('momentum_period', DEFAULT_MOMENTUM_PERIOD),
            ('cci_period', DEFAULT_CCI_PERIOD), ('williams_r_period', DEFAULT_WILLIAMS_R_PERIOD),
            ('mfi_period', DEFAULT_MFI_PERIOD), ('rsi_period', DEFAULT_RSI_PERIOD),
            ('bollinger_bands_period', DEFAULT_BBANDS_PERIOD), ('sma_10_period', DEFAULT_SMA10_PERIOD),
            ('volume_ma_period', DEFAULT_VOLUME_MA_PERIOD),
            ('stoch_rsi_period', DEFAULT_STOCH_RSI_PERIOD), ('stoch_rsi_rsi_period', DEFAULT_STOCH_RSI_RSI_PERIOD),
            ('stoch_rsi_k_period', DEFAULT_STOCH_RSI_K_PERIOD), ('stoch_rsi_d_period', DEFAULT_STOCH_RSI_D_PERIOD)
        ]
        params = {key: int(self.config.get(key, default)) for key, default in param_keys} # Ensure integers

        # Map internal base names to lists of potential pandas_ta column name patterns
        # These patterns should match the typical output of pandas_ta functions
        expected_patterns = {
            "ATR": [f"ATRr_{params['atr_period']}"], # 'r' suffix often means 'real' or result
            "EMA_Short": [f"EMA_{params['ema_short_period']}"],
            "EMA_Long": [f"EMA_{params['ema_long_period']}"],
            "Momentum": [f"MOM_{params['momentum_period']}"],
            "CCI": [f"CCI_{params['cci_period']}", f"CCI_{params['cci_period']}_0.015"], # Common suffix for constant
            "Williams_R": [f"WILLR_{params['williams_r_period']}"],
            "MFI": [f"MFI_{params['mfi_period']}"],
            "VWAP": ["VWAP", "VWAP_D"], # pandas_ta default VWAP often daily anchored ('_D')
            "PSAR_long": [f"PSARl_{psar_step_str}_{psar_max_str}"], # 'l' for long trend signal
            "PSAR_short": [f"PSARs_{psar_step_str}_{psar_max_str}"], # 's' for short trend signal
            "PSAR_af": [f"PSARaf_{psar_step_str}_{psar_max_str}"], # Acceleration factor
            "PSAR_rev": [f"PSARr_{psar_step_str}_{psar_max_str}"], # Reversal points
            "SMA_10": [f"SMA_{params['sma_10_period']}"],
            "StochRSI_K": [f"STOCHRSIk_{params['stoch_rsi_period']}_{params['stoch_rsi_rsi_period']}_{params['stoch_rsi_k_period']}"],
            "StochRSI_D": [f"STOCHRSId_{params['stoch_rsi_period']}_{params['stoch_rsi_rsi_period']}_{params['stoch_rsi_k_period']}_{params['stoch_rsi_d_period']}"],
            "RSI": [f"RSI_{params['rsi_period']}"],
            "BB_Lower": [f"BBL_{params['bollinger_bands_period']}_{bb_std_dev_str}"],
            "BB_Middle": [f"BBM_{params['bollinger_bands_period']}_{bb_std_dev_str}"],
            "BB_Upper": [f"BBU_{params['bollinger_bands_period']}_{bb_std_dev_str}"],
            "BB_Bandwidth": [f"BBB_{params['bollinger_bands_period']}_{bb_std_dev_str}"],
            "BB_Percent": [f"BBP_{params['bollinger_bands_period']}_{bb_std_dev_str}"],
            # Custom name used for Volume MA calculation
            "Volume_MA": [f"VOL_SMA_{params['volume_ma_period']}"]
        }

        patterns_to_check = expected_patterns.get(base_name)
        if not patterns_to_check:
            # self.logger.debug(f"No expected column pattern defined for indicator base name: '{base_name}'")
            return None

        # --- Search Strategy (from most specific to least specific) ---
        # 1. Exact Match (Case-Sensitive) - Most reliable
        for pattern in patterns_to_check:
            if pattern in result_df_columns:
                # self.logger.debug(f"Mapped '{base_name}' to column '{pattern}' (Exact Match)")
                return pattern

        # 2. Case-Insensitive Exact Match
        patterns_lower = [p.lower() for p in patterns_to_check]
        # Create mapping from lower-case column name to original case for efficient lookup
        cols_lower_map = {col.lower(): col for col in result_df_columns}
        for i, pattern_lower in enumerate(patterns_lower):
             if pattern_lower in cols_lower_map:
                  original_col_name = cols_lower_map[pattern_lower]
                  # self.logger.debug(f"Mapped '{base_name}' to column '{original_col_name}' (Case-Insensitive Exact Match)")
                  return original_col_name

        # 3. Starts With Match (Case-Insensitive) - Handles potential suffixes added by TA lib
        for pattern in patterns_to_check:
            pattern_lower = pattern.lower()
            for col in result_df_columns:
                col_lower = col.lower()
                # Check if column starts with the pattern (case-insensitive)
                if col_lower.startswith(pattern_lower):
                     # Sanity check: ensure the remaining suffix doesn't look like a different indicator name
                     suffix = col[len(pattern):]
                     if not any(c.isalpha() for c in suffix): # Allow numbers, underscores, periods in suffix
                          # self.logger.debug(f"Mapped '{base_name}' to column '{col}' (StartsWith Match: '{pattern}')")
                          return col
                     # else: suffix contains letters, might be a different indicator, continue search

        # 4. Fallback: Simple base name substring check (use with caution)
        # Example: base_name 'StochRSI_K' -> simple_base 'stochrsi'
        simple_base = base_name.split('_')[0].lower()
        potential_matches = [col for col in result_df_columns if simple_base in col.lower()]

        if len(potential_matches) == 1:
             match = potential_matches[0]
             # self.logger.debug(f"Mapped '{base_name}' to '{match}' via unique simple substring search ('{simple_base}').")
             return match
        elif len(potential_matches) > 1:
              # Ambiguous: Multiple columns contain the simple base name.
              # Try to resolve by checking if one of the full expected patterns is among the matches.
              for pattern in patterns_to_check:
                   if pattern in potential_matches: # Check exact expected pattern
                        # self.logger.debug(f"Resolved ambiguous substring match for '{base_name}' to expected pattern '{pattern}'.")
                        return pattern
                   if pattern.lower() in [p.lower() for p in potential_matches]: # Check case-insensitive expected pattern
                        # Find the original case match
                        original_case_match = next((p for p in potential_matches if p.lower() == pattern.lower()), None)
                        if original_case_match:
                             # self.logger.debug(f"Resolved ambiguous substring match for '{base_name}' to expected pattern '{original_case_match}' (case-insensitive).")
                             return original_case_match

              # If still ambiguous after checking expected patterns, it's safer to return None
              self.logger.warning(f"{NEON_YELLOW}Ambiguous substring match for '{base_name}' ('{simple_base}'): Found {potential_matches}. Could not resolve clearly based on expected patterns: {patterns_to_check}. No column mapped.{RESET}")
              return None

        # If no match found by any method
        self.logger.debug(f"Could not find matching column name for indicator '{base_name}' (Expected patterns: {patterns_to_check}) in DataFrame columns: {result_df_columns}")
        return None


    def _calculate_all_indicators(self):
        """
        Calculates all technical indicators specified and enabled in the configuration
        using the pandas_ta library. Handles data type conversions for compatibility.
        Updates the internal DataFrame with the calculated indicator columns.
        """
        if self.df.empty:
            self.logger.warning(f"DataFrame is empty for {self.symbol}, cannot calculate indicators.")
            return

        # --- Determine Minimum Required Data Length ---
        # Estimate required length based on the longest period among enabled & weighted indicators
        required_periods = []
        indicators_config = self.config.get("indicators", {})
        active_weights = self.weights # Use weights loaded during init

        # Helper to add period requirement if indicator is active
        def add_req_if_active(indicator_key, config_period_key, default_period):
            """Adds period requirement if indicator is enabled and has non-zero weight."""
            is_enabled = indicators_config.get(indicator_key, False)
            try: weight = float(active_weights.get(indicator_key, 0.0))
            except (ValueError, TypeError): weight = 0.0

            if is_enabled and weight > 1e-9: # Check weight > small tolerance
                try:
                    period = int(self.config.get(config_period_key, default_period))
                    if period > 0: required_periods.append(period)
                    else: self.logger.warning(f"Invalid zero/negative period configured for {config_period_key} ({period}). Ignoring for length check.")
                except (ValueError, TypeError):
                     self.logger.warning(f"Invalid period format for {config_period_key} ('{self.config.get(config_period_key)}'). Ignoring for length check.")

        # Add requirements for indicators with standard periods
        add_req_if_active("atr", "atr_period", DEFAULT_ATR_PERIOD)
        add_req_if_active("momentum", "momentum_period", DEFAULT_MOMENTUM_PERIOD)
        add_req_if_active("cci", "cci_period", DEFAULT_CCI_PERIOD)
        add_req_if_active("wr", "williams_r_period", DEFAULT_WILLIAMS_R_PERIOD)
        add_req_if_active("mfi", "mfi_period", DEFAULT_MFI_PERIOD)
        add_req_if_active("sma_10", "sma_10_period", DEFAULT_SMA10_PERIOD)
        add_req_if_active("rsi", "rsi_period", DEFAULT_RSI_PERIOD)
        add_req_if_active("bollinger_bands", "bollinger_bands_period", DEFAULT_BBANDS_PERIOD)
        add_req_if_active("volume_confirmation", "volume_ma_period", DEFAULT_VOLUME_MA_PERIOD)

        # Fibonacci period is a lookback window, include it
        try: fib_period = int(self.config.get("fibonacci_period", DEFAULT_FIB_PERIOD))
        except (ValueError, TypeError): fib_period = DEFAULT_FIB_PERIOD
        if fib_period > 0: required_periods.append(fib_period)

        # Compound indicators: EMA Alignment requires both short and long EMAs
        if indicators_config.get("ema_alignment", False) and float(active_weights.get("ema_alignment", 0.0)) > 1e-9:
             add_req_if_active("ema_alignment", "ema_short_period", DEFAULT_EMA_SHORT_PERIOD) # Use proxy key
             add_req_if_active("ema_alignment", "ema_long_period", DEFAULT_EMA_LONG_PERIOD)

        # StochRSI requires its main period and the underlying RSI period
        if indicators_config.get("stoch_rsi", False) and float(active_weights.get("stoch_rsi", 0.0)) > 1e-9:
             add_req_if_active("stoch_rsi", "stoch_rsi_period", DEFAULT_STOCH_RSI_PERIOD)
             add_req_if_active("stoch_rsi", "stoch_rsi_rsi_period", DEFAULT_STOCH_RSI_RSI_PERIOD)

        # Calculate minimum required length, add a buffer (e.g., 30 bars) for indicator stabilization
        min_required_data = max(required_periods) + 30 if required_periods else 50 # Default buffer if no periods found

        if len(self.df) < min_required_data:
             self.logger.warning(f"{NEON_YELLOW}Insufficient kline data ({len(self.df)} points) for {self.symbol} {self.ccxt_interval} "
                                f"to reliably calculate all active indicators (min recommended: {min_required_data} based on max period: {max(required_periods) if required_periods else 'N/A'}). "
                                f"Results may contain NaNs or be inaccurate.{RESET}")
             # Proceed with calculation, but be aware of potential issues in results

        try:
            # --- Prepare DataFrame for pandas_ta ---
            # pandas_ta generally works best with float types for OHLCV.
            # Convert Decimal columns to float temporarily, storing original types.
            df_calc = self.df # Use alias for clarity, modification happens on the instance's copy
            original_types = {}
            cols_to_float = ['open', 'high', 'low', 'close', 'volume']

            for col in cols_to_float:
                 if col in df_calc.columns:
                     # Check type of first non-NaN value to determine original type
                     first_valid_idx = df_calc[col].first_valid_index()
                     if first_valid_idx is not None:
                          col_type = type(df_calc.loc[first_valid_idx, col])
                          original_types[col] = col_type
                          # Only convert if the original type was Decimal
                          if col_type == Decimal:
                               # self.logger.debug(f"Converting Decimal column '{col}' to float for TA calculation.")
                               # Apply conversion robustly: finite Decimals -> float, non-finite -> np.nan
                               df_calc[col] = df_calc[col].apply(
                                   lambda x: float(x) if isinstance(x, Decimal) and x.is_finite() else np.nan
                               )
                          elif not pd.api.types.is_numeric_dtype(df_calc[col]):
                              # If original type wasn't Decimal and isn't numeric, attempt conversion
                              self.logger.debug(f"Column '{col}' is not Decimal or numeric ({col_type}), attempting conversion to float.")
                              df_calc[col] = pd.to_numeric(df_calc[col], errors='coerce')
                     else: # Column is all NaN
                          original_types[col] = None # Mark as unknown original type
                          # self.logger.debug(f"Column '{col}' contains only NaN values, skipping conversion.")

            # --- Dynamically Create pandas_ta Strategy ---
            ta_strategy = ta.Strategy(
                name="SXS_Dynamic_Strategy",
                description="Calculates indicators based on sxsBot config file",
                ta=[] # Initialize empty list of indicators to add
            )

            # --- Map internal keys to pandas_ta function names and parameters ---
            # Use lambda functions to fetch parameters from self.config at the time of calculation
            # Ensure parameters are cast to the types expected by pandas_ta (int for lengths, float for std/step)
            ta_map = {
                 # Indicator Key : { pandas_ta_function_name, parameter_name: lambda: type_cast(self.config.get(...)), ... }
                 "atr": {"kind": "atr", "length": lambda: int(self.config.get("atr_period", DEFAULT_ATR_PERIOD))},
                 "ema_short": {"kind": "ema", "length": lambda: int(self.config.get("ema_short_period", DEFAULT_EMA_SHORT_PERIOD))},
                 "ema_long": {"kind": "ema", "length": lambda: int(self.config.get("ema_long_period", DEFAULT_EMA_LONG_PERIOD))},
                 "momentum": {"kind": "mom", "length": lambda: int(self.config.get("momentum_period", DEFAULT_MOMENTUM_PERIOD))},
                 "cci": {"kind": "cci", "length": lambda: int(self.config.get("cci_period", DEFAULT_CCI_PERIOD))},
                 "wr": {"kind": "willr", "length": lambda: int(self.config.get("williams_r_period", DEFAULT_WILLIAMS_R_PERIOD))},
                 "mfi": {"kind": "mfi", "length": lambda: int(self.config.get("mfi_period", DEFAULT_MFI_PERIOD))},
                 "sma_10": {"kind": "sma", "length": lambda: int(self.config.get("sma_10_period", DEFAULT_SMA10_PERIOD))},
                 "rsi": {"kind": "rsi", "length": lambda: int(self.config.get("rsi_period", DEFAULT_RSI_PERIOD))},
                 "vwap": {"kind": "vwap"}, # VWAP typically uses default daily anchoring in pandas_ta
                 "psar": {"kind": "psar",
                          "step": lambda: float(self.config.get("psar_step", DEFAULT_PSAR_STEP)),
                          "max_step": lambda: float(self.config.get("psar_max_step", DEFAULT_PSAR_MAX_STEP))},
                 "stoch_rsi": {"kind": "stochrsi",
                               "length": lambda: int(self.config.get("stoch_rsi_period", DEFAULT_STOCH_RSI_PERIOD)),
                               "rsi_length": lambda: int(self.config.get("stoch_rsi_rsi_period", DEFAULT_STOCH_RSI_RSI_PERIOD)),
                               "k": lambda: int(self.config.get("stoch_rsi_k_period", DEFAULT_STOCH_RSI_K_PERIOD)),
                               "d": lambda: int(self.config.get("stoch_rsi_d_period", DEFAULT_STOCH_RSI_D_PERIOD))},
                 "bollinger_bands": {"kind": "bbands",
                                     "length": lambda: int(self.config.get("bollinger_bands_period", DEFAULT_BBANDS_PERIOD)),
                                     "std": lambda: float(self.config.get("bollinger_bands_std_dev", DEFAULT_BBANDS_STDDEV))},
                 # Note: Volume MA is calculated separately below, not added to ta_map
            }

            # --- Add Indicators to Strategy Based on Config/Weights ---
            calculated_indicator_keys = set() # Track which base indicators are added to avoid duplicates

            # Always calculate ATR if possible, as it's needed for SL/TP/BE sizing, even if not weighted for signals
            if "atr" in ta_map:
                 try:
                     params = {k: v() for k, v in ta_map["atr"].items() if k != 'kind'} # Extract params using lambdas
                     ta_strategy.ta.append(ta.Indicator(ta_map["atr"]["kind"], **params))
                     calculated_indicator_keys.add("atr")
                     # self.logger.debug(f"Adding ATR to TA strategy with params: {params}")
                 except Exception as e: self.logger.error(f"Error preparing ATR indicator for strategy: {e}")

            # Add other indicators only if they are enabled AND have a non-zero weight in the active set
            for key, is_enabled in indicators_config.items():
                 if key == "atr": continue # Already handled
                 try: weight = float(active_weights.get(key, 0.0))
                 except (ValueError, TypeError): weight = 0.0

                 # Skip if disabled in config OR has zero weight in the active set
                 if not is_enabled or weight < 1e-9: continue

                 # Handle compound indicators or indicators needing special logic
                 if key == "ema_alignment":
                      # Requires both short and long EMAs to be calculated
                      for ema_key in ["ema_short", "ema_long"]:
                          if ema_key not in calculated_indicator_keys and ema_key in ta_map:
                               try:
                                   params = {k: v() for k, v in ta_map[ema_key].items() if k != 'kind'}
                                   ta_strategy.ta.append(ta.Indicator(ta_map[ema_key]["kind"], **params))
                                   calculated_indicator_keys.add(ema_key)
                                   # self.logger.debug(f"Adding {ema_key} (for ema_alignment) to TA strategy with params: {params}")
                               except Exception as e: self.logger.error(f"Error preparing {ema_key} indicator for strategy: {e}")
                 elif key == "volume_confirmation":
                      # Volume MA is calculated separately after the main strategy run
                      pass
                 elif key == "orderbook":
                      # Order book analysis doesn't use pandas_ta
                      pass
                 elif key in ta_map:
                      # Check if this base indicator was already added (e.g., if EMA was added via ema_alignment)
                      if key not in calculated_indicator_keys:
                           try:
                               indicator_def = ta_map[key]
                               params = {k: v() for k, v in indicator_def.items() if k != 'kind'}
                               ta_strategy.ta.append(ta.Indicator(indicator_def["kind"], **params))
                               calculated_indicator_keys.add(key) # Mark base key as calculated
                               # self.logger.debug(f"Adding {key} to TA strategy with params: {params}")
                           except Exception as e: self.logger.error(f"Error preparing {key} indicator for strategy: {e}")
                 else:
                      # This indicates a mismatch between config['indicators'], config['weights'], and ta_map/special handling
                      self.logger.warning(f"Indicator '{key}' is enabled and weighted but has no calculation definition in ta_map or special handling. It will be ignored.")

            # --- Execute the TA Strategy ---
            if ta_strategy.ta: # Only run if indicators were actually added
                 self.logger.info(f"Running pandas_ta strategy '{ta_strategy.name}' with {len(ta_strategy.ta)} indicators for {self.symbol}...")
                 try:
                     # df.ta.strategy() applies the indicators and appends columns to df_calc inplace
                     df_calc.ta.strategy(ta_strategy, append=True)
                     self.logger.info(f"Pandas_ta strategy calculation complete for {self.symbol}.")
                 except Exception as ta_err:
                      self.logger.error(f"{NEON_RED}Error running pandas_ta strategy for {self.symbol}: {ta_err}{RESET}", exc_info=True)
                      # Allow continuation, but subsequent steps might fail if indicators are missing
            else:
                 self.logger.info(f"No pandas_ta indicators added to the strategy based on config and weights for {self.symbol}.")

            # --- Calculate Volume Moving Average Separately ---
            vol_key = "volume_confirmation"
            vol_ma_p = 0
            try: vol_ma_p = int(self.config.get("volume_ma_period", DEFAULT_VOLUME_MA_PERIOD))
            except (ValueError, TypeError): pass

            # Calculate only if enabled, weighted, and period is valid
            if indicators_config.get(vol_key, False) and float(active_weights.get(vol_key, 0.0)) > 1e-9 and vol_ma_p > 0:
                 try:
                     vol_ma_col = f"VOL_SMA_{vol_ma_p}" # Define a unique column name
                     # Ensure 'volume' column exists and is numeric (should be float after conversion)
                     if 'volume' in df_calc.columns and pd.api.types.is_numeric_dtype(df_calc['volume']):
                          # Use pandas_ta directly for SMA on the volume column
                          # Fill potential NaNs in volume with 0 before calculating SMA to avoid propagation
                          df_calc[vol_ma_col] = ta.sma(df_calc['volume'].fillna(0), length=vol_ma_p)
                          # self.logger.debug(f"Calculated Volume MA ({vol_ma_col}) for {self.symbol}.")
                          calculated_indicator_keys.add("volume_ma") # Mark for column mapping
                     else:
                          self.logger.warning(f"Volume column missing or not numeric in DataFrame for {self.symbol}, cannot calculate Volume MA.")
                 except Exception as vol_ma_err:
                      self.logger.error(f"Error calculating Volume MA for {self.symbol}: {vol_ma_err}")

            # --- Map Internal Names to Actual DataFrame Column Names ---
            # Get all column names present after calculations
            final_df_columns = df_calc.columns.tolist()
            # Define the mapping from internal keys (used in checks/scoring) to the base names used in _get_ta_col_name
            indicator_mapping = {
                # Internal Name : TA Indicator Base Name (used in _get_ta_col_name patterns)
                "ATR": "ATR", "EMA_Short": "EMA_Short", "EMA_Long": "EMA_Long",
                "Momentum": "Momentum", "CCI": "CCI", "Williams_R": "Williams_R", "MFI": "MFI",
                "SMA_10": "SMA_10", "RSI": "RSI", "VWAP": "VWAP",
                # PSAR generates multiple columns; map the specific ones needed by checks
                "PSAR_long": "PSAR_long", "PSAR_short": "PSAR_short",
                # StochRSI generates K and D; map both if used
                "StochRSI_K": "StochRSI_K", "StochRSI_D": "StochRSI_D",
                # BBands generates multiple; map components needed by checks
                "BB_Lower": "BB_Lower", "BB_Middle": "BB_Middle", "BB_Upper": "BB_Upper",
                "Volume_MA": "Volume_MA" # Use the custom name defined above
            }
            self.ta_column_names = {} # Clear previous mapping
            for internal_name, ta_base_name in indicator_mapping.items():
                 # Find the actual column name using the robust helper method
                 mapped_col = self._get_ta_col_name(ta_base_name, final_df_columns)
                 if mapped_col:
                     self.ta_column_names[internal_name] = mapped_col
                 # else: Warning logged by _get_ta_col_name if not found

            # --- Convert Selected Columns Back to Decimal (if original was Decimal) ---
            # Prioritize converting indicators used in precise calculations (ATR, price-based levels)
            # Check if original 'close' price was Decimal as a proxy for whether conversion is needed/meaningful
            if original_types.get('close') == Decimal:
                cols_to_decimalize = ["ATR", "BB_Lower", "BB_Middle", "BB_Upper", "PSAR_long",
                                      "PSAR_short", "VWAP", "SMA_10", "EMA_Short", "EMA_Long"]

                for key in cols_to_decimalize:
                    col_name = self.ta_column_names.get(key)
                    # Check if indicator was calculated, column name found, and column exists
                    if col_name and col_name in df_calc.columns:
                         # Check if the column actually contains float data (might be object/int if errors occurred)
                         if pd.api.types.is_float_dtype(df_calc[col_name]):
                             try:
                                 # self.logger.debug(f"Converting calculated column '{col_name}' (for '{key}') back to Decimal.")
                                 # Convert float column back to Decimal, handling potential NaNs/infs robustly
                                 df_calc[col_name] = df_calc[col_name].apply(
                                     lambda x: Decimal(str(x)) if pd.notna(x) and np.isfinite(x) else Decimal('NaN')
                                 )
                             except (ValueError, TypeError, InvalidOperation) as conv_err:
                                  self.logger.error(f"Failed to convert TA column '{col_name}' back to Decimal: {conv_err}. Leaving as float.")
                         # else: Column is not float, skip conversion attempt

            self.logger.debug(f"Finished indicator calculations for {self.symbol}. Final DF columns sample: {self.df.columns.tolist()[:15]}...")
            self.logger.debug(f"Mapped TA column names for {self.symbol}: {self.ta_column_names}")

        except Exception as e:
            self.logger.error(f"{NEON_RED}Critical error during indicator calculation setup or execution for {self.symbol}: {e}{RESET}", exc_info=True)
            # Consider clearing the DataFrame or setting flags to prevent further use
            # self.df = pd.DataFrame()

    def _update_latest_indicator_values(self):
        """
        Extracts the latest values for OHLCV and all calculated indicators from the
        DataFrame and stores them in the `self.indicator_values` dictionary.
        Handles type consistency (Decimal for price/ATR, float for others) and NaNs.
        """
        self.indicator_values = {} # Reset dictionary

        if self.df.empty:
            self.logger.warning(f"Cannot update latest indicator values: DataFrame empty for {self.symbol}.")
            return
        try:
            # Ensure index is sorted chronologically to get the truly latest row
            if not self.df.index.is_monotonic_increasing:
                 self.logger.warning(f"DataFrame index for {self.symbol} is not sorted. Sorting before extracting latest values.")
                 self.df.sort_index(inplace=True)

            # Get the last row of the DataFrame
            latest_row = self.df.iloc[-1]
            latest_timestamp = latest_row.name # Get timestamp from the index
            self.indicator_values["Timestamp"] = latest_timestamp # Store timestamp as datetime object

        except IndexError:
            self.logger.error(f"Error accessing latest row (iloc[-1]) for {self.symbol}. DataFrame might be empty or calculations failed.")
            return
        except Exception as e:
             self.logger.error(f"Unexpected error getting latest row for {self.symbol}: {e}", exc_info=True)
             return

        # --- Process Base OHLCV Columns ---
        # These should ideally be Decimal from fetch_klines or after reconversion
        for base_col in ['open', 'high', 'low', 'close', 'volume']:
            key_name = base_col.capitalize() # e.g., 'Open'
            value = Decimal('NaN') # Default to Decimal NaN
            if base_col in latest_row.index:
                 raw_value = latest_row[base_col]
                 if isinstance(raw_value, Decimal):
                      value = raw_value if raw_value.is_finite() else Decimal('NaN')
                 elif pd.notna(raw_value): # Handle case where it might be float/int after fallback
                      try:
                           dec_val = Decimal(str(raw_value))
                           value = dec_val if dec_val.is_finite() else Decimal('NaN')
                      except (InvalidOperation, ValueError, TypeError):
                           value = Decimal('NaN') # Failed conversion
                 # else: raw_value was None or NaN, value remains Decimal('NaN')
            self.indicator_values[key_name] = value

        # --- Process TA Indicators Using Mapped Column Names ---
        for key, col_name in self.ta_column_names.items():
            # Determine expected type (Decimal for price-based, float otherwise)
            is_price_based = key in ["ATR", "BB_Lower", "BB_Middle", "BB_Upper", "PSAR_long",
                                     "PSAR_short", "VWAP", "SMA_10", "EMA_Short", "EMA_Long"]
            target_type = Decimal if is_price_based else float
            nan_value = Decimal('NaN') if target_type == Decimal else np.nan
            value = nan_value # Default to appropriate NaN

            if col_name and col_name in latest_row.index:
                raw_value = latest_row[col_name]
                # Check if the value is valid (not None, not pd.NA, etc.)
                if pd.notna(raw_value):
                    try:
                        # Attempt conversion to the target type
                        if target_type == Decimal:
                             # Convert via string, check finiteness
                             converted_value = Decimal(str(raw_value))
                             value = converted_value if converted_value.is_finite() else nan_value
                        else: # Target is float
                             converted_value = float(raw_value)
                             value = converted_value if np.isfinite(converted_value) else nan_value
                    except (ValueError, TypeError, InvalidOperation):
                        # self.logger.debug(f"Could not convert TA value {key} ('{col_name}': {raw_value}) to {target_type}. Storing NaN.")
                        value = nan_value # Use appropriate NaN on conversion failure
                # else: raw_value is already NaN/None, value remains default NaN

            # Store the processed value or the appropriate NaN type
            self.indicator_values[key] = value

        # --- Log Summary of Latest Values (formatted, DEBUG level) ---
        if self.logger.isEnabledFor(logging.DEBUG):
            log_vals = {}
            price_prec = self.get_price_precision_places() # Use helper for precision
            amount_prec = self.get_amount_precision_places() # Use helper

            # Define key categories for formatting consistency
            price_keys = ['Open','High','Low','Close','ATR','BB_Lower','BB_Middle','BB_Upper',
                          'PSAR_long','PSAR_short','VWAP','SMA_10','EMA_Short','EMA_Long']
            amount_keys = ['Volume', 'Volume_MA'] # Treat Volume MA like an amount for formatting
            other_float_keys = ['Momentum', 'StochRSI_K', 'StochRSI_D', 'RSI', 'CCI', 'Williams_R', 'MFI']

            for k, v in self.indicator_values.items():
                if k == "Timestamp":
                    log_vals[k] = v.strftime('%Y-%m-%d %H:%M:%S %Z') if isinstance(v, datetime) else str(v)
                    continue

                formatted_val = "NaN" # Default for None or NaN types
                try:
                    if isinstance(v, Decimal) and v.is_finite():
                         # Use price or amount precision based on key category
                         prec = price_prec if k in price_keys else amount_prec if k in amount_keys else 8 # Default precision for other Decimals
                         formatted_val = f"{v:.{prec}f}"
                    elif isinstance(v, float) and np.isfinite(v):
                         # Use amount precision for volume-like floats, otherwise default float precision
                         prec = amount_prec if k in amount_keys else 5 # Default precision for other floats
                         formatted_val = f"{v:.{prec}f}"
                    elif isinstance(v, int): # Handle integers directly
                         formatted_val = str(v)
                except ValueError: # Handle invalid precision value if getters failed
                    formatted_val = str(v)

                # Only include non-NaN finite values in the log summary
                if formatted_val != "NaN":
                     log_vals[k] = formatted_val

            if log_vals:
                 # Sort keys for consistent log output: Prices, Amounts, Others alphabetically
                 sort_order = {k: 0 for k in price_keys}
                 sort_order.update({k: 1 for k in amount_keys})
                 sorted_keys = sorted(log_vals.keys(), key=lambda x: (sort_order.get(x, 2), x)) # Prices first, then amounts, then others
                 sorted_log_vals = {k: log_vals[k] for k in sorted_keys}
                 self.logger.debug(f"Latest indicator values updated ({self.symbol}): {json.dumps(sorted_log_vals)}")
            else:
                 self.logger.warning(f"No valid latest indicator values could be determined for {self.symbol} after processing.")

    def calculate_fibonacci_levels(self, window: Optional[int] = None) -> Dict[str, Decimal]:
        """
        Calculates Fibonacci retracement levels based on the High/Low range over a specified window.
        - Uses Decimal precision for calculations.
        - Quantizes results based on market's minimum tick size.
        - Stores results in `self.fib_levels_data`.

        Args:
            window (Optional[int]): The lookback period (number of bars) for finding High/Low.
                                    Uses 'fibonacci_period' from config if None.

        Returns:
            Dict[str, Decimal]: Dictionary of Fibonacci levels, e.g., {"Fib_38.2%": Decimal("...")}.
                                Returns empty dict if calculation fails.
        """
        # Use window from config if not provided, ensure it's an integer > 0
        if window is None:
            try: window = int(self.config.get("fibonacci_period", DEFAULT_FIB_PERIOD))
            except (ValueError, TypeError): window = DEFAULT_FIB_PERIOD
        if not isinstance(window, int) or window <= 1:
            self.logger.warning(f"Invalid window ({window}) for Fibonacci calculation on {self.symbol}. Needs integer > 1. Using default {DEFAULT_FIB_PERIOD}.")
            window = DEFAULT_FIB_PERIOD

        self.fib_levels_data = {} # Clear previous calculation results

        # Basic validation checks
        if self.df.empty or 'high' not in self.df.columns or 'low' not in self.df.columns:
             self.logger.debug(f"Fibonacci calc skipped for {self.symbol}: DataFrame empty or missing high/low columns.")
             return {}
        if len(self.df) < window:
            self.logger.debug(f"Not enough data ({len(self.df)} bars) for Fibonacci calculation (requires {window} bars) on {self.symbol}.")
            return {}

        # Get the relevant slice of the DataFrame
        df_slice = self.df.tail(window)

        try:
            # Extract high/low series, drop NaNs, find max/min (should be Decimal type)
            high_series = df_slice["high"].dropna()
            low_series = df_slice["low"].dropna()

            if high_series.empty or low_series.empty:
                 self.logger.warning(f"No valid high/low data points found in the last {window} bars for Fibonacci calculation on {self.symbol}.")
                 return {}

            # Find the highest high and lowest low within the window
            high_price = high_series.max()
            low_price = low_series.min()

            # Ensure we obtained valid, finite Decimal prices
            if not isinstance(high_price, Decimal) or not high_price.is_finite() or \
               not isinstance(low_price, Decimal) or not low_price.is_finite():
                self.logger.warning(f"Could not find valid finite high/low Decimal prices for Fibonacci (Window: {window}) on {self.symbol}. High: {high_price}, Low: {low_price}")
                return {}

            # --- Calculate Fibonacci Levels using Decimal Arithmetic ---
            price_range = high_price - low_price

            # Get market tick size for quantization
            min_tick = self.get_min_tick_size()
            if not min_tick.is_finite() or min_tick <= 0:
                # Fallback if tick size is invalid (shouldn't happen with robust getter)
                price_precision = self.get_price_precision_places()
                quantizer = Decimal('1e-' + str(price_precision))
                self.logger.warning(f"Invalid min_tick_size ({min_tick}), using precision-based quantizer ({quantizer}) for Fibonacci.")
            else:
                quantizer = min_tick # Use the market's minimum price increment

            calculated_levels = {}
            if price_range < quantizer: # Handle very small or zero range
                # If range is smaller than tick size, all levels effectively collapse to the high/low
                if price_range <= 0:
                    self.logger.debug(f"Fibonacci range is zero or negative (High={high_price}, Low={low_price}) for {self.symbol}. Setting all levels to High price.")
                    level_price_quantized = high_price.quantize(quantizer, rounding=ROUND_DOWN)
                else: # Range is positive but smaller than one tick
                     self.logger.debug(f"Fibonacci range ({price_range}) is smaller than tick size ({quantizer}) for {self.symbol}. Levels will likely collapse.")
                     # Treat high/low as the effective levels
                     level_price_quantized = high_price.quantize(quantizer, rounding=ROUND_DOWN) # Use high for consistency

                # Assign the single price to all standard levels
                calculated_levels = {f"Fib_{level_pct * 100:.1f}%": level_price_quantized for level_pct in FIB_LEVELS}
            else:
                # Calculate normal levels based on the range
                for level_pct_str in map(str, FIB_LEVELS): # Iterate through standard levels
                    level_pct = Decimal(level_pct_str)
                    level_name = f"Fib_{level_pct * 100:.1f}%" # e.g., "Fib_38.2%"

                    # Standard Retracement Level price = High - (Range * Percentage)
                    level_price_raw = high_price - (price_range * level_pct)

                    # Quantize the calculated level price based on market tick size
                    # Round DOWN for levels calculated from High (ensures level <= raw calculation)
                    calculated_levels[level_name] = level_price_raw.quantize(quantizer, rounding=ROUND_DOWN)

            # Store the calculated levels and log them
            self.fib_levels_data = calculated_levels
            price_prec = self.get_price_precision_places()
            # Format levels for logging
            log_levels = {k: f"{v:.{price_prec}f}" for k, v in calculated_levels.items()}
            self.logger.debug(f"Calculated Fibonacci levels for {self.symbol} (Window: {window}, High: {high_price:.{price_prec}f}, Low: {low_price:.{price_prec}f}, Tick: {min_tick}): {log_levels}")
            return calculated_levels

        except KeyError as e:
            self.logger.error(f"{NEON_RED}Fibonacci calc error for {self.symbol}: DataFrame missing column '{e}'. Ensure OHLCV data is present.{RESET}")
            return {}
        except (ValueError, TypeError, InvalidOperation) as e:
             self.logger.error(f"{NEON_RED}Fibonacci calc error for {self.symbol}: Invalid data type or operation during calculation. {e}{RESET}")
             return {}
        except Exception as e:
            self.logger.error(f"{NEON_RED}Unexpected Fibonacci calculation error for {self.symbol}: {e}{RESET}", exc_info=True)
            return {}

    # --- Precision and Limit Helper Methods ---
    # These methods extract precision and limit information from the market_info dictionary,
    # providing fallbacks and caching results for efficiency within an analysis cycle.

    def get_price_precision_places(self) -> int:
        """Determines price precision (number of decimal places) from market info."""
        # Return cached value if already calculated for this instance
        if self._cached_price_precision is not None:
            return self._cached_price_precision

        precision = None
        source = "Unknown"
        try:
            precision_info = self.market_info.get('precision', {})
            price_precision_val = precision_info.get('price') # This can be int (places) or float/str (tick size)

            if price_precision_val is not None:
                # Case 1: Integer value represents decimal places directly
                if isinstance(price_precision_val, int) and price_precision_val >= 0:
                    precision, source = price_precision_val, "market.precision.price (int)"
                # Case 2: Float/String value represents tick size; calculate places from it
                else:
                    try:
                        tick_size = Decimal(str(price_precision_val))
                        if tick_size.is_finite() and tick_size > 0:
                            # Number of decimal places is the absolute value of the exponent
                            precision = abs(tick_size.normalize().as_tuple().exponent)
                            source = f"market.precision.price (tick: {tick_size})"
                        else: pass # Invalid tick size value, proceed to fallbacks
                    except (TypeError, ValueError, InvalidOperation): pass # Error converting tick size

            # Fallback 1: Infer from limits.price.min (if it resembles a tick size)
            if precision is None:
                min_price_val = self.market_info.get('limits', {}).get('price', {}).get('min')
                if min_price_val is not None:
                    try:
                        min_price_tick = Decimal(str(min_price_val))
                        # Heuristic: if min price is between 0 and 1, treat it as tick size
                        if min_price_tick.is_finite() and 0 < min_price_tick < Decimal('1'):
                            precision = abs(min_price_tick.normalize().as_tuple().exponent)
                            source = f"market.limits.price.min (tick: {min_price_tick})"
                    except (TypeError, ValueError, InvalidOperation): pass

            # Fallback 2: Infer from last close price's decimal places (least reliable)
            if precision is None:
                last_close = self.indicator_values.get("Close") # Assumes latest values updated
                if isinstance(last_close, Decimal) and last_close.is_finite() and last_close > 0:
                    try:
                        # Get decimal places from the normalized exponent
                        p = abs(last_close.normalize().as_tuple().exponent)
                        # Set a reasonable range for crypto price decimal places (e.g., 0 to 12)
                        if 0 <= p <= 12:
                            precision = p
                            source = f"Inferred from Last Close Price ({last_close})"
                    except Exception: pass # Ignore potential errors during inference

        except Exception as e:
            self.logger.warning(f"Error determining price precision places for {self.symbol}: {e}. Using default.")

        # --- Final Default Fallback ---
        if precision is None:
            default_precision = 4 # A common default for many USDT pairs
            precision = default_precision
            source = f"Default ({default_precision})"
            self.logger.warning(f"{NEON_YELLOW}Could not determine price precision places for {self.symbol}. Using default: {precision}. Verify market info.{RESET}")

        # Cache and return the determined precision
        self._cached_price_precision = precision
        # self.logger.debug(f"Price precision places for {self.symbol}: {precision} (Source: {source})")
        return precision

    def get_min_tick_size(self) -> Decimal:
        """Gets the minimum price increment (tick size) from market info as Decimal."""
        if self._cached_min_tick_size is not None:
            return self._cached_min_tick_size

        tick_size = None
        source = "Unknown"
        try:
            # 1. Try precision.price directly if it's not an integer (interpreted as tick size)
            precision_info = self.market_info.get('precision', {})
            price_precision_val = precision_info.get('price')
            if price_precision_val is not None and not isinstance(price_precision_val, int):
                try:
                    tick = Decimal(str(price_precision_val))
                    if tick.is_finite() and tick > 0:
                        tick_size, source = tick, "market.precision.price (value)"
                    else: raise ValueError # Invalid tick
                except (TypeError, ValueError, InvalidOperation): pass

            # 2. Fallback: Try limits.price.min (often represents tick size)
            if tick_size is None:
                min_price_val = self.market_info.get('limits', {}).get('price', {}).get('min')
                if min_price_val is not None:
                    try:
                        min_tick = Decimal(str(min_price_val))
                        if min_tick.is_finite() and min_tick > 0:
                            tick_size, source = min_tick, "market.limits.price.min"
                        else: raise ValueError # Invalid min price
                    except (TypeError, ValueError, InvalidOperation): pass

            # 3. Fallback: Calculate from integer precision.price (number of decimal places)
            if tick_size is None and price_precision_val is not None and isinstance(price_precision_val, int) and price_precision_val >= 0:
                 tick_size = Decimal('1e-' + str(price_precision_val))
                 source = f"Calculated from market.precision.price (int: {price_precision_val})"

        except Exception as e:
            self.logger.warning(f"Could not determine min tick size for {self.symbol} from market info: {e}. Using fallback.")

        # --- Final Fallback: Calculate from derived decimal places ---
        if tick_size is None:
            price_precision_places = self.get_price_precision_places() # Call the robust getter
            tick_size = Decimal('1e-' + str(price_precision_places))
            source = f"Calculated from Derived Precision ({price_precision_places})"
            self.logger.warning(f"{NEON_YELLOW}Using fallback tick size based on derived precision for {self.symbol}: {tick_size}. Verify market info.{RESET}")

        # Emergency fallback if all methods failed to produce a valid positive Decimal
        if not isinstance(tick_size, Decimal) or not tick_size.is_finite() or tick_size <= 0:
             fallback_tick = Decimal('0.00000001') # Arbitrary small positive value
             self.logger.error(f"{NEON_RED}Failed to determine a valid tick size for {self.symbol}! Using emergency fallback: {fallback_tick}. Orders may fail.{RESET}")
             tick_size = fallback_tick
             source = "Emergency Fallback"

        self._cached_min_tick_size = tick_size
        # self.logger.debug(f"Min Tick Size for {self.symbol}: {tick_size} (Source: {source})")
        return tick_size

    def get_amount_precision_places(self) -> int:
        """Determines amount precision (number of decimal places) from market info."""
        if self._cached_amount_precision is not None:
            return self._cached_amount_precision

        precision = None
        source = "Unknown"
        try:
            precision_info = self.market_info.get('precision', {})
            amount_precision_val = precision_info.get('amount') # Can be int (places) or float/str (step size)

            if amount_precision_val is not None:
                # Case 1: Integer value represents decimal places
                if isinstance(amount_precision_val, int) and amount_precision_val >= 0:
                    precision, source = amount_precision_val, "market.precision.amount (int)"
                # Case 2: Float/String value represents step size; infer places
                else:
                     try:
                          step_size = Decimal(str(amount_precision_val))
                          if step_size.is_finite() and step_size > 0:
                               precision = abs(step_size.normalize().as_tuple().exponent)
                               source = f"market.precision.amount (step: {step_size})"
                          else: pass
                     except (TypeError, ValueError, InvalidOperation): pass

            # Fallback 1: Infer from limits.amount.min (if it looks like a step size)
            if precision is None:
                min_amount_val = self.market_info.get('limits', {}).get('amount', {}).get('min')
                if min_amount_val is not None:
                    try:
                        min_amount_step = Decimal(str(min_amount_val))
                        if min_amount_step.is_finite() and min_amount_step > 0:
                            # If step size is fractional or has decimals, infer places
                            if min_amount_step < 1 or '.' in str(min_amount_val):
                               precision = abs(min_amount_step.normalize().as_tuple().exponent)
                               source = f"market.limits.amount.min (step: {min_amount_step})"
                            # If step size is a whole number (e.g., 1), precision is 0
                            elif min_amount_step >= 1 and min_amount_step == min_amount_step.to_integral_value():
                               precision = 0
                               source = f"market.limits.amount.min (int step: {min_amount_step})"
                        else: pass
                    except (TypeError, ValueError, InvalidOperation): pass

        except Exception as e:
            self.logger.warning(f"Error determining amount precision places for {self.symbol}: {e}. Using default.")

        # --- Final Default Fallback ---
        if precision is None:
            default_precision = 8 # Common default for crypto base amounts (e.g., BTC, ETH)
            precision = default_precision
            source = f"Default ({default_precision})"
            self.logger.warning(f"{NEON_YELLOW}Could not determine amount precision places for {self.symbol}. Using default: {precision}. Verify market info.{RESET}")

        self._cached_amount_precision = precision
        # self.logger.debug(f"Amount precision places for {self.symbol}: {precision} (Source: {source})")
        return precision

    def get_min_amount_step(self) -> Decimal:
        """Gets the minimum amount increment (step size) from market info as Decimal."""
        if self._cached_min_amount_step is not None:
            return self._cached_min_amount_step

        step_size = None
        source = "Unknown"
        try:
            # 1. Try precision.amount directly if not integer (interpreted as step size)
            precision_info = self.market_info.get('precision', {})
            amount_precision_val = precision_info.get('amount')
            if amount_precision_val is not None and not isinstance(amount_precision_val, int):
                try:
                    step = Decimal(str(amount_precision_val))
                    if step.is_finite() and step > 0:
                        step_size, source = step, "market.precision.amount (value)"
                    else: raise ValueError
                except (TypeError, ValueError, InvalidOperation): pass

            # 2. Fallback: Try limits.amount.min (often is the step size)
            if step_size is None:
                min_amount_val = self.market_info.get('limits', {}).get('amount', {}).get('min')
                if min_amount_val is not None:
                    try:
                        min_step = Decimal(str(min_amount_val))
                        if min_step.is_finite() and min_step > 0:
                            step_size, source = min_step, "market.limits.amount.min"
                        else: raise ValueError
                    except (TypeError, ValueError, InvalidOperation): pass

            # 3. Fallback: Calculate from integer precision.amount (decimal places)
            if step_size is None and amount_precision_val is not None and isinstance(amount_precision_val, int) and amount_precision_val >= 0:
                 step_size = Decimal('1e-' + str(amount_precision_val))
                 source = f"Calculated from market.precision.amount (int: {amount_precision_val})"

        except Exception as e:
            self.logger.warning(f"Could not determine min amount step for {self.symbol} from market info: {e}. Using fallback.")

        # --- Final Fallback: Calculate from derived decimal places ---
        if step_size is None:
            amount_precision_places = self.get_amount_precision_places() # Use robust getter
            step_size = Decimal('1e-' + str(amount_precision_places))
            source = f"Calculated from Derived Precision ({amount_precision_places})"
            self.logger.warning(f"{NEON_YELLOW}Using fallback amount step based on derived precision for {self.symbol}: {step_size}. Verify market info.{RESET}")

        # Emergency fallback
        if not isinstance(step_size, Decimal) or not step_size.is_finite() or step_size <= 0:
             fallback_step = Decimal('0.00000001') # Arbitrary small positive value
             self.logger.error(f"{NEON_RED}Failed to determine a valid amount step size for {self.symbol}! Using emergency fallback: {fallback_step}. Orders may fail.{RESET}")
             step_size = fallback_step
             source = "Emergency Fallback"

        self._cached_min_amount_step = step_size
        # self.logger.debug(f"Min Amount Step for {self.symbol}: {step_size} (Source: {source})")
        return step_size

    def get_nearest_fibonacci_levels(self, current_price: Decimal, num_levels: int = 5) -> List[Tuple[str, Decimal]]:
        """
        Finds the N nearest calculated Fibonacci levels to the given current price.

        Args:
            current_price (Decimal): The current market price to compare against.
            num_levels (int): The number of nearest levels to return.

        Returns:
            List[Tuple[str, Decimal]]: A list of tuples, where each tuple contains the
                                       Fibonacci level name (str) and its price (Decimal),
                                       sorted by distance to the current price (nearest first).
                                       Returns an empty list if no valid levels or price provided.
        """
        if not self.fib_levels_data:
            # self.logger.debug(f"Fibonacci levels not calculated or empty for {self.symbol}. Cannot find nearest.")
            return []
        if not isinstance(current_price, Decimal) or not current_price.is_finite() or current_price <= 0:
            self.logger.warning(f"Invalid current price ({current_price}) provided for Fibonacci comparison on {self.symbol}.")
            return []

        try:
            level_distances = []
            # Calculate distance from current price to each valid Fibonacci level
            for name, level_price in self.fib_levels_data.items():
                # Ensure the stored level price is a valid Decimal before calculating distance
                if isinstance(level_price, Decimal) and level_price.is_finite() and level_price > 0:
                    distance = abs(current_price - level_price)
                    level_distances.append({'name': name, 'level': level_price, 'distance': distance})
                else:
                    # self.logger.debug(f"Skipping invalid or non-finite Fib level during distance calculation: {name}={level_price}.")
                    pass # Skip invalid levels

            if not level_distances:
                self.logger.debug(f"No valid Fibonacci levels found to compare distance against for {self.symbol}.")
                return []

            # Sort the levels based on their distance to the current price (ascending)
            level_distances.sort(key=lambda item: item['distance'])

            # Return the name and level price for the nearest N levels requested
            return [(item['name'], item['level']) for item in level_distances[:num_levels]]

        except Exception as e:
            self.logger.error(f"{NEON_RED}Error finding nearest Fibonacci levels for {self.symbol}: {e}{RESET}", exc_info=True)
            return []

    # --- Signal Generation and Indicator Check Methods ---

    def generate_trading_signal(self, current_price: Decimal, orderbook_data: Optional[Dict]) -> str:
        """
        Generates the final trading signal ('BUY', 'SELL', or 'HOLD') based on a
        weighted score derived from enabled indicator check methods.
        - Uses Decimal for score aggregation to maintain precision.
        - Compares the final score against the configured threshold.
        - Logs the signal decision and contributing factors.

        Args:
            current_price (Decimal): The current market price (used for logging and potentially some checks).
            orderbook_data (Optional[Dict]): Processed order book data (needed for '_check_orderbook').

        Returns:
            str: The final trading signal: 'BUY', 'SELL', or 'HOLD'.
        """
        final_score = Decimal("0.0") # Initialize score as Decimal
        total_weight = Decimal("0.0") # Sum of weights for indicators that provided a valid score
        active_indicator_count = 0 # Count of indicators contributing to the score
        contributing_indicators = {} # Dictionary to store scores of contributing indicators {indicator_key: score_str}

        # --- Basic Input Validation ---
        if not self.indicator_values:
            self.logger.warning(f"Signal Generation Skipped for {self.symbol}: Indicator values dictionary is empty (calculation likely failed).")
            return "HOLD"
        if not isinstance(current_price, Decimal) or not current_price.is_finite() or current_price <= 0:
            self.logger.warning(f"Signal Generation Skipped for {self.symbol}: Invalid current price ({current_price}).")
            return "HOLD"
        if not self.weights:
            self.logger.warning(f"Signal Generation Warning for {self.symbol}: Active weight set ('{self.active_weight_set_name}') is missing or empty. Score will be zero.")
            # No weights means no score can be generated, default to HOLD
            return "HOLD"

        # --- Iterate Through Configured Indicators ---
        # Find available check methods in this class (methods starting with _check_)
        available_check_methods = {m.replace('_check_', '') for m in dir(self) if m.startswith('_check_') and callable(getattr(self, m))}

        for indicator_key, is_enabled in self.config.get("indicators", {}).items():
            # Skip if indicator is explicitly disabled in the config
            if not is_enabled: continue

            # Check if a corresponding check method exists for this enabled indicator
            if indicator_key not in available_check_methods:
                 # Warn only if it's enabled AND has a non-zero weight defined (otherwise it's harmless)
                 if float(self.weights.get(indicator_key, 0.0)) > 1e-9:
                     self.logger.warning(f"No check method '_check_{indicator_key}' found for enabled and weighted indicator '{indicator_key}' in TradingAnalyzer. Skipping.")
                 continue # Skip processing this indicator

            # Get the weight for this indicator from the active weight set
            weight_val = self.weights.get(indicator_key)
            # Skip if no weight is defined for this indicator in the active set
            if weight_val is None: continue

            # Validate and convert weight to Decimal, ensuring it's non-negative
            try:
                weight = Decimal(str(weight_val))
                if not weight.is_finite() or weight < 0:
                    raise ValueError("Weight must be non-negative and finite")
                # Skip efficiently if weight is zero (or extremely close to it)
                if weight < Decimal('1e-9'): continue
            except (ValueError, TypeError, InvalidOperation):
                self.logger.warning(f"Invalid weight value '{weight_val}' configured for indicator '{indicator_key}' in weight set '{self.active_weight_set_name}'. Skipping this indicator.")
                continue

            # --- Execute the Indicator Check Method ---
            check_method_name = f"_check_{indicator_key}"
            score_float = np.nan # Default score is NaN (indicating no signal or error)

            try:
                method = getattr(self, check_method_name)
                # Special handling for orderbook check which requires extra data arguments
                if indicator_key == "orderbook":
                    if orderbook_data:
                        # Pass the orderbook dictionary and current price (Decimal)
                        score_float = method(orderbook_data=orderbook_data, current_price=current_price)
                    else:
                        # self.logger.debug("Orderbook check skipped: No orderbook data provided.")
                        score_float = np.nan # Cannot score without data
                else:
                    # Call the standard check method without extra arguments
                    score_float = method()

            except Exception as e:
                self.logger.error(f"Error executing indicator check '{check_method_name}' for {self.symbol}: {e}", exc_info=True)
                score_float = np.nan # Ensure score is NaN if the check method itself fails

            # --- Aggregate Score (using Decimal) ---
            # Process the score only if it's a valid, finite float number
            if pd.notna(score_float) and np.isfinite(score_float):
                try:
                    # Convert the float score [-1.0, 1.0] returned by check method to Decimal
                    score_dec = Decimal(str(score_float))
                    # Clamp score to the expected range [-1, 1] just in case a check method returned slightly out of bounds
                    clamped_score = max(Decimal("-1.0"), min(Decimal("1.0"), score_dec))

                    # Add the weighted score to the final aggregate score
                    final_score += clamped_score * weight
                    # Add the weight of this contributing indicator to the total weight sum
                    total_weight += weight
                    active_indicator_count += 1
                    # Store the clamped score (as string for JSON logging) for debugging
                    contributing_indicators[indicator_key] = f"{clamped_score:.3f}"

                except (ValueError, TypeError, InvalidOperation) as calc_err:
                    self.logger.error(f"Error processing score for indicator '{indicator_key}' (Raw Score: {score_float}, Weight: {weight}): {calc_err}")
            # else: Score was NaN or infinite from the check method; it does not contribute to the final score or total weight.

        # --- Determine Final Signal Based on Aggregated Score ---
        final_signal = "HOLD" # Default signal
        # Only generate BUY/SELL if there was meaningful contribution (total weight > 0)
        if total_weight > Decimal('1e-9'): # Use a small tolerance
            # Get the signal threshold from config, validate, use Decimal
            try:
                threshold_str = self.config.get("signal_score_threshold", "1.5")
                threshold = Decimal(str(threshold_str))
                # Ensure threshold is positive and finite
                if not threshold.is_finite() or threshold <= 0:
                    raise ValueError("Signal score threshold must be positive and finite")
            except (ValueError, TypeError, InvalidOperation):
                # Fallback to default threshold if config value is invalid
                default_threshold_str = str(default_config["signal_score_threshold"])
                threshold = Decimal(default_threshold_str)
                self.logger.warning(f"{NEON_YELLOW}Invalid 'signal_score_threshold' ('{threshold_str}') in config. Using default: {threshold}.{RESET}")

            # Compare the final aggregated score against the positive/negative threshold
            if final_score >= threshold:
                final_signal = "BUY"
            elif final_score <= -threshold:
                final_signal = "SELL"
            # else: Score is within the neutral zone (-threshold < score < threshold), signal remains "HOLD"
        else:
            # Log if no indicators contributed significantly
            self.logger.debug(f"No indicators provided valid scores or had non-zero weights for {self.symbol} (Total Weight: {total_weight:.4f}). Defaulting signal to HOLD.")

        # --- Log the Signal Generation Summary ---
        price_prec = self.get_price_precision_places()
        # Choose color based on the final signal
        sig_color = NEON_GREEN if final_signal == "BUY" else NEON_RED if final_signal == "SELL" else NEON_YELLOW
        log_msg = (
            f"Signal ({self.symbol} @ {current_price:.{price_prec}f}): "
            f"Strategy='{self.active_weight_set_name}', ActiveInd={active_indicator_count}, "
            f"TotalWeight={total_weight:.2f}, FinalScore={final_score:.4f} (Threshold: +/-{threshold:.2f}) "
            f"==> {sig_color}{final_signal}{RESET}"
        )
        self.logger.info(log_msg)

        # Log the scores of contributing indicators only if logger level is DEBUG
        if self.logger.isEnabledFor(logging.DEBUG) and contributing_indicators:
             # Sort scores by indicator key for consistent log output
             sorted_scores = dict(sorted(contributing_indicators.items()))
             self.logger.debug(f"  Contributing Scores ({self.symbol}): {json.dumps(sorted_scores)}")

        return final_signal

    # --- Indicator Check Methods ---
    # Each method should:
    # 1. Fetch required latest values from `self.indicator_values`.
    # 2. Validate that the fetched values are usable (not NaN, correct type expected).
    # 3. Perform the specific indicator logic.
    # 4. Return a float score between -1.0 (strong sell) and 1.0 (strong buy),
    #    or np.nan if the check cannot be performed (e.g., due to missing data).

    def _check_ema_alignment(self) -> float:
        """Checks EMA alignment (Short vs Long) and price position relative to EMAs.
           Returns float score [-1.0, 1.0] or np.nan."""
        ema_s = self.indicator_values.get("EMA_Short") # Expect Decimal or NaN
        ema_l = self.indicator_values.get("EMA_Long")  # Expect Decimal or NaN
        close = self.indicator_values.get("Close")     # Expect Decimal or NaN

        # Validate inputs: ensure all are finite Decimals
        if not all(isinstance(v, Decimal) and v.is_finite() for v in [ema_s, ema_l, close]):
            return np.nan # Cannot perform check if any value is missing or invalid

        try:
            # Determine relative positions
            price_above_short = close > ema_s
            short_above_long = ema_s > ema_l # Bullish EMA cross/alignment

            # --- Scoring Logic ---
            if short_above_long: # EMAs indicate uptrend bias
                if price_above_short: return 1.0   # Strongest Bullish: Close > Short > Long
                else: return -0.2 # Weaker Bullish: Short > Long, but Close < Short (potential pullback/weakness)
            else: # EMAs indicate downtrend bias (Long >= Short)
                if not price_above_short: return -1.0 # Strongest Bearish: Close < Short <= Long
                else: return 0.2 # Weaker Bearish: Long >= Short, but Close > Short (potential pullback/weakness)

        except TypeError: # Should not happen if validation passes, but safety check
            self.logger.warning(f"Type error during EMA alignment check for {self.symbol}.", exc_info=False)
            return np.nan

    def _check_momentum(self) -> float:
        """Scores based on the Momentum indicator value relative to zero.
           Returns float score [-1.0, 1.0] or np.nan."""
        momentum = self.indicator_values.get("Momentum") # Expect float or np.nan

        # Validate input: ensure it's a finite float/int
        if not isinstance(momentum, (float, int)) or not np.isfinite(momentum):
            return np.nan

        # Simple threshold-based scoring (could be refined with normalization)
        # These thresholds might need tuning based on asset volatility and timeframe.
        strong_pos_thresh = 0.5 # Example threshold for strong positive momentum relative to price scale (needs context)
        weak_pos_thresh = 0.1
        strong_neg_thresh = -0.5
        weak_neg_thresh = -0.1

        # Apply scaling based on thresholds
        if momentum >= strong_pos_thresh * 2: return 1.0  # Very strong positive momentum
        if momentum >= strong_pos_thresh: return 0.7    # Strong positive momentum
        if momentum >= weak_pos_thresh: return 0.3      # Weak positive momentum
        if momentum <= strong_neg_thresh * 2: return -1.0 # Very strong negative momentum
        if momentum <= strong_neg_thresh: return -0.7   # Strong negative momentum
        if momentum <= weak_neg_thresh: return -0.3     # Weak negative momentum

        # If momentum is between weak negative and weak positive thresholds (close to zero)
        return 0.0

    def _check_volume_confirmation(self) -> float:
        """Scores based on current volume relative to its moving average. High volume confirms trend strength.
           Returns float score [-1.0, 1.0] or np.nan."""
        current_volume = self.indicator_values.get("Volume") # Expect Decimal or NaN
        volume_ma = self.indicator_values.get("Volume_MA") # Expect float or np.nan

        # Validate inputs
        if not isinstance(current_volume, Decimal) or not current_volume.is_finite() or current_volume < 0:
            return np.nan # Invalid current volume
        if not isinstance(volume_ma, (float, int)) or not np.isfinite(volume_ma) or volume_ma <= 0:
            # If MA is zero or negative, comparison is meaningless or impossible
            # Could happen with very short periods or insufficient data
            return np.nan

        try:
            # Convert MA float to Decimal for accurate comparison
            volume_ma_dec = Decimal(str(volume_ma))
            # Get multiplier from config, ensure it's a valid Decimal > 0
            try:
                multiplier = Decimal(str(self.config.get("volume_confirmation_multiplier", 1.5)))
                if not multiplier.is_finite() or multiplier <= 0: raise ValueError
            except (ValueError, TypeError, InvalidOperation):
                 multiplier = Decimal('1.5') # Fallback to default if invalid

            # Avoid division by zero if MA is extremely small
            if volume_ma_dec < Decimal('1e-12'): return 0.0 # Treat as neutral

            # Calculate ratio of current volume to its moving average
            ratio = current_volume / volume_ma_dec

            # --- Scoring Logic ---
            # Score positive if volume is significantly above average (confirms move)
            if ratio >= multiplier * Decimal('1.5'): return 1.0 # Very high volume confirmation (strong signal)
            if ratio >= multiplier: return 0.6                 # High volume confirmation (moderate signal)

            # Score slightly negative if volume is significantly below average (lack of interest/conviction)
            if ratio <= (Decimal('1') / (multiplier * Decimal('1.5'))): return -0.4 # Unusually low volume
            if ratio <= (Decimal('1') / multiplier): return -0.2                 # Low volume

            # Volume is within the 'normal' range (between low and high thresholds)
            return 0.0

        except (InvalidOperation, ZeroDivisionError, TypeError) as e:
             self.logger.warning(f"Error during volume confirmation calculation for {self.symbol}: {e}")
             return np.nan

    def _check_stoch_rsi(self) -> float:
        """Scores based on Stochastic RSI K and D values relative to overbought/oversold thresholds and their crossover.
           Returns float score [-1.0, 1.0] or np.nan."""
        k_val = self.indicator_values.get("StochRSI_K") # Expect float or np.nan
        d_val = self.indicator_values.get("StochRSI_D") # Expect float or np.nan

        # Validate inputs: ensure K and D are finite floats/ints
        if not isinstance(k_val, (float, int)) or not np.isfinite(k_val) or \
           not isinstance(d_val, (float, int)) or not np.isfinite(d_val):
            return np.nan

        # Get thresholds from config, ensuring they are valid floats within 0-100
        try:
            oversold = float(self.config.get("stoch_rsi_oversold_threshold", 25))
            overbought = float(self.config.get("stoch_rsi_overbought_threshold", 75))
            # Basic validation: thresholds must be within range and oversold < overbought
            if not (0 < oversold < 100 and 0 < overbought < 100 and oversold < overbought):
                raise ValueError("Invalid StochRSI thresholds")
        except (ValueError, TypeError):
             oversold, overbought = 25.0, 75.0 # Fallback to safe defaults
             self.logger.warning(f"{NEON_YELLOW}Invalid StochRSI thresholds in config, using defaults ({oversold}/{overbought}) for {self.symbol}.{RESET}")

        score = 0.0 # Initialize score to neutral

        # --- Scoring Logic ---
        # 1. Extreme Conditions (Strongest Signal): Both K and D in overbought/oversold zones
        if k_val < oversold and d_val < oversold:
            score = 1.0 # Strong Buy Signal (Deeply Oversold)
        elif k_val > overbought and d_val > overbought:
            score = -1.0 # Strong Sell Signal (Deeply Overbought)

        # 2. Crossover Signals (Moderate Signal): K crossing D adds confirmation
        # Use a small tolerance for crossover to avoid noise around exact equality
        cross_tolerance = 1.0 # Adjust if needed
        is_bullish_cross = k_val > d_val + cross_tolerance and k_val > oversold # K crosses above D, ensure not deep in oversold
        is_bearish_cross = d_val > k_val + cross_tolerance and k_val < overbought # D crosses above K (or K crosses below D), ensure not deep in overbought

        if is_bullish_cross:
             # Give bullish cross positive score, potentially overriding weak OB signal
             score = max(score, 0.7) # Max ensures we don't overwrite a stronger signal (e.g., deep OS)
        elif is_bearish_cross:
             # Give bearish cross negative score, potentially overriding weak OS signal
             score = min(score, -0.7) # Min ensures we don't overwrite a stronger signal (e.g., deep OB)

        # 3. General Position Bias (Weakest Signal): Position relative to 50 midpoint
        mid_point = 50.0
        # If currently scoring positive or neutral, reinforce slightly if both > 50
        if score >= 0 and k_val > mid_point and d_val > mid_point:
             score = max(score, 0.1) # Minor bullish bias reinforcement
        # If currently scoring negative or neutral, reinforce slightly if both < 50
        elif score <= 0 and k_val < mid_point and d_val < mid_point:
             score = min(score, -0.1) # Minor bearish bias reinforcement

        # Could add divergence checks here for more advanced signals (more complex)

        # Final clamp score to ensure it's strictly within [-1.0, 1.0]
        return max(-1.0, min(1.0, score))

    def _check_rsi(self) -> float:
        """Scores based on RSI value relative to standard overbought (70) / oversold (30) levels, with extremes (80/20).
           Returns float score [-1.0, 1.0] or np.nan."""
        rsi = self.indicator_values.get("RSI") # Expect float or np.nan

        # Validate input: ensure RSI is a finite float/int (typically 0-100)
        if not isinstance(rsi, (float, int)) or not np.isfinite(rsi):
            return np.nan

        # --- Graded Scoring based on RSI Level ---
        if rsi >= 80: return -1.0 # Extreme Overbought (Strong Sell Signal)
        if rsi >= 70: return -0.7 # Standard Overbought (Moderate Sell Signal)
        if rsi > 60: return -0.3  # Approaching Overbought (Weak Sell Signal)

        if rsi <= 20: return 1.0 # Extreme Oversold (Strong Buy Signal)
        if rsi <= 30: return 0.7 # Standard Oversold (Moderate Buy Signal)
        if rsi < 40: return 0.3  # Approaching Oversold (Weak Buy Signal)

        # Neutral zone (typically 40-60)
        # if 40 <= rsi <= 60: return 0.0
        # Implicitly returns 0.0 if none of the above conditions match
        return 0.0

    def _check_cci(self) -> float:
        """Scores based on CCI value relative to standard levels (+/-100) and extremes (+/-200).
           Returns float score [-1.0, 1.0] or np.nan."""
        cci = self.indicator_values.get("CCI") # Expect float or np.nan

        # Validate input: ensure CCI is a finite float/int
        if not isinstance(cci, (float, int)) or not np.isfinite(cci):
            return np.nan

        # --- Scoring based on CCI levels ---
        # CCI > +100 suggests overbought (potential sell)
        # CCI < -100 suggests oversold (potential buy)
        if cci >= 200: return -1.0 # Extreme Overbought/Sell Signal
        if cci >= 100: return -0.7 # Standard Overbought/Sell Signal
        if cci > 0: return -0.1   # Mild bearish momentum bias (above zero line)

        if cci <= -200: return 1.0 # Extreme Oversold/Buy Signal
        if cci <= -100: return 0.7 # Standard Oversold/Buy Signal
        if cci < 0: return 0.1   # Mild bullish momentum bias (below zero line)

        # Exactly zero
        return 0.0

    def _check_wr(self) -> float:
        """Scores based on Williams %R value. Note W%R ranges from -100 (least oversold) to 0 (most overbought).
           Standard levels are -20 (Overbought threshold) and -80 (Oversold threshold).
           Returns float score [-1.0, 1.0] or np.nan."""
        wr = self.indicator_values.get("Williams_R") # Expect float (range -100 to 0) or np.nan

        # Validate input: ensure W%R is a finite float/int within expected range
        if not isinstance(wr, (float, int)) or not np.isfinite(wr) or not (-100 <= wr <= 0):
             # Log if value is outside expected range, might indicate calculation issue
             if isinstance(wr, (float, int)) and np.isfinite(wr):
                  self.logger.warning(f"Williams %R value ({wr}) is outside expected range [-100, 0] for {self.symbol}.")
             return np.nan

        # --- Scoring based on W%R levels (remembering inverse relationship) ---
        # W%R near 0 = Overbought (Sell signal)
        # W%R near -100 = Oversold (Buy signal)
        if wr >= -10: return -1.0 # Extreme Overbought (Strong Sell)
        if wr >= -20: return -0.7 # Standard Overbought (Moderate Sell)
        if wr > -50: return -0.2  # In upper half (closer to OB, slight sell bias)

        if wr <= -90: return 1.0 # Extreme Oversold (Strong Buy)
        if wr <= -80: return 0.7 # Standard Oversold (Moderate Buy)
        if wr < -50: return 0.2  # In lower half (closer to OS, slight buy bias)

        # Exactly -50 (midpoint)
        return 0.0

    def _check_psar(self) -> float:
        """Scores based on Parabolic SAR position relative to price (indicated by which PSAR value is active).
           PSAR below price = Uptrend (+1.0). PSAR above price = Downtrend (-1.0).
           Returns float score [-1.0, 1.0] or np.nan."""
        # pandas_ta PSAR calculation typically returns NaN for the non-active direction
        psar_l = self.indicator_values.get("PSAR_long")  # Value below price (uptrend) if active (Decimal or NaN)
        psar_s = self.indicator_values.get("PSAR_short") # Value above price (downtrend) if active (Decimal or NaN)

        # Check which PSAR value is finite (and implicitly non-NaN)
        # Assumes Decimal('NaN') or np.nan is used for invalid/inactive states
        l_active = isinstance(psar_l, Decimal) and psar_l.is_finite()
        s_active = isinstance(psar_s, Decimal) and psar_s.is_finite()

        if l_active and not s_active:
            return 1.0  # Uptrend Signal: PSAR Long is active (plotting below price)
        elif s_active and not l_active:
            return -1.0 # Downtrend Signal: PSAR Short is active (plotting above price)
        elif not l_active and not s_active:
            # self.logger.debug(f"PSAR check ({self.symbol}): Neither long nor short PSAR value is active/valid.")
            return np.nan # Indeterminate state or insufficient data for PSAR calculation
        else:
             # This state (both L and S are finite Decimals) shouldn't normally happen with standard PSAR.
             # It might indicate an issue with the TA calculation or data interpretation.
             self.logger.warning(f"PSAR check ({self.symbol}) encountered unusual state: Both Long ({psar_l}) and Short ({psar_s}) seem active/valid. Returning neutral (0.0).")
             return 0.0

    def _check_sma_10(self) -> float:
        """Scores based on current price position relative to the 10-period Simple Moving Average.
           Returns float score [-1.0, 1.0] or np.nan."""
        sma = self.indicator_values.get("SMA_10")   # Expect Decimal or NaN
        close = self.indicator_values.get("Close") # Expect Decimal or NaN

        # Validate inputs: ensure both are finite Decimals
        if not isinstance(sma, Decimal) or not sma.is_finite() or \
           not isinstance(close, Decimal) or not close.is_finite():
           return np.nan

        try:
            # Basic check: Price above SMA suggests bullish bias, below suggests bearish.
            if close > sma: return 0.6  # Moderate Buy Signal (Price > SMA)
            if close < sma: return -0.6 # Moderate Sell Signal (Price < SMA)
            # else: Price is exactly on SMA
            return 0.0
        except TypeError: # Safety net for comparison errors
             self.logger.warning(f"Type error during SMA_10 check for {self.symbol}.", exc_info=False)
             return np.nan

    def _check_vwap(self) -> float:
        """Scores based on current price position relative to the Volume Weighted Average Price (VWAP).
           VWAP often acts as a session mean or support/resistance.
           Returns float score [-1.0, 1.0] or np.nan."""
        vwap = self.indicator_values.get("VWAP")   # Expect Decimal or NaN
        close = self.indicator_values.get("Close") # Expect Decimal or NaN

        # Validate inputs: ensure both are finite Decimals
        if not isinstance(vwap, Decimal) or not vwap.is_finite() or \
           not isinstance(close, Decimal) or not close.is_finite():
           return np.nan

        # Scoring Logic: Price relative to VWAP indicates intraday trend/strength
        try:
            if close > vwap: return 0.7  # Moderate Buy Signal (Price trading above VWAP)
            if close < vwap: return -0.7 # Moderate Sell Signal (Price trading below VWAP)
            # else: Price is exactly on VWAP
            return 0.0
        except TypeError:
             self.logger.warning(f"Type error during VWAP check for {self.symbol}.", exc_info=False)
             return np.nan

    def _check_mfi(self) -> float:
        """Scores based on Money Flow Index (MFI) relative to standard overbought (80) / oversold (20) levels, with extremes (90/10).
           Returns float score [-1.0, 1.0] or np.nan."""
        mfi = self.indicator_values.get("MFI") # Expect float or np.nan

        # Validate input: ensure MFI is a finite float/int (typically 0-100)
        if not isinstance(mfi, (float, int)) or not np.isfinite(mfi):
            return np.nan

        # --- Graded Scoring based on MFI Level ---
        if mfi >= 90: return -1.0 # Extreme Overbought (Strong Sell Signal - potential exhaustion)
        if mfi >= 80: return -0.7 # Standard Overbought (Moderate Sell Signal)
        if mfi > 70: return -0.3  # Approaching Overbought (Weak Sell Signal)

        if mfi <= 10: return 1.0 # Extreme Oversold (Strong Buy Signal - potential exhaustion)
        if mfi <= 20: return 0.7 # Standard Oversold (Moderate Buy Signal)
        if mfi < 30: return 0.3  # Approaching Oversold (Weak Buy Signal)

        # Neutral zone (e.g., 30-70)
        return 0.0

    def _check_bollinger_bands(self) -> float:
        """Scores based on price position relative to Bollinger Bands (Lower, Middle, Upper).
           Touching bands suggests reversal potential. Position vs middle band suggests trend continuation/mean reversion bias.
           Returns float score [-1.0, 1.0] or np.nan."""
        bbl = self.indicator_values.get("BB_Lower")   # Expect Decimal or NaN
        bbm = self.indicator_values.get("BB_Middle")  # Expect Decimal or NaN
        bbu = self.indicator_values.get("BB_Upper")   # Expect Decimal or NaN
        close = self.indicator_values.get("Close")    # Expect Decimal or NaN

        # Validate inputs: ensure all are finite Decimals
        if not all(isinstance(v, Decimal) and v.is_finite() for v in [bbl, bbm, bbu, close]):
            return np.nan

        # Validate band structure: Upper band must be greater than Lower band
        band_width = bbu - bbl
        if band_width <= 0:
            # self.logger.debug(f"BBands check skipped for {self.symbol}: Upper band ({bbu}) <= Lower band ({bbl}).")
            return np.nan # Invalid bands

        try:
            # --- Scoring Logic ---
            # 1. Price Touching or Exceeding Bands (Strong Reversal/Fade Signal)
            # Use a small tolerance (e.g., 0.1% of band width) for "touching"
            tolerance = band_width * Decimal('0.001')
            if close <= bbl + tolerance: return 1.0 # Strong Buy Signal (at/below lower band)
            if close >= bbu - tolerance: return -1.0 # Strong Sell Signal (at/above upper band)

            # 2. Price Between Bands: Position relative to Middle Band (Mean Reversion / Trend Bias)
            # If price is above middle band, suggests potential reversion lower (slight sell bias)
            if close > bbm:
                 # Scale score from 0 (at BBM) towards -0.5 (approaching BBU)
                 # Normalize position within the upper half of the band: (Close - Mid) / (Upper - Mid)
                 position_in_upper_band = (close - bbm) / (bbu - bbm) # Range approx 0 to 1
                 score = float(position_in_upper_band) * -0.5 # Scale to 0 to -0.5
                 return max(-0.5, score) # Limit score (shouldn't exceed -0.5 here)
            # If price is below middle band, suggests potential reversion higher (slight buy bias)
            else: # close < bbm (since close == bbm handled implicitly)
                 # Scale score from 0 (at BBM) towards +0.5 (approaching BBL)
                 # Normalize position within the lower half: (Mid - Close) / (Mid - Lower)
                 position_in_lower_band = (bbm - close) / (bbm - bbl) # Range approx 0 to 1
                 score = float(position_in_lower_band) * 0.5 # Scale to 0 to +0.5
                 return min(0.5, score) # Limit score

        except (TypeError, ZeroDivisionError, InvalidOperation) as e: # Handle comparison errors or division by zero if bands collapse
             self.logger.warning(f"Error during Bollinger Bands check for {self.symbol}: {e}")
             return np.nan

    def _check_orderbook(self, orderbook_data: Optional[Dict], current_price: Decimal) -> float:
        """
        Analyzes Order Book Imbalance based on the volume within configured levels.
        Compares cumulative bid volume vs. cumulative ask volume.
        Returns float score [-1.0 (ask heavy), 1.0 (bid heavy)] or np.nan.
        """
        # Validate input data
        if not orderbook_data or not isinstance(orderbook_data.get('bids'), list) or not isinstance(orderbook_data.get('asks'), list):
            # self.logger.debug(f"Orderbook check skipped for {self.symbol}: Invalid or missing orderbook data.")
            return np.nan

        bids = orderbook_data['bids'] # List of [Decimal(price), Decimal(amount)], sorted high to low
        asks = orderbook_data['asks'] # List of [Decimal(price), Decimal(amount)], sorted low to high

        # Ensure bids and asks lists are not empty
        if not bids or not asks:
            # self.logger.debug(f"Orderbook check skipped for {self.symbol}: Bids or asks list is empty.")
            return np.nan

        try:
            # Use the number of levels specified in the config
            levels_to_analyze = int(self.config.get("orderbook_limit", 10))
            # Clamp levels to the actual available data depth
            levels_to_analyze = min(len(bids), len(asks), levels_to_analyze)
            if levels_to_analyze <= 0:
                self.logger.debug(f"Orderbook check ({self.symbol}): No levels to analyze ({levels_to_analyze}). Returning neutral.")
                return 0.0

            # --- Calculate Cumulative Volume within the specified levels ---
            # Ensure amounts are Decimal before summing
            total_bid_volume = sum(b[1] for b in bids[:levels_to_analyze] if isinstance(b[1], Decimal))
            total_ask_volume = sum(a[1] for a in asks[:levels_to_analyze] if isinstance(a[1], Decimal))

            # Calculate total volume in the analyzed range
            total_volume = total_bid_volume + total_ask_volume

            # Avoid division by zero if total volume is negligible
            if total_volume < Decimal('1e-12'):
                # self.logger.debug(f"Orderbook check ({self.symbol}): Zero total volume in analyzed {levels_to_analyze} levels.")
                return 0.0 # Return neutral if no significant volume

            # --- Calculate Order Book Imbalance (OBI) ---
            # Simple difference ratio: (Bids - Asks) / Total
            # Ranges from -1.0 (all asks) to +1.0 (all bids). 0.0 indicates perfect balance.
            obi_diff_ratio = (total_bid_volume - total_ask_volume) / total_volume

            # Convert the Decimal ratio to float for the score, clamping just in case
            score = float(max(Decimal("-1.0"), min(Decimal("1.0"), obi_diff_ratio)))

            # self.logger.debug(f"OB Check ({self.symbol}, {levels_to_analyze} levels): BidVol={total_bid_volume:.4f}, AskVol={total_ask_volume:.4f}, OBI_Diff={obi_diff_ratio:.4f} -> Score={score:.4f}")
            return score

        except (IndexError, ValueError, TypeError, InvalidOperation, ZeroDivisionError) as e:
             self.logger.warning(f"Orderbook analysis calculation failed for {self.symbol}: {e}", exc_info=False)
             return np.nan
        except Exception as e:
             self.logger.error(f"Unexpected error during order book analysis for {self.symbol}: {e}", exc_info=True)
             return np.nan

    # --- TP/SL Calculation Method ---

    def calculate_entry_tp_sl(
        self, entry_price_estimate: Decimal, signal: str
    ) -> Tuple[Optional[Decimal], Optional[Decimal], Optional[Decimal]]:
        """
        Calculates potential initial Take Profit (TP) and Stop Loss (SL) prices
        based on an estimated entry price, the trading signal ('BUY'/'SELL'), and ATR.
        - Uses Decimal precision throughout.
        - Applies market tick size for quantization.
        - Ensures TP/SL are valid prices and appropriately positioned relative to entry.

        Args:
            entry_price_estimate (Decimal): The estimated or target entry price.
            signal (str): The trading signal ('BUY' or 'SELL').

        Returns:
            Tuple[Optional[Decimal], Optional[Decimal], Optional[Decimal]]:
                - Validated Entry Price Estimate (currently just passed through, could be refined)
                - Calculated Take Profit Price (Decimal), or None if invalid/not calculable.
                - Calculated Stop Loss Price (Decimal), or None if invalid/not calculable.
        """
        final_tp: Optional[Decimal] = None
        final_sl: Optional[Decimal] = None

        # --- Validate Inputs ---
        if signal not in ["BUY", "SELL"]:
            self.logger.debug(f"TP/SL Calc skipped for {self.symbol}: Invalid signal '{signal}'.")
            return entry_price_estimate, None, None

        # Fetch latest ATR value (should be Decimal or NaN)
        atr_val = self.indicator_values.get("ATR")
        if not isinstance(atr_val, Decimal) or not atr_val.is_finite() or atr_val <= 0:
            self.logger.warning(f"{NEON_YELLOW}TP/SL Calc Fail ({self.symbol} {signal}): Invalid or non-positive ATR value ({atr_val}). Cannot calculate TP/SL.{RESET}")
            return entry_price_estimate, None, None

        if not isinstance(entry_price_estimate, Decimal) or not entry_price_estimate.is_finite() or entry_price_estimate <= 0:
            self.logger.warning(f"{NEON_YELLOW}TP/SL Calc Fail ({self.symbol} {signal}): Invalid entry price estimate ({entry_price_estimate}).{RESET}")
            return entry_price_estimate, None, None

        try:
            # --- Get Parameters as Decimals ---
            try:
                tp_mult = Decimal(str(self.config.get("take_profit_multiple", "1.0")))
                sl_mult = Decimal(str(self.config.get("stop_loss_multiple", "1.5")))
                if tp_mult <= 0 or sl_mult <= 0:
                     raise ValueError("Multipliers must be positive")
            except (ValueError, TypeError, InvalidOperation):
                 self.logger.warning(f"Invalid TP/SL multipliers in config. Using defaults ({default_config['take_profit_multiple']}/{default_config['stop_loss_multiple']}).")
                 tp_mult = Decimal(str(default_config["take_profit_multiple"]))
                 sl_mult = Decimal(str(default_config["stop_loss_multiple"]))

            # Get market tick size for quantization
            min_tick = self.get_min_tick_size() # Should be a valid positive Decimal
            quantizer = min_tick

            # --- Calculate Raw Price Offsets based on ATR ---
            tp_offset = atr_val * tp_mult
            sl_offset = atr_val * sl_mult

            # --- Calculate Raw TP/SL Prices ---
            if signal == "BUY":
                tp_raw = entry_price_estimate + tp_offset
                sl_raw = entry_price_estimate - sl_offset
            else: # SELL signal
                tp_raw = entry_price_estimate - tp_offset
                sl_raw = entry_price_estimate + sl_offset

            # --- Quantize TP/SL Prices using Market Tick Size ---
            # Apply rounding logic:
            # - TP: Round towards neutral (less profit) to increase chance of execution.
            #       BUY TP -> Round Down; SELL TP -> Round Up.
            # - SL: Round away from entry (more loss potential) to avoid premature stops due to rounding.
            #       BUY SL -> Round Down; SELL SL -> Round Up.
            if tp_raw.is_finite():
                rounding_mode_tp = ROUND_DOWN if signal == "BUY" else ROUND_UP
                final_tp = tp_raw.quantize(quantizer, rounding=rounding_mode_tp)
            else: final_tp = None

            if sl_raw.is_finite():
                rounding_mode_sl = ROUND_DOWN if signal == "BUY" else ROUND_UP
                final_sl = sl_raw.quantize(quantizer, rounding=rounding_mode_sl)
            else: final_sl = None

            # --- Validation and Refinement ---
            # 1. Ensure SL is strictly further from entry than the tick size allows after rounding
            if final_sl is not None:
                if signal == "BUY" and final_sl >= entry_price_estimate:
                    # If BUY SL ended up >= entry, move it one tick below entry
                    corrected_sl = (entry_price_estimate - min_tick).quantize(quantizer, rounding=ROUND_DOWN)
                    self.logger.debug(f"Adjusted BUY SL ({final_sl}) to be below entry: {corrected_sl}")
                    final_sl = corrected_sl
                elif signal == "SELL" and final_sl <= entry_price_estimate:
                    # If SELL SL ended up <= entry, move it one tick above entry
                    corrected_sl = (entry_price_estimate + min_tick).quantize(quantizer, rounding=ROUND_UP)
                    self.logger.debug(f"Adjusted SELL SL ({final_sl}) to be above entry: {corrected_sl}")
                    final_sl = corrected_sl
                # Ensure SL didn't become invalid (e.g., negative) after adjustment
                if final_sl <= 0:
                     self.logger.error(f"{NEON_RED}Calculated {signal} SL became zero or negative ({final_sl}) after adjustments. Nullifying SL.{RESET}")
                     final_sl = None

            # 2. Ensure TP offers potential profit (strictly beyond entry after rounding)
            if final_tp is not None:
                 if signal == "BUY" and final_tp <= entry_price_estimate:
                     self.logger.warning(f"{NEON_YELLOW}Calculated BUY TP ({final_tp}) is not above entry price ({entry_price_estimate}) after rounding. Nullifying TP.{RESET}")
                     final_tp = None
                 elif signal == "SELL" and final_tp >= entry_price_estimate:
                     self.logger.warning(f"{NEON_YELLOW}Calculated SELL TP ({final_tp}) is not below entry price ({entry_price_estimate}) after rounding. Nullifying TP.{RESET}")
                     final_tp = None
                 # Ensure TP didn't become invalid (e.g., negative)
                 if final_tp is not None and final_tp <= 0:
                      self.logger.warning(f"{NEON_YELLOW}Calculated {signal} TP is zero or negative ({final_tp}). Nullifying TP.{RESET}")
                      final_tp = None

            # 3. Final check: If SL or TP calculation failed, ensure they are None
            if final_sl is not None and (not final_sl.is_finite() or final_sl <= 0): final_sl = None
            if final_tp is not None and (not final_tp.is_finite() or final_tp <= 0): final_tp = None


            # --- Log Results ---
            price_prec = self.get_price_precision_places()
            tp_str = f"{final_tp:.{price_prec}f}" if final_tp else "None"
            sl_str = f"{final_sl:.{price_prec}f}" if final_sl else "None"
            self.logger.info(f"Calculated TP/SL for {signal} {self.symbol}: "
                             f"EntryEst={entry_price_estimate:.{price_prec}f}, ATR={atr_val:.{price_prec+2}f}, "
                             f"Tick={min_tick}, TP={tp_str}, SL={sl_str}")

            return entry_price_estimate, final_tp, final_sl

        except Exception as e:
            self.logger.error(f"{NEON_RED}Unexpected error calculating TP/SL for {signal} {self.symbol}: {e}{RESET}", exc_info=True)
            return entry_price_estimate, None, None

# --- Trading Logic Helper Functions ---

def fetch_balance(exchange: ccxt.Exchange, currency: str, logger: logging.Logger) -> Optional[Decimal]:
    """
    Fetches the *available* balance for a specific currency using CCXT.
    - Handles Bybit V5 account types (prioritizes 'CONTRACT', could be adapted for 'UNIFIED').
    - Parses various possible balance response structures from CCXT.
    - Falls back to using 'total' balance if 'free'/'available' cannot be found (with warning).
    - Converts the balance to Decimal, ensuring it's non-negative and finite.
    - Returns the available balance as Decimal, or None if fetching/parsing fails.

    Args:
        exchange (ccxt.Exchange): Initialized CCXT exchange object.
        currency (str): The currency code (e.g., 'USDT', 'BTC').
        logger (logging.Logger): Logger instance.

    Returns:
        Optional[Decimal]: Available balance as Decimal, or None on failure.
    """
    lg = logger
    balance_info = None
    account_type_tried = "N/A" # Track which account type was queried

    # --- Attempt 1: Fetch with Specific Account Type (Bybit V5 Optimization) ---
    if exchange.id == 'bybit':
        # Determine preferred account type based on exchange's defaultType setting
        # Default 'linear' usually corresponds to 'CONTRACT' or 'UNIFIED' (if enabled)
        # Default 'inverse' usually corresponds to 'CONTRACT'
        # TODO: Add logic to check config for unified account preference if needed
        preferred_account_type = 'CONTRACT' # Common default for derivatives
        lg.debug(f"Attempting Bybit V5 balance fetch for {currency} (Account Type: {preferred_account_type})...")
        try:
            params = {'accountType': preferred_account_type}
            balance_info = safe_api_call(exchange.fetch_balance, lg, params=params)
            account_type_tried = preferred_account_type
            # Optional: Log raw response for debugging structure issues
            # lg.debug(f"Raw balance response (Type: {account_type_tried}): {json.dumps(balance_info, default=str)}")
        except ccxt.ExchangeError as e:
            err_str = str(e).lower()
            # Handle specific errors indicating the account type might be wrong/unused
            # Bybit code 10001 can sometimes mean wrong account type in this context
            if "account type does not exist" in err_str or "unified account" in err_str or getattr(e, 'code', None) == 10001:
                lg.info(f"Account type '{preferred_account_type}' may not be applicable or used. Falling back to default balance fetch for {currency}.")
            else:
                # Log other exchange errors but still try fallback
                lg.warning(f"Exchange error fetching balance with type '{preferred_account_type}' for {currency}: {e}. Falling back.")
            balance_info = None # Ensure fallback is triggered
        except Exception as e: # Catch other potential errors from safe_api_call
             lg.warning(f"Failed fetching balance with type '{preferred_account_type}' for {currency}: {e}. Falling back.")
             balance_info = None

    # --- Attempt 2: Fallback to Default Fetch (if specific type failed or not Bybit) ---
    if balance_info is None:
        lg.debug(f"Fetching balance for {currency} using default parameters...")
        try:
            balance_info = safe_api_call(exchange.fetch_balance, lg)
            account_type_tried = "Default" # Indicate default fetch was used
            # lg.debug(f"Raw balance response (Type: {account_type_tried}): {json.dumps(balance_info, default=str)}")
        except Exception as e:
            lg.error(f"{NEON_RED}Failed to fetch balance info for {currency} even with default parameters: {e}{RESET}")
            return None # Both attempts failed

    # --- Parse the Balance Information ---
    if not balance_info:
         lg.error(f"Balance fetch (Type: {account_type_tried}) returned empty or None response for {currency}.")
         return None

    free_balance_str = None
    parse_source = "Unknown"

    # --- Parsing Logic (tries various common structures) ---
    # Structure 1: Standard CCXT `balance[currency]['free']` or `balance[currency]['available']`
    if currency in balance_info and isinstance(balance_info.get(currency), dict):
        currency_data = balance_info[currency]
        if currency_data.get('free') is not None:
            free_balance_str = str(currency_data['free'])
            parse_source = f"Standard ['{currency}']['free']"
        elif currency_data.get('available') is not None: # Some exchanges use 'available'
            free_balance_str = str(currency_data['available'])
            parse_source = f"Standard ['{currency}']['available']"

    # Structure 2: Top-level `balance['free'][currency]` or `balance['available'][currency]`
    elif free_balance_str is None and isinstance(balance_info.get('free'), dict) and balance_info['free'].get(currency) is not None:
         free_balance_str = str(balance_info['free'][currency])
         parse_source = f"Top-level ['free']['{currency}']"
    elif free_balance_str is None and isinstance(balance_info.get('available'), dict) and balance_info['available'].get(currency) is not None:
         free_balance_str = str(balance_info['available'][currency])
         parse_source = f"Top-level ['available']['{currency}']"

    # Structure 3: Bybit V5 Specific Parsing (from `info` field) - Often more reliable for V5 details
    elif free_balance_str is None and exchange.id == 'bybit' and isinstance(balance_info.get('info'), dict):
         info_data = balance_info['info']
         # V5 responses often nest results under 'result'
         result_data = info_data.get('result', info_data) # Use result if present, else info itself

         # Check for V5 list structure (common for balance endpoints)
         if isinstance(result_data.get('list'), list) and result_data['list']:
             account_list = result_data['list']
             found_in_list = False
             for account_details in account_list:
                 if not isinstance(account_details, dict): continue # Skip invalid entries

                 # --- Unified Account Parsing ---
                 # Unified accounts contain a 'coin' list
                 if isinstance(account_details.get('coin'), list):
                     for coin_data in account_details['coin']:
                         if isinstance(coin_data, dict) and coin_data.get('coin') == currency:
                              # Prefer availableToWithdraw > availableBalance > walletBalance for usable funds
                              free = coin_data.get('availableToWithdraw') or coin_data.get('availableBalance') or coin_data.get('walletBalance')
                              if free is not None:
                                  free_balance_str = str(free)
                                  parse_source = f"Bybit V5 info.result.list[coin='{currency}'] (Type: Unified)"
                                  found_in_list = True; break # Found currency in unified list
                     if found_in_list: break # Exit outer loop if found

                 # --- Contract Account Parsing (Derivatives) ---
                 # Contract accounts have balance directly under the account entry
                 elif account_details.get('accountType') == 'CONTRACT':
                     # Check if the account entry itself has the target currency (e.g., USDT balance for linear)
                     # Prefer availableBalance > walletBalance
                     if account_details.get('coin') == currency: # Ensure currency matches if specified directly
                          free = account_details.get('availableBalance') or account_details.get('walletBalance')
                          if free is not None:
                                free_balance_str = str(free)
                                parse_source = f"Bybit V5 info.result.list[CONTRACT] (Coin: {currency})"
                                found_in_list = True; break
                     # Sometimes CONTRACT balance is listed without explicit coin key if it's the main margin currency
                     elif currency == account_details.get('marginCoin', currency): # Check against marginCoin or assume target currency
                          free = account_details.get('availableBalance') or account_details.get('walletBalance')
                          if free is not None:
                               free_balance_str = str(free)
                               parse_source = f"Bybit V5 info.result.list[CONTRACT] (Margin Coin: {currency})"
                               found_in_list = True; break

             # Fallback: If not found via specific type checks, look in first entry generically (less reliable)
             if not found_in_list and account_list and isinstance(account_list[0], dict):
                  first_acc = account_list[0]
                  free = first_acc.get('availableBalance') or first_acc.get('availableToWithdraw') or first_acc.get('walletBalance')
                  if free is not None:
                       free_balance_str = str(free)
                       parse_source = f"Bybit V5 info.result.list[0] (Fallback Guess)"

         # Alternative V5 Structure: Check if currency is a direct key under 'info' or 'info.result'
         elif free_balance_str is None and isinstance(result_data.get(currency), dict):
              currency_data = result_data[currency]
              # Look for common available balance keys
              free = currency_data.get('available') or currency_data.get('free') or currency_data.get('availableBalance') or currency_data.get('walletBalance')
              if free is not None:
                  free_balance_str = str(free)
                  parse_source = f"Bybit V5 info[.result]['{currency}']"


    # --- Fallback: Use 'total' balance if 'free'/'available' couldn't be found ---
    if free_balance_str is None:
         total_balance_str = None
         parse_source_total = "Unknown Total"
         # Check standard structures for 'total'
         if currency in balance_info and isinstance(balance_info.get(currency), dict) and balance_info[currency].get('total') is not None:
             total_balance_str = str(balance_info[currency]['total'])
             parse_source_total = f"Standard ['{currency}']['total']"
         elif isinstance(balance_info.get('total'), dict) and balance_info['total'].get(currency) is not None:
             total_balance_str = str(balance_info['total'][currency])
             parse_source_total = f"Top-level ['total']['{currency}']"
         # TODO: Add V5 'total' parsing from info if needed

         if total_balance_str is not None:
              lg.warning(f"{NEON_YELLOW}Could not find 'free' or 'available' balance for {currency}. Using 'total' balance ({total_balance_str}) as fallback ({parse_source_total})."
                         f" Note: 'total' may include collateral or unrealized PNL and might not be fully available for new trades.{RESET}")
              free_balance_str = total_balance_str
              parse_source = parse_source_total + " (Fallback)"
         else:
              # If even 'total' couldn't be found, log error and return None
              lg.error(f"{NEON_RED}Could not determine any balance ('free', 'available', or 'total') for {currency} after checking known structures (Account Type Searched: {account_type_tried}).{RESET}")
              lg.debug(f"Full balance_info structure: {json.dumps(balance_info, default=str)}")
              return None

    # --- Convert the Found Balance String to Decimal ---
    try:
        final_balance = Decimal(free_balance_str)
        # Validate the converted Decimal value
        if not final_balance.is_finite():
             lg.warning(f"Parsed balance for {currency} ('{free_balance_str}' from {parse_source}) resulted in a non-finite Decimal. Treating as zero.")
             final_balance = Decimal('0')
        # Treat negative available balance as zero for trading decisions
        if final_balance < 0:
             lg.warning(f"Parsed available balance for {currency} ('{free_balance_str}' from {parse_source}) is negative. Treating as zero available.")
             final_balance = Decimal('0')

        lg.info(f"Available {currency} balance determined (Source: {parse_source}, AccType Searched: {account_type_tried}): {final_balance:.4f}") # Adjust precision as needed
        return final_balance
    except (ValueError, TypeError, InvalidOperation) as e:
        lg.error(f"{NEON_RED}Failed to convert final balance string '{free_balance_str}' (from {parse_source}) to Decimal for {currency}: {e}{RESET}")
        return None


def get_market_info(exchange: ccxt.Exchange, symbol: str, logger: logging.Logger) -> Optional[Dict]:
    """
    Retrieves the market information dictionary for a specific symbol from CCXT.
    - Ensures exchange markets are loaded first.
    - Handles cases where the symbol is not found.
    - Adds convenient boolean flags (is_contract, is_linear, is_inverse, is_spot)
      to the returned dictionary for easier logic elsewhere.
    - Infers linear/inverse status if not explicitly provided, based on defaultType and quote currency.
    - Logs key market details and checks if the market is active.

    Args:
        exchange (ccxt.Exchange): Initialized CCXT exchange object.
        symbol (str): The trading symbol (e.g., 'BTC/USDT:USDT').
        logger (logging.Logger): Logger instance.

    Returns:
        Optional[Dict]: The CCXT market dictionary augmented with convenience flags,
                        or None if market info cannot be retrieved or is invalid.
    """
    lg = logger
    try:
        # --- Ensure Markets Are Loaded ---
        # Crucial step, as market info is needed for almost all operations
        if not exchange.markets or not exchange.markets_by_id: # Check both for robustness
             lg.info(f"Markets not loaded for {exchange.id}. Attempting explicit load...")
             try:
                 # Use safe_api_call to load markets robustly
                 safe_api_call(exchange.load_markets, lg, reload=True) # Force reload
                 lg.info(f"Markets reloaded successfully ({len(exchange.symbols)} symbols found).")
                 # Double-check if markets are populated now
                 if not exchange.markets:
                      lg.error(f"{NEON_RED}Market loading appeared successful but exchange.markets is still empty! Cannot proceed.{RESET}")
                      return None
             except Exception as load_err:
                  lg.error(f"{NEON_RED}Failed to load markets after retries: {load_err}. Cannot get market info for {symbol}.{RESET}")
                  return None # Market loading failed, cannot proceed

        # --- Retrieve Market Dictionary ---
        # Use exchange.market() which handles lookup by symbol, id, etc.
        market = exchange.market(symbol)
        if not market or not isinstance(market, dict):
             lg.error(f"{NEON_RED}Market '{symbol}' not found in CCXT's loaded markets for {exchange.id}.{RESET}")
             # Provide hint for common Bybit V5 linear format if applicable
             if '/' in symbol and ':' not in symbol and exchange.id == 'bybit':
                  base, quote = symbol.split('/')[:2]
                  suggested_symbol = f"{base}/{quote}:{quote}"
                  lg.warning(f"{NEON_YELLOW}Hint: For Bybit V5 linear perpetuals, check format like '{suggested_symbol}'.{RESET}")
             return None

        # --- Add Convenience Flags for Easier Logic ---
        # Use .get() with defaults for safety in case keys are missing
        market_type = market.get('type', '').lower() # e.g., 'spot', 'swap', 'future'
        is_spot = (market_type == 'spot')
        is_swap = (market_type == 'swap') # Typically perpetual swaps
        is_future = (market_type == 'future') # Typically dated futures
        # General contract flag (covers swap, future, or explicit 'contract' flag)
        is_contract = is_swap or is_future or market.get('contract', False)

        # Determine Linear vs. Inverse (Crucial for contract sizing and PNL)
        is_linear = market.get('linear', False)
        is_inverse = market.get('inverse', False)

        # --- Infer Linear/Inverse if not explicitly set (common for V5) ---
        if is_contract and not is_linear and not is_inverse:
            lg.debug(f"Market {symbol} is contract but linear/inverse flag not explicit. Inferring...")
            # 1. Check defaultType set during exchange initialization
            default_type = exchange.options.get('defaultType', '').lower()
            if default_type == 'linear':
                 is_linear = True
                 lg.debug(f" > Inferred Linear based on exchange defaultType.")
            elif default_type == 'inverse':
                 is_inverse = True
                 lg.debug(f" > Inferred Inverse based on exchange defaultType.")
            else:
                 # 2. Fallback: Infer based on quote currency (less reliable but common pattern)
                 quote_id = market.get('quoteId', '').upper()
                 if quote_id in ['USD']: # Typically USD-margined are inverse
                     is_inverse = True
                     lg.debug(f" > Inferred Inverse based on quote currency '{quote_id}'.")
                 elif quote_id in ['USDT', 'USDC', 'BUSD', 'DAI']: # Stablecoin-margined are usually linear
                     is_linear = True
                     lg.debug(f" > Inferred Linear based on quote currency '{quote_id}'.")
                 else:
                     # If quote is crypto (e.g., BTC), it's likely inverse
                     # If quote is fiat other than USD, could be either, default guess? Risky.
                     lg.warning(f" > Could not reliably infer linear/inverse for {symbol} (Quote: {quote_id}). Assuming Linear (default guess). Verify!")
                     is_linear = True # Default assumption if unclear

        # Add the flags to the market dictionary (modifies the copy)
        market['is_spot'] = is_spot
        market['is_contract'] = is_contract
        market['is_linear'] = is_linear
        market['is_inverse'] = is_inverse

        # --- Log Key Market Details ---
        lg.debug(f"Market Info Retrieved ({symbol}): ID={market.get('id')}, Base={market.get('base')}, Quote={market.get('quote')}, "
                 f"Type={market_type}, IsContract={is_contract}, IsLinear={is_linear}, IsInverse={is_inverse}, "
                 f"IsActive={market.get('active', True)}, ContractSize={market.get('contractSize', 'N/A')}")
        # Log precision and limits at debug level - crucial for order placement issues
        lg.debug(f"  Precision Info: {market.get('precision')}")
        lg.debug(f"  Limit Info: {market.get('limits')}")

        # --- Check if Market is Active ---
        if not market.get('active', True):
             # Market is marked as inactive by the exchange (delisted, suspended, etc.)
             lg.warning(f"{NEON_YELLOW}Market {symbol} is marked as inactive by the exchange. Trading may not be possible.{RESET}")
             # Depending on strategy requirements, you might want to return None here to prevent trading attempts.
             # return None

        return market

    except ccxt.BadSymbol as e:
        # Specific error if the symbol format is invalid or not supported
        lg.error(f"{NEON_RED}Invalid symbol format or symbol not supported by {exchange.id}: '{symbol}'. Error: {e}{RESET}")
        return None
    except Exception as e:
        # Catch any other unexpected errors during market info retrieval
        lg.error(f"{NEON_RED}Unexpected error getting market info for {symbol}: {e}{RESET}", exc_info=True)
        return None

def calculate_position_size(
    balance: Decimal,
    risk_per_trade: float, # Configuration: fraction (0 to 1)
    initial_stop_loss_price: Decimal,
    entry_price: Decimal,
    market_info: Dict,
    exchange: ccxt.Exchange, # Needed for formatting final amount
    logger: Optional[logging.Logger] = None,
    config_override: Optional[Dict] = None # Optional: Allow passing config if needed globally
) -> Optional[Decimal]:
    """
    Calculates the appropriate position size based on account balance, risk percentage,
    stop loss distance, and market constraints (precision, limits, contract type).

    - Uses Decimal for all financial calculations to maintain precision.
    - Correctly applies amount step size and min/max amount/cost limits.
    - Currently supports **Linear Contracts** and **Spot** markets.
    - **Explicitly blocks Inverse Contracts** due to different sizing logic.
    - Returns the calculated position size (in base currency for Linear/Spot) as Decimal,
      or None if calculation fails or constraints cannot be met.

    Args:
        balance (Decimal): Available balance in the quote currency (e.g., USDT).
        risk_per_trade (float): Fraction of balance to risk (e.g., 0.01 for 1%).
        initial_stop_loss_price (Decimal): The calculated initial stop loss price.
        entry_price (Decimal): The estimated or actual entry price.
        market_info (Dict): Market details dictionary from get_market_info().
        exchange (ccxt.Exchange): Initialized CCXT exchange object (for formatting).
        logger (Optional[logging.Logger]): Logger instance. Uses default if None.
        config_
```python
# sx.py
# Enhanced and Upgraded Scalping Bot Framework
# Derived from xrscalper.py, focusing on robust execution, error handling,
# advanced position management (BE, TSL), and Bybit V5 compatibility.

import hashlib
import hmac
import json
import logging
import math
import os
import time
from datetime import datetime, timedelta, timezone
from decimal import ROUND_DOWN, ROUND_UP, Decimal, InvalidOperation, getcontext
from logging.handlers import RotatingFileHandler
from typing import Any, Dict, List, Optional, Tuple, Union

import ccxt
import numpy as np
import pandas as pd
import pandas_ta as ta # Import pandas_ta
import requests
from colorama import Fore, Style, init
from dotenv import load_dotenv
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from zoneinfo import ZoneInfo

# Initialize colorama and set Decimal precision
getcontext().prec = 36 # Increased precision for complex calculations
init(autoreset=True)
load_dotenv()

# Neon Color Scheme
NEON_GREEN = Fore.LIGHTGREEN_EX
NEON_BLUE = Fore.CYAN
NEON_PURPLE = Fore.MAGENTA
NEON_YELLOW = Fore.YELLOW
NEON_RED = Fore.LIGHTRED_EX
NEON_CYAN = Fore.CYAN
RESET = Style.RESET_ALL

# --- Constants ---
API_KEY = os.getenv("BYBIT_API_KEY")
API_SECRET = os.getenv("BYBIT_API_SECRET")
if not API_KEY or not API_SECRET:
    raise ValueError("BYBIT_API_KEY and BYBIT_API_SECRET must be set in .env")

CONFIG_FILE = "config.json"
LOG_DIRECTORY = "bot_logs"
# Timezone for logging and display
TIMEZONE = ZoneInfo("America/Chicago") # Adjust as needed
MAX_API_RETRIES = 5 # Max retries for recoverable API errors
RETRY_DELAY_SECONDS = 7 # Increased delay between retries
VALID_INTERVALS = ["1", "3", "5", "15", "30", "60", "120", "240", "D", "W", "M"]
CCXT_INTERVAL_MAP = { # Map our intervals to ccxt's expected format
    "1": "1m", "3": "3m", "5": "5m", "15": "15m", "30": "30m",
    "60": "1h", "120": "2h", "240": "4h", "D": "1d", "W": "1w", "M": "1M"
}
RETRY_ERROR_CODES = [429, 500, 502, 503, 504] # HTTP status codes considered retryable
# Default indicator periods (can be overridden by config.json)
DEFAULT_ATR_PERIOD = 14
DEFAULT_CCI_WINDOW = 20
DEFAULT_WILLIAMS_R_WINDOW = 14
DEFAULT_MFI_WINDOW = 14
DEFAULT_STOCH_RSI_WINDOW = 14
DEFAULT_STOCH_WINDOW = 12
DEFAULT_K_WINDOW = 3
DEFAULT_D_WINDOW = 3
DEFAULT_RSI_WINDOW = 14
DEFAULT_BOLLINGER_BANDS_PERIOD = 20
DEFAULT_BOLLINGER_BANDS_STD_DEV = 2.0
DEFAULT_SMA_10_WINDOW = 10
DEFAULT_EMA_SHORT_PERIOD = 9
DEFAULT_EMA_LONG_PERIOD = 21
DEFAULT_MOMENTUM_PERIOD = 7
DEFAULT_VOLUME_MA_PERIOD = 15
DEFAULT_FIB_WINDOW = 50
DEFAULT_PSAR_AF = 0.02
DEFAULT_PSAR_MAX_AF = 0.2

FIB_LEVELS = [0.0, 0.236, 0.382, 0.5, 0.618, 0.786, 1.0] # Standard Fibonacci levels
LOOP_DELAY_SECONDS = 10 # Time between the end of one cycle and the start of the next
POSITION_CONFIRM_DELAY_SECONDS = 10 # Increased wait time after placing order before confirming position
# QUOTE_CURRENCY dynamically loaded from config

os.makedirs(LOG_DIRECTORY, exist_ok=True)

class SensitiveFormatter(logging.Formatter):
    """Formatter to redact sensitive information (API keys) from logs."""
    def format(self, record: logging.LogRecord) -> str:
        msg = super().format(record)
        if API_KEY:
            msg = msg.replace(API_KEY, "***API_KEY***")
        if API_SECRET:
            msg = msg.replace(API_SECRET, "***API_SECRET***")
        return msg

def load_config(filepath: str) -> Dict[str, Any]:
    """Load configuration from JSON file, creating default if not found,
       and ensuring all default keys are present with validation."""
    default_config = {
        "symbol": "BTC/USDT:USDT", # Specify the full symbol including contract type if needed
        "interval": "5",
        "retry_delay": RETRY_DELAY_SECONDS,
        "atr_period": DEFAULT_ATR_PERIOD,
        "ema_short_period": DEFAULT_EMA_SHORT_PERIOD,
        "ema_long_period": DEFAULT_EMA_LONG_PERIOD,
        "rsi_period": DEFAULT_RSI_WINDOW,
        "bollinger_bands_period": DEFAULT_BOLLINGER_BANDS_PERIOD,
        "bollinger_bands_std_dev": DEFAULT_BOLLINGER_BANDS_STD_DEV,
        "cci_window": DEFAULT_CCI_WINDOW,
        "williams_r_window": DEFAULT_WILLIAMS_R_WINDOW,
        "mfi_window": DEFAULT_MFI_WINDOW,
        "stoch_rsi_window": DEFAULT_STOCH_RSI_WINDOW,
        "stoch_rsi_rsi_window": DEFAULT_STOCH_WINDOW,
        "stoch_rsi_k": DEFAULT_K_WINDOW,
        "stoch_rsi_d": DEFAULT_D_WINDOW,
        "psar_af": DEFAULT_PSAR_AF,
        "psar_max_af": DEFAULT_PSAR_MAX_AF,
        "sma_10_window": DEFAULT_SMA_10_WINDOW,
        "momentum_period": DEFAULT_MOMENTUM_PERIOD,
        "volume_ma_period": DEFAULT_VOLUME_MA_PERIOD,
        "orderbook_limit": 25,
        "signal_score_threshold": 1.5,
        "stoch_rsi_oversold_threshold": 25,
        "stoch_rsi_overbought_threshold": 75,
        "stop_loss_multiple": 1.8, # ATR multiple for initial SL (used for sizing)
        "take_profit_multiple": 0.7, # ATR multiple for TP
        "volume_confirmation_multiplier": 1.5,
        "scalping_signal_threshold": 2.5,
        "fibonacci_window": DEFAULT_FIB_WINDOW,
        "enable_trading": False,
        "use_sandbox": True,
        "risk_per_trade": 0.01, # e.g., 1%
        "leverage": 20,
        "max_concurrent_positions": 1, # Per symbol managed by this instance
        "quote_currency": "USDT",
        "entry_order_type": "market", # "market" or "limit"
        "limit_order_offset_buy": 0.0005, # Percentage offset (0.05%)
        "limit_order_offset_sell": 0.0005, # Percentage offset (0.05%)
        "enable_trailing_stop": True,
        "trailing_stop_callback_rate": 0.005, # e.g., 0.5% trail distance
        "trailing_stop_activation_percentage": 0.003, # e.g., Activate when profit reaches 0.3%
        "enable_break_even": True,
        "break_even_trigger_atr_multiple": 1.0,
        "break_even_offset_ticks": 2, # Place BE SL X ticks beyond entry
        "position_confirm_delay_seconds": POSITION_CONFIRM_DELAY_SECONDS,
        "time_based_exit_minutes": None, # e.g., 60 to exit after 1 hour
        "indicators": {
            "ema_alignment": True, "momentum": True, "volume_confirmation": True,
            "stoch_rsi": True, "rsi": True, "bollinger_bands": True, "vwap": True,
            "cci": True, "wr": True, "psar": True, "sma_10": True, "mfi": True,
            "orderbook": True,
        },
        "weight_sets": {
            "scalping": { # Example weighting for a fast scalping strategy
                "ema_alignment": 0.2, "momentum": 0.3, "volume_confirmation": 0.2,
                "stoch_rsi": 0.6, "rsi": 0.2, "bollinger_bands": 0.3, "vwap": 0.4,
                "cci": 0.3, "wr": 0.3, "psar": 0.2, "sma_10": 0.1, "mfi": 0.2, "orderbook": 0.15,
            },
            "default": { # A more balanced weighting strategy
                "ema_alignment": 0.3, "momentum": 0.2, "volume_confirmation": 0.1,
                "stoch_rsi": 0.4, "rsi": 0.3, "bollinger_bands": 0.2, "vwap": 0.3,
                "cci": 0.2, "wr": 0.2, "psar": 0.3, "sma_10": 0.1, "mfi": 0.2, "orderbook": 0.1,
            }
        },
        "active_weight_set": "default"
    }

    config = default_config.copy()
    if os.path.exists(filepath):
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                loaded_config = json.load(f)
            config = _merge_configs(loaded_config, default_config)
            print(f"{NEON_GREEN}Loaded configuration from {filepath}{RESET}")
        except (json.JSONDecodeError, IOError) as e:
            print(f"{NEON_RED}Error loading config file {filepath}: {e}. Using default config.{RESET}")
            # Optionally recreate default if load failed badly
            try:
                with open(filepath, "w", encoding="utf-8") as f_write:
                    json.dump(default_config, f_write, indent=4)
                print(f"{NEON_YELLOW}Recreated default config file: {filepath}{RESET}")
            except IOError as e_create:
                print(f"{NEON_RED}Error recreating default config file: {e_create}{RESET}")
    else:
        print(f"{NEON_YELLOW}Config file not found. Creating default config at {filepath}{RESET}")
        try:
            with open(filepath, "w", encoding="utf-8") as f:
                json.dump(default_config, f, indent=4)
            config = default_config
        except IOError as e:
            print(f"{NEON_RED}Error creating default config file {filepath}: {e}{RESET}")
            # Continue with in-memory default config

    # --- Validation ---
    updated = False
    if config.get("interval") not in VALID_INTERVALS:
        print(f"{NEON_RED}Invalid interval '{config.get('interval')}' in config. Resetting to default '{default_config['interval']}'.{RESET}")
        config["interval"] = default_config["interval"]
        updated = True
    if config.get("entry_order_type") not in ["market", "limit"]:
        print(f"{NEON_RED}Invalid entry_order_type '{config.get('entry_order_type')}' in config. Resetting to 'market'.{RESET}")
        config["entry_order_type"] = "market"
        updated = True
    if config.get("active_weight_set") not in config.get("weight_sets", {}):
         print(f"{NEON_RED}Active weight set '{config.get('active_weight_set')}' not found in 'weight_sets'. Resetting to 'default'.{RESET}")
         config["active_weight_set"] = "default" # Assume 'default' exists
         updated = True
    # Add more validation (numeric ranges, types) as needed
    for key in ["risk_per_trade", "leverage", "stop_loss_multiple", "take_profit_multiple",
                "trailing_stop_callback_rate", "trailing_stop_activation_percentage",
                "break_even_trigger_atr_multiple", "break_even_offset_ticks"]:
        try:
             val = config[key]
             # Check basic numeric types and ranges
             if key == "risk_per_trade" and not (0 < float(val) < 1): raise ValueError("must be between 0 and 1")
             if key == "leverage" and not (int(val) >= 1): raise ValueError("must be >= 1")
             if key in ["stop_loss_multiple", "take_profit_multiple", "break_even_trigger_atr_multiple"] and not (float(val) > 0): raise ValueError("must be > 0")
             if key in ["trailing_stop_callback_rate", "trailing_stop_activation_percentage"] and not (float(val) >= 0): raise ValueError("must be >= 0")
             if key == "break_even_offset_ticks" and not (int(val) >= 0): raise ValueError("must be >= 0")
        except (ValueError, TypeError, KeyError, InvalidOperation) as e:
            print(f"{NEON_RED}Invalid value for '{key}' ({config.get(key)}): {e}. Resetting to default '{default_config[key]}'.{RESET}")
            config[key] = default_config[key]
            updated = True

    # Ensure symbol exists
    if not config.get("symbol"):
        print(f"{NEON_RED}CRITICAL: 'symbol' is missing or empty in the configuration. Please define it.{RESET}")
        config["symbol"] = default_config["symbol"] # Set default, but it might not be what user wants
        updated = True


    # If config was updated due to invalid values, save it back
    if updated:
        try:
            with open(filepath, "w", encoding="utf-8") as f_write:
                json.dump(config, f_write, indent=4)
            print(f"{NEON_YELLOW}Updated config file {filepath} with corrected/default values.{RESET}")
        except IOError as e:
            print(f"{NEON_RED}Error writing updated config file {filepath}: {e}{RESET}")

    return config

def _merge_configs(loaded_config: Dict, default_config: Dict) -> Dict:
    """Recursively merges loaded config with defaults, ensuring all keys exist."""
    merged = default_config.copy()
    for key, value in loaded_config.items():
        if isinstance(value, dict) and isinstance(merged.get(key), dict):
            merged[key] = _merge_configs(value, merged[key])
        else:
            # Only update if the key exists in the loaded config
            # This preserves defaults for keys missing in the file
            merged[key] = value
    return merged

def setup_logger(name: str, level: int = logging.DEBUG) -> logging.Logger:
    """Sets up a logger with file and console handlers."""
    logger = logging.getLogger(name)
    # Prevent duplicate handlers if called multiple times
    if logger.hasHandlers():
        # Clear existing handlers to ensure clean setup
        for handler in logger.handlers[:]:
            handler.close()
            logger.removeHandler(handler)
        # return logger # Option: return existing logger

    logger.setLevel(level)

    # File Handler (Rotating)
    log_filename = os.path.join(LOG_DIRECTORY, f"{name}.log")
    try:
        file_handler = RotatingFileHandler(
            log_filename, maxBytes=10 * 1024 * 1024, backupCount=5, encoding='utf-8'
        )
        file_formatter = SensitiveFormatter("%(asctime)s - %(levelname)s - [%(name)s:%(lineno)d] - %(message)s")
        file_handler.setFormatter(file_formatter)
        file_handler.setLevel(logging.DEBUG) # Log all levels to file
        logger.addHandler(file_handler)
    except Exception as e:
        print(f"Error setting up file logger {log_filename}: {e}")

    # Console Handler
    stream_handler = logging.StreamHandler()
    stream_formatter = SensitiveFormatter(
        f"{NEON_BLUE}%(asctime)s{RESET} - {NEON_YELLOW}%(levelname)-8s{RESET} - {NEON_PURPLE}[%(name)s]{RESET} - %(message)s",
        datefmt='%Y-%m-%d %H:%M:%S %Z' # Include Timezone
    )
    # Use UTC for internal consistency, display local via timezone info in formatter
    stream_formatter.converter = time.gmtime # Log records in UTC internally
    # formatter's datefmt includes %Z which uses TIMEZONE for display
    # stream_formatter.converter = lambda *args: datetime.now(TIMEZONE).timetuple() # Alt: Use local time directly

    stream_handler.setFormatter(stream_formatter)
    # Set console level (e.g., INFO for less verbosity, DEBUG for more)
    console_log_level = logging.INFO
    stream_handler.setLevel(console_log_level)
    logger.addHandler(stream_handler)

    logger.propagate = False # Prevent duplicate messages in parent loggers
    return logger

# --- CCXT Exchange Setup ---
def initialize_exchange(logger: logging.Logger) -> Optional[ccxt.Exchange]:
    """Initializes the CCXT Bybit exchange object with enhanced error handling."""
    lg = logger
    try:
        exchange_options = {
            'apiKey': API_KEY,
            'secret': API_SECRET,
            'enableRateLimit': True, # Use CCXT's built-in rate limiter
            'rateLimit': 150, # Milliseconds between requests (adjust based on Bybit limits, e.g., 100ms for 10/s)
            'options': {
                'defaultType': 'linear', # Assume linear for Bybit V5
                'adjustForTimeDifference': True,
                # Increased timeouts
                'fetchTickerTimeout': 15000, # 15s
                'fetchBalanceTimeout': 20000, # 20s
                'createOrderTimeout': 25000, # 25s
                'cancelOrderTimeout': 20000, # 20s
                'fetchPositionsTimeout': 20000, # 20s
                'fetchOHLCVTimeout': 20000, # 20s
                # Bybit V5 specific options might be needed here if issues persist
                # 'recvWindow': 10000 # Example: Increase recvWindow if needed
                # Add user agent to identify bot potentially
                'user-agent': 'ScalpXRX Bot v1.0',
            }
        }

        # Default to Bybit, can be made dynamic if needed
        exchange_id = "bybit"
        exchange_class = getattr(ccxt, exchange_id)
        exchange = exchange_class(exchange_options)

        if CONFIG.get('use_sandbox'):
            lg.warning(f"{NEON_YELLOW}USING SANDBOX MODE (Testnet){RESET}")
            try:
                exchange.set_sandbox_mode(True)
                lg.info(f"Sandbox mode explicitly enabled for {exchange.id}.")
            except AttributeError:
                lg.warning(f"{exchange.id} does not support set_sandbox_mode via ccxt. Ensuring API keys are for Testnet.")
                # Attempt to set URLs manually for Bybit if needed
                if exchange.id == 'bybit':
                    exchange.urls['api'] = 'https://api-testnet.bybit.com'
                    lg.info("Manually set Bybit API URL to Testnet.")
            except Exception as e:
                lg.error(f"Error enabling sandbox mode: {e}")

        lg.info(f"Initializing {exchange.id}...")
        # Test connection and API keys by fetching balance early
        # This helps catch auth/permission issues before loading markets
        account_type_to_test = 'CONTRACT' # For Bybit V5, try CONTRACT or UNIFIED
        lg.info(f"Attempting initial balance fetch (Account Type: {account_type_to_test})...")
        try:
            params = {'type': account_type_to_test} if exchange.id == 'bybit' else {}
            # Use safe_api_call for this initial fetch as well
            balance = safe_api_call(exchange.fetch_balance, lg, params=params)

            if balance: # Check if call succeeded
                quote_curr = CONFIG.get("quote_currency", "USDT")
                available_quote = balance.get(quote_curr, {}).get('free', 'N/A')
                lg.info(f"{NEON_GREEN}Successfully connected and fetched initial balance.{RESET} (Example: {quote_curr} available: {available_quote})")
            else:
                 lg.warning(f"{NEON_YELLOW}Initial balance fetch returned no data. Proceeding, but check connection/permissions.{RESET}")
                 # Decide if this should be a fatal error
                 # return None

        except ccxt.AuthenticationError as auth_err:
             lg.error(f"{NEON_RED}CCXT Authentication Error during initial balance fetch: {auth_err}{RESET}")
             lg.error(f"{NEON_RED}>> Ensure API keys are correct, have necessary permissions (Read, Trade), match account type (Real/Testnet), and IP whitelist is correct.{RESET}")
             return None
        except ccxt.ExchangeError as balance_err:
             # If specific account type failed, try default
             lg.warning(f"{NEON_YELLOW}Exchange error during initial balance fetch ({account_type_to_test}): {balance_err}. Trying default fetch...{RESET}")
             try:
                  balance = safe_api_call(exchange.fetch_balance, lg)
                  if balance:
                       quote_curr = CONFIG.get("quote_currency", "USDT")
                       available_quote = balance.get(quote_curr, {}).get('free', 'N/A')
                       lg.info(f"{NEON_GREEN}Successfully fetched balance using default parameters.{RESET} (Example: {quote_curr} available: {available_quote})")
                  else:
                       lg.warning(f"{NEON_YELLOW}Default balance fetch also returned no data.{RESET}")
             except Exception as fallback_err:
                  lg.warning(f"{NEON_YELLOW}Default balance fetch also failed: {fallback_err}. Check API permissions/account type/network.{RESET}")
        except Exception as balance_err:
             # Catch errors from safe_api_call like max retries or unexpected errors
             lg.warning(f"{NEON_YELLOW}Could not perform initial balance fetch after retries or due to error: {balance_err}. Check logs. Proceeding cautiously.{RESET}")


        # Load markets after initial connection test
        lg.info(f"Loading markets for {exchange.id}...")
        try:
             safe_api_call(exchange.load_markets, lg, reload=True) # Force reload
             lg.info(f"Markets loaded successfully for {exchange.id}.")
        except Exception as market_err:
             lg.error(f"{NEON_RED}Failed to load markets after retries: {market_err}. Cannot operate without market data.{RESET}")
             return None

        lg.info(f"CCXT exchange initialized ({exchange.id}). Sandbox: {CONFIG.get('use_sandbox')}")
        return exchange

    except ccxt.AuthenticationError as e: # Catch auth errors during class instantiation
        lg.error(f"{NEON_RED}CCXT Authentication Error during initialization: {e}{RESET}")
        lg.error(f"{NEON_RED}>> Check API Key/Secret format and validity in your .env file.{RESET}")
    except ccxt.ExchangeError as e:
        lg.error(f"{NEON_RED}CCXT Exchange Error initializing: {e}{RESET}")
    except ccxt.NetworkError as e:
        lg.error(f"{NEON_RED}CCXT Network Error initializing: {e}{RESET}")
    except Exception as e:
        lg.error(f"{NEON_RED}Failed to initialize CCXT exchange: {e}{RESET}", exc_info=True)

    return None

# --- API Call Wrapper with Retries ---
def safe_api_call(func, logger: logging.Logger, *args, **kwargs):
    """Wraps an API call with retry logic for network/rate limit errors."""
    lg = logger
    attempts = 0
    while attempts <= MAX_API_RETRIES:
        try:
            result = func(*args, **kwargs)
            return result # Success
        except (ccxt.NetworkError, ccxt.RequestTimeout, requests.exceptions.ConnectionError, requests.exceptions.Timeout, ccxt.ExchangeNotAvailable, ccxt.DDoSProtection) as e:
            # Group common retryable network/server/rate limit issues
            wait_time = RETRY_DELAY_SECONDS * (1.5 ** attempts) # Exponential backoff
            lg.warning(f"{NEON_YELLOW}Retryable error in {func.__name__}: {type(e).__name__}. Waiting {wait_time:.1f}s (Attempt {attempts+1}/{MAX_API_RETRIES}). Error: {e}{RESET}")
            time.sleep(wait_time)
        except ccxt.RateLimitExceeded as e: # Explicit handling for potentially longer waits
            # Extract wait time from error if possible (e.g., from headers)
            wait_time_header = getattr(e, 'retry_after', None)
            wait_time = RETRY_DELAY_SECONDS * (2 ** attempts) # Default exponential backoff
            if wait_time_header:
                try: wait_time = max(wait_time, float(wait_time_header) + 0.5) # Use header value if longer
                except: pass
            lg.warning(f"{NEON_YELLOW}Rate limit exceeded in {func.__name__}. Waiting {wait_time:.1f}s (Attempt {attempts+1}/{MAX_API_RETRIES}). Error: {e}{RESET}")
            time.sleep(wait_time)
        except ccxt.AuthenticationError as e:
             # Don't retry auth errors, they need fixing
             lg.error(f"{NEON_RED}Authentication Error in {func.__name__}: {e}. Aborting call.{RESET}")
             raise e # Re-raise to be caught by caller
        except ccxt.ExchangeError as e:
            # Decide if specific exchange errors are retryable
            # Example: Bybit internal server error (e.g., code 10001) might be temporary
            bybit_retry_codes = [
                10001, # Internal server error
                10006, # Generic: Too many visits
                # Add other potentially transient error codes based on Bybit docs/experience
            ]
            exchange_code = getattr(e, 'code', None)
            err_str = str(e).lower()
            # Check if code is in retry list or if message suggests temporary issue
            if exchange_code in bybit_retry_codes or "internal server error" in err_str or "request validation failed" in err_str: # Example message check
                 wait_time = RETRY_DELAY_SECONDS * (1.5 ** attempts)
                 lg.warning(f"{NEON_YELLOW}Potentially retryable exchange error in {func.__name__}: {e} (Code: {exchange_code}). Waiting {wait_time:.1f}s (Attempt {attempts+1}/{MAX_API_RETRIES})...{RESET}")
                 time.sleep(wait_time)
            else:
                 # Non-retryable ExchangeError
                 lg.error(f"{NEON_RED}Non-retryable Exchange Error in {func.__name__}: {e} (Code: {exchange_code}){RESET}")
                 raise e # Re-raise
        except Exception as e:
            # Unexpected errors - typically don't retry these unless specifically known
            lg.error(f"{NEON_RED}Unexpected error in {func.__name__}: {e}{RESET}", exc_info=True)
            raise e # Re-raise

        attempts += 1

    lg.error(f"{NEON_RED}Max retries ({MAX_API_RETRIES}) exceeded for {func.__name__}.{RESET}")
    # Raise the last exception encountered after exhausting retries
    # This preserves the original error type for the caller
    raise e # Raise the last caught exception 'e'


# --- CCXT Data Fetching (Using safe_api_call) ---
def fetch_current_price_ccxt(exchange: ccxt.Exchange, symbol: str, logger: logging.Logger) -> Optional[Decimal]:
    """Fetch the current price of a trading symbol using CCXT ticker with fallbacks and retries."""
    lg = logger
    try:
        ticker = safe_api_call(exchange.fetch_ticker, lg, symbol)
        if not ticker:
            # safe_api_call already logged the error after retries
            return None

        lg.debug(f"Ticker data for {symbol}: {ticker}")
        price = None
        # Prioritize 'last', then mid-price, then ask/bid
        last_price = ticker.get('last')
        bid_price = ticker.get('bid')
        ask_price = ticker.get('ask')

        # Robust Decimal conversion helper
        def to_decimal(value) -> Optional[Decimal]:
            if value is None: return None
            try:
                d = Decimal(str(value))
                return d if d > 0 else None # Ensure positive price
            except (InvalidOperation, ValueError, TypeError):
                lg.warning(f"Invalid price format encountered: {value}")
                return None

        p_last = to_decimal(last_price)
        p_bid = to_decimal(bid_price)
        p_ask = to_decimal(ask_price)

        # Determine price with priority
        if p_last:
            price = p_last; lg.debug(f"Using 'last' price: {price}")
        elif p_bid and p_ask:
            price = (p_bid + p_ask) / 2; lg.debug(f"Using bid/ask midpoint: {price}")
        elif p_ask: # Use ask if only ask is valid
            price = p_ask; lg.warning(f"Using 'ask' price fallback (bid invalid/missing): {price}")
        elif p_bid: # Use bid if only bid is valid
            price = p_bid; lg.warning(f"Using 'bid' price fallback (ask invalid/missing): {price}")

        # Final validation
        if price is not None and price > 0:
            return price
        else:
            lg.error(f"{NEON_RED}Failed to extract a valid price from ticker data for {symbol}. Ticker: {ticker}{RESET}")
            return None

    except Exception as e:
        # Catch errors raised by safe_api_call (like AuthError or max retries exceeded) or parsing issues
        lg.error(f"{NEON_RED}Error fetching current price for {symbol}: {e}{RESET}", exc_info=False) # Keep log concise
        return None

def fetch_klines_ccxt(exchange: ccxt.Exchange, symbol: str, timeframe: str, limit: int = 250, logger: logging.Logger = None) -> pd.DataFrame:
    """Fetch OHLCV kline data using CCXT with retries and robust validation."""
    lg = logger or logging.getLogger(__name__)
    if not exchange.has['fetchOHLCV']:
        lg.error(f"Exchange {exchange.id} does not support fetchOHLCV.")
        return pd.DataFrame()

    try:
        # Use safe_api_call to handle retries
        ohlcv = safe_api_call(exchange.fetch_ohlcv, lg, symbol, timeframe=timeframe, limit=limit)

        if ohlcv is None or not isinstance(ohlcv, list) or len(ohlcv) == 0:
            # Error logged by safe_api_call if it failed
            if ohlcv is not None: # Log only if it returned empty list/None without error
                lg.warning(f"{NEON_YELLOW}No valid kline data returned for {symbol} {timeframe}.{RESET}")
            return pd.DataFrame()

        # Process the data into a pandas DataFrame
        df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])

        if df.empty:
            lg.warning(f"Kline data DataFrame is empty for {symbol} {timeframe}.")
            return df

        # Convert timestamp to datetime objects (UTC), coerce errors
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms', errors='coerce', utc=True)
        df.dropna(subset=['timestamp'], inplace=True)
        df.set_index('timestamp', inplace=True)

        # Convert price/volume columns to numeric Decimal, coercing errors
        for col in ['open', 'high', 'low', 'close', 'volume']:
             try:
                  # Apply robust conversion to Decimal
                  df[col] = df[col].apply(lambda x: Decimal(str(x)) if pd.notna(x) and x != '' else Decimal('NaN'))
             except (TypeError, ValueError, InvalidOperation) as conv_err:
                  lg.warning(f"Could not convert column '{col}' to Decimal, attempting numeric fallback: {conv_err}")
                  df[col] = pd.to_numeric(df[col], errors='coerce') # Fallback

        # Data Cleaning: Drop rows with NaN in essential price columns or zero close price
        initial_len = len(df)
        # Check type before comparison
        close_col_type = type(df['close'].iloc[0]) if not df.empty else None
        df.dropna(subset=['open', 'high', 'low', 'close'], inplace=True)
        if close_col_type == Decimal:
            df = df[df['close'] > Decimal(0)]
        elif pd.api.types.is_numeric_dtype(close_col_type): # Check if float/int
             df = df[df['close'] > 0]

        rows_dropped = initial_len - len(df)
        if rows_dropped > 0:
            lg.debug(f"Dropped {rows_dropped} rows with NaN/invalid price data for {symbol}.")

        if df.empty:
            lg.warning(f"Kline data for {symbol} {timeframe} empty after cleaning.")
            return pd.DataFrame()

        # Sort by timestamp index and remove duplicates
        df.sort_index(inplace=True)
        df = df[~df.index.duplicated(keep='last')]

        lg.info(f"Successfully fetched and processed {len(df)} klines for {symbol} {timeframe}")
        return df

    except Exception as e:
        # Catch errors from safe_api_call or during processing
        lg.error(f"{NEON_RED}Error fetching/processing klines for {symbol}: {e}{RESET}", exc_info=True)
        return pd.DataFrame()


def fetch_orderbook_ccxt(exchange: ccxt.Exchange, symbol: str, limit: int, logger: logging.Logger) -> Optional[Dict]:
    """Fetch orderbook data using ccxt with retries and validation."""
    lg = logger
    if not exchange.has['fetchOrderBook']:
        lg.error(f"Exchange {exchange.id} does not support fetchOrderBook.")
        return None

    try:
        orderbook = safe_api_call(exchange.fetch_order_book, lg, symbol, limit=limit)

        if not orderbook: # Error logged by safe_api_call if failed
            return None
        # Validate structure
        if not isinstance(orderbook, dict) or 'bids' not in orderbook or 'asks' not in orderbook or \
           not isinstance(orderbook['bids'], list) or not isinstance(orderbook['asks'], list):
            lg.warning(f"Invalid orderbook structure received for {symbol}. Data: {orderbook}")
            return None

        if not orderbook['bids'] and not orderbook['asks']:
            lg.warning(f"Orderbook received but both bids and asks lists are empty for {symbol}.")
            return orderbook # Return empty but valid book

        # Basic validation of bid/ask entry format
        valid = True
        for side in ['bids', 'asks']:
             if orderbook[side]: # Check first entry if list is not empty
                  entry = orderbook[side][0]
                  if not (isinstance(entry, list) and len(entry) == 2):
                       lg.warning(f"Invalid {side[:-1]} entry format in orderbook: {entry}")
                       valid = False; break
                  try: # Check numeric format
                       _ = float(entry[0]); _ = float(entry[1])
                  except (ValueError, TypeError):
                       lg.warning(f"Non-numeric data in {side[:-1]} entry: {entry}")
                       valid = False; break
        if not valid:
             lg.error("Orderbook data format validation failed.")
             return None

        lg.debug(f"Successfully fetched orderbook for {symbol} ({len(orderbook['bids'])} bids, {len(orderbook['asks'])} asks).")
        return orderbook

    except Exception as e:
        # Catch errors raised by safe_api_call or validation
        lg.error(f"{NEON_RED}Error fetching order book for {symbol}: {e}{RESET}", exc_info=False)
        return None

# --- Trading Analyzer Class ---
class TradingAnalyzer:
    """Analyzes trading data using pandas_ta and generates weighted signals."""

    def __init__(
        self,
        df: pd.DataFrame,
        logger: logging.Logger,
        config: Dict[str, Any],
        market_info: Dict[str, Any],
    ) -> None:
        self.df = df # Expects OHLCV columns, potentially Decimal type
        self.logger = logger
        self.config = config
        self.market_info = market_info # Expects dict from get_market_info
        self.symbol = market_info.get('symbol', 'UNKNOWN_SYMBOL')
        self.interval = config.get("interval", "5")
        self.ccxt_interval = CCXT_INTERVAL_MAP.get(self.interval)
        if not self.ccxt_interval:
            # Log error but allow continuation, _calculate_indicators will likely fail
            self.logger.error(f"Invalid interval '{self.interval}' in config for {self.symbol}.")

        # Stores latest calculated indicator values (Decimal for prices/ATR, float for others)
        self.indicator_values: Dict[str, Union[Decimal, float, Any]] = {}
        self.signals: Dict[str, int] = {"BUY": 0, "SELL": 0, "HOLD": 1} # Default HOLD
        self.active_weight_set_name = config.get("active_weight_set", "default")
        self.weights = config.get("weight_sets", {}).get(self.active_weight_set_name, {})
        self.fib_levels_data: Dict[str, Decimal] = {} # Stores calculated fib levels
        self.ta_column_names: Dict[str, Optional[str]] = {} # Maps internal name to actual DataFrame column name

        if not self.weights:
            logger.warning(f"{NEON_YELLOW}Active weight set '{self.active_weight_set_name}' not found or empty for {self.symbol}. Scoring will be zero.{RESET}")
            self.weights = {} # Use empty dict to prevent errors

        # Perform initial calculations only if DataFrame is valid
        if not self.df.empty:
             self._calculate_all_indicators()
             self._update_latest_indicator_values() # Run AFTER indicator calculation
             self.calculate_fibonacci_levels()
        else:
             self.logger.warning("TradingAnalyzer initialized with empty DataFrame. No calculations performed.")


    def _get_ta_col_name(self, base_name: str, result_df: pd.DataFrame) -> Optional[str]:
        """Helper to find the actual column name generated by pandas_ta."""
        # Define expected patterns, potentially using f-strings for dynamic parts
        expected_patterns = {
            "ATR": [f"ATRr_{self.config.get('atr_period', DEFAULT_ATR_PERIOD)}"],
            "EMA_Short": [f"EMA_{self.config.get('ema_short_period', DEFAULT_EMA_SHORT_PERIOD)}"],
            "EMA_Long": [f"EMA_{self.config.get('ema_long_period', DEFAULT_EMA_LONG_PERIOD)}"],
            "Momentum": [f"MOM_{self.config.get('momentum_period', DEFAULT_MOMENTUM_PERIOD)}"],
            # CCI often includes the constant (e.g., 100.0) which pandas_ta adds
            "CCI": [f"CCI_{self.config.get('cci_window', DEFAULT_CCI_WINDOW)}"],
            "Williams_R": [f"WILLR_{self.config.get('williams_r_window', DEFAULT_WILLIAMS_R_WINDOW)}"],
            "MFI": [f"MFI_{self.config.get('mfi_window', DEFAULT_MFI_WINDOW)}"],
            "VWAP": ["VWAP_D"], # Default pandas_ta VWAP often daily anchored
            "PSAR_long": [f"PSARl_{self.config.get('psar_af', DEFAULT_PSAR_AF)}_{self.config.get('psar_max_af', DEFAULT_PSAR_MAX_AF)}"],
            "PSAR_short": [f"PSARs_{self.config.get('psar_af', DEFAULT_PSAR_AF)}_{self.config.get('psar_max_af', DEFAULT_PSAR_MAX_AF)}"],
            "SMA10": [f"SMA_{self.config.get('sma_10_window', DEFAULT_SMA_10_WINDOW)}"],
            # StochRSI names can be complex, include core parameters
            "StochRSI_K": [f"STOCHRSIk_{self.config.get('stoch_rsi_window', DEFAULT_STOCH_RSI_WINDOW)}_{self.config.get('stoch_rsi_rsi_window', DEFAULT_STOCH_WINDOW)}_{self.config.get('stoch_rsi_k', DEFAULT_K_WINDOW)}"],
            "StochRSI_D": [f"STOCHRSId_{self.config.get('stoch_rsi_window', DEFAULT_STOCH_RSI_WINDOW)}_{self.config.get('stoch_rsi_rsi_window', DEFAULT_STOCH_WINDOW)}_{self.config.get('stoch_rsi_k', DEFAULT_K_WINDOW)}_{self.config.get('stoch_rsi_d', DEFAULT_D_WINDOW)}"],
            "RSI": [f"RSI_{self.config.get('rsi_period', DEFAULT_RSI_WINDOW)}"],
            # BBands names include period and std dev (formatted to 1 decimal place by default)
            "BB_Lower": [f"BBL_{self.config.get('bollinger_bands_period', DEFAULT_BOLLINGER_BANDS_PERIOD)}_{float(self.config.get('bollinger_bands_std_dev', DEFAULT_BOLLINGER_BANDS_STD_DEV)):.1f}"],
            "BB_Middle": [f"BBM_{self.config.get('bollinger_bands_period', DEFAULT_BOLLINGER_BANDS_PERIOD)}_{float(self.config.get('bollinger_bands_std_dev', DEFAULT_BOLLINGER_BANDS_STD_DEV)):.1f}"],
            "BB_Upper": [f"BBU_{self.config.get('bollinger_bands_period', DEFAULT_BOLLINGER_BANDS_PERIOD)}_{float(self.config.get('bollinger_bands_std_dev', DEFAULT_BOLLINGER_BANDS_STD_DEV)):.1f}"],
            # Custom name used for Volume MA
            "Volume_MA": [f"VOL_SMA_{self.config.get('volume_ma_period', DEFAULT_VOLUME_MA_PERIOD)}"]
        }

        patterns = expected_patterns.get(base_name, [])
        df_cols = result_df.columns.tolist()

        # Exact match or startswith preferred
        for col in df_cols:
            for pattern in patterns:
                # Use startswith for flexibility (e.g., CCI_20_100.0 matches CCI_20)
                if col.startswith(pattern):
                    self.logger.debug(f"Mapped '{base_name}' to column '{col}'")
                    return col

        # Fallback: Simple case-insensitive substring search
        base_lower = base_name.lower()
        simple_base = base_lower.split('_')[0] # e.g., "ema_short" -> "ema"
        for col in df_cols:
            col_lower = col.lower()
            # Check full base name first, then simpler version
            if base_lower in col_lower:
                 self.logger.debug(f"Mapped '{base_name}' to '{col}' via substring search ('{base_lower}').")
                 return col
            # Avoid overly broad matches with simple base (e.g., 'r' matching 'atr')
            elif len(simple_base) > 2 and simple_base in col_lower:
                 self.logger.debug(f"Mapped '{base_name}' to '{col}' via substring search ('{simple_base}').")
                 return col

        self.logger.warning(f"Could not find column name for indicator '{base_name}' in DataFrame columns: {df_cols}")
        return None

    def _calculate_all_indicators(self):
        """Calculates all enabled indicators using pandas_ta."""
        if self.df.empty:
            self.logger.warning(f"DataFrame is empty, cannot calculate indicators for {self.symbol}.")
            return

        # Determine minimum required data length based on enabled & weighted indicators
        required_periods = []
        indicators_config = self.config.get("indicators", {})
        active_weights = self.weights # Use stored weights

        # Helper to add requirement if indicator is enabled AND weighted
        def add_req(key, config_key, default_period):
            if indicators_config.get(key, False) and float(active_weights.get(key, 0)) != 0:
                required_periods.append(self.config.get(config_key, default_period))

        add_req("atr", "atr_period", DEFAULT_ATR_PERIOD) # ATR always calculated, but check weight for period needs
        add_req("momentum", "momentum_period", DEFAULT_MOMENTUM_PERIOD)
        add_req("cci", "cci_window", DEFAULT_CCI_WINDOW)
        add_req("wr", "williams_r_window", DEFAULT_WILLIAMS_R_WINDOW)
        add_req("mfi", "mfi_window", DEFAULT_MFI_WINDOW)
        add_req("sma_10", "sma_10_window", DEFAULT_SMA_10_WINDOW)
        add_req("rsi", "rsi_period", DEFAULT_RSI_WINDOW)
        add_req("bollinger_bands", "bollinger_bands_period", DEFAULT_BOLLINGER_BANDS_PERIOD)
        add_req("volume_confirmation", "volume_ma_period", DEFAULT_VOLUME_MA_PERIOD)
        required_periods.append(self.config.get("fibonacci_window", DEFAULT_FIB_WINDOW)) # For Fib levels

        if indicators_config.get("ema_alignment", False) and float(active_weights.get("ema_alignment", 0)) != 0:
             required_periods.append(self.config.get("ema_short_period", DEFAULT_EMA_SHORT_PERIOD))
             required_periods.append(self.config.get("ema_long_period", DEFAULT_EMA_LONG_PERIOD))
        if indicators_config.get("stoch_rsi", False) and float(active_weights.get("stoch_rsi", 0)) != 0:
            required_periods.append(self.config.get("stoch_rsi_window", DEFAULT_STOCH_RSI_WINDOW))
            required_periods.append(self.config.get("stoch_rsi_rsi_window", DEFAULT_STOCH_WINDOW))

        min_required_data = max(required_periods) + 30 if required_periods else 50 # Add buffer

        if len(self.df) < min_required_data:
             self.logger.warning(f"{NEON_YELLOW}Insufficient data ({len(self.df)} points) for {self.symbol} to calculate indicators reliably (min recommended: {min_required_data}). Results may contain NaNs.{RESET}")

        try:
            df_calc = self.df.copy()
            # Ensure OHLCV columns are numeric floats for pandas_ta compatibility
            # pandas_ta works best with floats, convert Decimals if present
            for col in ['open', 'high', 'low', 'close', 'volume']:
                 if col in df_calc.columns:
                     if isinstance(df_calc[col].iloc[0], Decimal):
                          self.logger.debug(f"Converting Decimal column '{col}' to float for TA calculation.")
                          df_calc[col] = df_calc[col].astype(float)
                     elif not pd.api.types.is_numeric_dtype(df_calc[col]):
                          self.logger.debug(f"Converting non-numeric column '{col}' to float for TA calculation.")
                          df_calc[col] = pd.to_numeric(df_calc[col], errors='coerce')

            # --- Calculate Indicators ---
            # Always calculate ATR
            atr_period = self.config.get("atr_period", DEFAULT_ATR_PERIOD)
            df_calc.ta.atr(length=atr_period, append=True)
            self.ta_column_names["ATR"] = self._get_ta_col_name("ATR", df_calc)

            # Calculate others based on config and weight
            key_map = { # Map internal keys to config keys and defaults if needed
                "ema_alignment": None, # Special case below
                "momentum": ("momentum_period", DEFAULT_MOMENTUM_PERIOD),
                "cci": ("cci_window", DEFAULT_CCI_WINDOW),
                "wr": ("williams_r_window", DEFAULT_WILLIAMS_R_WINDOW),
                "mfi": ("mfi_window", DEFAULT_MFI_WINDOW),
                "vwap": None, # Uses default ta.vwap()
                "psar": None, # Special case below
                "sma_10": ("sma_10_window", DEFAULT_SMA_10_WINDOW),
                "stoch_rsi": None, # Special case below
                "rsi": ("rsi_period", DEFAULT_RSI_WINDOW),
                "bollinger_bands": None, # Special case below
                "volume_confirmation": None, # Special case below
            }

            for key, enabled in indicators_config.items():
                if key == "atr": continue # Already calculated
                if enabled and float(active_weights.get(key, 0)) != 0:
                    self.logger.debug(f"Calculating indicator: {key}")
                    try:
                        if key == "ema_alignment":
                            ema_short = self.config.get("ema_short_period", DEFAULT_EMA_SHORT_PERIOD)
                            ema_long = self.config.get("ema_long_period", DEFAULT_EMA_LONG_PERIOD)
                            df_calc.ta.ema(length=ema_short, append=True)
                            self.ta_column_names["EMA_Short"] = self._get_ta_col_name("EMA_Short", df_calc)
                            df_calc.ta.ema(length=ema_long, append=True)
                            self.ta_column_names["EMA_Long"] = self._get_ta_col_name("EMA_Long", df_calc)
                        elif key == "psar":
                            psar_af = self.config.get("psar_af", DEFAULT_PSAR_AF)
                            psar_max_af = self.config.get("psar_max_af", DEFAULT_PSAR_MAX_AF)
                            psar_result = df_calc.ta.psar(af=psar_af, max_af=psar_max_af)
                            if psar_result is not None and not psar_result.empty:
                                df_calc = pd.concat([df_calc, psar_result], axis=1)
                                self.ta_column_names["PSAR_long"] = self._get_ta_col_name("PSAR_long", df_calc)
                                self.ta_column_names["PSAR_short"] = self._get_ta_col_name("PSAR_short", df_calc)
                        elif key == "stoch_rsi":
                            st_len = self.config.get("stoch_rsi_window", DEFAULT_STOCH_RSI_WINDOW)
                            st_rsi_len = self.config.get("stoch_rsi_rsi_window", DEFAULT_STOCH_WINDOW)
                            st_k = self.config.get("stoch_rsi_k", DEFAULT_K_WINDOW)
                            st_d = self.config.get("stoch_rsi_d", DEFAULT_D_WINDOW)
                            st_result = df_calc.ta.stochrsi(length=st_len, rsi_length=st_rsi_len, k=st_k, d=st_d)
                            if st_result is not None and not st_result.empty:
                                df_calc = pd.concat([df_calc, st_result], axis=1)
                                self.ta_column_names["StochRSI_K"] = self._get_ta_col_name("StochRSI_K", df_calc)
                                self.ta_column_names["StochRSI_D"] = self._get_ta_col_name("StochRSI_D", df_calc)
                        elif key == "bollinger_bands":
                            bb_p = self.config.get("bollinger_bands_period", DEFAULT_BOLLINGER_BANDS_PERIOD)
                            bb_std = float(self.config.get("bollinger_bands_std_dev", DEFAULT_BOLLINGER_BANDS_STD_DEV))
                            bb_result = df_calc.ta.bbands(length=bb_p, std=bb_std)
                            if bb_result is not None and not bb_result.empty:
                                df_calc = pd.concat([df_calc, bb_result], axis=1)
                                self.ta_column_names["BB_Lower"] = self._get_ta_col_name("BB_Lower", df_calc)
                                self.ta_column_names["BB_Middle"] = self._get_ta_col_name("BB_Middle", df_calc)
                                self.ta_column_names["BB_Upper"] = self._get_ta_col_name("BB_Upper", df_calc)
                        elif key == "volume_confirmation":
                            vol_ma_p = self.config.get("volume_ma_period", DEFAULT_VOLUME_MA_PERIOD)
                            vol_ma_col = f"VOL_SMA_{vol_ma_p}"
                            df_calc[vol_ma_col] = ta.sma(df_calc['volume'].fillna(0), length=vol_ma_p)
                            self.ta_column_names["Volume_MA"] = vol_ma_col
                        elif key == "vwap":
                             df_calc.ta.vwap(append=True)
                             self.ta_column_names["VWAP"] = self._get_ta_col_name("VWAP", df_calc)
                        elif key in key_map and key_map[key] is not None: # General case using key_map
                            config_k, default_p = key_map[key]
                            period = self.config.get(config_k, default_p)
                            # Call the corresponding pandas_ta method dynamically
                            method = getattr(df_calc.ta, key, None)
                            if method and callable(method):
                                method(length=period, append=True)
                                # Map internal key to pandas_ta base name for column lookup
                                ta_base_name = key.replace("_", " ").title().replace(" ", "_") # e.g., sma_10 -> SMA10
                                if key == 'wr': ta_base_name = 'Williams_R' # Specific override if needed
                                self.ta_column_names[ta_base_name] = self._get_ta_col_name(ta_base_name, df_calc)
                            else:
                                self.logger.warning(f"Pandas TA method '{key}' not found or not callable.")
                        #else: # Handle indicators not in map or without specific params if needed
                        #    self.logger.debug(f"Skipping calculation for unmapped/simple indicator: {key}")

                    except Exception as calc_err:
                        self.logger.error(f"Error calculating indicator '{key}': {calc_err}", exc_info=True)


            # Convert ATR column back to Decimal after calculation
            atr_col = self.ta_column_names.get("ATR")
            if atr_col and atr_col in df_calc.columns:
                 try:
                     df_calc[atr_col] = df_calc[atr_col].apply(lambda x: Decimal(str(x)) if pd.notna(x) else Decimal('NaN'))
                     self.logger.debug(f"Converted calculated ATR column '{atr_col}' back to Decimal.")
                 except (ValueError, TypeError, InvalidOperation) as conv_err:
                      self.logger.error(f"Failed to convert ATR column '{atr_col}' back to Decimal: {conv_err}")

            # Update the instance's DataFrame
            self.df = df_calc
            self.logger.debug(f"Finished indicator calculations. Final DF columns: {self.df.columns.tolist()}")

        except Exception as e:
            self.logger.error(f"{NEON_RED}Error during indicator calculation setup or execution: {e}{RESET}", exc_info=True)


    def _update_latest_indicator_values(self):
        """Updates indicator_values dict with latest values, handling types."""
        default_values = {k: np.nan for k in list(self.ta_column_names.keys()) + ["Open", "High", "Low", "Close", "Volume"]}
        if self.df.empty:
            self.logger.warning(f"Cannot update latest values: DataFrame empty for {self.symbol}.")
            self.indicator_values = default_values
            return
        try:
            latest = self.df.iloc[-1]
        except IndexError:
            self.logger.error(f"Error accessing latest row (iloc[-1]) for {self.symbol}. DataFrame might be empty.")
            self.indicator_values = default_values
            return

        if latest.isnull().all():
            self.logger.warning(f"Last row contains all NaNs for {self.symbol}. Cannot update values.")
            self.indicator_values = default_values
            return

        updated_values = {}
        # Process TA indicators (expect float, except ATR which is Decimal)
        for key, col_name in self.ta_column_names.items():
            if col_name and col_name in latest.index:
                value = latest[col_name]
                if pd.notna(value):
                    try:
                        if key == "ATR": # ATR should be Decimal
                            updated_values[key] = Decimal(str(value)) if not isinstance(value, Decimal) else value
                        else: # Others as float
                            updated_values[key] = float(value)
                    except (ValueError, TypeError, InvalidOperation) as conv_err:
                        self.logger.warning(f"Could not convert TA value {key} ('{col_name}': {value}): {conv_err}. Storing NaN.")
                        updated_values[key] = np.nan
                else: updated_values[key] = np.nan
            else:
                 if key in self.ta_column_names: # Log only if calc was attempted
                     self.logger.debug(f"Indicator column '{col_name}' for '{key}' not found in latest data. Storing NaN.")
                 updated_values[key] = np.nan

        # Process Base OHLCV (ensure Decimal)
        for base_col in ['open', 'high', 'low', 'close', 'volume']:
            key_name = base_col.capitalize()
            value = latest.get(base_col)
            if pd.notna(value):
                 try:
                      updated_values[key_name] = Decimal(str(value)) if not isinstance(value, Decimal) else value
                 except (ValueError, TypeError, InvalidOperation) as conv_err:
                      self.logger.warning(f"Could not convert base '{base_col}' ({value}) to Decimal: {conv_err}. Storing NaN.")
                      updated_values[key_name] = np.nan
            else: updated_values[key_name] = np.nan

        self.indicator_values = updated_values

        # Log Summary (formatted)
        log_vals = {}
        price_prec = self.get_price_precision()
        for k, v in self.indicator_values.items():
            if pd.notna(v):
                if isinstance(v, Decimal):
                    prec = price_prec if k in ['Open', 'High', 'Low', 'Close', 'ATR'] else 8
                    log_vals[k] = f"{v:.{prec}f}"
                elif isinstance(v, float): log_vals[k] = f"{v:.5f}"
                else: log_vals[k] = str(v)
            # else: log_vals[k] = "NaN" # Optionally log NaNs
        self.logger.debug(f"Latest values updated ({self.symbol}): {log_vals}")


    def calculate_fibonacci_levels(self, window: Optional[int] = None) -> Dict[str, Decimal]:
        """Calculates Fibonacci levels using Decimal precision."""
        window = window or self.config.get("fibonacci_window", DEFAULT_FIB_WINDOW)
        if len(self.df) < window:
            self.logger.debug(f"Not enough data ({len(self.df)}) for Fibonacci ({window}) on {self.symbol}.")
            self.fib_levels_data = {}; return {}

        df_slice = self.df.tail(window)
        try:
            # Ensure 'high'/'low' are numeric before finding max/min
            high_series = pd.to_numeric(df_slice["high"], errors='coerce')
            low_series = pd.to_numeric(df_slice["low"], errors='coerce')
            high_price_raw = high_series.dropna().max()
            low_price_raw = low_series.dropna().min()

            if pd.isna(high_price_raw) or pd.isna(low_price_raw):
                self.logger.warning(f"Could not find valid high/low for Fibonacci (Window: {window}).")
                self.fib_levels_data = {}; return {}

            high = Decimal(str(high_price_raw))
            low = Decimal(str(low_price_raw))
            diff = high - low

            levels = {}
            price_precision = self.get_price_precision()
            rounding_factor = Decimal('1e-' + str(price_precision))

            if diff > 0:
                for level_pct in FIB_LEVELS:
                    level_name = f"Fib_{level_pct * 100:.1f}%"
                    level_price = high - (diff * Decimal(str(level_pct)))
                    # Round down from high for support levels
                    levels[level_name] = level_price.quantize(rounding_factor, rounding=ROUND_DOWN)
            else: # Handle zero range
                self.logger.debug(f"Fibonacci range is zero (High=Low={high}). Setting all levels to this price.")
                level_price_quantized = high.quantize(rounding_factor, rounding=ROUND_DOWN)
                for level_pct in FIB_LEVELS:
                    levels[f"Fib_{level_pct * 100:.1f}%"] = level_price_quantized

            self.fib_levels_data = levels
            log_levels = {k: str(v) for k, v in levels.items()}
            self.logger.debug(f"Calculated Fibonacci levels (Window: {window}): {log_levels}")
            return levels

        except KeyError as e:
            self.logger.error(f"{NEON_RED}Fibonacci error: Missing column '{e}'.{RESET}")
            self.fib_levels_data = {}; return {}
        except (ValueError, TypeError, InvalidOperation) as e:
             self.logger.error(f"{NEON_RED}Fibonacci error: Invalid data type for high/low. {e}{RESET}")
             self.fib_levels_data = {}; return {}
        except Exception as e:
            self.logger.error(f"{NEON_RED}Unexpected Fibonacci calculation error: {e}{RESET}", exc_info=True)
            self.fib_levels_data = {}; return {}

    def get_price_precision(self) -> int:
        """Determines price precision (decimal places) from market info."""
        try:
            precision_info = self.market_info.get('precision', {})
            price_precision_val = precision_info.get('price')
            if price_precision_val is not None:
                if isinstance(price_precision_val, int) and price_precision_val >= 0: return price_precision_val
                try: # Assume tick size
                    tick_size = Decimal(str(price_precision_val))
                    if tick_size > 0: return abs(tick_size.normalize().as_tuple().exponent)
                except (TypeError, ValueError, InvalidOperation) as e: self.logger.debug(f"Parsing precision.price '{price_precision_val}' failed: {e}")

            min_price_val = self.market_info.get('limits', {}).get('price', {}).get('min')
            if min_price_val is not None:
                try:
                    min_price_tick = Decimal(str(min_price_val))
                    if 0 < min_price_tick < Decimal('0.1'): # Heuristic
                        return abs(min_price_tick.normalize().as_tuple().exponent)
                except (TypeError, ValueError, InvalidOperation) as e: self.logger.debug(f"Parsing limits.price.min '{min_price_val}' failed: {e}")

            last_close = self.indicator_values.get("Close") # Least reliable
            if isinstance(last_close, Decimal) and last_close > 0:
                try:
                    precision = abs(last_close.normalize().as_tuple().exponent)
                    if 0 <= precision < 10: return precision # Sanity check
                except Exception: pass
        except Exception as e: self.logger.warning(f"Error determining price precision: {e}.")
        default_precision = 4
        self.logger.warning(f"Using default price precision: {default_precision}.")
        return default_precision

    def get_min_tick_size(self) -> Decimal:
        """Gets the minimum price increment (tick size) from market info."""
        try:
            precision_info = self.market_info.get('precision', {})
            price_precision_val = precision_info.get('price')
            if price_precision_val is not None:
                if isinstance(price_precision_val, (float, str, int)):
                     try:
                          if isinstance(price_precision_val, int):
                               if price_precision_val >= 0: return Decimal('1e-' + str(price_precision_val))
                          else:
                               tick = Decimal(str(price_precision_val))
                               if tick > 0: return tick
                     except (TypeError, ValueError, InvalidOperation) as e: self.logger.debug(f"Parsing precision.price '{price_precision_val}' failed: {e}")

            min_price_val = self.market_info.get('limits', {}).get('price', {}).get('min')
            if min_price_val is not None:
                try:
                    min_tick = Decimal(str(min_price_val))
                    if 0 < min_tick < Decimal('0.1'): return min_tick # Heuristic
                except (TypeError, ValueError, InvalidOperation) as e: self.logger.debug(f"Parsing limits.price.min '{min_price_val}' failed: {e}")
        except Exception as e: self.logger.warning(f"Error determining tick size: {e}.")
        price_precision_places = self.get_price_precision()
        fallback_tick = Decimal('1e-' + str(price_precision_places))
        self.logger.debug(f"Using fallback tick size based on precision ({price_precision_places}): {fallback_tick}")
        return fallback_tick

    def get_amount_precision_places(self) -> int:
        """Determines amount precision (decimal places) from market info."""
        try:
            precision_info = self.market_info.get('precision', {})
            amount_precision_val = precision_info.get('amount')
            if amount_precision_val is not None:
                if isinstance(amount_precision_val, int) and amount_precision_val >= 0: return amount_precision_val
                try: # Assume step size
                    step_size = Decimal(str(amount_precision_val))
                    if step_size > 0: return abs(step_size.normalize().as_tuple().exponent)
                except (TypeError, ValueError, InvalidOperation): pass

            min_amount_val = self.market_info.get('limits', {}).get('amount', {}).get('min')
            if min_amount_val is not None:
                try:
                    min_amount_step = Decimal(str(min_amount_val))
                    if 0 < min_amount_step <= Decimal('1'): # Allow 1, check if small
                       # Use exponent if it looks like a step size (e.g., 0.001)
                       if min_amount_step < 1: return abs(min_amount_step.normalize().as_tuple().exponent)
                       # If min amount is 1 or more, precision might be 0
                       elif min_amount_step >= 1 and '.' not in str(min_amount_val): return 0
                except (TypeError, ValueError, InvalidOperation): pass
        except Exception as e: self.logger.warning(f"Error determining amount precision: {e}.")
        default_precision = 8
        self.logger.warning(f"Using default amount precision: {default_precision}.")
        return default_precision

    def get_min_amount_step(self) -> Decimal:
        """Gets the minimum amount increment (step size) from market info."""
        try:
            precision_info = self.market_info.get('precision', {})
            amount_precision_val = precision_info.get('amount')
            if amount_precision_val is not None:
                if isinstance(amount_precision_val, (float, str, int)):
                     try:
                          if isinstance(amount_precision_val, int):
                               if amount_precision_val >= 0: return Decimal('1e-' + str(amount_precision_val))
                          else:
                               step = Decimal(str(amount_precision_val))
                               if step > 0: return step
                     except (TypeError, ValueError, InvalidOperation): pass

            min_amount_val = self.market_info.get('limits', {}).get('amount', {}).get('min')
            if min_amount_val is not None:
                try:
                    min_step = Decimal(str(min_amount_val))
                    # Assume min limit IS the step size if it's positive
                    if min_step > 0: return min_step
                except (TypeError, ValueError, InvalidOperation): pass
        except Exception as e: self.logger.warning(f"Error determining amount step: {e}.")
        amount_precision_places = self.get_amount_precision_places()
        fallback_step = Decimal('1e-' + str(amount_precision_places))
        self.logger.debug(f"Using fallback amount step based on precision ({amount_precision_places}): {fallback_step}")
        return fallback_step

    def get_nearest_fibonacci_levels(self, current_price: Decimal, num_levels: int = 5) -> List[Tuple[str, Decimal]]:
        """Finds the N nearest Fibonacci levels to the current price."""
        if not self.fib_levels_data: return []
        if not isinstance(current_price, Decimal) or pd.isna(current_price) or current_price <= 0: return []
        try:
            level_distances = [{'name': name, 'level': level, 'distance': abs(current_price - level)}
                               for name, level in self.fib_levels_data.items() if isinstance(level, Decimal) and level > 0]
            level_distances.sort(key=lambda x: x['distance'])
            return [(item['name'], item['level']) for item in level_distances[:num_levels]]
        except Exception as e:
            self.logger.error(f"Error finding nearest Fib levels: {e}", exc_info=True); return []

    def calculate_ema_alignment_score(self) -> float:
        """Calculates EMA alignment score."""
        ema_s = self.indicator_values.get("EMA_Short")
        ema_l = self.indicator_values.get("EMA_Long")
        close_dec = self.indicator_values.get("Close")
        price_f = float(close_dec) if isinstance(close_dec, Decimal) else np.nan
        if pd.isna(ema_s) or pd.isna(ema_l) or pd.isna(price_f): return np.nan
        if price_f > ema_s > ema_l: return 1.0
        elif price_f < ema_s < ema_l: return -1.0
        else: return 0.0

    def generate_trading_signal(self, current_price: Decimal, orderbook_data: Optional[Dict]) -> str:
        """Generates final trading signal (BUY/SELL/HOLD) based on weighted score."""
        self.signals = {"BUY": 0, "SELL": 0, "HOLD": 1}
        final_score = Decimal("0.0")
        total_weight = Decimal("0.0")
        active_count, nan_count = 0, 0
        debug_scores = {}

        # Basic validation checks
        if not self.indicator_values: self.logger.warning("Signal Gen: Indicator values empty."); return "HOLD"
        core_ok = any(pd.notna(v) for k, v in self.indicator_values.items() if k not in ['Open', 'High', 'Low', 'Close', 'Volume'])
        if not core_ok: self.logger.warning("Signal Gen: All core indicators NaN."); return "HOLD"
        if pd.isna(current_price) or not isinstance(current_price, Decimal) or current_price <= 0:
            self.logger.warning(f"Signal Gen: Invalid current price ({current_price})."); return "HOLD"
        if not self.weights: self.logger.error("Signal Gen: Active weight set missing/empty."); return "HOLD"

        # Iterate through indicators defined in config
        for indicator_key, enabled in self.config.get("indicators", {}).items():
            if not enabled: continue
            weight_str = self.weights.get(indicator_key)
            if weight_str is None: continue # No weight defined

            try: weight = Decimal(str(weight_str)); assert weight.is_finite()
            except: self.logger.warning(f"Invalid weight '{weight_str}' for '{indicator_key}'. Skipping."); continue
            if weight == 0: continue # Skip zero weight

            check_method_name = f"_check_{indicator_key}"
            score_float = np.nan
            if hasattr(self, check_method_name) and callable(getattr(self, check_method_name)):
                try:
                    method = getattr(self, check_method_name)
                    if indicator_key == "orderbook":
                        if orderbook_data: score_float = method(orderbook_data, current_price)
                        elif weight != 0: self.logger.debug("Orderbook check skipped: No data.")
                    else: score_float = method()
                except Exception as e: self.logger.error(f"Error in check {check_method_name}: {e}", exc_info=True)
            elif weight != 0: self.logger.warning(f"Check method '{check_method_name}' not found for weighted indicator '{indicator_key}'.")

            debug_scores[indicator_key] = f"{score_float:.3f}" if pd.notna(score_float) else "NaN"
            if pd.notna(score_float):
                try:
                    score_dec = Decimal(str(score_float))
                    clamped = max(Decimal("-1.0"), min(Decimal("1.0"), score_dec))
                    final_score += clamped * weight
                    total_weight += weight
                    active_count += 1
                except: nan_count += 1 # Count as NaN if conversion/calc fails
            else: nan_count += 1

        # Determine Final Signal
        final_signal = "HOLD"
        if total_weight > 0:
            try: threshold = Decimal(str(self.config.get("signal_score_threshold", "1.5")))
            except: threshold = Decimal("1.5")
            if final_score >= threshold: final_signal = "BUY"
            elif final_score <= -threshold: final_signal = "SELL"
        else: self.logger.warning("No indicators contributed valid scores. Defaulting to HOLD.")

        # Log Summary
        price_prec = self.get_price_precision()
        sig_color = NEON_GREEN if final_signal == "BUY" else NEON_RED if final_signal == "SELL" else NEON_YELLOW
        log_msg = (
            f"Signal Summary ({self.symbol} @ {current_price:.{price_prec}f}): "
            f"Set='{self.active_weight_set_name}', Ind=[Act:{active_count}, NaN:{nan_count}], "
            f"Weight={total_weight:.2f}, Score={final_score:.4f} (Thr: +/-{threshold:.2f}) "
            f"==> {sig_color}{final_signal}{RESET}"
        )
        self.logger.info(log_msg)
        self.logger.debug(f"  Indicator Scores ({self.symbol}): {debug_scores}")

        if final_signal == "BUY": self.signals = {"BUY": 1, "SELL": 0, "HOLD": 0}
        elif final_signal == "SELL": self.signals = {"BUY": 0, "SELL": 1, "HOLD": 0}
        else: self.signals = {"BUY": 0, "SELL": 0, "HOLD": 1}
        return final_signal

    # --- Indicator Check Methods ---
    # (These remain largely the same as the input, ensure they use self.indicator_values correctly)
    def _check_ema_alignment(self) -> float:
        if "EMA_Short" not in self.indicator_values or "EMA_Long" not in self.indicator_values: return np.nan
        return self.calculate_ema_alignment_score()

    def _check_momentum(self) -> float:
        mom = self.indicator_values.get("Momentum"); threshold = 0.1
        if pd.isna(mom): return np.nan
        if mom > threshold: return 1.0
        elif mom < -threshold: return -1.0
        else: return float(mom / threshold) if threshold != 0 else 0.0

    def _check_volume_confirmation(self) -> float:
        vol = self.indicator_values.get("Volume") # Decimal
        vol_ma = self.indicator_values.get("Volume_MA") # Float
        mult = float(self.config.get("volume_confirmation_multiplier", 1.5))
        if pd.isna(vol) or not isinstance(vol, Decimal) or pd.isna(vol_ma) or vol_ma <= 0: return np.nan
        try:
            vol_ma_dec = Decimal(str(vol_ma)); mult_dec = Decimal(str(mult))
            if vol > vol_ma_dec * mult_dec: return 0.7
            elif vol < vol_ma_dec / mult_dec: return -0.4
            else: return 0.0
        except: return np.nan

    def _check_stoch_rsi(self) -> float:
        k = self.indicator_values.get("StochRSI_K"); d = self.indicator_values.get("StochRSI_D")
        if pd.isna(k) or pd.isna(d): return np.nan
        osold = float(self.config.get("stoch_rsi_oversold_threshold", 25))
        obought = float(self.config.get("stoch_rsi_overbought_threshold", 75))
        score = 0.0
        if k < osold and d < osold: score = 1.0
        elif k > obought and d > obought: score = -1.0
        diff = k - d
        if abs(diff) > 5: score = max(score, 0.6) if diff > 0 else min(score, -0.6)
        elif k > d: score = max(score, 0.2)
        elif k < d: score = min(score, -0.2)
        if 40 < k < 60: score *= 0.5
        return score

    def _check_rsi(self) -> float:
        rsi = self.indicator_values.get("RSI")
        if pd.isna(rsi): return np.nan
        if rsi <= 30: return 1.0;   elif rsi >= 70: return -1.0
        if rsi < 40: return 0.5;    elif rsi > 60: return -0.5
        if 40 <= rsi <= 60: return (rsi - 50) / 50.0
        return 0.0

    def _check_cci(self) -> float:
        cci = self.indicator_values.get("CCI")
        if pd.isna(cci): return np.nan
        if cci <= -150: return 1.0; elif cci >= 150: return -1.0
        if cci < -80: return 0.6;   elif cci > 80: return -0.6
        if cci > 0: return -0.1;    elif cci < 0: return 0.1
        return 0.0

    def _check_wr(self) -> float:
        wr = self.indicator_values.get("Williams_R")
        if pd.isna(wr): return np.nan
        if wr <= -80: return 1.0;   elif wr >= -20: return -1.0
        if wr < -50: return 0.4;    elif wr > -50: return -0.4
        return 0.0

    def _check_psar(self) -> float:
        psar_l = self.indicator_values.get("PSAR_long"); psar_s = self.indicator_values.get("PSAR_short")
        l_act = pd.notna(psar_l); s_act = pd.notna(psar_s)
        if l_act and not s_act: return 1.0
        elif s_act and not l_act: return -1.0
        elif not l_act and not s_act: return np.nan
        else: self.logger.warning(f"PSAR unusual: L={psar_l}, S={psar_s}"); return 0.0

    def _check_sma_10(self) -> float:
        sma = self.indicator_values.get("SMA10"); close = self.indicator_values.get("Close")
        if pd.isna(sma) or pd.isna(close) or not isinstance(close, Decimal): return np.nan
        try: sma_dec = Decimal(str(sma))
        except: return np.nan
        if close > sma_dec: return 0.6
        elif close < sma_dec: return -0.6
        else: return 0.0

    def _check_vwap(self) -> float:
        vwap = self.indicator_values.get("VWAP"); close = self.indicator_values.get("Close")
        if pd.isna(vwap) or pd.isna(close) or not isinstance(close, Decimal): return np.nan
        try: vwap_dec = Decimal(str(vwap))
        except: return np.nan
        if close > vwap_dec: return 0.7
        elif close < vwap_dec: return -0.7
        else: return 0.0

    def _check_mfi(self) -> float:
        mfi = self.indicator_values.get("MFI")
        if pd.isna(mfi): return np.nan
        if mfi <= 20: return 1.0;   elif mfi >= 80: return -1.0
        if mfi < 40: return 0.4;    elif mfi > 60: return -0.4
        return 0.0

    def _check_bollinger_bands(self) -> float:
        bbl=self.indicator_values.get("BB_Lower"); bbm=self.indicator_values.get("BB_Middle"); bbu=self.indicator_values.get("BB_Upper")
        close = self.indicator_values.get("Close")
        if pd.isna(bbl) or pd.isna(bbm) or pd.isna(bbu) or pd.isna(close) or not isinstance(close, Decimal): return np.nan
        try: bbl_d, bbm_d, bbu_d = Decimal(str(bbl)), Decimal(str(bbm)), Decimal(str(bbu))
        except: return np.nan
        if close <= bbl_d: return 1.0
        if close >= bbu_d: return -1.0
        bw = bbu_d - bbl_d
        if bw > 0:
             if close > bbm_d: prox = (close - bbm_d) / (bbu_d - bbm_d) if (bbu_d - bbm_d) > 0 else 0; return float(Decimal(0.5)*(1-prox))
             elif close < bbm_d: prox = (bbm_d - close) / (bbm_d - bbl_d) if (bbm_d - bbl_d) > 0 else 0; return float(Decimal(-0.5)*(1-prox))
        return 0.0

    def _check_orderbook(self, orderbook_data: Optional[Dict], current_price: Decimal) -> float:
        if not orderbook_data or not orderbook_data.get('bids') or not orderbook_data.get('asks'): return np.nan
        try:
            bids = orderbook_data['bids']; asks = orderbook_data['asks']
            levels = min(len(bids), len(asks), 10)
            if levels == 0: return 0.0
            bid_v = sum(Decimal(str(b[1])) for b in bids[:levels] if len(b)==2)
            ask_v = sum(Decimal(str(a[1])) for a in asks[:levels] if len(a)==2)
            total_v = bid_v + ask_v
            if total_v == 0: return 0.0
            obi = (bid_v - ask_v) / total_v
            score = float(max(Decimal("-1.0"), min(Decimal("1.0"), obi))) # Clamp and convert
            self.logger.debug(f"OB Check: Lvl={levels}, BidV={bid_v:.4f}, AskV={ask_v:.4f}, OBI={obi:.4f} -> Score={score:.4f}")
            return score
        except: self.logger.warning("Orderbook analysis failed.", exc_info=True); return np.nan

    def calculate_entry_tp_sl(self, entry_price_estimate: Decimal, signal: str) -> Tuple[Optional[Decimal], Optional[Decimal], Optional[Decimal]]:
        """Calculates potential TP and initial SL based on entry estimate, signal, and ATR."""
        if signal not in ["BUY", "SELL"]: return entry_price_estimate, None, None
        atr = self.indicator_values.get("ATR")
        if not isinstance(atr, Decimal) or pd.isna(atr) or atr <= 0:
            self.logger.warning(f"Calc TP/SL Fail ({signal}): Invalid ATR ({atr})."); return entry_price_estimate, None, None
        if not isinstance(entry_price_estimate, Decimal) or pd.isna(entry_price_estimate) or entry_price_estimate <= 0:
            self.logger.warning(f"Calc TP/SL Fail ({signal}): Invalid entry estimate ({entry_price_estimate})."); return entry_price_estimate, None, None

        try:
            tp_mult = Decimal(str(self.config.get("take_profit_multiple", "1.0")))
            sl_mult = Decimal(str(self.config.get("stop_loss_multiple", "1.5")))
            prec = self.get_price_precision()
            rnd = Decimal('1e-' + str(prec))
            tick = self.get_min_tick_size()

            tp_off = atr * tp_mult; sl_off = atr * sl_mult
            tp_raw, sl_raw = None, None

            if signal == "BUY": tp_raw, sl_raw = entry_price_estimate + tp_off, entry_price_estimate - sl_off
            else: tp_raw, sl_raw = entry_price_estimate - tp_off, entry_price_estimate + sl_off

            tp_q = tp_raw.quantize(rnd, rounding=ROUND_HALF_UP) if tp_raw else None
            sl_q = sl_raw.quantize(rnd, rounding=ROUND_DOWN if signal=="BUY" else ROUND_UP) if sl_raw else None

            # Validate and adjust
            final_tp, final_sl = tp_q, sl_q
            if final_sl: # Ensure SL is beyond entry
                if signal == "BUY" and final_sl >= entry_price_estimate: final_sl = (entry_price_estimate - tick).quantize(rnd, rounding=ROUND_DOWN)
                elif signal == "SELL" and final_sl <= entry_price_estimate: final_sl = (entry_price_estimate + tick).quantize(rnd, rounding=ROUND_UP)
            if final_tp: # Ensure TP offers profit
                 if signal == "BUY" and final_tp <= entry_price_estimate: self.logger.warning(f"BUY TP {final_tp} <= Entry {entry_price_estimate}. Null TP."); final_tp = None
                 elif signal == "SELL" and final_tp >= entry_price_estimate: self.logger.warning(f"SELL TP {final_tp} >= Entry {entry_price_estimate}. Null TP."); final_tp = None
            if final_sl and final_sl <= 0: self.logger.error(f"SL calc non-positive ({final_sl}). Null SL."); final_sl = None
            if final_tp and final_tp <= 0: self.logger.warning(f"TP calc non-positive ({final_tp}). Null TP."); final_tp = None

            tp_str = f"{final_tp:.{prec}f}" if final_tp else "None"; sl_str = f"{final_sl:.{prec}f}" if final_sl else "None"
            self.logger.debug(f"Calc TP/SL ({signal}): Entry={entry_price_estimate:.{prec}f}, ATR={atr:.{prec+2}f}, TP={tp_str}, SL={sl_str}")
            return entry_price_estimate, final_tp, final_sl
        except Exception as e:
            self.logger.error(f"Unexpected error calculating TP/SL: {e}", exc_info=True)
            return entry_price_estimate, None, None

# --- Trading Logic Helper Functions ---

def fetch_balance(exchange: ccxt.Exchange, currency: str, logger: logging.Logger) -> Optional[Decimal]:
    """Fetches available balance for a specific currency with retries and robust parsing."""
    lg = logger
    try:
        balance_info = None; params = {}; account_type = "default"
        if exchange.id == 'bybit': params = {'type': 'CONTRACT'}; account_type = 'CONTRACT'

        lg.debug(f"Fetching balance for {currency} (Account: {account_type})...")
        balance_info = safe_api_call(exchange.fetch_balance, lg, params=params)

        if not balance_info: # Try default fetch as fallback
             lg.debug("Attempting default balance fetch fallback...")
             balance_info = safe_api_call(exchange.fetch_balance, lg)
             if not balance_info: lg.error(f"Balance fetch failed after retries for {currency}."); return None

        # --- Parse balance_info ---
        free_balance = None
        if currency in balance_info and balance_info[currency].get('free') is not None:
            free_balance = balance_info[currency]['free']
            lg.debug(f"Found balance via standard ['{currency}']['free']: {free_balance}")
        elif exchange.id == 'bybit' and 'info' in balance_info and isinstance(balance_info['info'].get('result', {}).get('list'), list):
            for account in balance_info['info']['result']['list']:
                if isinstance(account.get('coin'), list):
                    for coin_data in account['coin']:
                        if coin_data.get('coin') == currency:
                            free = coin_data.get('availableToWithdraw') or coin_data.get('availableBalance') or coin_data.get('walletBalance')
                            if free is not None: free_balance = free; lg.debug(f"Found balance via Bybit V5 nested: {free}"); break
                    if free_balance is not None: break
        elif 'free' in balance_info and currency in balance_info['free']: # Less common fallback
             free_balance = balance_info['free'][currency]; lg.debug(f"Found balance via top-level 'free': {free_balance}")

        if free_balance is None: # Final fallback to 'total', use cautiously
             total_balance = balance_info.get(currency, {}).get('total')
             if total_balance is not None:
                  lg.warning(f"Using 'total' balance ({total_balance}) as fallback for {currency}. May include collateral.")
                  free_balance = total_balance
             else: lg.error(f"Could not determine any balance for {currency}."); return None

        # Convert to Decimal
        try:
            final_balance = Decimal(str(free_balance))
            if final_balance < 0: lg.error(f"Parsed balance negative ({final_balance}). Treating as zero."); final_balance = Decimal('0')
            lg.info(f"Available {currency} balance: {final_balance:.4f}")
            return final_balance
        except: lg.error(f"Failed to convert balance '{free_balance}' to Decimal."); return None
    except Exception as e:
        lg.error(f"Error fetching balance for {currency}: {e}", exc_info=False); return None


def get_market_info(exchange: ccxt.Exchange, symbol: str, logger: logging.Logger) -> Optional[Dict]:
    """Gets market information with retries for loading."""
    lg = logger
    try:
        # Ensure markets are loaded, reload if necessary with retries
        if not exchange.markets or symbol not in exchange.markets:
             lg.info(f"Market info for {symbol} not loaded, attempting reload...")
             try: safe_api_call(exchange.load_markets, lg, reload=True)
             except Exception as load_err: lg.error(f"Failed to load markets: {load_err}"); return None

        if symbol not in exchange.markets:
             lg.error(f"Market {symbol} still not found after reload.")
             if symbol == "BTC/USDT": lg.warning(f"Hint: For Bybit linear perpetual, try '{symbol}:USDT'")
             return None

        market = exchange.market(symbol)
        if market:
            # Add custom flags for convenience
            market['is_contract'] = market.get('contract', False) or market.get('type') in ['swap', 'future']
            market['is_linear'] = market.get('linear', False)
            market['is_inverse'] = market.get('inverse', False)
            # Log key details
            lg.debug(f"Market Info ({symbol}): ID={market.get('id')}, Base={market.get('base')}, Quote={market.get('quote')}, "
                     f"Type={market.get('type')}, Contract={market['is_contract']}, Linear={market['is_linear']}, Inverse={market['is_inverse']}")
            return market
        else: lg.error(f"Market dict not found for validated symbol {symbol}."); return None
    except ccxt.BadSymbol as e: lg.error(f"Invalid symbol '{symbol}': {e}"); return None
    except Exception as e: lg.error(f"Unexpected error getting market info: {e}", exc_info=True); return None


def calculate_position_size(
    balance: Decimal, risk_per_trade: float, initial_stop_loss_price: Decimal,
    entry_price: Decimal, market_info: Dict, exchange: ccxt.Exchange,
    logger: Optional[logging.Logger] = None
) -> Optional[Decimal]:
    """Calculates position size based on risk, SL, balance, and market constraints."""
    lg = logger or logging.getLogger(__name__)
    symbol = market_info.get('symbol', 'UNK')
    quote = market_info.get('quote', QUOTE_CURRENCY)
    base = market_info.get('base', 'BASE')
    is_contract = market_info.get('is_contract', False)
    is_inverse = market_info.get('is_inverse', False)
    size_unit = "Contracts" if is_contract else base

    # --- Input Validation ---
    if not (isinstance(balance, Decimal) and balance >= 0): lg.error(f"SizeCalc Fail ({symbol}): Invalid balance {balance}."); return None
    if not (0 < risk_per_trade < 1): lg.error(f"SizeCalc Fail ({symbol}): Invalid risk {risk_per_trade}."); return None
    if not (isinstance(initial_stop_loss_price, Decimal) and initial_stop_loss_price > 0): lg.error(f"SizeCalc Fail ({symbol}): Invalid SL {initial_stop_loss_price}."); return None
    if not (isinstance(entry_price, Decimal) and entry_price > 0): lg.error(f"SizeCalc Fail ({symbol}): Invalid entry {entry_price}."); return None
    if initial_stop_loss_price == entry_price: lg.error(f"SizeCalc Fail ({symbol}): SL equals Entry."); return None
    if 'limits' not in market_info or 'precision' not in market_info: lg.error(f"SizeCalc Fail ({symbol}): Market info missing limits/precision."); return None
    if is_inverse: lg.error(f"Inverse contract sizing not implemented for {symbol}."); return None
    if balance == 0: lg.warning(f"SizeCalc ({symbol}): Balance is zero. Cannot calculate size."); return None

    try:
        risk_amount_quote = balance * Decimal(str(risk_per_trade))
        sl_dist_quote_per_base = abs(entry_price - initial_stop_loss_price)
        if sl_dist_quote_per_base <= 0: lg.error(f"SizeCalc Fail ({symbol}): SL distance zero/negative."); return None

        # Get Contract Size (value per contract, usually in base currency)
        try: contract_size = Decimal(str(market_info.get('contractSize', '1')))
        except: lg.warning(f"Invalid contract size, using 1."); contract_size = Decimal('1')
        if contract_size <= 0: lg.warning("Contract size zero/negative, using 1."); contract_size = Decimal('1')

        # Calculate Initial Size (Linear/Spot)
        # SizeInContracts = RiskQuote / (SL_Dist_Quote_Per_Base * ContractSize_Base)
        risk_per_unit_quote = sl_dist_quote_per_base * contract_size
        if risk_per_unit_quote <= 0: lg.error(f"SizeCalc Fail ({symbol}): Risk per unit zero/negative."); return None
        calc_size = risk_amount_quote / risk_per_unit_quote

        if calc_size <= 0: lg.error(f"Initial size calc zero/negative: {calc_size}."); return None

        lg.info(f"SizeCalc ({symbol}): Bal={balance:.2f}, Risk={risk_per_trade:.2%}, RiskAmt={risk_amount_quote:.4f} {quote}")
        lg.info(f"  Entry={entry_price}, SL={initial_stop_loss_price}, SL Dist={sl_dist_quote_per_base}")
        lg.info(f"  ContrSize={contract_size}, Initial Size = {calc_size:.8f} {size_unit}")

        # --- Apply Market Limits and Precision ---
        analyzer = TradingAnalyzer(pd.DataFrame(), lg, CONFIG, market_info) # Temp instance for helpers
        min_amt = Decimal(str(market_info.get('limits', {}).get('amount', {}).get('min', '0')))
        max_amt = Decimal(str(market_info.get('limits', {}).get('amount', {}).get('max', 'inf')))
        min_cost = Decimal(str(market_info.get('limits', {}).get('cost', {}).get('min', '0')))
        max_cost = Decimal(str(market_info.get('limits', {}).get('cost', {}).get('max', 'inf')))
        amt_step = analyzer.get_min_amount_step()

        adj_size = calc_size
        # 1. Clamp by Amount Limits
        orig_size = adj_size
        adj_size = max(min_amt, min(adj_size, max_amt))
        if adj_size != orig_size: lg.warning(f"Size adjusted by Amount Limits: {orig_size:.8f} -> {adj_size:.8f}")

        # 2. Apply Amount Step Size (Round DOWN)
        if amt_step > 0:
            orig_size = adj_size
            adj_size = (adj_size // amt_step) * amt_step
            if adj_size != orig_size: lg.info(f"Applied Amount Step ({amt_step}): {orig_size:.8f} -> {adj_size:.8f}")
        else: lg.warning("Amount step size zero/negative. Skipping.")

        # 3. Re-check Min Amount & Cost Limits with final adjusted size
        if adj_size < min_amt: lg.error(f"Final size {adj_size} < Min Amount {min_amt}. Cannot order."); return None
        est_cost = adj_size * entry_price * contract_size # Cost = Size * Price * ContractValue (for linear)
        lg.debug(f"  Cost Check: Final Size={adj_size:.8f}, Est. Cost={est_cost:.4f} (Min:{min_cost}, Max:{max_cost})")
        if min_cost > 0 and est_cost < min_cost: lg.error(f"Est. cost {est_cost:.4f} < Min Cost {min_cost}. Cannot order."); return None
        if max_cost > 0 and est_cost > max_cost: lg.error(f"Est. cost {est_cost:.4f} > Max Cost {max_cost}. Cannot order."); return None

        # --- Final Validation ---
        final_size = adj_size
        if final_size <= 0: lg.error(f"Final size zero/negative ({final_size}). Aborted."); return None

        lg.info(f"{NEON_GREEN}Final calculated size for {symbol}: {final_size} {size_unit}{RESET}")
        return final_size
    except Exception as e: lg.error(f"Unexpected error calculating size: {e}", exc_info=True); return None


def get_open_position(exchange: ccxt.Exchange, symbol: str, logger: logging.Logger) -> Optional[Dict]:
    """Checks for an open position using fetch_positions with robust parsing for Bybit V5."""
    lg = logger
    if not exchange.has.get('fetchPositions'): lg.warning(f"{exchange.id} lacks fetchPositions."); return None

    try:
        lg.debug(f"Fetching positions for symbol: {symbol}")
        market = exchange.market(symbol) # Needed for market ID
        params = {}
        if exchange.id == 'bybit': params = {'symbol': market['id']}

        positions: List[Dict] = safe_api_call(exchange.fetch_positions, lg, symbols=[symbol], params=params)

        if positions is None: # Try fetching all as fallback
             lg.debug("Fetching single position failed/unsupported, trying all...")
             all_positions = safe_api_call(exchange.fetch_positions, lg)
             if all_positions: positions = [p for p in all_positions if p.get('symbol') == symbol]
             else: lg.error("Fallback fetch of all positions failed."); return None

        # --- Process positions ---
        active_position = None
        size_threshold = Decimal('1e-9')
        for pos in positions:
            if pos.get('symbol') != symbol: continue
            pos_size_str = pos.get('contracts') or pos.get('info', {}).get('size')
            if pos_size_str is None: continue
            try:
                pos_size = Decimal(str(pos_size_str))
                if abs(pos_size) > size_threshold: active_position = pos; break
            except: continue

        # --- Post-Process active position ---
        if active_position:
            try:
                analyzer = TradingAnalyzer(pd.DataFrame(), lg, CONFIG, market) # Temp instance
                price_prec, amt_prec = analyzer.get_price_precision(), analyzer.get_amount_precision_places()

                # Standardize essential fields to Decimal
                size_dec = Decimal(str(active_position.get('contracts', active_position['info'].get('size', '0'))))
                active_position['contractsDecimal'] = size_dec
                entry_str = active_position.get('entryPrice') or active_position['info'].get('avgPrice')
                active_position['entryPriceDecimal'] = Decimal(str(entry_str)) if entry_str else None
                liq_str = active_position.get('liquidationPrice') or active_position['info'].get('liqPrice')
                active_position['liquidationPriceDecimal'] = Decimal(str(liq_str)) if liq_str else None
                pnl_str = active_position.get('unrealizedPnl') or active_position['info'].get('unrealisedPnl')
                active_position['unrealizedPnlDecimal'] = Decimal(str(pnl_str)) if pnl_str else None

                # Standardize side
                side = active_position.get('side')
                if side not in ['long', 'short']: side = 'long' if size_dec > 0 else 'short' if size_dec < 0 else None
                if not side: lg.warning("Could not determine position side."); return None
                active_position['side'] = side

                # Extract protection from info dict (Bybit V5)
                info = active_position.get('info', {})
                sl_str, tp_str = info.get('stopLoss'), info.get('takeProfit')
                tsl_d_str, tsl_a_str = info.get('trailingStop'), info.get('activePrice')
                active_position['stopLossPriceDecimal'] = Decimal(str(sl_str)) if sl_str and str(sl_str)!='0' else None
                active_position['takeProfitPriceDecimal'] = Decimal(str(tp_str)) if tp_str and str(tp_str)!='0' else None
                active_position['trailingStopLossValueDecimal'] = Decimal(str(tsl_d_str)) if tsl_d_str and str(tsl_d_str)!='0' else None
                active_position['trailingStopActivationPriceDecimal'] = Decimal(str(tsl_a_str)) if tsl_a_str and str(tsl_a_str)!='0' else None

                # Timestamp
                ts_ms = info.get('updatedTime') or active_position.get('timestamp')
                active_position['timestamp_ms'] = int(ts_ms) if ts_ms else None
                ts_dt = datetime.fromtimestamp(ts_ms / 1000, tz=timezone.utc).strftime('%Y-%m-%d %H:%M:%S %Z') if ts_ms else "N/A"

                # Log Formatted Info
                entry_f=f"{active_position['entryPriceDecimal']:.{price_prec}f}" if active_position['entryPriceDecimal'] else 'N/A'
                size_f=f"{abs(size_dec):.{amt_prec}f}"; liq_f=f"{active_position['liquidationPriceDecimal']:.{price_prec}f}" if active_position['liquidationPriceDecimal'] else 'N/A'
                lev_f=f"{Decimal(str(info.get('leverage', 'N/A'))):.1f}x" if info.get('leverage') else 'N/A'
                pnl_f=f"{active_position['unrealizedPnlDecimal']:.{price_prec}f}" if active_position['unrealizedPnlDecimal'] else 'N/A'
                sl_f=f"{active_position['stopLossPriceDecimal']:.{price_prec}f}" if active_position['stopLossPriceDecimal'] else 'N/A'
                tp_f=f"{active_position['takeProfitPriceDecimal']:.{price_prec}f}" if active_position['takeProfitPriceDecimal'] else 'N/A'
                tsl_d_f=f"{active_position['trailingStopLossValueDecimal']:.{price_prec}f}" if active_position['trailingStopLossValueDecimal'] else 'N/A'
                tsl_a_f=f"{active_position['trailingStopActivationPriceDecimal']:.{price_prec}f}" if active_position['trailingStopActivationPriceDecimal'] else 'N/A'

                logger.info(f"{NEON_GREEN}Active {side.upper()} position ({symbol}):{RESET} "
                            f"Size={size_f}, Entry={entry_f}, Liq={liq_f}, Lev={lev_f}, PnL={pnl_f}, "
                            f"SL={sl_f}, TP={tp_f}, TSL(Dist/Act): {tsl_d_f}/{tsl_a_f} (Upd: {ts_dt})")
                logger.debug(f"Full processed position: {active_position}")
                return active_position
            except Exception as proc_err: lg.error(f"Error processing position details: {proc_err}", exc_info=True); return None
        else: logger.info(f"No active open position found for {symbol}."); return None
    except Exception as e: lg.error(f"Error fetching/processing positions: {e}", exc_info=False); return None


def set_leverage_ccxt(exchange: ccxt.Exchange, symbol: str, leverage: int, market_info: Dict, logger: logging.Logger) -> bool:
    """Sets leverage using CCXT, handling Bybit V5 specifics."""
    lg = logger
    if not market_info.get('is_contract', False): lg.debug(f"Leverage skipped ({symbol}: Not contract)."); return True
    if not (isinstance(leverage, int) and leverage > 0): lg.warning(f"Leverage skipped: Invalid value {leverage}."); return False
    if not exchange.has.get('setLeverage') and not exchange.has.get('setMarginMode'): lg.error(f"{exchange.id} lacks setLeverage/setMarginMode."); return False

    try:
        lg.info(f"Attempting to set leverage for {symbol} to {leverage}x...")
        params = {}
        if exchange.id == 'bybit': params = {'buyLeverage': str(leverage), 'sellLeverage': str(leverage)}
        response = safe_api_call(exchange.set_leverage, lg, leverage, symbol, params)
        lg.debug(f"Set leverage response: {response}")
        lg.info(f"{NEON_GREEN}Leverage for {symbol} set/requested to {leverage}x.{RESET}")
        return True
    except ccxt.ExchangeError as e:
        code = getattr(e, 'code', None); err_str = str(e).lower()
        lg.error(f"Exchange error setting leverage: {e} (Code: {code})")
        if exchange.id == 'bybit':
            if code == 110045 or "not modified" in err_str: lg.info(f"Leverage already set to {leverage}x."); return True
            elif code in [110028, 110009, 110055] or "margin mode" in err_str: lg.error("Hint: Check Margin Mode (Isolated/Cross).")
            elif code == 110044 or "risk limit" in err_str: lg.error("Hint: Leverage exceeds Risk Limit tier.")
            elif code == 110013 or "parameter error" in err_str: lg.error(f"Hint: Leverage {leverage}x invalid/out of range?")
    except Exception as e: lg.error(f"Failed leverage setting: {e}", exc_info=False)
    return False


def place_trade(
    exchange: ccxt.Exchange, symbol: str, trade_signal: str, position_size: Decimal,
    market_info: Dict, logger: Optional[logging.Logger] = None, order_type: str = 'market',
    limit_price: Optional[Decimal] = None, reduce_only: bool = False, params: Optional[Dict] = None
) -> Optional[Dict]:
    """Places an order using CCXT with retries and enhanced logging."""
    lg = logger or logging.getLogger(__name__)
    side = 'buy' if trade_signal == "BUY" else 'sell'
    size_unit = "Contracts" if market_info.get('is_contract') else market_info.get('base', '')
    action = "Close/Reduce" if reduce_only else "Open/Increase"

    # Validate Inputs
    try: amount_f = float(position_size); assert amount_f > 0
    except: lg.error(f"Trade Aborted ({action} {side} {symbol}): Invalid size {position_size}."); return None
    price_f = None
    if order_type == 'limit':
         if not (isinstance(limit_price, Decimal) and limit_price > 0): lg.error(f"Trade Aborted ({action} {side} {symbol}): Limit needs valid price."); return None
         try: price_f = float(limit_price)
         except: lg.error(f"Trade Aborted ({action} {side} {symbol}): Invalid limit_price format {limit_price}."); return None

    # Prepare Parameters
    order_params = {'reduceOnly': reduce_only}
    if exchange.id == 'bybit': order_params['positionIdx'] = 0 # Assume one-way mode default
    if order_type == 'market' and reduce_only: order_params['timeInForce'] = 'IOC'
    if params: order_params = {**params, **order_params} # Ensure our settings override external if conflict

    # Log Details
    analyzer = TradingAnalyzer(pd.DataFrame(), lg, CONFIG, market_info) # Temp instance
    amt_prec = analyzer.get_amount_precision_places()
    lg.info(f"Attempting: {action} {side.upper()} {order_type.upper()} {symbol}")
    lg.info(f"  Size: {amount_f:.{amt_prec}f} {size_unit}")
    if order_type == 'limit': lg.info(f"  Limit Price: {limit_price}")
    lg.info(f"  ReduceOnly: {reduce_only}, Params: {order_params}")

    # Execute via safe_api_call
    try:
        order = safe_api_call(exchange.create_order, lg, symbol=symbol, type=order_type,
                              side=side, amount=amount_f, price=price_f, params=order_params)
        if order and order.get('id'):
            lg.info(f"{NEON_GREEN}{action} Order Placed Successfully!{RESET}")
            lg.info(f"  ID: {order.get('id')}, Status: {order.get('status', '?')}, Filled: {order.get('filled', 0.0)}, AvgPx: {order.get('average')}")
            lg.debug(f"Raw order response: {order}")
            return order
        else: lg.error(f"{NEON_RED}Order placement failed or response lacked ID. Response: {order}{RESET}"); return None
    except ccxt.InsufficientFunds as e: lg.error(f"{NEON_RED}Insufficient funds: {e}{RESET}")
    except ccxt.InvalidOrder as e:
        lg.error(f"{NEON_RED}Invalid order params: {e}{RESET}")
        err = str(e).lower()
        if "tick size" in err: lg.error(" >> Hint: Check limit price tick size.")
        if "step size" in err: lg.error(" >> Hint: Check amount step size.")
        if "minnotional" in err or "cost" in err: lg.error(" >> Hint: Order cost below minimum?")
        if "reduce-only" in err or (getattr(e,'code',0)==110014 and exchange.id=='bybit'): lg.error(" >> Hint: Reduce-only failed (pos closed?).")
    except ccxt.ExchangeError as e: lg.error(f"{NEON_RED}Exchange error placing order: {e} (Code: {getattr(e,'code',None)}){RESET}")
    except Exception as e: lg.error(f"{NEON_RED}Failed placing {action} order: {e}{RESET}", exc_info=False)
    return None


def _set_position_protection(
    exchange: ccxt.Exchange, symbol: str, market_info: Dict, position_info: Dict,
    logger: logging.Logger, stop_loss_price: Optional[Decimal] = None,
    take_profit_price: Optional[Decimal] = None, trailing_stop_distance: Optional[Decimal] = None,
    tsl_activation_price: Optional[Decimal] = None,
) -> bool:
    """Internal helper using Bybit V5 API to set SL, TP, or TSL."""
    lg = logger
    if 'bybit' not in exchange.id.lower(): lg.error("Protection via private_post only for Bybit."); return False
    if not market_info.get('is_contract'): lg.warning(f"Protection skipped ({symbol}: Not contract)."); return False
    if not position_info: lg.error(f"Cannot set protection ({symbol}): Missing position info."); return False

    pos_side = position_info.get('side'); entry_price = position_info.get('entryPriceDecimal')
    pos_idx = int(position_info.get('info', {}).get('positionIdx', 0)) # Default 0 for One-Way
    if pos_side not in ['long', 'short']: lg.error("Invalid position side."); return False
    if not isinstance(entry_price, Decimal) or entry_price <= 0: lg.error("Invalid entry price."); return False

    # Validate Protection Parameters
    has_sl = isinstance(stop_loss_price, Decimal) and stop_loss_price > 0
    has_tp = isinstance(take_profit_price, Decimal) and take_profit_price > 0
    has_tsl = isinstance(trailing_stop_distance, Decimal) and trailing_stop_distance > 0 and \
              isinstance(tsl_activation_price, Decimal) and tsl_activation_price > 0

    # Check SL/TP relative to entry
    if has_sl and ((pos_side=='long' and stop_loss_price >= entry_price) or (pos_side=='short' and stop_loss_price <= entry_price)): lg.error(f"Invalid SL {stop_loss_price} vs Entry {entry_price} for {pos_side}. Ignoring SL."); has_sl = False
    if has_tp and ((pos_side=='long' and take_profit_price <= entry_price) or (pos_side=='short' and take_profit_price >= entry_price)): lg.error(f"Invalid TP {take_profit_price} vs Entry {entry_price} for {pos_side}. Ignoring TP."); has_tp = False
    if has_tsl and ((pos_side=='long' and tsl_activation_price <= entry_price) or (pos_side=='short' and tsl_activation_price >= entry_price)): lg.error(f"Invalid TSL Act {tsl_activation_price} vs Entry {entry_price} for {pos_side}. Ignoring TSL."); has_tsl = False
    if has_sl and has_tp and stop_loss_price == take_profit_price: lg.error("SL price equals TP price. Ignoring both."); has_sl = False; has_tp = False

    if not has_sl and not has_tp and not has_tsl: lg.info(f"No valid protection params remaining for {symbol}."); return True

    # Prepare API Parameters
    category = 'linear' if market_info.get('is_linear', True) else 'inverse'
    params = {'category': category, 'symbol': market_info['id'], 'tpslMode': 'Full',
              'tpTriggerBy': 'LastPrice', 'slTriggerBy': 'LastPrice', 'positionIdx': pos_idx}
    log_parts = [f"Setting protection for {symbol} ({pos_side.upper()} PosIdx:{pos_idx}):"]

    try: # Format parameters
        analyzer = TradingAnalyzer(pd.DataFrame(), lg, CONFIG, market_info)
        min_tick = analyzer.get_min_tick_size()
        def fmt_p(p): return exchange.price_to_precision(symbol, float(p)) if isinstance(p,Decimal) and p>0 else None
        def fmt_d(d):
             if not (isinstance(d, Decimal) and d > 0): return None
             prec = abs(min_tick.normalize().as_tuple().exponent) if min_tick>0 else analyzer.get_price_precision()
             fmt = exchange.decimal_to_precision(d, exchange.ROUND, prec, exchange.NO_PADDING)
             return str(min_tick) if min_tick > 0 and Decimal(fmt) < min_tick else fmt

        if has_tsl:
            tsl_d_fmt, tsl_a_fmt = fmt_d(trailing_stop_distance), fmt_p(tsl_activation_price)
            if tsl_d_fmt and tsl_a_fmt: params['trailingStop']=tsl_d_fmt; params['activePrice']=tsl_a_fmt; log_parts.append(f"  TSL: Dist={tsl_d_fmt}, Act={tsl_a_fmt}"); has_sl=False
            else: lg.error("Failed formatting TSL params."); has_tsl=False # Mark TSL failed
        if has_sl:
            sl_fmt = fmt_p(stop_loss_price)
            if sl_fmt: params['stopLoss']=sl_fmt; log_parts.append(f"  FixSL: {sl_fmt}")
            else: lg.error("Failed formatting Fixed SL."); has_sl=False # Mark SL failed
        if has_tp:
            tp_fmt = fmt_p(take_profit_price)
            if tp_fmt: params['takeProfit']=tp_fmt; log_parts.append(f"  FixTP: {tp_fmt}")
            else: lg.error("Failed formatting Fixed TP."); has_tp=False # Mark TP failed
    except Exception as fmt_err: lg.error(f"Error formatting protection params: {fmt_err}", exc_info=True); return False

    if not params.get('stopLoss') and not params.get('takeProfit') and not params.get('trailingStop'):
        lg.warning(f"No valid protection parameters formatted for {symbol}. No API call."); return False

    # Make API Call
    lg.info("\n".join(log_parts)); lg.debug(f"  API Call: private_post('/v5/position/set-trading-stop', {params})")
    try:
        response = safe_api_call(exchange.private_post, lg, '/v5/position/set-trading-stop', params)
        lg.debug(f"Set protection response: {response}")
        code=response.get('retCode'); msg=response.get('retMsg','Err'); ext=response.get('retExtInfo',{})
        if code == 0:
            if "not modified" in msg.lower(): lg.info(f"{NEON_YELLOW}Protection already set or partially modified ({symbol}). Msg: {msg}{RESET}")
            else: lg.info(f"{NEON_GREEN}Protection set/updated successfully ({symbol}).{RESET}")
            return True
        else:
            lg.error(f"{NEON_RED}Failed set protection ({symbol}): {msg} (Code:{code}) Ext:{ext}{RESET}")
            if code == 110013: lg.error(" >> Hint(110013): Param Error? Check prices vs entry/tick, TSL values.")
            elif code == 110036: lg.error(f" >> Hint(110036): TSL Act Price '{params.get('activePrice')}' invalid?")
            elif code == 110086: lg.error(" >> Hint(110086): SL price == TP price.")
            elif code == 110025: lg.error(" >> Hint(110025): Position closed or posIdx mismatch?")
            return False
    except Exception as e: lg.error(f"Failed protection API call: {e}", exc_info=False); return False


def set_trailing_stop_loss(
    exchange: ccxt.Exchange, symbol: str, market_info: Dict, position_info: Dict,
    config: Dict[str, Any], logger: logging.Logger, take_profit_price: Optional[Decimal] = None
) -> bool:
    """Calculates and sets Exchange-Native Trailing Stop Loss."""
    lg = logger
    if not config.get("enable_trailing_stop"): lg.debug(f"TSL disabled ({symbol})."); return False

    try: # Validate inputs
        cb_rate = Decimal(str(config["trailing_stop_callback_rate"]))
        act_pct = Decimal(str(config["trailing_stop_activation_percentage"]))
        entry = position_info['entryPriceDecimal']; side = position_info['side']
        assert cb_rate > 0 and act_pct >= 0 and isinstance(entry, Decimal) and entry > 0 and side in ['long','short']
    except: lg.error(f"Invalid TSL config or pos info ({symbol}).", exc_info=True); return False

    try: # Calculate parameters
        analyzer = TradingAnalyzer(pd.DataFrame(), lg, config, market_info)
        prec = analyzer.get_price_precision(); rnd = Decimal(f'1e-{prec}'); tick = analyzer.get_min_tick_size()
        act_off = entry * act_pct; act_price = None
        if side == 'long': act_price = (entry + act_off).quantize(rnd, rounding=ROUND_UP); act_price = max(act_price, (entry+tick).quantize(rnd,rounding=ROUND_UP))
        else: act_price = (entry - act_off).quantize(rnd, rounding=ROUND_DOWN); act_price = min(act_price, (entry-tick).quantize(rnd,rounding=ROUND_DOWN))
        if act_price <= 0: lg.error(f"Invalid TSL Act price calc ({act_price})."); return False

        dist_raw = act_price * cb_rate; dist = None
        if tick > 0: dist = (dist_raw / tick).quantize(Decimal('1'), rounding=ROUND_UP) * tick; dist = max(dist, tick)
        else: dist = dist_raw.quantize(rnd, rounding=ROUND_UP)
        if dist <= 0: lg.error(f"Invalid TSL Dist calc ({dist})."); return False

        lg.info(f"Calc TSL Params ({symbol} {side.upper()}): ActPrice={act_price:.{prec}f}, Dist={dist:.{prec}f}")
        if isinstance(take_profit_price, Decimal) and take_profit_price > 0: lg.info(f"  Also setting TP: {take_profit_price:.{prec}f}")

        # Set protection via helper
        return _set_position_protection(exchange, symbol, market_info, position_info, lg,
                                        stop_loss_price=None, take_profit_price=take_profit_price,
                                        trailing_stop_distance=dist, tsl_activation_price=act_price)
    except Exception as e: lg.error(f"Error calculating/setting TSL: {e}", exc_info=True); return False


# --- Main Analysis and Trading Loop ---
def analyze_and_trade_symbol(exchange: ccxt.Exchange, symbol: str, config: Dict[str, Any], logger: logging.Logger) -> None:
    """Performs one cycle of analysis and trading logic for a single symbol."""
    lg = logger
    lg.info(f"---== Analyzing {symbol} ({config['interval']}) Cycle Start ==---")
    cycle_start_time = time.monotonic()

    try:
        # --- Get Market Info (critical) ---
        market_info = get_market_info(exchange, symbol, lg)
        if not market_info: raise ValueError(f"Fatal: Failed to get market info for {symbol}.")

        # --- Fetch Data ---
        ccxt_interval = CCXT_INTERVAL_MAP.get(config["interval"])
        if not ccxt_interval: raise ValueError(f"Invalid interval '{config['interval']}'.")
        klines_df = fetch_klines_ccxt(exchange, symbol, ccxt_interval, limit=500, logger=lg)
        if klines_df.empty or len(klines_df) < 50: raise ValueError(f"Insufficient kline data ({len(klines_df)}).")

        current_price = fetch_current_price_ccxt(exchange, symbol, lg)
        if current_price is None: # Fallback to last close
             lg.warning("Using last close from klines as current price.")
             try: last_close = klines_df['close'].iloc[-1]; assert pd.notna(last_close)
             except: raise ValueError("Failed to get valid last close price.")
             current_price = Decimal(str(last_close))
             if current_price <= 0: raise ValueError("Last close price non-positive.")

        # Fetch order book if needed
        orderbook_data = None
        active_weights = config.get("weight_sets", {}).get(config.get("active_weight_set", "default"), {})
        if config.get("indicators",{}).get("orderbook", False) and float(active_weights.get("orderbook", 0)) != 0:
            orderbook_data = fetch_orderbook_ccxt(exchange, symbol, config["orderbook_limit"], lg)
            if not orderbook_data: lg.warning(f"Failed orderbook fetch for {symbol}.")

        # --- Analyze Data ---
        analyzer = TradingAnalyzer(klines_df.copy(), lg, config, market_info)
        if not analyzer.indicator_values: raise ValueError("Indicator calculation failed.")
        signal = analyzer.generate_trading_signal(current_price, orderbook_data)

        # --- Calculate Potential TP/SL & Log Summary ---
        _, tp_calc, sl_calc = analyzer.calculate_entry_tp_sl(current_price, signal)
        price_prec = analyzer.get_price_precision(); current_atr = analyzer.indicator_values.get("ATR")
        lg.info(f"Current Price: {current_price:.{price_prec}f}")
        lg.info(f"ATR: {current_atr:.{price_prec+2}f}" if isinstance(current_atr, Decimal) else 'ATR: N/A')
        lg.info(f"Calc Initial SL (sizing): {sl_calc or 'N/A'}, TP (target): {tp_calc or 'N/A'}")
        lg.info(f"Mgmt: TSL={'On' if config['enable_trailing_stop'] else 'Off'}, BE={'On' if config['enable_break_even'] else 'Off'}, TimeExit={config.get('time_based_exit_minutes') or 'Off'}")

        # --- Trading Execution Logic ---
        if not config.get("enable_trading"): lg.debug("Trading disabled. Cycle complete."); return

        open_position = get_open_position(exchange, symbol, lg)

        # --- Scenario 1: No Open Position ---
        if open_position is None:
            if signal in ["BUY", "SELL"]:
                lg.info(f"*** {signal} Signal & No Position: Initiating Trade Sequence ***")
                balance = fetch_balance(exchange, QUOTE_CURRENCY, lg)
                if balance is None or balance <= 0: raise ValueError("Balance fetch failed or zero/negative.")
                if sl_calc is None: raise ValueError("Initial SL calculation failed (ATR invalid?).")

                if market_info.get('is_contract') and int(config.get("leverage", 0)) > 0:
                    if not set_leverage_ccxt(exchange, symbol, int(config["leverage"]), market_info, lg):
                        raise ValueError("Failed to set leverage.")

                pos_size = calculate_position_size(balance, config["risk_per_trade"], sl_calc, current_price, market_info, exchange, lg)
                if pos_size is None or pos_size <= 0: raise ValueError(f"Position size calculation failed ({pos_size}).")

                # Place Order (Market or Limit)
                entry_type = config.get("entry_order_type", "market"); limit_px = None
                if entry_type == "limit":
                     offset = Decimal(str(config[f"limit_order_offset_{signal.lower()}"]))
                     rnd_f = Decimal(f'1e-{price_prec}')
                     raw_px = current_price * (1 - offset if signal=='BUY' else 1 + offset)
                     limit_px = raw_px.quantize(rnd_f, rounding=ROUND_DOWN if signal=='BUY' else ROUND_UP)
                     if limit_px <= 0: lg.error(f"Limit px calc failed ({limit_px}). Switching to Market."); entry_type="market"; limit_px=None
                     else: lg.info(f"Calc Limit Entry for {signal}: {limit_px}")

                trade_order = place_trade(exchange, symbol, signal, pos_size, market_info, lg, entry_type, limit_px)

                # Post-Order Handling
                if trade_order and trade_order.get('id'):
                    order_id, status = trade_order['id'], trade_order.get('status')
                    if status == 'closed' or entry_type == 'market':
                        delay = config["position_confirm_delay_seconds"] if entry_type=='market' else 2
                        lg.info(f"Order {order_id} placed/filled. Waiting {delay}s for confirmation...")
                        time.sleep(delay)
                        confirmed_pos = get_open_position(exchange, symbol, lg)
                        if confirmed_pos:
                            lg.info(f"{NEON_GREEN}Position Confirmed!{RESET}")
                            # --- Set Protection ---
                            try:
                                entry_act = confirmed_pos.get('entryPriceDecimal') or current_price # Use actual or estimate
                                lg.info(f"Actual Entry ~ {entry_act:.{price_prec}f}")
                                _, tp_f, sl_f = analyzer.calculate_entry_tp_sl(entry_act, signal)
                                protection_ok = False
                                if config["enable_trailing_stop"]:
                                     lg.info(f"Setting TSL (TP target: {tp_f})...")
                                     protection_ok = set_trailing_stop_loss(exchange, symbol, market_info, confirmed_pos, config, lg, tp_f)
                                elif sl_f or tp_f: # Use fixed if TSL disabled AND calc valid
                                     lg.info(f"Setting Fixed SL ({sl_f}) / TP ({tp_f})...")
                                     protection_ok = _set_position_protection(exchange, symbol, market_info, confirmed_pos, lg, sl_f, tp_f)
                                else: lg.warning("No valid protection calculated (TSL disabled).")

                                if protection_ok: lg.info(f"{NEON_GREEN}=== TRADE ENTRY & PROTECTION COMPLETE ({symbol} {signal}) ===")
                                else: lg.error(f"{NEON_RED}=== TRADE PLACED BUT PROTECTION FAILED ({symbol} {signal}) ===\n{NEON_YELLOW}>>> MANUAL MONITORING REQUIRED! <<<")
                            except Exception as post_err: lg.error(f"Error setting protection: {post_err}", exc_info=True); lg.warning(f"{NEON_YELLOW}Position open, manual check needed!{RESET}")
                        else: lg.error(f"{NEON_RED}Order {order_id} placed/filled BUT POSITION NOT CONFIRMED! Manual check!{RESET}")
                    elif status == 'open' and entry_type == 'limit': lg.info(f"Limit order {order_id} OPEN. Check next cycle.")
                    else: lg.error(f"Order {order_id} status: {status}. Trade did not open as expected.")
                else: lg.error(f"{NEON_RED}=== TRADE EXECUTION FAILED. Order placement error. ===")
            else: lg.info("Signal HOLD, no position. No action.")

        # --- Scenario 2: Existing Open Position ---
        else:
            pos_side = open_position['side']; pos_size = open_position['contractsDecimal']
            entry_price = open_position['entryPriceDecimal']; pos_ts_ms = open_position['timestamp_ms']
            lg.info(f"Managing existing {pos_side.upper()} position. Size: {pos_size}, Entry: {entry_price}")

            # Check for Exit Signal (opposite direction)
            if (pos_side == 'long' and signal == "SELL") or (pos_side == 'short' and signal == "BUY"):
                lg.warning(f"{NEON_YELLOW}*** EXIT Signal ({signal}) opposes {pos_side} position. Closing... ***{RESET}")
                try:
                    close_sig = "SELL" if pos_side == 'long' else "BUY"
                    size_close = abs(pos_size); assert size_close > 0
                    lg.info(f"==> Placing {close_sig} MARKET order (reduceOnly=True) | Size: {size_close} <==")
                    close_order = place_trade(exchange, symbol, close_sig, size_close, market_info, lg, 'market', reduce_only=True)
                    if close_order: lg.info(f"{NEON_GREEN}Close order placed successfully. ID: {close_order.get('id','?')}{RESET}")
                    else: lg.error(f"{NEON_RED}Failed placing CLOSE order! Manual check!{RESET}")
                except Exception as close_err: lg.error(f"Error closing position: {close_err}", exc_info=True); lg.warning(f"{NEON_YELLOW}Manual close may be needed!{RESET}")
                return # Exit cycle after close attempt

            # Check for Time-Based Exit
            time_exit = config.get("time_based_exit_minutes")
            if isinstance(time_exit, (int, float)) and time_exit > 0 and pos_ts_ms:
                 try:
                      elapsed_mins = (time.time() * 1000 - pos_ts_ms) / 60000
                      lg.debug(f"Time Exit Check: Elapsed={elapsed_mins:.2f}m, Limit={time_exit}m")
                      if elapsed_mins >= time_exit:
                           lg.warning(f"{NEON_YELLOW}*** TIME-BASED EXIT ({elapsed_mins:.1f} >= {time_exit}m). Closing... ***{RESET}")
                           # Execute Close Logic
                           close_sig = "SELL" if pos_side == 'long' else "BUY"
                           size_close = abs(pos_size); assert size_close > 0
                           close_order = place_trade(exchange, symbol, close_sig, size_close, market_info, lg, 'market', reduce_only=True)
                           if close_order: lg.info(f"{NEON_GREEN}Time-based CLOSE order placed. ID: {close_order.get('id','?')}{RESET}")
                           else: lg.error(f"{NEON_RED}Failed time-based CLOSE order! Manual check!{RESET}")
                           return # Exit cycle
                 except Exception as time_err: lg.error(f"Error in time exit check: {time_err}")

            # --- Manage Position (BE) ---
            is_tsl_active = open_position.get('trailingStopLossValueDecimal') is not None
            if config["enable_break_even"] and not is_tsl_active:
                 lg.debug("Checking Break-Even conditions...")
                 try:
                     assert isinstance(entry_price, Decimal) and entry_price > 0
                     assert isinstance(current_atr, Decimal) and current_atr > 0
                     be_trig_atr = Decimal(str(config["break_even_trigger_atr_multiple"]))
                     be_off_ticks = int(config["break_even_offset_ticks"])
                     min_tick = analyzer.get_min_tick_size()

                     price_diff = current_price - entry_price if pos_side == 'long' else entry_price - current_price
                     profit_atr = price_diff / current_atr if current_atr > 0 else 0
                     lg.debug(f"BE Check: ProfitATRs={profit_atr:.2f}, TargetATRs={be_trig_atr}")

                     if profit_atr >= be_trig_atr:
                          tick_off = min_tick * be_off_ticks
                          be_sl = (entry_price + tick_off).quantize(min_tick, ROUND_UP) if pos_side=='long' else \
                                  (entry_price - tick_off).quantize(min_tick, ROUND_DOWN)
                          assert be_sl > 0

                          curr_sl = open_position.get('stopLossPriceDecimal')
                          update_needed = False
                          if curr_sl is None: update_needed = True; lg.info("BE triggered: No current SL.")
                          elif pos_side=='long' and be_sl > curr_sl: update_needed = True; lg.info(f"BE triggered: Target {be_sl} > Current {curr_sl}.")
                          elif pos_side=='short' and be_sl < curr_sl: update_needed = True; lg.info(f"BE triggered: Target {be_sl} < Current {curr_sl}.")
                          else: lg.debug(f"BE triggered but current SL {curr_sl} already adequate.")

                          if update_needed:
                               lg.warning(f"{NEON_PURPLE}*** Moving SL to Break-Even ({symbol} @ {be_sl}) ***{RESET}")
                               curr_tp = open_position.get('takeProfitPriceDecimal')
                               success = _set_position_protection(exchange, symbol, market_info, open_position, lg, be_sl, curr_tp)
                               if success: lg.info(f"{NEON_GREEN}Break-Even SL updated.{RESET}")
                               else: lg.error(f"{NEON_RED}Failed updating Break-Even SL.{RESET}")
                     else: lg.debug("BE Profit target not reached.")
                 except AssertionError as ae: lg.warning(f"BE Check skipped: Invalid data ({ae})")
                 except Exception as be_err: lg.error(f"Error during BE check: {be_err}", exc_info=True)
            elif is_tsl_active: lg.debug("BE check skipped: TSL active.")
            else: lg.debug("BE check skipped: Disabled in config.")

            # Placeholder for other management (e.g., TSL updates if needed)

    # --- Error Handling for the entire cycle ---
    except ValueError as data_err: # Catch data/config related errors
        lg.error(f"{NEON_RED}Data/Config Error ({symbol}): {data_err}. Skipping cycle.{RESET}")
    except ccxt.AuthenticationError as auth_err: # Catch critical auth errors
         lg.critical(f"{NEON_RED}CRITICAL: Authentication Failed: {auth_err}. Stopping bot.{RESET}")
         raise SystemExit("Authentication Failed") # Stop the bot
    except (ccxt.NetworkError, ccxt.RequestTimeout, ccxt.ExchangeNotAvailable, ccxt.DDoSProtection) as net_err:
         lg.error(f"{NEON_RED}Network/Exchange Availability Error ({symbol}): {net_err}. Skipping cycle.{RESET}")
    except Exception as cycle_err: # Catch unexpected errors
        lg.error(f"{NEON_RED}Unexpected Cycle Error ({symbol}): {cycle_err}{RESET}", exc_info=True)
        # Decide behavior: continue or stop? For now, just log and continue.

    finally:
        # --- Cycle End Logging ---
        cycle_end_time = time.monotonic()
        lg.debug(f"---== Analysis Cycle End ({symbol}, {cycle_end_time - cycle_start_time:.2f}s) ==---")


def main() -> None:
    """Main function to initialize the bot and run the analysis loop."""
    global CONFIG, QUOTE_CURRENCY # Allow modification of globals

    # Setup initial logger
    init_logger = setup_logger("ScalpXRX_Init")
    init_logger.info(f"--- Starting ScalpXRX Bot ({datetime.now(TIMEZONE).strftime('%Y-%m-%d %H:%M:%S %Z')}) ---")

    try:
        CONFIG = load_config(CONFIG_FILE)
        QUOTE_CURRENCY = CONFIG.get("quote_currency", "USDT")
        TARGET_SYMBOL = CONFIG.get("symbol")

        if not TARGET_SYMBOL:
            init_logger.critical("CRITICAL: 'symbol' not defined in config.json. Exiting.")
            return

        # Setup logger specific to the target symbol
        symbol_logger_name = f"ScalpXRX_{TARGET_SYMBOL.replace('/', '_').replace(':', '-')}"
        main_logger = setup_logger(symbol_logger_name)
        main_logger.info(f"Logging initialized for symbol: {TARGET_SYMBOL}")
        main_logger.info(f"Config loaded. Quote: {QUOTE_CURRENCY}, Interval: {CONFIG['interval']}")
        main_logger.info(f"Versions: CCXT={ccxt.__version__}, Pandas={pd.__version__}, PandasTA={getattr(ta, 'version', 'N/A')}")


        # --- Trading Enabled Warning ---
        if CONFIG.get("enable_trading"):
            main_logger.warning(f"{NEON_YELLOW}!!! LIVE TRADING IS ENABLED !!!{RESET}")
            env_type = "SANDBOX (Testnet)" if CONFIG.get("use_sandbox") else f"{NEON_RED}REAL MONEY"
            main_logger.warning(f"Environment: {env_type}{RESET}")
            risk_pct = CONFIG.get('risk_per_trade', 0) * 100
            lev = CONFIG.get('leverage', 1)
            main_logger.warning(f"Settings: Risk/Trade={risk_pct:.2f}%, Leverage={lev}x")
            time.sleep(3) # Pause for user to see warning
        else:
            main_logger.info("Trading is disabled in config. Running in analysis-only mode.")

        # --- Initialize Exchange ---
        exchange = initialize_exchange(main_logger)
        if not exchange:
            main_logger.critical("Failed to initialize exchange. Exiting.")
            return

        # --- Main Loop ---
        main_logger.info(f"Starting main analysis loop for {TARGET_SYMBOL}...")
        while True:
            try:
                analyze_and_trade_symbol(exchange, TARGET_SYMBOL, CONFIG, main_logger)
            except SystemExit as e: # Catch SystemExit specifically for clean shutdown
                 main_logger.critical(f"SystemExit triggered: {e}. Shutting down.")
                 break
            except Exception as loop_err:
                # Catch unexpected errors from analyze_and_trade_symbol if they weren't caught internally
                main_logger.error(f"{NEON_RED}Error in main loop iteration: {loop_err}{RESET}", exc_info=True)
                # Decide whether to continue or stop based on the error

            # Delay before next cycle
            main_logger.debug(f"Waiting {LOOP_DELAY_SECONDS} seconds before next cycle...")
            time.sleep(LOOP_DELAY_SECONDS)

    except KeyboardInterrupt:
        init_logger.info("KeyboardInterrupt received. Shutting down gracefully...")
    except Exception as startup_err:
        init_logger.critical(f"Critical error during startup: {startup_err}", exc_info=True)
    finally:
        init_logger.info(f"--- ScalpXRX Bot Shutdown ({datetime.now(TIMEZONE).strftime('%Y-%m-%d %H:%M:%S %Z')}) ---")
        logging.shutdown() # Ensure all logs are flushed


if __name__ == "__main__":
    main()
```

```python
# sx.py
# Enhanced and Upgraded Scalping Bot Framework
# Derived from xrscalper.py, focusing on robust execution, error handling,
# advanced position management (BE, TSL), and Bybit V5 compatibility.

import hashlib
import hmac
import json
import logging
import math
import os
import time
from datetime import datetime, timedelta, timezone
from decimal import ROUND_DOWN, ROUND_UP, Decimal, InvalidOperation, getcontext
from logging.handlers import RotatingFileHandler
from typing import Any, Dict, List, Optional, Tuple, Union

import ccxt
import numpy as np
import pandas as pd
import pandas_ta as ta # Import pandas_ta
import requests
from colorama import Fore, Style, init
from dotenv import load_dotenv
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from zoneinfo import ZoneInfo

# Initialize colorama and set Decimal precision
getcontext().prec = 36 # Increased precision for complex calculations
init(autoreset=True)
load_dotenv()

# Neon Color Scheme
NEON_GREEN = Fore.LIGHTGREEN_EX
NEON_BLUE = Fore.CYAN
NEON_PURPLE = Fore.MAGENTA
NEON_YELLOW = Fore.YELLOW
NEON_RED = Fore.LIGHTRED_EX
NEON_CYAN = Fore.CYAN
RESET = Style.RESET_ALL

# --- Constants ---
API_KEY = os.getenv("BYBIT_API_KEY")
API_SECRET = os.getenv("BYBIT_API_SECRET")
if not API_KEY or not API_SECRET:
    raise ValueError("BYBIT_API_KEY and BYBIT_API_SECRET must be set in .env")

CONFIG_FILE = "config.json"
LOG_DIRECTORY = "bot_logs"
# Timezone for logging and display
TIMEZONE = ZoneInfo("America/Chicago") # Adjust as needed
MAX_API_RETRIES = 5 # Max retries for recoverable API errors
RETRY_DELAY_SECONDS = 7 # Increased delay between retries
VALID_INTERVALS = ["1", "3", "5", "15", "30", "60", "120", "240", "D", "W", "M"]
CCXT_INTERVAL_MAP = { # Map our intervals to ccxt's expected format
    "1": "1m", "3": "3m", "5": "5m", "15": "15m", "30": "30m",
    "60": "1h", "120": "2h", "240": "4h", "D": "1d", "W": "1w", "M": "1M"
}
RETRY_ERROR_CODES = [429, 500, 502, 503, 504] # HTTP status codes considered retryable
# Default indicator periods (can be overridden by config.json)
DEFAULT_ATR_PERIOD = 14
DEFAULT_CCI_WINDOW = 20
DEFAULT_WILLIAMS_R_WINDOW = 14
DEFAULT_MFI_WINDOW = 14
DEFAULT_STOCH_RSI_WINDOW = 14
DEFAULT_STOCH_WINDOW = 12
DEFAULT_K_WINDOW = 3
DEFAULT_D_WINDOW = 3
DEFAULT_RSI_WINDOW = 14
DEFAULT_BOLLINGER_BANDS_PERIOD = 20
DEFAULT_BOLLINGER_BANDS_STD_DEV = 2.0
DEFAULT_SMA_10_WINDOW = 10
DEFAULT_EMA_SHORT_PERIOD = 9
DEFAULT_EMA_LONG_PERIOD = 21
DEFAULT_MOMENTUM_PERIOD = 7
DEFAULT_VOLUME_MA_PERIOD = 15
DEFAULT_FIB_WINDOW = 50
DEFAULT_PSAR_AF = 0.02
DEFAULT_PSAR_MAX_AF = 0.2

FIB_LEVELS = [0.0, 0.236, 0.382, 0.5, 0.618, 0.786, 1.0] # Standard Fibonacci levels
LOOP_DELAY_SECONDS = 10 # Time between the end of one cycle and the start of the next
POSITION_CONFIRM_DELAY_SECONDS = 10 # Increased wait time after placing order before confirming position
# QUOTE_CURRENCY dynamically loaded from config

os.makedirs(LOG_DIRECTORY, exist_ok=True)

class SensitiveFormatter(logging.Formatter):
    """Formatter to redact sensitive information (API keys) from logs."""
    def format(self, record: logging.LogRecord) -> str:
        msg = super().format(record)
        if API_KEY:
            msg = msg.replace(API_KEY, "***API_KEY***")
        if API_SECRET:
            msg = msg.replace(API_SECRET, "***API_SECRET***")
        return msg

def load_config(filepath: str) -> Dict[str, Any]:
    """Load configuration from JSON file, creating default if not found,
       and ensuring all default keys are present with validation."""
    default_config = {
        "symbol": "BTC/USDT:USDT", # Specify the full symbol including contract type if needed
        "interval": "5",
        "retry_delay": RETRY_DELAY_SECONDS,
        "atr_period": DEFAULT_ATR_PERIOD,
        "ema_short_period": DEFAULT_EMA_SHORT_PERIOD,
        "ema_long_period": DEFAULT_EMA_LONG_PERIOD,
        "rsi_period": DEFAULT_RSI_WINDOW,
        "bollinger_bands_period": DEFAULT_BOLLINGER_BANDS_PERIOD,
        "bollinger_bands_std_dev": DEFAULT_BOLLINGER_BANDS_STD_DEV,
        "cci_window": DEFAULT_CCI_WINDOW,
        "williams_r_window": DEFAULT_WILLIAMS_R_WINDOW,
        "mfi_window": DEFAULT_MFI_WINDOW,
        "stoch_rsi_window": DEFAULT_STOCH_RSI_WINDOW,
        "stoch_rsi_rsi_window": DEFAULT_STOCH_WINDOW,
        "stoch_rsi_k": DEFAULT_K_WINDOW,
        "stoch_rsi_d": DEFAULT_D_WINDOW,
        "psar_af": DEFAULT_PSAR_AF,
        "psar_max_af": DEFAULT_PSAR_MAX_AF,
        "sma_10_window": DEFAULT_SMA_10_WINDOW,
        "momentum_period": DEFAULT_MOMENTUM_PERIOD,
        "volume_ma_period": DEFAULT_VOLUME_MA_PERIOD,
        "orderbook_limit": 25,
        "signal_score_threshold": 1.5,
        "stoch_rsi_oversold_threshold": 25,
        "stoch_rsi_overbought_threshold": 75,
        "stop_loss_multiple": 1.8, # ATR multiple for initial SL (used for sizing)
        "take_profit_multiple": 0.7, # ATR multiple for TP
        "volume_confirmation_multiplier": 1.5,
        "scalping_signal_threshold": 2.5,
        "fibonacci_window": DEFAULT_FIB_WINDOW,
        "enable_trading": False,
        "use_sandbox": True,
        "risk_per_trade": 0.01, # e.g., 1%
        "leverage": 20,
        "max_concurrent_positions": 1, # Per symbol managed by this instance
        "quote_currency": "USDT",
        "entry_order_type": "market", # "market" or "limit"
        "limit_order_offset_buy": 0.0005, # Percentage offset (0.05%)
        "limit_order_offset_sell": 0.0005, # Percentage offset (0.05%)
        "enable_trailing_stop": True,
        "trailing_stop_callback_rate": 0.005, # e.g., 0.5% trail distance
        "trailing_stop_activation_percentage": 0.003, # e.g., Activate when profit reaches 0.3%
        "enable_break_even": True,
        "break_even_trigger_atr_multiple": 1.0,
        "break_even_offset_ticks": 2, # Place BE SL X ticks beyond entry
        "position_confirm_delay_seconds": POSITION_CONFIRM_DELAY_SECONDS,
        "time_based_exit_minutes": None, # e.g., 60 to exit after 1 hour
        "indicators": {
            "ema_alignment": True, "momentum": True, "volume_confirmation": True,
            "stoch_rsi": True, "rsi": True, "bollinger_bands": True, "vwap": True,
            "cci": True, "wr": True, "psar": True, "sma_10": True, "mfi": True,
            "orderbook": True,
        },
        "weight_sets": {
            "scalping": { # Example weighting for a fast scalping strategy
                "ema_alignment": 0.2, "momentum": 0.3, "volume_confirmation": 0.2,
                "stoch_rsi": 0.6, "rsi": 0.2, "bollinger_bands": 0.3, "vwap": 0.4,
                "cci": 0.3, "wr": 0.3, "psar": 0.2, "sma_10": 0.1, "mfi": 0.2, "orderbook": 0.15,
            },
            "default": { # A more balanced weighting strategy
                "ema_alignment": 0.3, "momentum": 0.2, "volume_confirmation": 0.1,
                "stoch_rsi": 0.4, "rsi": 0.3, "bollinger_bands": 0.2, "vwap": 0.3,
                "cci": 0.2, "wr": 0.2, "psar": 0.3, "sma_10": 0.1, "mfi": 0.2, "orderbook": 0.1,
            }
        },
        "active_weight_set": "default"
    }

    config = default_config.copy()
    if os.path.exists(filepath):
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                loaded_config = json.load(f)
            config = _merge_configs(loaded_config, default_config)
            print(f"{NEON_GREEN}Loaded configuration from {filepath}{RESET}")
        except (json.JSONDecodeError, IOError) as e:
            print(f"{NEON_RED}Error loading config file {filepath}: {e}. Using default config.{RESET}")
            # Optionally recreate default if load failed badly
            try:
                with open(filepath, "w", encoding="utf-8") as f_write:
                    json.dump(default_config, f_write, indent=4)
                print(f"{NEON_YELLOW}Recreated default config file: {filepath}{RESET}")
            except IOError as e_create:
                print(f"{NEON_RED}Error recreating default config file: {e_create}{RESET}")
    else:
        print(f"{NEON_YELLOW}Config file not found. Creating default config at {filepath}{RESET}")
        try:
            with open(filepath, "w", encoding="utf-8") as f:
                json.dump(default_config, f, indent=4)
            config = default_config
        except IOError as e:
            print(f"{NEON_RED}Error creating default config file {filepath}: {e}{RESET}")
            # Continue with in-memory default config

    # --- Validation ---
    updated = False
    if config.get("interval") not in VALID_INTERVALS:
        print(f"{NEON_RED}Invalid interval '{config.get('interval')}' in config. Resetting to default '{default_config['interval']}'.{RESET}")
        config["interval"] = default_config["interval"]
        updated = True
    if config.get("entry_order_type") not in ["market", "limit"]:
        print(f"{NEON_RED}Invalid entry_order_type '{config.get('entry_order_type')}' in config. Resetting to 'market'.{RESET}")
        config["entry_order_type"] = "market"
        updated = True
    if config.get("active_weight_set") not in config.get("weight_sets", {}):
         print(f"{NEON_RED}Active weight set '{config.get('active_weight_set')}' not found in 'weight_sets'. Resetting to 'default'.{RESET}")
         config["active_weight_set"] = "default" # Assume 'default' exists
         updated = True
    # Add more validation (numeric ranges, types) as needed
    for key in ["risk_per_trade", "leverage", "stop_loss_multiple", "take_profit_multiple",
                "trailing_stop_callback_rate", "trailing_stop_activation_percentage",
                "break_even_trigger_atr_multiple", "break_even_offset_ticks"]:
        try:
             val = config[key]
             # Check basic numeric types and ranges
             if key == "risk_per_trade" and not (0 < float(val) < 1): raise ValueError("must be between 0 and 1")
             if key == "leverage" and not (int(val) >= 1): raise ValueError("must be >= 1")
             if key in ["stop_loss_multiple", "take_profit_multiple", "break_even_trigger_atr_multiple"] and not (float(val) > 0): raise ValueError("must be > 0")
             if key in ["trailing_stop_callback_rate", "trailing_stop_activation_percentage"] and not (float(val) >= 0): raise ValueError("must be >= 0")
             if key == "break_even_offset_ticks" and not (int(val) >= 0): raise ValueError("must be >= 0")
        except (ValueError, TypeError, KeyError, InvalidOperation) as e:
            print(f"{NEON_RED}Invalid value for '{key}' ({config.get(key)}): {e}. Resetting to default '{default_config[key]}'.{RESET}")
            config[key] = default_config[key]
            updated = True

    # Ensure symbol exists
    if not config.get("symbol"):
        print(f"{NEON_RED}CRITICAL: 'symbol' is missing or empty in the configuration. Please define it.{RESET}")
        config["symbol"] = default_config["symbol"] # Set default, but it might not be what user wants
        updated = True


    # If config was updated due to invalid values, save it back
    if updated:
        try:
            with open(filepath, "w", encoding="utf-8") as f_write:
                json.dump(config, f_write, indent=4)
            print(f"{NEON_YELLOW}Updated config file {filepath} with corrected/default values.{RESET}")
        except IOError as e:
            print(f"{NEON_RED}Error writing updated config file {filepath}: {e}{RESET}")

    return config

def _merge_configs(loaded_config: Dict, default_config: Dict) -> Dict:
    """Recursively merges loaded config with defaults, ensuring all keys exist."""
    merged = default_config.copy()
    for key, value in loaded_config.items():
        if isinstance(value, dict) and isinstance(merged.get(key), dict):
            merged[key] = _merge_configs(value, merged[key])
        else:
            # Only update if the key exists in the loaded config
            # This preserves defaults for keys missing in the file
            merged[key] = value
    return merged

def setup_logger(name: str, level: int = logging.DEBUG) -> logging.Logger:
    """Sets up a logger with file and console handlers."""
    logger = logging.getLogger(name)
    # Prevent duplicate handlers if called multiple times
    if logger.hasHandlers():
        # Clear existing handlers to ensure clean setup
        for handler in logger.handlers[:]:
            handler.close()
            logger.removeHandler(handler)
        # return logger # Option: return existing logger

    logger.setLevel(level)

    # File Handler (Rotating)
    log_filename = os.path.join(LOG_DIRECTORY, f"{name}.log")
    try:
        file_handler = RotatingFileHandler(
            log_filename, maxBytes=10 * 1024 * 1024, backupCount=5, encoding='utf-8'
        )
        file_formatter = SensitiveFormatter("%(asctime)s - %(levelname)s - [%(name)s:%(lineno)d] - %(message)s")
        file_handler.setFormatter(file_formatter)
        file_handler.setLevel(logging.DEBUG) # Log all levels to file
        logger.addHandler(file_handler)
    except Exception as e:
        print(f"Error setting up file logger {log_filename}: {e}")

    # Console Handler
    stream_handler = logging.StreamHandler()
    stream_formatter = SensitiveFormatter(
        f"{NEON_BLUE}%(asctime)s{RESET} - {NEON_YELLOW}%(levelname)-8s{RESET} - {NEON_PURPLE}[%(name)s]{RESET} - %(message)s",
        datefmt='%Y-%m-%d %H:%M:%S %Z' # Include Timezone
    )
    # Use UTC for internal consistency, display local via timezone info in formatter
    stream_formatter.converter = time.gmtime # Log records in UTC internally
    # formatter's datefmt includes %Z which uses TIMEZONE for display
    # stream_formatter.converter = lambda *args: datetime.now(TIMEZONE).timetuple() # Alt: Use local time directly

    stream_handler.setFormatter(stream_formatter)
    # Set console level (e.g., INFO for less verbosity, DEBUG for more)
    console_log_level = logging.INFO
    stream_handler.setLevel(console_log_level)
    logger.addHandler(stream_handler)

    logger.propagate = False # Prevent duplicate messages in parent loggers
    return logger

# --- CCXT Exchange Setup ---
def initialize_exchange(logger: logging.Logger) -> Optional[ccxt.Exchange]:
    """Initializes the CCXT Bybit exchange object with enhanced error handling."""
    lg = logger
    try:
        exchange_options = {
            'apiKey': API_KEY,
            'secret': API_SECRET,
            'enableRateLimit': True, # Use CCXT's built-in rate limiter
            'rateLimit': 150, # Milliseconds between requests (adjust based on Bybit limits, e.g., 100ms for 10/s)
            'options': {
                'defaultType': 'linear', # Assume linear for Bybit V5
                'adjustForTimeDifference': True,
                # Increased timeouts
                'fetchTickerTimeout': 15000, # 15s
                'fetchBalanceTimeout': 20000, # 20s
                'createOrderTimeout': 25000, # 25s
                'cancelOrderTimeout': 20000, # 20s
                'fetchPositionsTimeout': 20000, # 20s
                'fetchOHLCVTimeout': 20000, # 20s
                # Bybit V5 specific options might be needed here if issues persist
                # 'recvWindow': 10000 # Example: Increase recvWindow if needed
                # Add user agent to identify bot potentially
                'user-agent': 'ScalpXRX Bot v1.0',
            }
        }

        # Default to Bybit, can be made dynamic if needed
        exchange_id = "bybit"
        exchange_class = getattr(ccxt, exchange_id)
        exchange = exchange_class(exchange_options)

        if CONFIG.get('use_sandbox'):
            lg.warning(f"{NEON_YELLOW}USING SANDBOX MODE (Testnet){RESET}")
            try:
                exchange.set_sandbox_mode(True)
                lg.info(f"Sandbox mode explicitly enabled for {exchange.id}.")
            except AttributeError:
                lg.warning(f"{exchange.id} does not support set_sandbox_mode via ccxt. Ensuring API keys are for Testnet.")
                # Attempt to set URLs manually for Bybit if needed
                if exchange.id == 'bybit':
                    exchange.urls['api'] = 'https://api-testnet.bybit.com'
                    lg.info("Manually set Bybit API URL to Testnet.")
            except Exception as e:
                lg.error(f"Error enabling sandbox mode: {e}")

        lg.info(f"Initializing {exchange.id}...")
        # Test connection and API keys by fetching balance early
        # This helps catch auth/permission issues before loading markets
        account_type_to_test = 'CONTRACT' # For Bybit V5, try CONTRACT or UNIFIED
        lg.info(f"Attempting initial balance fetch (Account Type: {account_type_to_test})...")
        try:
            params = {'type': account_type_to_test} if exchange.id == 'bybit' else {}
            # Use safe_api_call for this initial fetch as well
            balance = safe_api_call(exchange.fetch_balance, lg, params=params)

            if balance: # Check if call succeeded
                quote_curr = CONFIG.get("quote_currency", "USDT")
                available_quote = balance.get(quote_curr, {}).get('free', 'N/A')
                lg.info(f"{NEON_GREEN}Successfully connected and fetched initial balance.{RESET} (Example: {quote_curr} available: {available_quote})")
            else:
                 lg.warning(f"{NEON_YELLOW}Initial balance fetch returned no data. Proceeding, but check connection/permissions.{RESET}")
                 # Decide if this should be a fatal error
                 # return None

        except ccxt.AuthenticationError as auth_err:
             lg.error(f"{NEON_RED}CCXT Authentication Error during initial balance fetch: {auth_err}{RESET}")
             lg.error(f"{NEON_RED}>> Ensure API keys are correct, have necessary permissions (Read, Trade), match account type (Real/Testnet), and IP whitelist is correct.{RESET}")
             return None
        except ccxt.ExchangeError as balance_err:
             # If specific account type failed, try default
             lg.warning(f"{NEON_YELLOW}Exchange error during initial balance fetch ({account_type_to_test}): {balance_err}. Trying default fetch...{RESET}")
             try:
                  balance = safe_api_call(exchange.fetch_balance, lg)
                  if balance:
                       quote_curr = CONFIG.get("quote_currency", "USDT")
                       available_quote = balance.get(quote_curr, {}).get('free', 'N/A')
                       lg.info(f"{NEON_GREEN}Successfully fetched balance using default parameters.{RESET} (Example: {quote_curr} available: {available_quote})")
                  else:
                       lg.warning(f"{NEON_YELLOW}Default balance fetch also returned no data.{RESET}")
             except Exception as fallback_err:
                  lg.warning(f"{NEON_YELLOW}Default balance fetch also failed: {fallback_err}. Check API permissions/account type/network.{RESET}")
        except Exception as balance_err:
             # Catch errors from safe_api_call like max retries or unexpected errors
             lg.warning(f"{NEON_YELLOW}Could not perform initial balance fetch after retries or due to error: {balance_err}. Check logs. Proceeding cautiously.{RESET}")


        # Load markets after initial connection test
        lg.info(f"Loading markets for {exchange.id}...")
        try:
             safe_api_call(exchange.load_markets, lg, reload=True) # Force reload
             lg.info(f"Markets loaded successfully for {exchange.id}.")
        except Exception as market_err:
             lg.error(f"{NEON_RED}Failed to load markets after retries: {market_err}. Cannot operate without market data.{RESET}")
             return None

        lg.info(f"CCXT exchange initialized ({exchange.id}). Sandbox: {CONFIG.get('use_sandbox')}")
        return exchange

    except ccxt.AuthenticationError as e: # Catch auth errors during class instantiation
        lg.error(f"{NEON_RED}CCXT Authentication Error during initialization: {e}{RESET}")
        lg.error(f"{NEON_RED}>> Check API Key/Secret format and validity in your .env file.{RESET}")
    except ccxt.ExchangeError as e:
        lg.error(f"{NEON_RED}CCXT Exchange Error initializing: {e}{RESET}")
    except ccxt.NetworkError as e:
        lg.error(f"{NEON_RED}CCXT Network Error initializing: {e}{RESET}")
    except Exception as e:
        lg.error(f"{NEON_RED}Failed to initialize CCXT exchange: {e}{RESET}", exc_info=True)

    return None

# --- API Call Wrapper with Retries ---
def safe_api_call(func, logger: logging.Logger, *args, **kwargs):
    """Wraps an API call with retry logic for network/rate limit errors."""
    lg = logger
    attempts = 0
    last_exception = None
    while attempts <= MAX_API_RETRIES:
        try:
            result = func(*args, **kwargs)
            return result # Success
        except (ccxt.NetworkError, ccxt.RequestTimeout, requests.exceptions.ConnectionError, requests.exceptions.Timeout, ccxt.ExchangeNotAvailable, ccxt.DDoSProtection) as e:
            # Group common retryable network/server/rate limit issues
            last_exception = e
            wait_time = RETRY_DELAY_SECONDS * (1.5 ** attempts) # Exponential backoff
            lg.warning(f"{NEON_YELLOW}Retryable error in {func.__name__}: {type(e).__name__}. Waiting {wait_time:.1f}s (Attempt {attempts+1}/{MAX_API_RETRIES}). Error: {e}{RESET}")
            time.sleep(wait_time)
        except ccxt.RateLimitExceeded as e: # Explicit handling for potentially longer waits
            last_exception = e
            # Extract wait time from error if possible (e.g., from headers)
            wait_time_header = getattr(e, 'retry_after', None)
            wait_time = RETRY_DELAY_SECONDS * (2 ** attempts) # Default exponential backoff
            if wait_time_header:
                try: wait_time = max(wait_time, float(wait_time_header) + 0.5) # Use header value if longer
                except: pass
            lg.warning(f"{NEON_YELLOW}Rate limit exceeded in {func.__name__}. Waiting {wait_time:.1f}s (Attempt {attempts+1}/{MAX_API_RETRIES}). Error: {e}{RESET}")
            time.sleep(wait_time)
        except ccxt.AuthenticationError as e:
             # Don't retry auth errors, they need fixing
             lg.error(f"{NEON_RED}Authentication Error in {func.__name__}: {e}. Aborting call.{RESET}")
             raise e # Re-raise to be caught by caller
        except ccxt.ExchangeError as e:
            last_exception = e
            # Decide if specific exchange errors are retryable
            # Example: Bybit internal server error (e.g., code 10001) might be temporary
            bybit_retry_codes = [
                10001, # Internal server error
                10006, # Generic: Too many visits
                # Add other potentially transient error codes based on Bybit docs/experience
            ]
            exchange_code = getattr(e, 'code', None)
            err_str = str(e).lower()
            # Check if code is in retry list or if message suggests temporary issue
            if exchange_code in bybit_retry_codes or "internal server error" in err_str or "request validation failed" in err_str: # Example message check
                 wait_time = RETRY_DELAY_SECONDS * (1.5 ** attempts)
                 lg.warning(f"{NEON_YELLOW}Potentially retryable exchange error in {func.__name__}: {e} (Code: {exchange_code}). Waiting {wait_time:.1f}s (Attempt {attempts+1}/{MAX_API_RETRIES})...{RESET}")
                 time.sleep(wait_time)
            else:
                 # Non-retryable ExchangeError
                 lg.error(f"{NEON_RED}Non-retryable Exchange Error in {func.__name__}: {e} (Code: {exchange_code}){RESET}")
                 raise e # Re-raise
        except Exception as e:
            # Unexpected errors - typically don't retry these unless specifically known
            last_exception = e
            lg.error(f"{NEON_RED}Unexpected error in {func.__name__}: {e}{RESET}", exc_info=True)
            raise e # Re-raise

        attempts += 1

    lg.error(f"{NEON_RED}Max retries ({MAX_API_RETRIES}) exceeded for {func.__name__}.{RESET}")
    # Raise the last exception encountered after exhausting retries
    if last_exception:
        raise last_exception
    else:
        # Should not happen if loop was entered, but safeguard
        raise ccxt.RequestTimeout(f"Max retries exceeded for {func.__name__} (no specific exception captured)")


# --- CCXT Data Fetching (Using safe_api_call) ---
def fetch_current_price_ccxt(exchange: ccxt.Exchange, symbol: str, logger: logging.Logger) -> Optional[Decimal]:
    """Fetch the current price of a trading symbol using CCXT ticker with fallbacks and retries."""
    lg = logger
    try:
        ticker = safe_api_call(exchange.fetch_ticker, lg, symbol)
        if not ticker:
            # safe_api_call already logged the error after retries
            return None

        lg.debug(f"Ticker data for {symbol}: {ticker}")
        price = None
        # Prioritize 'last', then mid-price, then ask/bid
        last_price = ticker.get('last')
        bid_price = ticker.get('bid')
        ask_price = ticker.get('ask')

        # Robust Decimal conversion helper
        def to_decimal(value) -> Optional[Decimal]:
            if value is None: return None
            try:
                d = Decimal(str(value))
                return d if d.is_finite() and d > 0 else None # Ensure positive finite price
            except (InvalidOperation, ValueError, TypeError):
                lg.warning(f"Invalid price format encountered: {value}")
                return None

        p_last = to_decimal(last_price)
        p_bid = to_decimal(bid_price)
        p_ask = to_decimal(ask_price)

        # Determine price with priority
        if p_last:
            price = p_last; lg.debug(f"Using 'last' price: {price}")
        elif p_bid and p_ask:
            price = (p_bid + p_ask) / 2; lg.debug(f"Using bid/ask midpoint: {price}")
        elif p_ask: # Use ask if only ask is valid
            price = p_ask; lg.warning(f"Using 'ask' price fallback (bid invalid/missing): {price}")
        elif p_bid: # Use bid if only bid is valid
            price = p_bid; lg.warning(f"Using 'bid' price fallback (ask invalid/missing): {price}")

        # Final validation
        if price is not None and price.is_finite() and price > 0:
            return price
        else:
            lg.error(f"{NEON_RED}Failed to extract a valid price from ticker data for {symbol}. Ticker: {ticker}{RESET}")
            return None

    except Exception as e:
        # Catch errors raised by safe_api_call (like AuthError or max retries exceeded) or parsing issues
        lg.error(f"{NEON_RED}Error fetching current price for {symbol}: {e}{RESET}", exc_info=False) # Keep log concise
        return None

def fetch_klines_ccxt(exchange: ccxt.Exchange, symbol: str, timeframe: str, limit: int = 250, logger: logging.Logger = None) -> pd.DataFrame:
    """Fetch OHLCV kline data using CCXT with retries and robust validation."""
    lg = logger or logging.getLogger(__name__)
    if not exchange.has['fetchOHLCV']:
        lg.error(f"Exchange {exchange.id} does not support fetchOHLCV.")
        return pd.DataFrame()

    try:
        # Use safe_api_call to handle retries
        ohlcv = safe_api_call(exchange.fetch_ohlcv, lg, symbol, timeframe=timeframe, limit=limit)

        if ohlcv is None or not isinstance(ohlcv, list) or len(ohlcv) == 0:
            # Error logged by safe_api_call if it failed
            if ohlcv is not None: # Log only if it returned empty list/None without error
                lg.warning(f"{NEON_YELLOW}No valid kline data returned for {symbol} {timeframe}.{RESET}")
            return pd.DataFrame()

        # Process the data into a pandas DataFrame
        df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])

        if df.empty:
            lg.warning(f"Kline data DataFrame is empty for {symbol} {timeframe}.")
            return df

        # Convert timestamp to datetime objects (UTC), coerce errors
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms', errors='coerce', utc=True)
        df.dropna(subset=['timestamp'], inplace=True)
        df.set_index('timestamp', inplace=True)

        # Convert price/volume columns to numeric Decimal, coercing errors
        for col in ['open', 'high', 'low', 'close', 'volume']:
             try:
                  # Apply robust conversion to Decimal, handle empty strings
                  df[col] = df[col].apply(lambda x: Decimal(str(x)) if pd.notna(x) and str(x).strip() != '' else Decimal('NaN'))
             except (TypeError, ValueError, InvalidOperation) as conv_err:
                  lg.warning(f"Could not convert column '{col}' to Decimal, attempting numeric fallback: {conv_err}")
                  df[col] = pd.to_numeric(df[col], errors='coerce') # Fallback

        # Data Cleaning: Drop rows with NaN in essential price columns or zero/non-finite close price
        initial_len = len(df)
        # Check type before comparison
        close_col = df['close']
        df.dropna(subset=['open', 'high', 'low', 'close'], inplace=True)

        # Ensure close price is positive and finite
        if not df.empty:
            if isinstance(close_col.iloc[0], Decimal):
                df = df[close_col.apply(lambda x: x.is_finite() and x > 0)]
            elif pd.api.types.is_numeric_dtype(close_col.dtype): # Check if float/int
                df = df[np.isfinite(close_col) & (close_col > 0)]

        rows_dropped = initial_len - len(df)
        if rows_dropped > 0:
            lg.debug(f"Dropped {rows_dropped} rows with NaN/invalid price data for {symbol}.")

        if df.empty:
            lg.warning(f"Kline data for {symbol} {timeframe} empty after cleaning.")
            return pd.DataFrame()

        # Sort by timestamp index and remove duplicates
        df.sort_index(inplace=True)
        df = df[~df.index.duplicated(keep='last')]

        lg.info(f"Successfully fetched and processed {len(df)} klines for {symbol} {timeframe}")
        return df

    except Exception as e:
        # Catch errors from safe_api_call or during processing
        lg.error(f"{NEON_RED}Error fetching/processing klines for {symbol}: {e}{RESET}", exc_info=True)
        return pd.DataFrame()


def fetch_orderbook_ccxt(exchange: ccxt.Exchange, symbol: str, limit: int, logger: logging.Logger) -> Optional[Dict]:
    """Fetch orderbook data using ccxt with retries and validation."""
    lg = logger
    if not exchange.has['fetchOrderBook']:
        lg.error(f"Exchange {exchange.id} does not support fetchOrderBook.")
        return None

    try:
        orderbook = safe_api_call(exchange.fetch_order_book, lg, symbol, limit=limit)

        if not orderbook: # Error logged by safe_api_call if failed
            return None
        # Validate structure
        if not isinstance(orderbook, dict) or 'bids' not in orderbook or 'asks' not in orderbook or \
           not isinstance(orderbook['bids'], list) or not isinstance(orderbook['asks'], list):
            lg.warning(f"Invalid orderbook structure received for {symbol}. Data: {orderbook}")
            return None

        if not orderbook['bids'] and not orderbook['asks']:
            lg.warning(f"Orderbook received but both bids and asks lists are empty for {symbol}.")
            return orderbook # Return empty but valid book

        # Basic validation of bid/ask entry format
        valid = True
        for side in ['bids', 'asks']:
             if orderbook[side]: # Check first entry if list is not empty
                  entry = orderbook[side][0]
                  if not (isinstance(entry, list) and len(entry) == 2):
                       lg.warning(f"Invalid {side[:-1]} entry format in orderbook: {entry}")
                       valid = False; break
                  try: # Check numeric format (allow float conversion)
                       _ = float(entry[0]); _ = float(entry[1])
                  except (ValueError, TypeError):
                       lg.warning(f"Non-numeric data in {side[:-1]} entry: {entry}")
                       valid = False; break
        if not valid:
             lg.error("Orderbook data format validation failed.")
             return None

        lg.debug(f"Successfully fetched orderbook for {symbol} ({len(orderbook['bids'])} bids, {len(orderbook['asks'])} asks).")
        return orderbook

    except Exception as e:
        # Catch errors raised by safe_api_call or validation
        lg.error(f"{NEON_RED}Error fetching order book for {symbol}: {e}{RESET}", exc_info=False)
        return None

# --- Trading Analyzer Class ---
class TradingAnalyzer:
    """Analyzes trading data using pandas_ta and generates weighted signals."""

    def __init__(
        self,
        df: pd.DataFrame,
        logger: logging.Logger,
        config: Dict[str, Any],
        market_info: Dict[str, Any],
    ) -> None:
        self.df = df # Expects OHLCV columns, potentially Decimal type
        self.logger = logger
        self.config = config
        self.market_info = market_info # Expects dict from get_market_info
        self.symbol = market_info.get('symbol', 'UNKNOWN_SYMBOL')
        self.interval = config.get("interval", "5")
        self.ccxt_interval = CCXT_INTERVAL_MAP.get(self.interval)
        if not self.ccxt_interval:
            # Log error but allow continuation, _calculate_indicators will likely fail
            self.logger.error(f"Invalid interval '{self.interval}' in config for {self.symbol}.")

        # Stores latest calculated indicator values (Decimal for prices/ATR, float for others)
        self.indicator_values: Dict[str, Union[Decimal, float, Any]] = {}
        self.signals: Dict[str, int] = {"BUY": 0, "SELL": 0, "HOLD": 1} # Default HOLD
        self.active_weight_set_name = config.get("active_weight_set", "default")
        self.weights = config.get("weight_sets", {}).get(self.active_weight_set_name, {})
        self.fib_levels_data: Dict[str, Decimal] = {} # Stores calculated fib levels
        self.ta_column_names: Dict[str, Optional[str]] = {} # Maps internal name to actual DataFrame column name

        if not self.weights:
            logger.warning(f"{NEON_YELLOW}Active weight set '{self.active_weight_set_name}' not found or empty for {self.symbol}. Scoring will be zero.{RESET}")
            self.weights = {} # Use empty dict to prevent errors

        # Perform initial calculations only if DataFrame is valid
        if not self.df.empty:
             self._calculate_all_indicators()
             self._update_latest_indicator_values() # Run AFTER indicator calculation
             self.calculate_fibonacci_levels()
        else:
             self.logger.warning("TradingAnalyzer initialized with empty DataFrame. No calculations performed.")


    def _get_ta_col_name(self, base_name: str, result_df: pd.DataFrame) -> Optional[str]:
        """Helper to find the actual column name generated by pandas_ta."""
        # Define expected patterns, potentially using f-strings for dynamic parts
        expected_patterns = {
            "ATR": [f"ATRr_{self.config.get('atr_period', DEFAULT_ATR_PERIOD)}"],
            "EMA_Short": [f"EMA_{self.config.get('ema_short_period', DEFAULT_EMA_SHORT_PERIOD)}"],
            "EMA_Long": [f"EMA_{self.config.get('ema_long_period', DEFAULT_EMA_LONG_PERIOD)}"],
            "Momentum": [f"MOM_{self.config.get('momentum_period', DEFAULT_MOMENTUM_PERIOD)}"],
            # CCI often includes the constant (e.g., 100.0) which pandas_ta adds
            "CCI": [f"CCI_{self.config.get('cci_window', DEFAULT_CCI_WINDOW)}"],
            "Williams_R": [f"WILLR_{self.config.get('williams_r_window', DEFAULT_WILLIAMS_R_WINDOW)}"],
            "MFI": [f"MFI_{self.config.get('mfi_window', DEFAULT_MFI_WINDOW)}"],
            "VWAP": ["VWAP_D"], # Default pandas_ta VWAP often daily anchored
            "PSAR_long": [f"PSARl_{self.config.get('psar_af', DEFAULT_PSAR_AF)}_{self.config.get('psar_max_af', DEFAULT_PSAR_MAX_AF)}"],
            "PSAR_short": [f"PSARs_{self.config.get('psar_af', DEFAULT_PSAR_AF)}_{self.config.get('psar_max_af', DEFAULT_PSAR_MAX_AF)}"],
            "SMA10": [f"SMA_{self.config.get('sma_10_window', DEFAULT_SMA_10_WINDOW)}"],
            # StochRSI names can be complex, include core parameters
            "StochRSI_K": [f"STOCHRSIk_{self.config.get('stoch_rsi_window', DEFAULT_STOCH_RSI_WINDOW)}_{self.config.get('stoch_rsi_rsi_window', DEFAULT_STOCH_WINDOW)}_{self.config.get('stoch_rsi_k', DEFAULT_K_WINDOW)}"],
            "StochRSI_D": [f"STOCHRSId_{self.config.get('stoch_rsi_window', DEFAULT_STOCH_RSI_WINDOW)}_{self.config.get('stoch_rsi_rsi_window', DEFAULT_STOCH_WINDOW)}_{self.config.get('stoch_rsi_k', DEFAULT_K_WINDOW)}_{self.config.get('stoch_rsi_d', DEFAULT_D_WINDOW)}"],
            "RSI": [f"RSI_{self.config.get('rsi_period', DEFAULT_RSI_WINDOW)}"],
            # BBands names include period and std dev (formatted to 1 decimal place by default)
            "BB_Lower": [f"BBL_{self.config.get('bollinger_bands_period', DEFAULT_BOLLINGER_BANDS_PERIOD)}_{float(self.config.get('bollinger_bands_std_dev', DEFAULT_BOLLINGER_BANDS_STD_DEV)):.1f}"],
            "BB_Middle": [f"BBM_{self.config.get('bollinger_bands_period', DEFAULT_BOLLINGER_BANDS_PERIOD)}_{float(self.config.get('bollinger_bands_std_dev', DEFAULT_BOLLINGER_BANDS_STD_DEV)):.1f}"],
            "BB_Upper": [f"BBU_{self.config.get('bollinger_bands_period', DEFAULT_BOLLINGER_BANDS_PERIOD)}_{float(self.config.get('bollinger_bands_std_dev', DEFAULT_BOLLINGER_BANDS_STD_DEV)):.1f}"],
            # Custom name used for Volume MA
            "Volume_MA": [f"VOL_SMA_{self.config.get('volume_ma_period', DEFAULT_VOLUME_MA_PERIOD)}"]
        }

        patterns = expected_patterns.get(base_name, [])
        df_cols = result_df.columns.tolist()

        # Exact match or startswith preferred
        for col in df_cols:
            for pattern in patterns:
                # Use startswith for flexibility (e.g., CCI_20_100.0 matches CCI_20)
                if col.startswith(pattern):
                    self.logger.debug(f"Mapped '{base_name}' to column '{col}'")
                    return col

        # Fallback: Simple case-insensitive substring search
        base_lower = base_name.lower()
        simple_base = base_lower.split('_')[0] # e.g., "ema_short" -> "ema"
        for col in df_cols:
            col_lower = col.lower()
            # Check full base name first, then simpler version
            if base_lower in col_lower:
                 self.logger.debug(f"Mapped '{base_name}' to '{col}' via substring search ('{base_lower}').")
                 return col
            # Avoid overly broad matches with simple base (e.g., 'r' matching 'atr')
            elif len(simple_base) > 2 and simple_base in col_lower:
                 self.logger.debug(f"Mapped '{base_name}' to '{col}' via substring search ('{simple_base}').")
                 return col

        self.logger.warning(f"Could not find column name for indicator '{base_name}' in DataFrame columns: {df_cols}")
        return None

    def _calculate_all_indicators(self):
        """Calculates all enabled indicators using pandas_ta."""
        if self.df.empty:
            self.logger.warning(f"DataFrame is empty, cannot calculate indicators for {self.symbol}.")
            return

        # Determine minimum required data length based on enabled & weighted indicators
        required_periods = []
        indicators_config = self.config.get("indicators", {})
        active_weights = self.weights # Use stored weights

        # Helper to add requirement if indicator is enabled AND weighted
        def add_req(key, config_key, default_period):
            if indicators_config.get(key, False) and float(active_weights.get(key, 0)) != 0:
                required_periods.append(self.config.get(config_key, default_period))

        add_req("atr", "atr_period", DEFAULT_ATR_PERIOD) # ATR always calculated, but check weight for period needs
        add_req("momentum", "momentum_period", DEFAULT_MOMENTUM_PERIOD)
        add_req("cci", "cci_window", DEFAULT_CCI_WINDOW)
        add_req("wr", "williams_r_window", DEFAULT_WILLIAMS_R_WINDOW)
        add_req("mfi", "mfi_window", DEFAULT_MFI_WINDOW)
        add_req("sma_10", "sma_10_window", DEFAULT_SMA_10_WINDOW)
        add_req("rsi", "rsi_period", DEFAULT_RSI_WINDOW)
        add_req("bollinger_bands", "bollinger_bands_period", DEFAULT_BOLLINGER_BANDS_PERIOD)
        add_req("volume_confirmation", "volume_ma_period", DEFAULT_VOLUME_MA_PERIOD)
        required_periods.append(self.config.get("fibonacci_window", DEFAULT_FIB_WINDOW)) # For Fib levels

        if indicators_config.get("ema_alignment", False) and float(active_weights.get("ema_alignment", 0)) != 0:
             required_periods.append(self.config.get("ema_short_period", DEFAULT_EMA_SHORT_PERIOD))
             required_periods.append(self.config.get("ema_long_period", DEFAULT_EMA_LONG_PERIOD))
        if indicators_config.get("stoch_rsi", False) and float(active_weights.get("stoch_rsi", 0)) != 0:
            required_periods.append(self.config.get("stoch_rsi_window", DEFAULT_STOCH_RSI_WINDOW))
            required_periods.append(self.config.get("stoch_rsi_rsi_window", DEFAULT_STOCH_WINDOW))

        min_required_data = max(required_periods) + 30 if required_periods else 50 # Add buffer

        if len(self.df) < min_required_data:
             self.logger.warning(f"{NEON_YELLOW}Insufficient data ({len(self.df)} points) for {self.symbol} to calculate indicators reliably (min recommended: {min_required_data}). Results may contain NaNs.{RESET}")

        try:
            df_calc = self.df.copy()
            # Ensure OHLCV columns are numeric floats for pandas_ta compatibility
            # pandas_ta works best with floats, convert Decimals if present
            for col in ['open', 'high', 'low', 'close', 'volume']:
                 if col in df_calc.columns:
                     # Check if column exists and get first non-NaN value's type
                     first_valid_type = df_calc[col].dropna().apply(type).iloc[0] if not df_calc[col].dropna().empty else None
                     if first_valid_type == Decimal:
                          self.logger.debug(f"Converting Decimal column '{col}' to float for TA calculation.")
                          df_calc[col] = df_calc[col].apply(lambda x: float(x) if isinstance(x, Decimal) and x.is_finite() else np.nan)
                     elif first_valid_type is not None and not pd.api.types.is_numeric_dtype(df_calc[col].dtype):
                          self.logger.debug(f"Converting non-numeric column '{col}' to float for TA calculation.")
                          df_calc[col] = pd.to_numeric(df_calc[col], errors='coerce')


            # --- Calculate Indicators ---
            # Always calculate ATR
            atr_period = self.config.get("atr_period", DEFAULT_ATR_PERIOD)
            df_calc.ta.atr(length=atr_period, append=True)
            self.ta_column_names["ATR"] = self._get_ta_col_name("ATR", df_calc)

            # Calculate others based on config and weight
            key_map = { # Map internal keys to config keys and defaults if needed
                "ema_alignment": None, # Special case below
                "momentum": ("momentum_period", DEFAULT_MOMENTUM_PERIOD),
                "cci": ("cci_window", DEFAULT_CCI_WINDOW),
                "wr": ("williams_r_window", DEFAULT_WILLIAMS_R_WINDOW),
                "mfi": ("mfi_window", DEFAULT_MFI_WINDOW),
                "vwap": None, # Uses default ta.vwap()
                "psar": None, # Special case below
                "sma_10": ("sma_10_window", DEFAULT_SMA_10_WINDOW),
                "stoch_rsi": None, # Special case below
                "rsi": ("rsi_period", DEFAULT_RSI_WINDOW),
                "bollinger_bands": None, # Special case below
                "volume_confirmation": None, # Special case below
            }

            for key, enabled in indicators_config.items():
                if key == "atr": continue # Already calculated
                if enabled and float(active_weights.get(key, 0)) != 0:
                    self.logger.debug(f"Calculating indicator: {key}")
                    try:
                        if key == "ema_alignment":
                            ema_short = self.config.get("ema_short_period", DEFAULT_EMA_SHORT_PERIOD)
                            ema_long = self.config.get("ema_long_period", DEFAULT_EMA_LONG_PERIOD)
                            df_calc.ta.ema(length=ema_short, append=True)
                            self.ta_column_names["EMA_Short"] = self._get_ta_col_name("EMA_Short", df_calc)
                            df_calc.ta.ema(length=ema_long, append=True)
                            self.ta_column_names["EMA_Long"] = self._get_ta_col_name("EMA_Long", df_calc)
                        elif key == "psar":
                            psar_af = self.config.get("psar_af", DEFAULT_PSAR_AF)
                            psar_max_af = self.config.get("psar_max_af", DEFAULT_PSAR_MAX_AF)
                            psar_result = df_calc.ta.psar(af=psar_af, max_af=psar_max_af)
                            if psar_result is not None and not psar_result.empty:
                                df_calc = pd.concat([df_calc, psar_result], axis=1)
                                self.ta_column_names["PSAR_long"] = self._get_ta_col_name("PSAR_long", df_calc)
                                self.ta_column_names["PSAR_short"] = self._get_ta_col_name("PSAR_short", df_calc)
                        elif key == "stoch_rsi":
                            st_len = self.config.get("stoch_rsi_window", DEFAULT_STOCH_RSI_WINDOW)
                            st_rsi_len = self.config.get("stoch_rsi_rsi_window", DEFAULT_STOCH_WINDOW)
                            st_k = self.config.get("stoch_rsi_k", DEFAULT_K_WINDOW)
                            st_d = self.config.get("stoch_rsi_d", DEFAULT_D_WINDOW)
                            st_result = df_calc.ta.stochrsi(length=st_len, rsi_length=st_rsi_len, k=st_k, d=st_d)
                            if st_result is not None and not st_result.empty:
                                df_calc = pd.concat([df_calc, st_result], axis=1)
                                self.ta_column_names["StochRSI_K"] = self._get_ta_col_name("StochRSI_K", df_calc)
                                self.ta_column_names["StochRSI_D"] = self._get_ta_col_name("StochRSI_D", df_calc)
                        elif key == "bollinger_bands":
                            bb_p = self.config.get("bollinger_bands_period", DEFAULT_BOLLINGER_BANDS_PERIOD)
                            bb_std = float(self.config.get("bollinger_bands_std_dev", DEFAULT_BOLLINGER_BANDS_STD_DEV))
                            bb_result = df_calc.ta.bbands(length=bb_p, std=bb_std)
                            if bb_result is not None and not bb_result.empty:
                                df_calc = pd.concat([df_calc, bb_result], axis=1)
                                self.ta_column_names["BB_Lower"] = self._get_ta_col_name("BB_Lower", df_calc)
                                self.ta_column_names["BB_Middle"] = self._get_ta_col_name("BB_Middle", df_calc)
                                self.ta_column_names["BB_Upper"] = self._get_ta_col_name("BB_Upper", df_calc)
                        elif key == "volume_confirmation":
                            vol_ma_p = self.config.get("volume_ma_period", DEFAULT_VOLUME_MA_PERIOD)
                            vol_ma_col = f"VOL_SMA_{vol_ma_p}"
                            # Ensure volume is float for SMA calculation
                            vol_series = df_calc['volume'].astype(float) # Already converted above
                            df_calc[vol_ma_col] = ta.sma(vol_series.fillna(0), length=vol_ma_p)
                            self.ta_column_names["Volume_MA"] = vol_ma_col
                        elif key == "vwap":
                             df_calc.ta.vwap(append=True)
                             self.ta_column_names["VWAP"] = self._get_ta_col_name("VWAP", df_calc)
                        elif key in key_map and key_map[key] is not None: # General case using key_map
                            config_k, default_p = key_map[key]
                            period = self.config.get(config_k, default_p)
                            # Call the corresponding pandas_ta method dynamically
                            method = getattr(df_calc.ta, key, None)
                            if method and callable(method):
                                method(length=period, append=True)
                                # Map internal key to pandas_ta base name for column lookup
                                ta_base_map = {"cci": "CCI", "wr": "Williams_R", "mfi": "MFI", "sma_10": "SMA10", "rsi": "RSI", "momentum": "Momentum"}
                                ta_base_name = ta_base_map.get(key, key.upper()) # Simple mapping
                                self.ta_column_names[ta_base_name] = self._get_ta_col_name(ta_base_name, df_calc)
                            else:
                                self.logger.warning(f"Pandas TA method '{key}' not found or not callable.")

                    except Exception as calc_err:
                        self.logger.error(f"Error calculating indicator '{key}': {calc_err}", exc_info=True)


            # Convert ATR column back to Decimal after calculation (pandas_ta outputs float)
            atr_col = self.ta_column_names.get("ATR")
            if atr_col and atr_col in df_calc.columns:
                 try:
                     # Convert float column to Decimal, handling potential NaNs
                     df_calc[atr_col] = df_calc[atr_col].apply(lambda x: Decimal(str(x)) if pd.notna(x) and np.isfinite(x) else Decimal('NaN'))
                     self.logger.debug(f"Converted calculated ATR column '{atr_col}' back to Decimal.")
                 except (ValueError, TypeError, InvalidOperation) as conv_err:
                      self.logger.error(f"Failed to convert ATR column '{atr_col}' back to Decimal: {conv_err}")

            # Update the instance's DataFrame
            self.df = df_calc
            self.logger.debug(f"Finished indicator calculations. Final DF columns: {self.df.columns.tolist()}")

        except Exception as e:
            self.logger.error(f"{NEON_RED}Error during indicator calculation setup or execution: {e}{RESET}", exc_info=True)


    def _update_latest_indicator_values(self):
        """Updates indicator_values dict with latest values, handling types."""
        default_values = {k: np.nan for k in list(self.ta_column_names.keys()) + ["Open", "High", "Low", "Close", "Volume"]}
        if self.df.empty:
            self.logger.warning(f"Cannot update latest values: DataFrame empty for {self.symbol}.")
            self.indicator_values = default_values
            return
        try:
            # Use the last valid index in case of skipped timestamps
            latest = self.df.iloc[self.df.index.get_loc(self.df.last_valid_index())] if self.df.last_valid_index() is not None else self.df.iloc[-1]
        except (IndexError, KeyError):
            self.logger.error(f"Error accessing latest row/index for {self.symbol}.")
            self.indicator_values = default_values
            return

        if latest.isnull().all():
            self.logger.warning(f"Last valid row contains all NaNs for {self.symbol}. Cannot update values.")
            self.indicator_values = default_values
            return

        updated_values = {}
        # Process TA indicators (expect float, except ATR which is Decimal)
        for key, col_name in self.ta_column_names.items():
            if col_name and col_name in latest.index:
                value = latest[col_name]
                # Check for NaN and non-finite values (like inf)
                if pd.notna(value) and np.isfinite(value):
                    try:
                        if key == "ATR": # ATR should be Decimal
                            # Ensure value is Decimal, convert if needed
                            updated_values[key] = value if isinstance(value, Decimal) else Decimal(str(value))
                        else: # Others as float
                            updated_values[key] = float(value)
                    except (ValueError, TypeError, InvalidOperation) as conv_err:
                        self.logger.warning(f"Could not convert TA value {key} ('{col_name}': {value}): {conv_err}. Storing NaN.")
                        updated_values[key] = np.nan
                else: updated_values[key] = np.nan # Store NaN if value is NaN or inf/-inf
            else:
                 if key in self.ta_column_names: # Log only if calc was attempted
                     self.logger.debug(f"Indicator column '{col_name}' for '{key}' not found in latest data. Storing NaN.")
                 updated_values[key] = np.nan

        # Process Base OHLCV (ensure Decimal and finite)
        for base_col in ['open', 'high', 'low', 'close', 'volume']:
            key_name = base_col.capitalize()
            value = latest.get(base_col)
            # Check for NaN and if it's already Decimal (from fetch_klines)
            if pd.notna(value):
                 try:
                    if isinstance(value, Decimal):
                        if value.is_finite(): updated_values[key_name] = value
                        else: updated_values[key_name] = np.nan # Treat non-finite Decimals as NaN
                    else: # Try converting other types (e.g., float from direct calc)
                        dec_val = Decimal(str(value))
                        if dec_val.is_finite(): updated_values[key_name] = dec_val
                        else: updated_values[key_name] = np.nan
                 except (ValueError, TypeError, InvalidOperation) as conv_err:
                      self.logger.warning(f"Could not convert base '{base_col}' ({value}) to Decimal: {conv_err}. Storing NaN.")
                      updated_values[key_name] = np.nan
            else: updated_values[key_name] = np.nan

        self.indicator_values = updated_values

        # Log Summary (formatted)
        log_vals = {}
        price_prec = self.get_price_precision()
        for k, v in self.indicator_values.items():
            if pd.notna(v) and isinstance(v, (Decimal, float, int)) and np.isfinite(v): # Ensure displayable number
                if isinstance(v, Decimal):
                    prec = price_prec if k in ['Open', 'High', 'Low', 'Close', 'ATR'] else 8
                    log_vals[k] = f"{v:.{prec}f}"
                elif isinstance(v, float): log_vals[k] = f"{v:.5f}"
                else: log_vals[k] = str(v)
            # else: log_vals[k] = "NaN" # Optionally log NaNs
        self.logger.debug(f"Latest values updated ({self.symbol}): {log_vals}")


    def calculate_fibonacci_levels(self, window: Optional[int] = None) -> Dict[str, Decimal]:
        """Calculates Fibonacci levels using Decimal precision."""
        window = window or self.config.get("fibonacci_window", DEFAULT_FIB_WINDOW)
        if len(self.df) < window:
            self.logger.debug(f"Not enough data ({len(self.df)}) for Fibonacci ({window}) on {self.symbol}.")
            self.fib_levels_data = {}; return {}

        df_slice = self.df.tail(window)
        try:
            # Ensure 'high'/'low' are numeric before finding max/min
            # Convert potentially Decimal columns to numeric (float) for max/min
            high_series = pd.to_numeric(df_slice["high"], errors='coerce')
            low_series = pd.to_numeric(df_slice["low"], errors='coerce')
            high_price_raw = high_series.dropna().max()
            low_price_raw = low_series.dropna().min()

            if pd.isna(high_price_raw) or pd.isna(low_price_raw):
                self.logger.warning(f"Could not find valid high/low for Fibonacci (Window: {window}).")
                self.fib_levels_data = {}; return {}

            high = Decimal(str(high_price_raw))
            low = Decimal(str(low_price_raw))
            diff = high - low

            levels = {}
            price_precision = self.get_price_precision()
            rounding_factor = Decimal('1e-' + str(price_precision))

            if diff > 0:
                for level_pct in FIB_LEVELS:
                    level_name = f"Fib_{level_pct * 100:.1f}%"
                    level_price = high - (diff * Decimal(str(level_pct)))
                    # Round down from high for support levels
                    levels[level_name] = level_price.quantize(rounding_factor, rounding=ROUND_DOWN)
            else: # Handle zero range
                self.logger.debug(f"Fibonacci range is zero (High=Low={high}). Setting all levels to this price.")
                level_price_quantized = high.quantize(rounding_factor, rounding=ROUND_DOWN)
                for level_pct in FIB_LEVELS:
                    levels[f"Fib_{level_pct * 100:.1f}%"] = level_price_quantized

            self.fib_levels_data = levels
            log_levels = {k: str(v) for k, v in levels.items()}
            self.logger.debug(f"Calculated Fibonacci levels (Window: {window}): {log_levels}")
            return levels

        except KeyError as e:
            self.logger.error(f"{NEON_RED}Fibonacci error: Missing column '{e}'.{RESET}")
            self.fib_levels_data = {}; return {}
        except (ValueError, TypeError, InvalidOperation) as e:
             self.logger.error(f"{NEON_RED}Fibonacci error: Invalid data type for high/low. {e}{RESET}")
             self.fib_levels_data = {}; return {}
        except Exception as e:
            self.logger.error(f"{NEON_RED}Unexpected Fibonacci calculation error: {e}{RESET}", exc_info=True)
            self.fib_levels_data = {}; return {}

    def get_price_precision(self) -> int:
        """Determines price precision (decimal places) from market info."""
        try:
            # 1. Check precision.price (most reliable)
            precision_info = self.market_info.get('precision', {})
            price_precision_val = precision_info.get('price')
            if price_precision_val is not None:
                # If it's an integer >= 0, it's decimal places
                if isinstance(price_precision_val, int) and price_precision_val >= 0:
                    return price_precision_val
                # If it's float/str, assume it represents tick size
                try:
                    tick_size = Decimal(str(price_precision_val))
                    # Ensure tick_size is positive and finite
                    if tick_size.is_finite() and tick_size > 0:
                        precision = abs(tick_size.normalize().as_tuple().exponent)
                        return precision
                except (TypeError, ValueError, InvalidOperation) as e:
                     self.logger.debug(f"Could not parse precision.price '{price_precision_val}' as tick size: {e}")

            # 2. Fallback: Infer from limits.price.min (less reliable)
            min_price_val = self.market_info.get('limits', {}).get('price', {}).get('min')
            if min_price_val is not None:
                try:
                    min_price_tick = Decimal(str(min_price_val))
                    # Check finite, positive, and small (heuristic for tick size)
                    if min_price_tick.is_finite() and 0 < min_price_tick < Decimal('0.1'):
                        precision = abs(min_price_tick.normalize().as_tuple().exponent)
                        return precision
                except (TypeError, ValueError, InvalidOperation) as e:
                    self.logger.debug(f"Could not parse limits.price.min '{min_price_val}' for precision: {e}")

            # 3. Fallback: Infer from last close price (least reliable)
            last_close = self.indicator_values.get("Close")
            if isinstance(last_close, Decimal) and last_close.is_finite() and last_close > 0:
                try:
                    # Get exponent of normalized value
                    precision = abs(last_close.normalize().as_tuple().exponent)
                    # Sanity check precision range
                    if 0 <= precision < 10: return precision
                except Exception: pass # Ignore errors in fallback

        except Exception as e:
            self.logger.warning(f"Error determining price precision for {self.symbol}: {e}. Falling back.")

        # Final fallback
        default_precision = 4
        self.logger.warning(f"Could not determine price precision for {self.symbol}. Using default: {default_precision}.")
        return default_precision

    def get_min_tick_size(self) -> Decimal:
        """Gets the minimum price increment (tick size) from market info."""
        try:
            # 1. Try precision.price
            precision_info = self.market_info.get('precision', {})
            price_precision_val = precision_info.get('price')
            if price_precision_val is not None:
                if isinstance(price_precision_val, (float, str, int)):
                     try:
                          # If int (decimal places), calculate tick size
                          if isinstance(price_precision_val, int) and price_precision_val >= 0:
                               tick = Decimal('1e-' + str(price_precision_val))
                               if tick.is_finite() and tick > 0: return tick
                          else: # float or str, assume it IS the tick size
                               tick = Decimal(str(price_precision_val))
                               if tick.is_finite() and tick > 0: return tick
                     except (TypeError, ValueError, InvalidOperation) as e:
                          self.logger.debug(f"Could not parse precision.price '{price_precision_val}' as tick size: {e}")

            # 2. Fallback: Try limits.price.min
            min_price_val = self.market_info.get('limits', {}).get('price', {}).get('min')
            if min_price_val is not None:
                try:
                    min_tick = Decimal(str(min_price_val))
                    # Check finite, positive, and small (heuristic)
                    if min_tick.is_finite() and 0 < min_tick < Decimal('0.1'):
                        return min_tick
                except (TypeError, ValueError, InvalidOperation) as e:
                     self.logger.debug(f"Could not parse limits.price.min '{min_price_val}' for tick size: {e}")

        except Exception as e:
            self.logger.warning(f"Could not determine min tick size for {self.symbol} from market info: {e}. Using precision fallback.")

        # --- Final Fallback: Calculate from derived decimal places ---
        price_precision_places = self.get_price_precision()
        fallback_tick = Decimal('1e-' + str(price_precision_places))
        self.logger.debug(f"Using fallback tick size based on derived precision ({price_precision_places}): {fallback_tick}")
        return fallback_tick

    def get_amount_precision_places(self) -> int:
        """Determines amount precision (decimal places) from market info."""
        # Similar logic to get_price_precision, but using 'amount' field
        try:
            precision_info = self.market_info.get('precision', {})
            amount_precision_val = precision_info.get('amount')
            if amount_precision_val is not None:
                # Direct decimal places
                if isinstance(amount_precision_val, int) and amount_precision_val >= 0:
                    return amount_precision_val
                # Assume step size (float/str)
                try:
                    step_size = Decimal(str(amount_precision_val))
                    if step_size.is_finite() and step_size > 0:
                        return abs(step_size.normalize().as_tuple().exponent)
                except (TypeError, ValueError, InvalidOperation): pass # Ignore parsing error

            # Fallback: Infer from limits.amount.min
            min_amount_val = self.market_info.get('limits', {}).get('amount', {}).get('min')
            if min_amount_val is not None:
                try:
                    min_amount_step = Decimal(str(min_amount_val))
                    # Check finite, positive, and potentially small
                    if min_amount_step.is_finite() and 0 < min_amount_step <= Decimal('1'): # Allow 1, check if fractional
                       if min_amount_step < 1: # Looks like step size
                           return abs(min_amount_step.normalize().as_tuple().exponent)
                       # If min amount is 1 or more integer, precision is 0
                       elif min_amount_step >= 1 and '.' not in str(min_amount_val): return 0
                except (TypeError, ValueError, InvalidOperation): pass # Ignore parsing error

        except Exception as e:
            self.logger.warning(f"Error determining amount precision for {self.symbol}: {e}.")

        # Final fallback
        default_precision = 8 # Common default for crypto amounts
        self.logger.warning(f"Could not determine amount precision for {self.symbol}. Using default: {default_precision}.")
        return default_precision

    def get_min_amount_step(self) -> Decimal:
        """Gets the minimum amount increment (step size) from market info."""
        # Similar logic to get_min_tick_size, using 'amount' field
        try:
            # 1. Try precision.amount
            precision_info = self.market_info.get('precision', {})
            amount_precision_val = precision_info.get('amount')
            if amount_precision_val is not None:
                if isinstance(amount_precision_val, (float, str, int)):
                     try:
                          # Int = decimal places -> calculate step
                          if isinstance(amount_precision_val, int) and amount_precision_val >= 0:
                               step = Decimal('1e-' + str(amount_precision_val))
                               if step.is_finite() and step > 0: return step
                          else: # Float/Str = step size itself
                               step = Decimal(str(amount_precision_val))
                               if step.is_finite() and step > 0: return step
                     except (TypeError, ValueError, InvalidOperation): pass # Ignore parsing errors

            # 2. Fallback: Try limits.amount.min (often IS the step size)
            min_amount_val = self.market_info.get('limits', {}).get('amount', {}).get('min')
            if min_amount_val is not None:
                try:
                    min_step = Decimal(str(min_amount_val))
                    # Assume min limit IS the step size if it's positive and finite
                    if min_step.is_finite() and min_step > 0: return min_step
                except (TypeError, ValueError, InvalidOperation): pass # Ignore parsing errors

        except Exception as e:
            self.logger.warning(f"Could not determine min amount step for {self.symbol}: {e}.")

        # --- Final Fallback: Calculate from derived precision ---
        amount_precision_places = self.get_amount_precision_places()
        fallback_step = Decimal('1e-' + str(amount_precision_places))
        self.logger.debug(f"Using fallback amount step based on derived precision ({amount_precision_places}): {fallback_step}")
        return fallback_step


    def get_nearest_fibonacci_levels(self, current_price: Decimal, num_levels: int = 5) -> List[Tuple[str, Decimal]]:
        """Finds the N nearest Fibonacci levels to the current price."""
        if not self.fib_levels_data:
            self.logger.debug(f"Fibonacci levels not calculated for {self.symbol}.")
            return []
        if not isinstance(current_price, Decimal) or not current_price.is_finite() or current_price <= 0:
            self.logger.warning(f"Invalid current price ({current_price}) for Fibonacci comparison on {self.symbol}.")
            return []

        try:
            level_distances = []
            for name, level_price in self.fib_levels_data.items():
                # Ensure level price is valid Decimal
                if isinstance(level_price, Decimal) and level_price.is_finite() and level_price > 0:
                    distance = abs(current_price - level_price)
                    level_distances.append({'name': name, 'level': level_price, 'distance': distance})
                else:
                    self.logger.warning(f"Invalid Fib level value encountered: {name}={level_price}. Skipping.")

            level_distances.sort(key=lambda x: x['distance'])
            # Return N nearest levels as (name, price) tuples
            return [(item['name'], item['level']) for item in level_distances[:num_levels]]

        except Exception as e:
            self.logger.error(f"{NEON_RED}Error finding nearest Fibonacci levels for {self.symbol}: {e}{RESET}", exc_info=True)
            return []

    def calculate_ema_alignment_score(self) -> float:
        """Calculates EMA alignment score."""
        ema_s = self.indicator_values.get("EMA_Short") # Float
        ema_l = self.indicator_values.get("EMA_Long") # Float
        close_dec = self.indicator_values.get("Close") # Decimal

        # Ensure all values are valid numbers for comparison
        if not (isinstance(ema_s, (float, int)) and np.isfinite(ema_s) and
                isinstance(ema_l, (float, int)) and np.isfinite(ema_l) and
                isinstance(close_dec, Decimal) and close_dec.is_finite()):
            self.logger.debug("EMA alignment check skipped: Missing or non-finite values.")
            return np.nan

        price_f = float(close_dec) # Convert Decimal to float for comparison
        if price_f > ema_s > ema_l: return 1.0 # Strong Bullish
        elif price_f < ema_s < ema_l: return -1.0 # Strong Bearish
        else: return 0.0 # Mixed / Crossing

    def generate_trading_signal(self, current_price: Decimal, orderbook_data: Optional[Dict]) -> str:
        """Generates final trading signal (BUY/SELL/HOLD) based on weighted score."""
        self.signals = {"BUY": 0, "SELL": 0, "HOLD": 1} # Default HOLD
        final_score = Decimal("0.0")
        total_weight = Decimal("0.0")
        active_count, nan_count = 0, 0
        debug_scores = {}

        # Basic validation checks
        if not self.indicator_values: self.logger.warning("Signal Gen: Indicator values empty."); return "HOLD"
        # Check if at least one *weighted* core indicator has a valid value
        core_ok = any(
            pd.notna(self.indicator_values.get(k)) and np.isfinite(self.indicator_values.get(k, np.nan))
            for k, enabled in self.config.get("indicators", {}).items()
            if enabled and float(self.weights.get(k, 0)) != 0 and k not in ['Open', 'High', 'Low', 'Close', 'Volume']
        )
        if not core_ok: self.logger.warning("Signal Gen: All weighted core indicators are NaN/invalid."); return "HOLD"
        if not isinstance(current_price, Decimal) or not current_price.is_finite() or current_price <= 0:
            self.logger.warning(f"Signal Gen: Invalid current price ({current_price})."); return "HOLD"
        if not self.weights: self.logger.error("Signal Gen: Active weight set missing/empty."); return "HOLD"

        # Iterate through indicators defined in config
        for indicator_key, enabled in self.config.get("indicators", {}).items():
            if not enabled: continue
            weight_str = self.weights.get(indicator_key)
            if weight_str is None: continue # No weight defined

            try:
                weight = Decimal(str(weight_str))
                if not weight.is_finite(): raise ValueError("Weight not finite")
            except (ValueError, TypeError, InvalidOperation):
                self.logger.warning(f"Invalid weight format '{weight_str}' for '{indicator_key}'. Skipping.")
                continue
            if weight == 0: continue # Skip zero weight

            check_method_name = f"_check_{indicator_key}"
            score_float = np.nan # Default to NaN
            if hasattr(self, check_method_name) and callable(getattr(self, check_method_name)):
                try:
                    method = getattr(self, check_method_name)
                    # Pass necessary arguments based on the check method
                    if indicator_key == "orderbook":
                        if orderbook_data: score_float = method(orderbook_data, current_price)
                        elif weight != 0: self.logger.debug("Orderbook check skipped: No data.")
                    else: score_float = method() # Assume other methods need no args

                except Exception as e:
                    self.logger.error(f"Error executing check method {check_method_name}: {e}", exc_info=True)
            elif weight != 0: # Log only if weighted but method missing
                self.logger.warning(f"Check method '{check_method_name}' not found for weighted indicator '{indicator_key}'.")

            # Store score for debugging, handling NaN/inf
            debug_scores[indicator_key] = f"{score_float:.3f}" if pd.notna(score_float) and np.isfinite(score_float) else str(score_float)

            # Aggregate score if valid (not NaN, not infinite)
            if pd.notna(score_float) and np.isfinite(score_float):
                try:
                    score_dec = Decimal(str(score_float))
                    # Clamp score to [-1, 1] range
                    clamped_score = max(Decimal("-1.0"), min(Decimal("1.0"), score_dec))
                    final_score += clamped_score * weight
                    total_weight += weight
                    active_count += 1
                except (ValueError, TypeError, InvalidOperation) as calc_err:
                    self.logger.error(f"Error processing score for {indicator_key} (Score: {score_float}, Weight: {weight}): {calc_err}")
                    nan_count += 1 # Count as NaN if processing failed
            else:
                nan_count += 1 # Count indicators that returned NaN or inf

        # --- Determine Final Signal ---
        final_signal = "HOLD" # Default signal
        if total_weight == 0:
            self.logger.warning(f"No indicators contributed valid scores or total weight is zero for {self.symbol}. Defaulting to HOLD.")
        else:
            try:
                threshold_str = self.config.get("signal_score_threshold", "1.5")
                threshold = Decimal(str(threshold_str))
                if not threshold.is_finite() or threshold <= 0: raise ValueError("Threshold must be positive finite")
            except (ValueError, TypeError, InvalidOperation):
                self.logger.warning(f"Invalid signal_score_threshold '{threshold_str}'. Using default 1.5.")
                threshold = Decimal("1.5")

            # Compare final score to threshold
            if final_score >= threshold: final_signal = "BUY"
            elif final_score <= -threshold: final_signal = "SELL"
            # Otherwise, final_signal remains "HOLD"

        # --- Log Summary ---
        price_prec = self.get_price_precision()
        sig_color = NEON_GREEN if final_signal == "BUY" else NEON_RED if final_signal == "SELL" else NEON_YELLOW
        log_msg = (
            f"Signal Summary ({self.symbol} @ {current_price:.{price_prec}f}): "
            f"Set='{self.active_weight_set_name}', Ind=[Act:{active_count}, NaN:{nan_count}], "
            f"Weight={total_weight:.2f}, Score={final_score:.4f} (Thr: +/-{threshold:.2f}) "
            f"==> {sig_color}{final_signal}{RESET}"
        )
        self.logger.info(log_msg)
        self.logger.debug(f"  Indicator Scores ({self.symbol}): {debug_scores}")

        # Update internal signal state
        if final_signal == "BUY": self.signals = {"BUY": 1, "SELL": 0, "HOLD": 0}
        elif final_signal == "SELL": self.signals = {"BUY": 0, "SELL": 1, "HOLD": 0}
        else: self.signals = {"BUY": 0, "SELL": 0, "HOLD": 1} # HOLD

        return final_signal

    # --- Indicator Check Methods (return float score -1.0 to 1.0 or np.nan) ---
    # Ensure these methods handle potential NaN/inf values from self.indicator_values
    def _check_ema_alignment(self) -> float:
        # Relies on calculate_ema_alignment_score which handles internal checks
        return self.calculate_ema_alignment_score()

    def _check_momentum(self) -> float:
        momentum = self.indicator_values.get("Momentum")
        if not (isinstance(momentum, (float, int)) and np.isfinite(momentum)): return np.nan
        threshold = 0.1 # Example threshold, needs tuning based on symbol/timeframe
        if threshold == 0: return 0.0 # Avoid division by zero
        score = momentum / threshold
        return max(-1.0, min(1.0, score)) # Clamp result to [-1, 1]

    def _check_volume_confirmation(self) -> float:
        current_volume = self.indicator_values.get("Volume") # Decimal
        volume_ma = self.indicator_values.get("Volume_MA") # Float
        multiplier = float(self.config.get("volume_confirmation_multiplier", 1.5))

        if not (isinstance(current_volume, Decimal) and current_volume.is_finite() and
                isinstance(volume_ma, (float, int)) and np.isfinite(volume_ma) and volume_ma > 0 and multiplier > 0):
            return np.nan
        try:
            volume_ma_dec = Decimal(str(volume_ma)); multiplier_dec = Decimal(str(multiplier))
            if current_volume > volume_ma_dec * multiplier_dec: return 0.7 # High volume confirmation
            elif current_volume < volume_ma_dec / multiplier_dec: return -0.4 # Low volume lack of confirmation
            else: return 0.0 # Neutral volume
        except (ValueError, TypeError, InvalidOperation) as e:
            self.logger.warning(f"Error during volume confirmation check: {e}")
            return np.nan

    def _check_stoch_rsi(self) -> float:
        k = self.indicator_values.get("StochRSI_K")
        d = self.indicator_values.get("StochRSI_D")
        if not (isinstance(k, (float, int)) and np.isfinite(k) and
                isinstance(d, (float, int)) and np.isfinite(d)): return np.nan

        oversold = float(self.config.get("stoch_rsi_oversold_threshold", 25))
        overbought = float(self.config.get("stoch_rsi_overbought_threshold", 75))
        score = 0.0
        if k < oversold and d < oversold: score = 1.0
        elif k > overbought and d > overbought: score = -1.0
        diff = k - d # Assess K/D cross momentum
        if abs(diff) > 5: score = max(score, 0.6) if diff > 0 else min(score, -0.6) # Stronger signal on cross
        elif k > d: score = max(score, 0.2) # Mild bullish momentum
        elif k < d: score = min(score, -0.2) # Mild bearish momentum
        if 40 < k < 60: score *= 0.5 # Dampen score in neutral zone
        return score

    def _check_rsi(self) -> float:
        rsi = self.indicator_values.get("RSI")
        if not (isinstance(rsi, (float, int)) and np.isfinite(rsi)): return np.nan
        if rsi <= 30: return 1.0;   elif rsi >= 70: return -1.0
        if rsi < 40: return 0.5;    elif rsi > 60: return -0.5
        if 40 <= rsi <= 60: return (rsi - 50) / 50.0 # Scale between -0.2 and +0.2
        return 0.0 # Should not be reached

    def _check_cci(self) -> float:
        cci = self.indicator_values.get("CCI")
        if not (isinstance(cci, (float, int)) and np.isfinite(cci)): return np.nan
        if cci <= -150: return 1.0; elif cci >= 150: return -1.0 # Strong OB/OS
        if cci < -80: return 0.6;   elif cci > 80: return -0.6 # Moderate OB/OS
        if cci > 0: return -0.1;    elif cci < 0: return 0.1 # Weak directional bias
        return 0.0

    def _check_wr(self) -> float:
        wr = self.indicator_values.get("Williams_R")
        if not (isinstance(wr, (float, int)) and np.isfinite(wr)): return np.nan
        if wr <= -80: return 1.0;   elif wr >= -20: return -1.0 # OB/OS
        if wr < -50: return 0.4;    elif wr > -50: return -0.4 # Approaching midpoint
        return 0.0

    def _check_psar(self) -> float:
        psar_l = self.indicator_values.get("PSAR_long"); psar_s = self.indicator_values.get("PSAR_short")
        # PSAR values are prices, check if they are finite numbers if not NaN
        l_act = pd.notna(psar_l) and np.isfinite(psar_l)
        s_act = pd.notna(psar_s) and np.isfinite(psar_s)
        if l_act and not s_act: return 1.0 # Long trend
        elif s_act and not l_act: return -1.0 # Short trend
        elif not l_act and not s_act: return np.nan # Indeterminate / Start of data
        else: self.logger.warning(f"PSAR check unusual state: Long={psar_l}, Short={psar_s}"); return 0.0 # Both active? Error state.

    def _check_sma_10(self) -> float:
        sma = self.indicator_values.get("SMA10") # Float
        close = self.indicator_values.get("Close") # Decimal
        if not (isinstance(sma, (float, int)) and np.isfinite(sma) and
                isinstance(close, Decimal) and close.is_finite()): return np.nan
        try: sma_dec = Decimal(str(sma))
        except: return np.nan # Failed conversion
        if close > sma_dec: return 0.6
        elif close < sma_dec: return -0.6
        else: return 0.0

    def _check_vwap(self) -> float:
        vwap = self.indicator_values.get("VWAP") # Float
        close = self.indicator
```python
# xrscalper.py
# Merged and enhanced version derived from livexy.py and incorporating concepts from ScalpingBot,
# focusing on robust stop-loss/take-profit mechanisms, including break-even and exchange-native trailing stops.

import hashlib
import hmac
import json
import logging
import math
import os
import time
from datetime import datetime
from decimal import Decimal, ROUND_DOWN, ROUND_UP, getcontext
from logging.handlers import RotatingFileHandler
from typing import Any, Dict, Optional, Tuple, List

import ccxt
import numpy as np
import pandas as pd
import pandas_ta as ta # Import pandas_ta
import requests
from colorama import Fore, Style, init
from dotenv import load_dotenv
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from zoneinfo import ZoneInfo

# Initialize colorama and set precision
getcontext().prec = 28  # Increased precision for calculations
init(autoreset=True)
load_dotenv()

# Neon Color Scheme
NEON_GREEN = Fore.LIGHTGREEN_EX
NEON_BLUE = Fore.CYAN
NEON_PURPLE = Fore.MAGENTA
NEON_YELLOW = Fore.YELLOW
NEON_RED = Fore.LIGHTRED_EX
NEON_CYAN = Fore.CYAN
RESET = Style.RESET_ALL

# --- Constants ---
API_KEY = os.getenv("BYBIT_API_KEY")
API_SECRET = os.getenv("BYBIT_API_SECRET")
if not API_KEY or not API_SECRET:
    raise ValueError("BYBIT_API_KEY and BYBIT_API_SECRET must be set in .env")

CONFIG_FILE = "config.json"
LOG_DIRECTORY = "bot_logs"
# Timezone for logging and display
TIMEZONE = ZoneInfo("America/Chicago") # Adjust as needed
MAX_API_RETRIES = 3 # Max retries for recoverable API errors
RETRY_DELAY_SECONDS = 5 # Delay between retries
VALID_INTERVALS = ["1", "3", "5", "15", "30", "60", "120", "240", "D", "W", "M"] # Intervals supported by the bot's logic
CCXT_INTERVAL_MAP = { # Map our intervals to ccxt's expected format
    "1": "1m", "3": "3m", "5": "5m", "15": "15m", "30": "30m",
    "60": "1h", "120": "2h", "240": "4h", "D": "1d", "W": "1w", "M": "1M"
}
RETRY_ERROR_CODES = [429, 500, 502, 503, 504] # HTTP status codes considered retryable
# Default periods (can be overridden by config.json)
DEFAULT_ATR_PERIOD = 14
DEFAULT_CCI_WINDOW = 20
DEFAULT_WILLIAMS_R_WINDOW = 14
DEFAULT_MFI_WINDOW = 14
DEFAULT_STOCH_RSI_WINDOW = 14 # Window for Stoch RSI calculation itself
DEFAULT_STOCH_WINDOW = 12     # Window for underlying RSI in StochRSI
DEFAULT_K_WINDOW = 3          # K period for StochRSI
DEFAULT_D_WINDOW = 3          # D period for StochRSI
DEFAULT_RSI_WINDOW = 14
DEFAULT_BOLLINGER_BANDS_PERIOD = 20
DEFAULT_BOLLINGER_BANDS_STD_DEV = 2.0 # Ensure float
DEFAULT_SMA_10_WINDOW = 10
DEFAULT_EMA_SHORT_PERIOD = 9
DEFAULT_EMA_LONG_PERIOD = 21
DEFAULT_MOMENTUM_PERIOD = 7
DEFAULT_VOLUME_MA_PERIOD = 15
DEFAULT_FIB_WINDOW = 50
DEFAULT_PSAR_AF = 0.02
DEFAULT_PSAR_MAX_AF = 0.2

FIB_LEVELS = [0.0, 0.236, 0.382, 0.5, 0.618, 0.786, 1.0] # Standard Fibonacci levels
LOOP_DELAY_SECONDS = 10 # Time between the end of one cycle and the start of the next
POSITION_CONFIRM_DELAY_SECONDS = 8 # Wait time after placing order before confirming position
# QUOTE_CURRENCY dynamically loaded from config

os.makedirs(LOG_DIRECTORY, exist_ok=True)


class SensitiveFormatter(logging.Formatter):
    """Formatter to redact sensitive information (API keys) from logs."""
    def format(self, record: logging.LogRecord) -> str:
        msg = super().format(record)
        if API_KEY:
            msg = msg.replace(API_KEY, "***API_KEY***")
        if API_SECRET:
            msg = msg.replace(API_SECRET, "***API_SECRET***")
        return msg


def load_config(filepath: str) -> Dict[str, Any]:
    """Load configuration from JSON file, creating default if not found,
       and ensuring all default keys are present."""
    default_config = {
        "interval": "5", # Default to '5' (map to 5m later)
        "retry_delay": 5,
        "atr_period": DEFAULT_ATR_PERIOD,
        "ema_short_period": DEFAULT_EMA_SHORT_PERIOD,
        "ema_long_period": DEFAULT_EMA_LONG_PERIOD,
        "rsi_period": DEFAULT_RSI_WINDOW,
        "bollinger_bands_period": DEFAULT_BOLLINGER_BANDS_PERIOD,
        "bollinger_bands_std_dev": DEFAULT_BOLLINGER_BANDS_STD_DEV,
        "cci_window": DEFAULT_CCI_WINDOW,
        "williams_r_window": DEFAULT_WILLIAMS_R_WINDOW,
        "mfi_window": DEFAULT_MFI_WINDOW,
        "stoch_rsi_window": DEFAULT_STOCH_RSI_WINDOW,
        "stoch_rsi_rsi_window": DEFAULT_STOCH_WINDOW,
        "stoch_rsi_k": DEFAULT_K_WINDOW,
        "stoch_rsi_d": DEFAULT_D_WINDOW,
        "psar_af": DEFAULT_PSAR_AF,
        "psar_max_af": DEFAULT_PSAR_MAX_AF,
        "sma_10_window": DEFAULT_SMA_10_WINDOW,
        "momentum_period": DEFAULT_MOMENTUM_PERIOD,
        "volume_ma_period": DEFAULT_VOLUME_MA_PERIOD,
        "orderbook_limit": 25, # Depth of orderbook to fetch
        "signal_score_threshold": 1.5, # Score needed to trigger BUY/SELL signal
        "stoch_rsi_oversold_threshold": 25,
        "stoch_rsi_overbought_threshold": 75,
        "stop_loss_multiple": 1.8, # ATR multiple for initial SL (used for sizing)
        "take_profit_multiple": 0.7, # ATR multiple for TP
        "volume_confirmation_multiplier": 1.5, # How much higher volume needs to be than MA
        "scalping_signal_threshold": 2.5, # Separate threshold for 'scalping' weight set
        "fibonacci_window": DEFAULT_FIB_WINDOW,
        "enable_trading": False, # SAFETY FIRST: Default to False, enable consciously
        "use_sandbox": True,     # SAFETY FIRST: Default to True (testnet), disable consciously
        "risk_per_trade": 0.01, # Risk 1% of account balance per trade
        "leverage": 20,          # Set desired leverage (check exchange limits)
        "max_concurrent_positions": 1, # Limit open positions for this symbol
        "quote_currency": "USDT", # Currency for balance check and sizing
        "entry_order_type": "market", # "market" or "limit"
        "limit_order_offset_buy": 0.0005, # Percentage offset from current price for BUY limit orders (e.g., 0.0005 = 0.05%)
        "limit_order_offset_sell": 0.0005, # Percentage offset from current price for SELL limit orders (e.g., 0.0005 = 0.05%)

        # --- Trailing Stop Loss Config (Exchange-Native) ---
        "enable_trailing_stop": True,           # Default to enabling TSL (exchange TSL)
        "trailing_stop_callback_rate": 0.005,   # e.g., 0.5% trail distance (as decimal) from high water mark
        "trailing_stop_activation_percentage": 0.003, # e.g., Activate TSL when price moves 0.3% in favor from entry (set to 0 for immediate activation)

        # --- Break-Even Stop Config ---
        "enable_break_even": True,              # Enable moving SL to break-even
        "break_even_trigger_atr_multiple": 1.0, # Move SL when profit >= X * ATR
        "break_even_offset_ticks": 2,           # Place BE SL X ticks beyond entry price (in profit direction)

        # --- Position Management ---
        "position_confirm_delay_seconds": POSITION_CONFIRM_DELAY_SECONDS, # Delay after order before checking position status
        "time_based_exit_minutes": None, # Optional: Exit position after X minutes (e.g., 60). Set to None or 0 to disable.

        # --- Indicator Control ---
        "indicators": { # Control which indicators are calculated and contribute to score
            "ema_alignment": True, "momentum": True, "volume_confirmation": True,
            "stoch_rsi": True, "rsi": True, "bollinger_bands": True, "vwap": True,
            "cci": True, "wr": True, "psar": True, "sma_10": True, "mfi": True,
            "orderbook": True, # Flag to enable fetching and scoring orderbook data
        },
        "weight_sets": { # Define different weighting strategies
            "scalping": { # Example weighting for a fast scalping strategy
                "ema_alignment": 0.2, "momentum": 0.3, "volume_confirmation": 0.2,
                "stoch_rsi": 0.6, "rsi": 0.2, "bollinger_bands": 0.3, "vwap": 0.4,
                "cci": 0.3, "wr": 0.3, "psar": 0.2, "sma_10": 0.1, "mfi": 0.2, "orderbook": 0.15,
            },
            "default": { # A more balanced weighting strategy
                "ema_alignment": 0.3, "momentum": 0.2, "volume_confirmation": 0.1,
                "stoch_rsi": 0.4, "rsi": 0.3, "bollinger_bands": 0.2, "vwap": 0.3,
                "cci": 0.2, "wr": 0.2, "psar": 0.3, "sma_10": 0.1, "mfi": 0.2, "orderbook": 0.1,
            }
        },
        "active_weight_set": "default" # Choose which weight set to use ("default" or "scalping")
    }

    if not os.path.exists(filepath):
        try:
            with open(filepath, "w", encoding="utf-8") as f:
                json.dump(default_config, f, indent=4)
            print(f"{NEON_YELLOW}Created default config file: {filepath}{RESET}")
            return default_config
        except IOError as e:
            print(f"{NEON_RED}Error creating default config file {filepath}: {e}{RESET}")
            return default_config # Return default if creation failed

    try:
        with open(filepath, encoding="utf-8") as f:
            config_from_file = json.load(f)
        # Ensure all keys from default are present, add missing ones
        updated_config = _ensure_config_keys(config_from_file, default_config)
        # If updates were made, write them back
        if updated_config != config_from_file:
             try:
                 with open(filepath, "w", encoding="utf-8") as f_write:
                    json.dump(updated_config, f_write, indent=4)
                 print(f"{NEON_YELLOW}Updated config file with missing default keys: {filepath}{RESET}")
             except IOError as e:
                 print(f"{NEON_RED}Error writing updated config file {filepath}: {e}{RESET}")

        # Validate crucial values after loading/updating
        if updated_config.get("interval") not in VALID_INTERVALS:
            print(f"{NEON_RED}Invalid interval '{updated_config.get('interval')}' found in config. Using default '{default_config['interval']}'.{RESET}")
            updated_config["interval"] = default_config["interval"]
            # Save back the corrected interval
            try:
                 with open(filepath, "w", encoding="utf-8") as f_write:
                    json.dump(updated_config, f_write, indent=4)
                 print(f"{NEON_YELLOW}Corrected invalid interval in config file: {filepath}{RESET}")
            except IOError as e:
                 print(f"{NEON_RED}Error writing corrected interval to config file {filepath}: {e}{RESET}")
        if updated_config.get("entry_order_type") not in ["market", "limit"]:
             print(f"{NEON_RED}Invalid entry_order_type '{updated_config.get('entry_order_type')}' in config. Using default 'market'.{RESET}")
             updated_config["entry_order_type"] = "market"
             # Save back the corrected type
             try:
                 with open(filepath, "w", encoding="utf-8") as f_write:
                    json.dump(updated_config, f_write, indent=4)
                 print(f"{NEON_YELLOW}Corrected invalid entry_order_type in config file: {filepath}{RESET}")
             except IOError as e:
                 print(f"{NEON_RED}Error writing corrected entry_order_type to config file {filepath}: {e}{RESET}")

        return updated_config
    except (FileNotFoundError, json.JSONDecodeError) as e:
        print(f"{NEON_RED}Error loading config file {filepath}: {e}. Using default config.{RESET}")
        try:
            # Attempt to recreate default if loading failed badly
            with open(filepath, "w", encoding="utf-8") as f:
                json.dump(default_config, f, indent=4)
            print(f"{NEON_YELLOW}Created default config file: {filepath}{RESET}")
        except IOError as e_create:
             print(f"{NEON_RED}Error creating default config file after load error: {e_create}{RESET}")
        return default_config # Return default


def _ensure_config_keys(config: Dict[str, Any], default_config: Dict[str, Any]) -> Dict[str, Any]:
    """Recursively ensures all keys from the default config are present in the loaded config."""
    updated_config = config.copy()
    for key, default_value in default_config.items():
        if key not in updated_config:
            updated_config[key] = default_value
        elif isinstance(default_value, dict) and isinstance(updated_config.get(key), dict):
            # Recursively check nested dictionaries
            updated_config[key] = _ensure_config_keys(updated_config[key], default_value)
        # Optional: Check type consistency for non-dict items if needed
        # elif not isinstance(updated_config.get(key), type(default_value)):
        #     print(f"Warning: Config type mismatch for key '{key}'. Expected {type(default_value)}, got {type(updated_config.get(key))}. Using default.")
        #     updated_config[key] = default_value
    return updated_config

CONFIG = load_config(CONFIG_FILE)
QUOTE_CURRENCY = CONFIG.get("quote_currency", "USDT") # Get quote currency from config

# --- Logger Setup ---
def setup_logger(symbol: str) -> logging.Logger:
    """Sets up a logger for the given symbol with file and console handlers."""
    safe_symbol = symbol.replace('/', '_').replace(':', '-')
    logger_name = f"xrscalper_bot_{safe_symbol}"
    log_filename = os.path.join(LOG_DIRECTORY, f"{logger_name}.log")
    logger = logging.getLogger(logger_name)

    # Prevent duplicate handlers if logger already exists
    if logger.hasHandlers():
        return logger

    logger.setLevel(logging.DEBUG) # Set logger level to DEBUG to capture all messages

    # File Handler (writes DEBUG level and above)
    try:
        file_handler = RotatingFileHandler(
            log_filename, maxBytes=10 * 1024 * 1024, backupCount=5, encoding='utf-8'
        )
        # Use SensitiveFormatter for file logs as well
        file_formatter = SensitiveFormatter("%(asctime)s - %(levelname)s - [%(name)s:%(lineno)d] - %(message)s")
        file_handler.setFormatter(file_formatter)
        file_handler.setLevel(logging.DEBUG) # Log everything to file
        logger.addHandler(file_handler)
    except Exception as e:
        print(f"Error setting up file logger for {log_filename}: {e}")

    # Stream Handler (Console - writes INFO level and above by default)
    stream_handler = logging.StreamHandler()
    stream_formatter = SensitiveFormatter(
        f"{NEON_BLUE}%(asctime)s{RESET} - {NEON_YELLOW}%(levelname)-8s{RESET} - {NEON_PURPLE}[%(name)s]{RESET} - %(message)s",
        datefmt='%Y-%m-%d %H:%M:%S %Z' # Include Timezone
    )
    stream_formatter.converter = lambda *args: datetime.now(TIMEZONE).timetuple() # Use local timezone for console display
    stream_handler.setFormatter(stream_formatter)
    console_log_level = logging.INFO # Change to DEBUG for more verbose console output
    stream_handler.setLevel(console_log_level)
    logger.addHandler(stream_handler)

    logger.propagate = False # Prevent messages from propagating to the root logger
    return logger

# --- CCXT Exchange Setup ---
def initialize_exchange(logger: logging.Logger) -> Optional[ccxt.Exchange]:
    """Initializes the CCXT Bybit exchange object with error handling."""
    try:
        exchange_options = {
            'apiKey': API_KEY,
            'secret': API_SECRET,
            'enableRateLimit': True,
            'options': {
                'defaultType': 'linear', # Default to linear for USDT perpetuals
                'adjustForTimeDifference': True,
                # Increased timeouts for robustness
                'fetchTickerTimeout': 10000, # 10 seconds
                'fetchBalanceTimeout': 15000, # 15 seconds
                'createOrderTimeout': 20000, # 20 seconds
                'cancelOrderTimeout': 15000, # 15 seconds
                'fetchPositionsTimeout': 15000, # 15 seconds
                'fetchOHLCVTimeout': 15000, # 15 seconds
            }
        }

        # Dynamically select the exchange class based on config if needed, default Bybit
        exchange_id = CONFIG.get("exchange_id", "bybit").lower()
        if not hasattr(ccxt, exchange_id):
             logger.error(f"Exchange ID '{exchange_id}' not found in CCXT.")
             return None
        exchange_class = getattr(ccxt, exchange_id)
        exchange = exchange_class(exchange_options)

        if CONFIG.get('use_sandbox'):
            logger.warning(f"{NEON_YELLOW}USING SANDBOX MODE (Testnet){RESET}")
            # Check if the exchange supports sandbox mode setting
            if hasattr(exchange, 'set_sandbox_mode'):
                exchange.set_sandbox_mode(True)
            else:
                logger.warning(f"{exchange.id} does not support set_sandbox_mode via ccxt. Ensure API keys are for Testnet.")
                # Attempt to set URLs manually if known (example for Bybit)
                if exchange.id == 'bybit':
                     exchange.urls['api'] = 'https://api-testnet.bybit.com'


        logger.info(f"Loading markets for {exchange.id}...")
        exchange.load_markets()
        logger.info(f"CCXT exchange initialized ({exchange.id}). Sandbox: {CONFIG.get('use_sandbox')}")

        # Test connection and API keys by fetching balance
        account_type_to_test = 'CONTRACT' # For Bybit V5, try CONTRACT or UNIFIED
        logger.info(f"Attempting initial balance fetch (Account Type: {account_type_to_test})...")
        try:
            # Use params suitable for the specific exchange (e.g., Bybit V5)
            params = {}
            if exchange.id == 'bybit':
                 params={'type': account_type_to_test}

            balance = exchange.fetch_balance(params=params)
            available_quote = balance.get(QUOTE_CURRENCY, {}).get('free', 'N/A')
            logger.info(f"{NEON_GREEN}Successfully connected and fetched initial balance.{RESET} (Example: {QUOTE_CURRENCY} available: {available_quote})")

        except ccxt.AuthenticationError as auth_err:
             logger.error(f"{NEON_RED}CCXT Authentication Error during initial balance fetch: {auth_err}{RESET}")
             logger.error(f"{NEON_RED}>> Ensure API keys are correct, have necessary permissions (Read, Trade), match the account type (Real/Testnet), and IP whitelist is correctly set if enabled on the exchange.{RESET}")
             return None
        except ccxt.ExchangeError as balance_err:
             logger.warning(f"{NEON_YELLOW}Exchange error during initial balance fetch ({account_type_to_test}): {balance_err}. Trying default fetch...{RESET}")
             # Fallback to default fetch_balance call
             try:
                  balance = exchange.fetch_balance()
                  available_quote = balance.get(QUOTE_CURRENCY, {}).get('free', 'N/A')
                  logger.info(f"{NEON_GREEN}Successfully fetched balance using default parameters.{RESET} (Example: {QUOTE_CURRENCY} available: {available_quote})")
             except Exception as fallback_err:
                  logger.warning(f"{NEON_YELLOW}Default balance fetch also failed: {fallback_err}. Check API permissions/account type.{RESET}")
        except Exception as balance_err:
             # Catch other potential errors like network issues during balance fetch
             logger.warning(f"{NEON_YELLOW}Could not perform initial balance fetch: {balance_err}. Check API permissions/account type/network.{RESET}")

        return exchange

    except ccxt.AuthenticationError as e:
        # This catches auth errors during the initial exchange class instantiation
        logger.error(f"{NEON_RED}CCXT Authentication Error during initialization: {e}{RESET}")
        logger.error(f"{NEON_RED}>> Check API Key/Secret format and validity in your .env file.{RESET}")
    except ccxt.ExchangeError as e:
        logger.error(f"{NEON_RED}CCXT Exchange Error initializing: {e}{RESET}")
    except ccxt.NetworkError as e:
        logger.error(f"{NEON_RED}CCXT Network Error initializing: {e}{RESET}")
    except Exception as e:
        logger.error(f"{NEON_RED}Failed to initialize CCXT exchange: {e}{RESET}", exc_info=True)

    return None


# --- CCXT Data Fetching (Adapted from livexy.py) ---
def fetch_current_price_ccxt(exchange: ccxt.Exchange, symbol: str, logger: logging.Logger) -> Optional[Decimal]:
    """Fetch the current price of a trading symbol using CCXT ticker with fallbacks."""
    lg = logger
    attempts = 0
    while attempts <= MAX_API_RETRIES:
        try:
            lg.debug(f"Fetching ticker for {symbol}... (Attempt {attempts + 1})")
            ticker = exchange.fetch_ticker(symbol)
            lg.debug(f"Ticker data for {symbol}: {ticker}")

            price = None
            # Prioritize 'last', then mid-price, then ask/bid
            last_price = ticker.get('last')
            bid_price = ticker.get('bid')
            ask_price = ticker.get('ask')

            if last_price is not None:
                try:
                    p = Decimal(str(last_price))
                    if p > 0: price = p; lg.debug(f"Using 'last' price: {p}")
                except Exception: lg.warning(f"Invalid 'last' price format: {last_price}")

            if price is None and bid_price is not None and ask_price is not None:
                try:
                    bid = Decimal(str(bid_price))
                    ask = Decimal(str(ask_price))
                    if bid > 0 and ask > 0 and ask >= bid:
                        price = (bid + ask) / 2 # Midpoint
                        lg.debug(f"Using bid/ask midpoint: {price}")
                    elif ask > 0: # If only ask is valid (e.g., thin book)
                         price = ask
                         lg.debug(f"Using 'ask' price (bid invalid): {price}")
                    elif bid > 0: # If only bid is valid
                         price = bid
                         lg.debug(f"Using 'bid' price (ask invalid): {price}")
                except Exception: lg.warning(f"Invalid bid/ask format: {bid_price}, {ask_price}")

            # Fallbacks if midpoint failed or wasn't available
            if price is None and ask_price is not None:
                 try:
                      p = Decimal(str(ask_price));
                      if p > 0: price = p; lg.warning(f"Using 'ask' price fallback: {p}")
                 except Exception: lg.warning(f"Invalid 'ask' price format: {ask_price}")

            if price is None and bid_price is not None:
                 try:
                      p = Decimal(str(bid_price));
                      if p > 0: price = p; lg.warning(f"Using 'bid' price fallback: {p}")
                 except Exception: lg.warning(f"Invalid 'bid' price format: {bid_price}")

            # Final validation
            if price is not None and price > 0:
                return price
            else:
                lg.warning(f"Failed to get a valid price from ticker data on attempt {attempts + 1}.")
                # Continue to retry logic

        except (ccxt.NetworkError, ccxt.RequestTimeout, requests.exceptions.ConnectionError, requests.exceptions.Timeout) as e:
            lg.warning(f"{NEON_YELLOW}Network error fetching price for {symbol}: {e}. Retrying...{RESET}")
        except ccxt.RateLimitExceeded as e:
            lg.warning(f"{NEON_YELLOW}Rate limit exceeded fetching price: {e}. Waiting longer...{RESET}")
            # Apply a longer delay specifically for rate limit errors
            time.sleep(RETRY_DELAY_SECONDS * 5)
            attempts += 1 # Consume an attempt
            continue # Skip standard delay
        except ccxt.ExchangeError as e:
            lg.error(f"{NEON_RED}Exchange error fetching price for {symbol}: {e}{RESET}")
            # Decide if retryable based on error message/code if needed
            # For now, assume most exchange errors aren't retryable for fetching price
            return None
        except Exception as e:
            lg.error(f"{NEON_RED}Unexpected error fetching price for {symbol}: {e}{RESET}", exc_info=True)
            return None # Don't retry unexpected errors

        # Standard delay before next attempt
        attempts += 1
        if attempts <= MAX_API_RETRIES:
            time.sleep(RETRY_DELAY_SECONDS)

    lg.error(f"{NEON_RED}Failed to fetch a valid current price for {symbol} after {MAX_API_RETRIES + 1} attempts.{RESET}")
    return None

def fetch_klines_ccxt(exchange: ccxt.Exchange, symbol: str, timeframe: str, limit: int = 250, logger: logging.Logger = None) -> pd.DataFrame:
    """Fetch OHLCV kline data using CCXT with retries and basic validation."""
    lg = logger or logging.getLogger(__name__) # Use provided logger or default
    try:
        # Check if the exchange supports fetching OHLCV data
        if not exchange.has['fetchOHLCV']:
             lg.error(f"Exchange {exchange.id} does not support fetchOHLCV.")
             return pd.DataFrame()

        ohlcv = None
        for attempt in range(MAX_API_RETRIES + 1):
             try:
                  lg.debug(f"Fetching klines for {symbol}, {timeframe}, limit={limit} (Attempt {attempt+1}/{MAX_API_RETRIES + 1})")
                  # Fetch the data
                  ohlcv = exchange.fetch_ohlcv(symbol, timeframe=timeframe, limit=limit)

                  # Basic check if data was returned
                  if ohlcv is not None and isinstance(ohlcv, list): # Ensure it's a list
                    # Optional: Check if list is not empty
                    # if not ohlcv:
                    #    lg.warning(f"fetch_ohlcv returned an empty list for {symbol} (Attempt {attempt+1}). Retrying...")
                    # else:
                    break # Success
                  else:
                    lg.warning(f"fetch_ohlcv returned invalid data (None or not list) for {symbol} (Attempt {attempt+1}). Retrying...")

             except (ccxt.NetworkError, ccxt.RequestTimeout, requests.exceptions.ConnectionError, requests.exceptions.Timeout) as e:
                  if attempt < MAX_API_RETRIES:
                      lg.warning(f"Network error fetching klines for {symbol} (Attempt {attempt + 1}): {e}. Retrying in {RETRY_DELAY_SECONDS}s...")
                      time.sleep(RETRY_DELAY_SECONDS)
                  else:
                      lg.error(f"{NEON_RED}Max retries reached fetching klines for {symbol} after network errors.{RESET}")
                      raise e # Re-raise the last error
             except ccxt.RateLimitExceeded as e:
                 # Use a longer delay for rate limits
                 wait_time = RETRY_DELAY_SECONDS * 5
                 lg.warning(f"Rate limit exceeded fetching klines for {symbol}. Retrying in {wait_time}s... (Attempt {attempt+1})")
                 time.sleep(wait_time)
             except ccxt.ExchangeError as e:
                 # Non-network/rate-limit errors from the exchange
                 lg.error(f"{NEON_RED}Exchange error fetching klines for {symbol}: {e}{RESET}")
                 # Consider if specific exchange errors are retryable, otherwise raise
                 # Example: Bad symbol error should not be retried
                 if "symbol" in str(e).lower(): raise e
                 if attempt < MAX_API_RETRIES: time.sleep(RETRY_DELAY_SECONDS)
                 else: raise e # Re-raise after retries
             except Exception as e:
                # Catch any other unexpected error during the fetch attempt
                lg.error(f"{NEON_RED}Unexpected error during kline fetch attempt {attempt+1} for {symbol}: {e}{RESET}", exc_info=True)
                if attempt < MAX_API_RETRIES: time.sleep(RETRY_DELAY_SECONDS)
                else: raise e # Re-raise after retries


        # After the loop, check if we successfully got data
        if not ohlcv or not isinstance(ohlcv, list):
            lg.warning(f"{NEON_YELLOW}No valid kline data returned for {symbol} {timeframe} after retries.{RESET}")
            return pd.DataFrame()

        # Process the data into a pandas DataFrame
        df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])

        # Basic validation of the DataFrame structure
        if df.empty:
             lg.warning(f"{NEON_YELLOW}Kline data DataFrame is empty for {symbol} {timeframe}.{RESET}")
             return df

        # Convert timestamp to datetime objects
        # Use errors='coerce' to handle potential conversion errors gracefully
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms', errors='coerce')
        # Drop rows where timestamp conversion failed
        df.dropna(subset=['timestamp'], inplace=True)
        # Set timestamp as index
        df.set_index('timestamp', inplace=True)

        # Convert price/volume columns to numeric, coercing errors to NaN
        for col in ['open', 'high', 'low', 'close', 'volume']:
            df[col] = pd.to_numeric(df[col], errors='coerce')

        # Data Cleaning: Drop rows with NaN in essential price columns or zero close price
        initial_len = len(df)
        df.dropna(subset=['open', 'high', 'low', 'close'], inplace=True)
        # Ensure close price is positive (relevant for log returns, some indicators)
        df = df[df['close'] > 0]
        rows_dropped = initial_len - len(df)
        if rows_dropped > 0:
             lg.debug(f"Dropped {rows_dropped} rows with NaN/invalid price data for {symbol}.")

        # Check if DataFrame became empty after cleaning
        if df.empty:
             lg.warning(f"{NEON_YELLOW}Kline data for {symbol} {timeframe} empty after cleaning.{RESET}")
             return pd.DataFrame()

        # Sort by timestamp index to ensure chronological order
        df.sort_index(inplace=True)

        lg.info(f"Successfully fetched and processed {len(df)} klines for {symbol} {timeframe}")
        return df

    # Catch errors that occur outside the retry loop (e.g., during DataFrame processing)
    except ccxt.NetworkError as e:
        # This might be hit if the initial check for fetchOHLCV fails due to network
        lg.error(f"{NEON_RED}Network error occurred during kline processing for {symbol}: {e}{RESET}")
    except ccxt.ExchangeError as e:
        lg.error(f"{NEON_RED}Exchange error occurred during kline processing for {symbol}: {e}{RESET}")
    except Exception as e:
        lg.error(f"{NEON_RED}Unexpected error processing klines for {symbol}: {e}{RESET}", exc_info=True)

    # Return an empty DataFrame in case of any caught exception during processing
    return pd.DataFrame()


def fetch_orderbook_ccxt(exchange: ccxt.Exchange, symbol: str, limit: int, logger: logging.Logger) -> Optional[Dict]:
    """Fetch orderbook data using ccxt with retries and basic validation."""
    lg = logger
    attempts = 0
    while attempts <= MAX_API_RETRIES:
        try:
            # Check if the exchange supports fetching order book data
            if not exchange.has['fetchOrderBook']:
                 lg.error(f"Exchange {exchange.id} does not support fetchOrderBook.")
                 return None

            lg.debug(f"Fetching order book for {symbol}, limit={limit} (Attempt {attempts+1}/{MAX_API_RETRIES + 1})")
            orderbook = exchange.fetch_order_book(symbol, limit=limit)

            # Validate the received orderbook structure
            if not orderbook:
                lg.warning(f"fetch_order_book returned None/empty for {symbol} (Attempt {attempts+1}).")
            elif not isinstance(orderbook, dict):
                 lg.warning(f"{NEON_YELLOW}Invalid orderbook type received for {symbol}. Expected dict, got {type(orderbook)}. Attempt {attempts + 1}.{RESET}")
            elif 'bids' not in orderbook or 'asks' not in orderbook:
                 lg.warning(f"{NEON_YELLOW}Invalid orderbook structure for {symbol}: missing 'bids' or 'asks'. Attempt {attempts + 1}. Response keys: {list(orderbook.keys())}{RESET}")
            elif not isinstance(orderbook['bids'], list) or not isinstance(orderbook['asks'], list):
                 lg.warning(f"{NEON_YELLOW}Invalid orderbook structure for {symbol}: 'bids' or 'asks' are not lists. Attempt {attempts + 1}. bids type: {type(orderbook['bids'])}, asks type: {type(orderbook['asks'])}{RESET}")
            elif not orderbook['bids'] and not orderbook['asks']:
                 # It's possible to receive an empty book, especially on inactive markets
                 lg.warning(f"{NEON_YELLOW}Orderbook received but bids and asks lists are both empty for {symbol}. (Attempt {attempts + 1}).{RESET}")
                 return orderbook # Return the empty but validly structured book
            else:
                 # Basic validation passed
                 lg.debug(f"Successfully fetched orderbook for {symbol} with {len(orderbook['bids'])} bids, {len(orderbook['asks'])} asks.")
                 # Optional: Deeper validation (check price/size format)
                 # for i, bid in enumerate(orderbook['bids']):
                 #     if not (isinstance(bid, list) and len(bid) == 2 and isinstance(bid[0], (float, int)) and isinstance(bid[1], (float, int))):
                 #          lg.warning(f"Invalid bid format at index {i}: {bid}")
                 #          # Handle error or continue
                 # for i, ask in enumerate(orderbook['asks']):
                 #      if not (isinstance(ask, list) and len(ask) == 2 and isinstance(ask[0], (float, int)) and isinstance(ask[1], (float, int))):
                 #          lg.warning(f"Invalid ask format at index {i}: {ask}")
                 #          # Handle error or continue
                 return orderbook

        # Handle specific CCXT exceptions
        except (ccxt.NetworkError, ccxt.RequestTimeout, requests.exceptions.ConnectionError, requests.exceptions.Timeout) as e:
            lg.warning(f"{NEON_YELLOW}Orderbook fetch network error for {symbol}: {e}. Retrying...{RESET}")
        except ccxt.RateLimitExceeded as e:
            wait_time = RETRY_DELAY_SECONDS * 5 # Longer wait for rate limits
            lg.warning(f"Rate limit exceeded fetching orderbook for {symbol}. Retrying in {wait_time}s...")
            time.sleep(wait_time)
            attempts += 1 # Consume attempt
            continue # Skip standard delay
        except ccxt.ExchangeError as e:
            lg.error(f"{NEON_RED}Exchange error fetching orderbook for {symbol}: {e}{RESET}")
            # Decide if retryable based on error message/code
            # Example: Bad symbol should not be retried
            if "symbol" in str(e).lower(): return None
            # Otherwise, retry for potential temporary exchange issues
        except Exception as e:
            lg.error(f"{NEON_RED}Unexpected error fetching orderbook for {symbol}: {e}{RESET}", exc_info=True)
            # Decide whether to retry unexpected errors or not
            # For now, let's not retry these by default
            return None

        # Standard delay before next attempt
        attempts += 1
        if attempts <= MAX_API_RETRIES:
             time.sleep(RETRY_DELAY_SECONDS)

    lg.error(f"{NEON_RED}Max retries reached fetching orderbook for {symbol}.{RESET}")
    return None

# --- Trading Analyzer Class (Using pandas_ta) ---
class TradingAnalyzer:
    """Analyzes trading data using pandas_ta and generates weighted signals."""

    def __init__(
        self,
        df: pd.DataFrame,
        logger: logging.Logger,
        config: Dict[str, Any],
        market_info: Dict[str, Any],
    ) -> None:
        """
        Initializes the TradingAnalyzer.

        Args:
            df: Pandas DataFrame with OHLCV data, indexed by timestamp.
            logger: Logger instance for logging messages.
            config: Dictionary containing bot configuration.
            market_info: Dictionary containing market details (precision, limits, etc.).
        """
        self.df = df
        self.logger = logger
        self.config = config
        self.market_info = market_info
        self.symbol = market_info.get('symbol', 'UNKNOWN_SYMBOL')
        # Get interval from config, default to '5' if missing
        self.interval = config.get("interval", "5")
        # Map to CCXT format, handle missing mapping
        self.ccxt_interval = CCXT_INTERVAL_MAP.get(self.interval)
        if not self.ccxt_interval:
             self.logger.error(f"Invalid interval '{self.interval}' in config, cannot map to CCXT timeframe. Defaulting calculation logic if possible, but fetching will fail.")
             # Handle fallback or raise error depending on desired behavior
             # For now, let it proceed but log the error.

        # Stores latest calculated indicator values (float or Decimal)
        self.indicator_values: Dict[str, Any] = {}
        # Stores binary signal states (BUY:1, SELL:1, HOLD:1) - only one can be 1
        self.signals: Dict[str, int] = {"BUY": 0, "SELL": 0, "HOLD": 1} # Default HOLD
        # Get the name of the active weight set from config
        self.active_weight_set_name = config.get("active_weight_set", "default")
        # Get the actual weight dictionary for the active set
        self.weights = config.get("weight_sets",{}).get(self.active_weight_set_name, {})
        # Stores calculated Fibonacci levels
        self.fib_levels_data: Dict[str, Decimal] = {}
        # Stores the actual column names generated by pandas_ta for mapping
        self.ta_column_names: Dict[str, Optional[str]] = {}

        if not self.weights:
             logger.error(f"Active weight set '{self.active_weight_set_name}' not found or empty in config for {self.symbol}.")
             # Handle this case, maybe use default weights or stop

        # Perform initial calculations upon instantiation
        self._calculate_all_indicators()
        self._update_latest_indicator_values()
        self.calculate_fibonacci_levels() # Calculate Fib levels based on initial data


    def _get_ta_col_name(self, base_name: str, result_df: pd.DataFrame) -> Optional[str]:
        """
        Helper to find the actual column name generated by pandas_ta based on common patterns.

        Args:
            base_name: The conceptual name of the indicator (e.g., "ATR", "EMA_Short").
            result_df: The DataFrame containing the calculated indicator columns.

        Returns:
            The actual column name if found, otherwise None.
        """
        # Define expected patterns for pandas_ta column names
        # These might need adjustment based on pandas_ta version and parameters used
        expected_patterns = {
            "ATR": [f"ATRr_{self.config.get('atr_period', DEFAULT_ATR_PERIOD)}"],
            "EMA_Short": [f"EMA_{self.config.get('ema_short_period', DEFAULT_EMA_SHORT_PERIOD)}"],
            "EMA_Long": [f"EMA_{self.config.get('ema_long_period', DEFAULT_EMA_LONG_PERIOD)}"],
            "Momentum": [f"MOM_{self.config.get('momentum_period', DEFAULT_MOMENTUM_PERIOD)}"],
            "CCI": [f"CCI_{self.config.get('cci_window', DEFAULT_CCI_WINDOW)}"], # May have suffix like _100.0
            "Williams_R": [f"WILLR_{self.config.get('williams_r_window', DEFAULT_WILLIAMS_R_WINDOW)}"],
            "MFI": [f"MFI_{self.config.get('mfi_window', DEFAULT_MFI_WINDOW)}"],
            "VWAP": ["VWAP_D"], # Often includes anchor like 'D' for daily
            "PSAR_long": [f"PSARl_{self.config.get('psar_af', DEFAULT_PSAR_AF)}_{self.config.get('psar_max_af', DEFAULT_PSAR_MAX_AF)}"],
            "PSAR_short": [f"PSARs_{self.config.get('psar_af', DEFAULT_PSAR_AF)}_{self.config.get('psar_max_af', DEFAULT_PSAR_MAX_AF)}"],
            "SMA10": [f"SMA_{self.config.get('sma_10_window', DEFAULT_SMA_10_WINDOW)}"],
            # StochRSI patterns can vary, try common ones
            "StochRSI_K": [
                f"STOCHRSIk_{self.config.get('stoch_rsi_window', DEFAULT_STOCH_RSI_WINDOW)}_{self.config.get('stoch_rsi_rsi_window', DEFAULT_STOCH_WINDOW)}_{self.config.get('stoch_rsi_k', DEFAULT_K_WINDOW)}",
                f"STOCHRSIk_{self.config.get('stoch_rsi_window', DEFAULT_STOCH_RSI_WINDOW)}" # Simpler fallback
            ],
            "StochRSI_D": [
                f"STOCHRSId_{self.config.get('stoch_rsi_window', DEFAULT_STOCH_RSI_WINDOW)}_{self.config.get('stoch_rsi_rsi_window', DEFAULT_STOCH_WINDOW)}_{self.config.get('stoch_rsi_k', DEFAULT_K_WINDOW)}_{self.config.get('stoch_rsi_d', DEFAULT_D_WINDOW)}",
                 f"STOCHRSId_{self.config.get('stoch_rsi_window', DEFAULT_STOCH_RSI_WINDOW)}" # Simpler fallback
            ],
            "RSI": [f"RSI_{self.config.get('rsi_period', DEFAULT_RSI_WINDOW)}"],
            # BBands patterns often include std dev
            "BB_Lower": [
                f"BBL_{self.config.get('bollinger_bands_period', DEFAULT_BOLLINGER_BANDS_PERIOD)}_{float(self.config.get('bollinger_bands_std_dev', DEFAULT_BOLLINGER_BANDS_STD_DEV)):.1f}",
                f"BBL_{self.config.get('bollinger_bands_period', DEFAULT_BOLLINGER_BANDS_PERIOD)}" # Simpler fallback
            ],
            "BB_Middle": [
                f"BBM_{self.config.get('bollinger_bands_period', DEFAULT_BOLLINGER_BANDS_PERIOD)}_{float(self.config.get('bollinger_bands_std_dev', DEFAULT_BOLLINGER_BANDS_STD_DEV)):.1f}",
                f"BBM_{self.config.get('bollinger_bands_period', DEFAULT_BOLLINGER_BANDS_PERIOD)}"
            ],
            "BB_Upper": [
                f"BBU_{self.config.get('bollinger_bands_period', DEFAULT_BOLLINGER_BANDS_PERIOD)}_{float(self.config.get('bollinger_bands_std_dev', DEFAULT_BOLLINGER_BANDS_STD_DEV)):.1f}",
                f"BBU_{self.config.get('bollinger_bands_period', DEFAULT_BOLLINGER_BANDS_PERIOD)}"
            ],
            "Volume_MA": [f"VOL_SMA_{self.config.get('volume_ma_period', DEFAULT_VOLUME_MA_PERIOD)}"] # Custom name used in calc
        }

        patterns = expected_patterns.get(base_name, [])
        # Search dataframe columns for a match starting with any pattern
        for col in result_df.columns:
             for pattern in patterns:
                 # Use startswith for flexibility (e.g., CCI might have CCI_20_100.0)
                 if col.startswith(pattern):
                     self.logger.debug(f"Mapped '{base_name}' to column '{col}'")
                     return col

        # Fallback: Simple substring search (less reliable but might catch variations)
        for col in result_df.columns:
            # Make search case-insensitive and handle simple names
            if base_name.lower() in col.lower():
                self.logger.debug(f"Found column '{col}' for base '{base_name}' using fallback substring search.")
                return col

        self.logger.warning(f"Could not find column name for indicator '{base_name}' in DataFrame columns: {result_df.columns.tolist()}")
        return None


    def _calculate_all_indicators(self):
        """Calculates all enabled indicators using pandas_ta and stores column names."""
        if self.df.empty:
            self.logger.warning(f"{NEON_YELLOW}DataFrame is empty, cannot calculate indicators for {self.symbol}.{RESET}")
            return

        # --- Check Sufficient Data Length ---
        # Create a list of required periods based on enabled indicators in config
        required_periods = []
        indicators_config = self.config.get("indicators", {})
        if indicators_config.get("atr_period"): required_periods.append(self.config.get("atr_period", DEFAULT_ATR_PERIOD))
        if indicators_config.get("ema_alignment"):
            required_periods.append(self.config.get("ema_short_period", DEFAULT_EMA_SHORT_PERIOD))
            required_periods.append(self.config.get("ema_long_period", DEFAULT_EMA_LONG_PERIOD))
        if indicators_config.get("momentum"): required_periods.append(self.config.get("momentum_period", DEFAULT_MOMENTUM_PERIOD))
        if indicators_config.get("cci"): required_periods.append(self.config.get("cci_window", DEFAULT_CCI_WINDOW))
        if indicators_config.get("wr"): required_periods.append(self.config.get("williams_r_window", DEFAULT_WILLIAMS_R_WINDOW))
        if indicators_config.get("mfi"): required_periods.append(self.config.get("mfi_window", DEFAULT_MFI_WINDOW))
        # VWAP doesn't have a standard period parameter in basic ta.vwap
        # PSAR doesn't have a length period
        if indicators_config.get("sma_10"): required_periods.append(self.config.get("sma_10_window", DEFAULT_SMA_10_WINDOW))
        if indicators_config.get("stoch_rsi"):
            required_periods.append(self.config.get("stoch_rsi_window", DEFAULT_STOCH_RSI_WINDOW))
            required_periods.append(self.config.get("stoch_rsi_rsi_window", DEFAULT_STOCH_WINDOW))
            # K and D periods are applied after StochRSI calc, so main windows are limiting factors
        if indicators_config.get("rsi"): required_periods.append(self.config.get("rsi_period", DEFAULT_RSI_WINDOW))
        if indicators_config.get("bollinger_bands"): required_periods.append(self.config.get("bollinger_bands_period", DEFAULT_BOLLINGER_BANDS_PERIOD))
        if indicators_config.get("volume_confirmation"): required_periods.append(self.config.get("volume_ma_period", DEFAULT_VOLUME_MA_PERIOD))
        # Fibonacci window for price range, not strictly an indicator period but needs data
        required_periods.append(self.config.get("fibonacci_window", DEFAULT_FIB_WINDOW))

        # Determine minimum data length needed (max period + some buffer)
        min_required_data = max(required_periods) + 20 if required_periods else 50 # Default min 50 if no periods found

        if len(self.df) < min_required_data:
             self.logger.warning(f"{NEON_YELLOW}Insufficient data ({len(self.df)} points) for {self.symbol} to calculate all indicators reliably (min recommended: {min_required_data}). Results may contain NaNs.{RESET}")
             # Continue calculation, but expect potential issues

        try:
            # Work on a copy to avoid modifying the original DataFrame passed to the class
            df_calc = self.df.copy()

            # --- Always calculate ATR as it's crucial for SL/TP/Sizing ---
            atr_period = self.config.get("atr_period", DEFAULT_ATR_PERIOD)
            # Use pandas_ta's atr method
            df_calc.ta.atr(length=atr_period, append=True)
            # Find and store the actual column name generated by ta.atr
            self.ta_column_names["ATR"] = self._get_ta_col_name("ATR", df_calc)
            # --- Calculate indicators based on config ---
            if indicators_config.get("ema_alignment", False):
                ema_short = self.config.get("ema_short_period", DEFAULT_EMA_SHORT_PERIOD)
                ema_long = self.config.get("ema_long_period", DEFAULT_EMA_LONG_PERIOD)
                df_calc.ta.ema(length=ema_short, append=True)
                self.ta_column_names["EMA_Short"] = self._get_ta_col_name("EMA_Short", df_calc)
                df_calc.ta.ema(length=ema_long, append=True)
                self.ta_column_names["EMA_Long"] = self._get_ta_col_name("EMA_Long", df_calc)

            if indicators_config.get("momentum", False):
                mom_period = self.config.get("momentum_period", DEFAULT_MOMENTUM_PERIOD)
                df_calc.ta.mom(length=mom_period, append=True)
                self.ta_column_names["Momentum"] = self._get_ta_col_name("Momentum", df_calc)

            if indicators_config.get("cci", False):
                cci_period = self.config.get("cci_window", DEFAULT_CCI_WINDOW)
                # Note: pandas_ta might add a constant suffix like '_100.0'
                df_calc.ta.cci(length=cci_period, append=True)
                self.ta_column_names["CCI"] = self._get_ta_col_name("CCI", df_calc)

            if indicators_config.get("wr", False):
                wr_period = self.config.get("williams_r_window", DEFAULT_WILLIAMS_R_WINDOW)
                df_calc.ta.willr(length=wr_period, append=True)
                self.ta_column_names["Williams_R"] = self._get_ta_col_name("Williams_R", df_calc)

            if indicators_config.get("mfi", False):
                mfi_period = self.config.get("mfi_window", DEFAULT_MFI_WINDOW)
                df_calc.ta.mfi(length=mfi_period, append=True)
                self.ta_column_names["MFI"] = self._get_ta_col_name("MFI", df_calc)

            if indicators_config.get("vwap", False):
                # Standard VWAP often anchors daily ('D'). Ensure your data covers enough time.
                # If using intraday data, VWAP might reset daily or calculate cumulatively.
                # pandas_ta's default might be daily anchored. Check behavior if needed.
                df_calc.ta.vwap(append=True) # Use default settings first
                self.ta_column_names["VWAP"] = self._get_ta_col_name("VWAP", df_calc)

            if indicators_config.get("psar", False):
                psar_af = self.config.get("psar_af", DEFAULT_PSAR_AF)
                psar_max_af = self.config.get("psar_max_af", DEFAULT_PSAR_MAX_AF)
                # psar returns a DataFrame with multiple columns (long, short, af, reversal)
                psar_result = df_calc.ta.psar(af=psar_af, max_af=psar_max_af)
                if psar_result is not None and not psar_result.empty:
                    # Concatenate the results back to the main calculation DataFrame
                    df_calc = pd.concat([df_calc, psar_result], axis=1)
                    # Get the column names for long and short PSAR signals
                    self.ta_column_names["PSAR_long"] = self._get_ta_col_name("PSAR_long", df_calc)
                    self.ta_column_names["PSAR_short"] = self._get_ta_col_name("PSAR_short", df_calc)

            if indicators_config.get("sma_10", False):
                sma10_period = self.config.get("sma_10_window", DEFAULT_SMA_10_WINDOW)
                df_calc.ta.sma(length=sma10_period, append=True)
                self.ta_column_names["SMA10"] = self._get_ta_col_name("SMA10", df_calc)

            if indicators_config.get("stoch_rsi", False):
                stoch_rsi_len = self.config.get("stoch_rsi_window", DEFAULT_STOCH_RSI_WINDOW)
                stoch_rsi_rsi_len = self.config.get("stoch_rsi_rsi_window", DEFAULT_STOCH_WINDOW)
                stoch_rsi_k = self.config.get("stoch_rsi_k", DEFAULT_K_WINDOW)
                stoch_rsi_d = self.config.get("stoch_rsi_d", DEFAULT_D_WINDOW)
                # stochrsi returns a DataFrame with K and D columns
                stochrsi_result = df_calc.ta.stochrsi(length=stoch_rsi_len, rsi_length=stoch_rsi_rsi_len, k=stoch_rsi_k, d=stoch_rsi_d)
                if stochrsi_result is not None and not stochrsi_result.empty:
                     df_calc = pd.concat([df_calc, stochrsi_result], axis=1)
                     # Get the specific column names for K and D
                     self.ta_column_names["StochRSI_K"] = self._get_ta_col_name("StochRSI_K", df_calc)
                     self.ta_column_names["StochRSI_D"] = self._get_ta_col_name("StochRSI_D", df_calc)

            if indicators_config.get("rsi", False):
                rsi_period = self.config.get("rsi_period", DEFAULT_RSI_WINDOW)
                df_calc.ta.rsi(length=rsi_period, append=True)
                self.ta_column_names["RSI"] = self._get_ta_col_name("RSI", df_calc)

            if indicators_config.get("bollinger_bands", False):
                bb_period = self.config.get("bollinger_bands_period", DEFAULT_BOLLINGER_BANDS_PERIOD)
                # Ensure std_dev is float for pandas_ta
                bb_std = float(self.config.get("bollinger_bands_std_dev", DEFAULT_BOLLINGER_BANDS_STD_DEV))
                # bbands returns a DataFrame with lower, middle, upper, bandwidth, percent
                bbands_result = df_calc.ta.bbands(length=bb_period, std=bb_std)
                if bbands_result is not None and not bbands_result.empty:
                    # Concatenate results back
                    df_calc = pd.concat([df_calc, bbands_result], axis=1)
                    # Get column names for lower, middle, upper bands
                    self.ta_column_names["BB_Lower"] = self._get_ta_col_name("BB_Lower", df_calc)
                    self.ta_column_names["BB_Middle"] = self._get_ta_col_name("BB_Middle", df_calc)
                    self.ta_column_names["BB_Upper"] = self._get_ta_col_name("BB_Upper", df_calc)

            if indicators_config.get("volume_confirmation", False):
                vol_ma_period = self.config.get("volume_ma_period", DEFAULT_VOLUME_MA_PERIOD)
                # Use a distinct name for the volume MA column
                vol_ma_col_name = f"VOL_SMA_{vol_ma_period}"
                # Calculate SMA on the 'volume' column, filling potential NaNs with 0 for calculation
                df_calc[vol_ma_col_name] = ta.sma(df_calc['volume'].fillna(0), length=vol_ma_period)
                # Store the custom column name
                self.ta_column_names["Volume_MA"] = vol_ma_col_name

            # Update the instance's DataFrame with the calculated indicators
            self.df = df_calc
            self.logger.debug(f"Finished indicator calculations for {self.symbol}. Final DF columns: {self.df.columns.tolist()}")

        except AttributeError as e:
             # This can happen if pandas_ta methods are called incorrectly or on incompatible data
             self.logger.error(f"{NEON_RED}AttributeError calculating indicators for {self.symbol}: {e}{RESET}. Check pandas_ta usage and data.", exc_info=True)
        except Exception as e:
            # Catch any other unexpected errors during calculation
            self.logger.error(f"{NEON_RED}Error calculating indicators with pandas_ta for {self.symbol}: {e}{RESET}", exc_info=True)


    def _update_latest_indicator_values(self):
        """Updates the indicator_values dict with the latest (most recent) values from self.df."""
        if self.df.empty:
            self.logger.warning(f"Cannot update latest values: DataFrame empty for {self.symbol}.")
            # Initialize with NaNs if empty
            self.indicator_values = {k: np.nan for k in list(self.ta_column_names.keys()) + ["Close", "Volume", "High", "Low", "Open"]}
            return
        if self.df.iloc[-1].isnull().all():
            self.logger.warning(f"Cannot update latest values: Last row contains all NaNs for {self.symbol}.")
            # Initialize with NaNs if last row is unusable
            self.indicator_values = {k: np.nan for k in list(self.ta_column_names.keys()) + ["Close", "Volume", "High", "Low", "Open"]}
            return

        try:
            # Get the last row (most recent data)
            latest = self.df.iloc[-1]
            updated_values = {}

            # --- Process TA indicator columns stored in ta_column_names ---
            for key, col_name in self.ta_column_names.items():
                if col_name and col_name in latest.index:
                    value = latest[col_name]
                    # Check if the value is valid (not NaN)
                    if pd.notna(value):
                        try:
                            # Store ATR as Decimal for precision in SL/TP calculations
                            if key == "ATR":
                                updated_values[key] = Decimal(str(value))
                            # Store most other indicators as float for general use in scoring
                            else:
                                updated_values[key] = float(value)
                        except (ValueError, TypeError) as conv_err:
                            self.logger.warning(f"Could not convert value for {key} ('{col_name}': {value}) for {self.symbol}. Storing NaN. Error: {conv_err}")
                            updated_values[key] = np.nan
                    else:
                        # Store NaN if the value in the DataFrame is NaN
                        updated_values[key] = np.nan
                else:
                    # Log if the column was expected but not found
                    if key in self.ta_column_names: # Only log if calculation was attempted
                        self.logger.debug(f"Indicator column '{col_name}' for key '{key}' not found in latest data row for {self.symbol}. Storing NaN.")
                    updated_values[key] = np.nan

            # --- Add essential price/volume data as Decimal for precision ---
            # These are directly from the OHLCV data, not calculated indicators via TA
            for base_col in ['open', 'high', 'low', 'close', 'volume']:
                 key_name = base_col.capitalize() # e.g., 'Open', 'Close'
                 value = latest.get(base_col) # Use .get() for safety if column might be missing
                 if pd.notna(value):
                      try:
                           updated_values[key_name] = Decimal(str(value))
                      except (ValueError, TypeError) as conv_err:
                           self.logger.warning(f"Could not convert base value for '{base_col}' ({value}) to Decimal for {self.symbol}. Storing NaN. Error: {conv_err}")
                           updated_values[key_name] = np.nan
                 else:
                      updated_values[key_name] = np.nan # Store NaN if base value is missing/NaN

            # Update the instance's dictionary
            self.indicator_values = updated_values

            # --- Log the updated values (formatted for readability) ---
            # Create a dictionary for logging, formatting Decimals and floats appropriately
            valid_values_log = {}
            for k, v in self.indicator_values.items():
                 if pd.notna(v):
                     if isinstance(v, Decimal):
                          # Determine precision for logging (more for price/ATR, less for volume?)
                          # Use market price precision for price-related values
                          prec = self.get_price_precision() if k in ['Open','High','Low','Close','ATR'] else 6
                          # Avoid scientific notation for small numbers if possible, format nicely
                          valid_values_log[k] = f"{v:.{prec}f}"
                     elif isinstance(v, float):
                          # Format floats with reasonable precision for indicators
                          valid_values_log[k] = f"{v:.5f}"
                     else: # Handle other types if necessary (e.g., strings, though unlikely here)
                          valid_values_log[k] = str(v)
                 # Optionally include NaN values in the log
                 # else:
                 #     valid_values_log[k] = "NaN"

            self.logger.debug(f"Latest indicator values updated for {self.symbol}: {valid_values_log}")

        except IndexError:
             # This error occurs if the DataFrame is empty or iloc[-1] fails
             self.logger.error(f"Error accessing latest row (iloc[-1]) for {self.symbol}. DataFrame might be empty or too short after cleaning.")
             # Reset to NaNs if access fails
             self.indicator_values = {k: np.nan for k in list(self.ta_column_names.keys()) + ["Close", "Volume", "High", "Low", "Open"]}
        except Exception as e:
             # Catch any other unexpected errors during the update process
             self.logger.error(f"Unexpected error updating latest indicator values for {self.symbol}: {e}", exc_info=True)
             # Reset to NaNs as a safety measure
             self.indicator_values = {k: np.nan for k in list(self.ta_column_names.keys()) + ["Close", "Volume", "High", "Low", "Open"]}

    # --- Fibonacci Calculation ---
    def calculate_fibonacci_levels(self, window: Optional[int] = None) -> Dict[str, Decimal]:
        """
        Calculates Fibonacci retracement levels based on the high/low over a specified window.
        Uses Decimal for precision. Stores results in self.fib_levels_data.

        Args:
            window: The number of recent periods (candles) to consider for high/low.
                    Defaults to the value in config['fibonacci_window'].

        Returns:
            A dictionary where keys are Fibonacci level names (e.g., "Fib_23.6%")
            and values are the corresponding price levels as Decimal objects.
            Returns an empty dictionary if calculation is not possible.
        """
        # Use provided window or get from config, falling back to default
        window = window or self.config.get("fibonacci_window", DEFAULT_FIB_WINDOW)

        # Check if DataFrame is long enough for the window
        if len(self.df) < window:
            self.logger.debug(f"Not enough data ({len(self.df)} points) for Fibonacci window ({window}) on {self.symbol}.")
            self.fib_levels_data = {} # Clear any previous data
            return {}

        # Get the relevant slice of the DataFrame
        df_slice = self.df.tail(window)

        try:
            # Find the maximum high and minimum low in the window, drop NaNs first
            high_price_raw = df_slice["high"].dropna().max()
            low_price_raw = df_slice["low"].dropna().min()

            # Check if valid high/low prices were found
            if pd.isna(high_price_raw) or pd.isna(low_price_raw):
                 self.logger.warning(f"Could not find valid high/low prices within the last {window} periods for Fibonacci calculation on {self.symbol}.")
                 self.fib_levels_data = {}
                 return {}

            # Convert raw high/low to Decimal
            high = Decimal(str(high_price_raw))
            low = Decimal(str(low_price_raw))

            # Calculate the difference (range)
            diff = high - low

            # Initialize the levels dictionary
            levels = {}
            # Get market price precision for rounding
            price_precision = self.get_price_precision()
            # Create a Decimal quantizer based on precision (e.g., '0.01' for 2 decimal places)
            rounding_factor = Decimal('1e-' + str(price_precision))

            # Check if there's a valid range (high > low)
            if diff > 0:
                # Calculate each Fibonacci level
                for level_pct in FIB_LEVELS:
                    level_name = f"Fib_{level_pct * 100:.1f}%"
                    # Calculate level price: High - (Range * Percentage)
                    level_price = high - (diff * Decimal(str(level_pct)))
                    # Quantize the calculated price to the market's tick size/precision
                    # Use ROUND_DOWN for levels based on range from high (conservative support)
                    level_price_quantized = level_price.quantize(rounding_factor, rounding=ROUND_DOWN)
                    levels[level_name] = level_price_quantized
            else:
                 # Handle case where high == low (no range)
                 self.logger.debug(f"Fibonacci range is zero or negative (High={high}, Low={low}) for {self.symbol} over last {window} periods. All levels set to High/Low.")
                 # Quantize the single price level
                 level_price_quantized = high.quantize(rounding_factor, rounding=ROUND_DOWN)
                 # Assign this price to all levels
                 for level_pct in FIB_LEVELS:
                     levels[f"Fib_{level_pct * 100:.1f}%"] = level_price_quantized

            # Store the calculated levels in the instance variable
            self.fib_levels_data = levels
            # Log the calculated levels (convert Decimals to strings for logging)
            log_levels = {k: str(v) for k, v in levels.items()}
            self.logger.debug(f"Calculated Fibonacci levels for {self.symbol} (Window: {window}): {log_levels}")
            return levels

        except KeyError as e:
             self.logger.error(f"{NEON_RED}Fibonacci calculation error for {self.symbol}: Missing column '{e}'. Ensure 'high' and 'low' columns exist.{RESET}")
             self.fib_levels_data = {}
             return {}
        except Exception as e:
            # Catch any other unexpected errors
            self.logger.error(f"{NEON_RED}Unexpected Fibonacci calculation error for {self.symbol}: {e}{RESET}", exc_info=True)
            self.fib_levels_data = {}
            return {}


    def get_price_precision(self) -> int:
        """
        Determines the number of decimal places required for price values
        based on the market information provided by the exchange.

        Uses 'precision' and 'limits' fields from the market info.
        Falls back to inferring from the last close price or a default value.

        Returns:
            The number of decimal places (integer).
        """
        try:
            # 1. Check 'precision.price' (most common field)
            precision_info = self.market_info.get('precision', {})
            price_precision_val = precision_info.get('price')

            if price_precision_val is not None:
                 # If it's an integer, it usually represents decimal places directly
                 if isinstance(price_precision_val, int):
                      if price_precision_val >= 0:
                           self.logger.debug(f"Using price precision (decimal places) from market_info.precision.price: {price_precision_val}")
                           return price_precision_val
                 # If it's float/str, it often represents the tick size
                 elif isinstance(price_precision_val, (float, str)):
                      try:
                           tick_size = Decimal(str(price_precision_val))
                           # Ensure tick size is positive
                           if tick_size > 0:
                                # Calculate decimal places from tick size
                                # normalize() removes trailing zeros, as_tuple().exponent gives the exponent
                                precision = abs(tick_size.normalize().as_tuple().exponent)
                                self.logger.debug(f"Calculated price precision from market_info.precision.price (tick size {tick_size}): {precision}")
                                return precision
                      except Exception as e:
                           self.logger.warning(f"Could not parse precision.price '{price_precision_val}' as tick size: {e}")

            # 2. Fallback: Check 'limits.price.min' (sometimes represents tick size)
            limits_info = self.market_info.get('limits', {})
            price_limits = limits_info.get('price', {})
            min_price_val = price_limits.get('min')

            if min_price_val is not None:
                 try:
                      min_price_tick = Decimal(str(min_price_val))
                      if min_price_tick > 0:
                           # Heuristic: Check if min_price looks like a tick size (small value)
                           # rather than just a minimum orderable price (e.g., 0.1).
                           # Tick sizes are usually << 1. Adjust threshold if needed.
                           if min_price_tick < Decimal('0.1'):
                                precision = abs(min_price_tick.normalize().as_tuple().exponent)
                                self.logger.debug(f"Inferred price precision from limits.price.min ({min_price_tick}): {precision}")
                                return precision
                           else:
                                self.logger.debug(f"limits.price.min ({min_price_tick}) seems too large for tick size, likely minimum order price. Ignoring for precision.")
                 except Exception as e:
                      self.logger.warning(f"Could not parse limits.price.min '{min_price_val}' for precision inference: {e}")

            # 3. Fallback: Infer from the last known close price's decimal places
            # This is less reliable as prices can fluctuate (e.g., 10.0 vs 10.123)
            last_close = self.indicator_values.get("Close") # Uses Decimal value if available
            if last_close and isinstance(last_close, Decimal) and last_close > 0:
                 try:
                      # Get the number of decimal places from the Decimal object
                      precision = abs(last_close.normalize().as_tuple().exponent)
                      self.logger.debug(f"Inferring price precision from last close price ({last_close}) as {precision} for {self.symbol}.")
                      # Add a small sanity check - avoid excessively high precision from weird prices
                      if precision < 10: # Arbitrary sanity limit
                           return precision
                      else:
                           self.logger.warning(f"Inferred precision {precision} from last close price seems too high. Skipping.")
                 except Exception as e:
                     self.logger.warning(f"Could not infer precision from last close price {last_close}: {e}")

        except Exception as e:
            self.logger.warning(f"Error determining price precision for {self.symbol} from market info: {e}. Falling back.")

        # --- Final Fallback ---
        # Use a reasonable default if no other method worked
        default_precision = 4 # Common default, adjust if needed for your typical markets
        self.logger.warning(f"Could not determine price precision for {self.symbol}. Using default: {default_precision}.")
        return default_precision


    def get_min_tick_size(self) -> Decimal:
        """
        Gets the minimum price increment (tick size) from market info using Decimal.

        Returns:
            The minimum tick size as a Decimal object. Falls back based on precision.
        """
        try:
            # 1. Try precision.price (often the tick size as float/str)
            precision_info = self.market_info.get('precision', {})
            price_precision_val = precision_info.get('price')
            if price_precision_val is not None:
                 if isinstance(price_precision_val, (float, str)):
                      try:
                           tick_size = Decimal(str(price_precision_val))
                           if tick_size > 0:
                                self.logger.debug(f"Using tick size from precision.price: {tick_size} for {self.symbol}")
                                return tick_size
                      except Exception as e:
                            self.logger.warning(f"Could not parse precision.price '{price_precision_val}' as tick size: {e}")
                 # If it's an integer (decimal places), calculate tick size
                 elif isinstance(price_precision_val, int) and price_precision_val >= 0:
                      tick_size = Decimal('1e-' + str(price_precision_val))
                      self.logger.debug(f"Calculated tick size from precision.price (decimal places {price_precision_val}): {tick_size} for {self.symbol}")
                      return tick_size

            # 2. Fallback: Try limits.price.min (sometimes represents tick size)
            limits_info = self.market_info.get('limits', {})
            price_limits = limits_info.get('price', {})
            min_price_val = price_limits.get('min')
            if min_price_val is not None:
                try:
                    min_tick_from_limit = Decimal(str(min_price_val))
                    if min_tick_from_limit > 0:
                        # Heuristic check: if it's very small, assume it's the tick size
                        if min_tick_from_limit < Decimal('0.1'):
                             self.logger.debug(f"Using tick size from limits.price.min: {min_tick_from_limit} for {self.symbol}")
                             return min_tick_from_limit
                        else:
                             self.logger.debug(f"limits.price.min ({min_tick_from_limit}) seems too large for tick size, potentially min order price.")
                except Exception as e:
                    self.logger.warning(f"Could not parse limits.price.min '{min_price_val}' for tick size inference: {e}")

        except Exception as e:
             self.logger.warning(f"Could not determine min tick size for {self.symbol} from market info: {e}. Using precision fallback.")

        # --- Final Fallback: Calculate from get_price_precision (decimal places) ---
        price_precision_places = self.get_price_precision()
        fallback_tick = Decimal('1e-' + str(price_precision_places))
        self.logger.debug(f"Using fallback tick size based on derived precision places ({price_precision_places}): {fallback_tick} for {self.symbol}")
        return fallback_tick


    def get_nearest_fibonacci_levels(
        self, current_price: Decimal, num_levels: int = 5
    ) -> list[Tuple[str, Decimal]]:
        """
        Finds the N nearest Fibonacci levels (support and resistance) to the current price.

        Args:
            current_price: The current market price as a Decimal.
            num_levels: The maximum number of nearest levels (combined support/resistance) to return.

        Returns:
            A list of tuples, where each tuple contains (level_name, level_price).
            The list is sorted by proximity to the current price. Returns empty list on error.
        """
        # Check if Fibonacci levels have been calculated
        if not self.fib_levels_data:
            self.logger.debug(f"Fibonacci levels not calculated yet for {self.symbol}. Cannot find nearest.")
            return []
        # Validate input price
        if not isinstance(current_price, Decimal) or pd.isna(current_price) or current_price <= 0:
            self.logger.warning(f"Invalid current price ({current_price}) provided for Fibonacci comparison on {self.symbol}.")
            return []

        try:
            level_distances = []
            # Iterate through the calculated Fibonacci levels
            for name, level_price in self.fib_levels_data.items():
                # Ensure the level price is a valid Decimal
                if isinstance(level_price, Decimal) and level_price > 0:
                    # Calculate the absolute distance between current price and level price
                    distance = abs(current_price - level_price)
                    # Store name, price, and distance
                    level_distances.append({'name': name, 'level': level_price, 'distance': distance})
                else:
                     self.logger.warning(f"Invalid or non-decimal value found in fib_levels_data: {name}={level_price}. Skipping.")

            # Sort the levels based on their distance to the current price (ascending)
            level_distances.sort(key=lambda x: x['distance'])

            # Return the top N nearest levels as (name, price) tuples
            return [(item['name'], item['level']) for item in level_distances[:num_levels]]

        except Exception as e:
            self.logger.error(f"{NEON_RED}Error finding nearest Fibonacci levels for {self.symbol}: {e}{RESET}", exc_info=True)
            return []

    # --- EMA Alignment Calculation ---
    def calculate_ema_alignment_score(self) -> float:
        """
        Calculates EMA alignment score based on the latest EMA_Short, EMA_Long, and Close price.

        Returns:
             1.0 if Price > EMA_Short > EMA_Long (Strong Bullish Alignment)
            -1.0 if Price < EMA_Short < EMA_Long (Strong Bearish Alignment)
             0.0 otherwise (Mixed or Crossing)
             np.nan if any required value is missing.
        """
        # Retrieve latest values (should be floats or NaN)
        ema_short = self.indicator_values.get("EMA_Short")
        ema_long = self.indicator_values.get("EMA_Long")
        # Retrieve Close price (should be Decimal or NaN) and convert to float for comparison
        close_decimal = self.indicator_values.get("Close")
        current_price_float = float(close_decimal) if isinstance(close_decimal, Decimal) else np.nan

        # Check if all necessary values are available and valid numbers
        if pd.isna(ema_short) or pd.isna(ema_long) or pd.isna(current_price_float):
            self.logger.debug("EMA alignment check skipped: Missing required values (EMA_Short, EMA_Long, or Close).")
            return np.nan # Return NaN if data is missing

        # Check for bullish alignment
        if current_price_float > ema_short > ema_long:
            return 1.0
        # Check for bearish alignment
        elif current_price_float < ema_short < ema_long:
            return -1.0
        # Otherwise, EMAs are crossed or price is between them (neutral/mixed alignment)
        else:
            return 0.0


    # --- Signal Generation & Scoring ---
    def generate_trading_signal(
        self, current_price: Decimal, orderbook_data: Optional[Dict]
    ) -> str:
        """
        Generates a final trading signal (BUY/SELL/HOLD) based on a weighted score
        from various enabled indicator checks.

        Args:
            current_price: The current market price (Decimal).
            orderbook_data: Optional order book data dictionary from fetch_orderbook_ccxt.

        Returns:
            "BUY", "SELL", or "HOLD" string signal.
        """
        # Reset signal states
        self.signals = {"BUY": 0, "SELL": 0, "HOLD": 1} # Default to HOLD
        final_signal_score = Decimal("0.0")
        total_weight_applied = Decimal("0.0")
        active_indicator_count = 0
        nan_indicator_count = 0
        debug_scores = {} # For detailed logging

        # --- Pre-checks ---
        if not self.indicator_values:
             self.logger.warning(f"{NEON_YELLOW}Cannot generate signal for {self.symbol}: Indicator values dictionary is empty.{RESET}")
             return "HOLD"
        # Check if at least one core indicator has a valid value
        core_indicators_present = any(
            pd.notna(v) for k, v in self.indicator_values.items()
            if k not in ['Open', 'High', 'Low', 'Close', 'Volume'] # Exclude raw OHLCV
        )
        if not core_indicators_present:
            self.logger.warning(f"{NEON_YELLOW}Cannot generate signal for {self.symbol}: All core indicator values are NaN.{RESET}")
            return "HOLD"
        # Check current price validity
        if pd.isna(current_price) or not isinstance(current_price, Decimal) or current_price <= 0:
             self.logger.warning(f"{NEON_YELLOW}Cannot generate signal for {self.symbol}: Invalid current price ({current_price}).{RESET}")
             return "HOLD"

        # Get the active weight set from config
        active_weights = self.config.get("weight_sets", {}).get(self.active_weight_set_name)
        if not active_weights:
             self.logger.error(f"Active weight set '{self.active_weight_set_name}' missing or empty in config for {self.symbol}. Cannot generate signal.")
             return "HOLD"

        # --- Iterate through configured indicators ---
        for indicator_key, enabled in self.config.get("indicators", {}).items():
            # Skip if indicator is disabled in the config
            if not enabled: continue

            # Get the weight for this indicator from the active weight set
            weight_str = active_weights.get(indicator_key)
            # Skip if no weight is defined for this enabled indicator
            if weight_str is None: continue

            try:
                # Convert weight to Decimal, skip if weight is zero
                weight = Decimal(str(weight_str))
                if weight == 0: continue
            except Exception:
                self.logger.warning(f"Invalid weight format '{weight_str}' for indicator '{indicator_key}' in weight set '{self.active_weight_set_name}'. Skipping.")
                continue

            # --- Call the corresponding check method ---
            check_method_name = f"_check_{indicator_key}"
            if hasattr(self, check_method_name) and callable(getattr(self, check_method_name)):
                method_to_call = getattr(self, check_method_name)
                indicator_score_float = np.nan # Initialize score as NaN

                try:
                    # Special case for orderbook check which needs extra data
                    if indicator_key == "orderbook":
                         # Only call if orderbook data is available
                         if orderbook_data:
                             indicator_score_float = method_to_call(orderbook_data, current_price)
                         else:
                             # Log if orderbook indicator is enabled/weighted but data is missing
                              if weight != 0: # Only log if it would have contributed
                                 self.logger.debug(f"Orderbook check skipped for {self.symbol}: No orderbook data provided.")
                    else:
                         # Call standard check methods
                         indicator_score_float = method_to_call() # Expected to return float score or np.nan

                except Exception as e:
                    self.logger.error(f"Error executing indicator check method {check_method_name} for {self.symbol}: {e}", exc_info=True)
                    # Keep score as NaN

                # Store score for debugging, format nicely
                debug_scores[indicator_key] = f"{indicator_score_float:.3f}" if pd.notna(indicator_score_float) else "NaN"

                # --- Aggregate score if valid ---
                if pd.notna(indicator_score_float):
                    try:
                        # Convert float score to Decimal for weighted sum
                        score_decimal = Decimal(str(indicator_score_float))
                        # Clamp score between -1 and 1 before applying weight
                        clamped_score = max(Decimal("-1.0"), min(Decimal("1.0"), score_decimal))
                        # Calculate contribution to final score
                        score_contribution = clamped_score * weight
                        final_signal_score += score_contribution
                        # Track total weight applied for normalization/debugging
                        total_weight_applied += weight
                        active_indicator_count += 1
                    except Exception as calc_err:
                        self.logger.error(f"Error processing score for {indicator_key} (Score: {indicator_score_float}, Weight: {weight}): {calc_err}")
                        nan_indicator_count += 1 # Count as NaN if processing failed
                else:
                    # Count indicators that returned NaN
                    nan_indicator_count += 1
            else:
                # Log warning if a check method is missing for an enabled/weighted indicator
                self.logger.warning(f"Indicator check method '{check_method_name}' not found for enabled/weighted indicator: {indicator_key} ({self.symbol})")


        # --- Determine Final Signal based on Score ---
        final_signal = "HOLD" # Default
        if total_weight_applied == 0:
             self.logger.warning(f"No indicators contributed valid scores to the signal calculation for {self.symbol}. Defaulting to HOLD.")
        else:
            # Normalize score (optional, but can be useful for consistent thresholding)
            # normalized_score = final_signal_score / total_weight_applied if total_weight_applied else Decimal("0.0")
            # Use raw score for thresholding as weights already scale contributions
            threshold_str = self.config.get("signal_score_threshold", "1.5")
            try:
                threshold = Decimal(str(threshold_str))
            except:
                self.logger.warning(f"Invalid signal_score_threshold '{threshold_str}'. Using default 1.5.")
                threshold = Decimal("1.5")

            if final_signal_score >= threshold:
                final_signal = "BUY"
            elif final_signal_score <= -threshold:
                final_signal = "SELL"
            # else: final_signal remains "HOLD"

        # --- Log Summary ---
        price_prec = self.get_price_precision()
        log_msg = (
            f"Signal Summary ({self.symbol} @ {current_price:.{price_prec}f}): "
            f"Set='{self.active_weight_set_name}', Indicators=[Active:{active_indicator_count}, NaN:{nan_indicator_count}], "
            f"TotalWeight={total_weight_applied:.2f}, "
            f"FinalScore={final_signal_score:.4f} (Threshold: +/-{threshold:.2f}) "
            # Colorize the final signal
            f"==> {NEON_GREEN if final_signal == 'BUY' else NEON_RED if final_signal == 'SELL' else NEON_YELLOW}{final_signal}{RESET}"
        )
        self.logger.info(log_msg)
        # Log detailed scores only at DEBUG level
        self.logger.debug(f"  Indicator Scores ({self.symbol}): {debug_scores}")

        # Update the signals dictionary
        if final_signal == "BUY": self.signals = {"BUY": 1, "SELL": 0, "HOLD": 0}
        elif final_signal == "SELL": self.signals = {"BUY": 0, "SELL": 1, "HOLD": 0}
        else: self.signals = {"BUY": 0, "SELL": 0, "HOLD": 1} # HOLD

        return final_signal


    # --- Indicator Check Methods (returning float score -1.0 to 1.0 or np.nan) ---
    # Each method should access self.indicator_values to get the latest calculated data.

    def _check_ema_alignment(self) -> float:
        """Checks EMA alignment. Requires EMA_Short, EMA_Long, Close."""
        # Check if required values are present (they might be NaN if calc failed)
        if "EMA_Short" not in self.indicator_values or "EMA_Long" not in self.indicator_values:
             self.logger.debug("EMA Alignment check skipped: EMA values not found in indicator_values.")
             return np.nan
        # Delegate to the calculation method which handles NaN checks inside
        return self.calculate_ema_alignment_score()

    def _check_momentum(self) -> float:
        """Checks Momentum indicator."""
        momentum = self.indicator_values.get("Momentum") # Should be float or NaN
        if pd.isna(momentum):
            return np.nan

        # Simple thresholding example (can be refined)
        # Scale momentum to a -1 to 1 range based on some expected magnitude
        # Example: Assume significant momentum is > 0.1 or < -0.1
        threshold = 0.1
        if momentum > threshold:
            return 1.0 # Strong positive momentum
        elif momentum < -threshold:
            return -1.0 # Strong negative momentum
        else:
            # Linearly scale momentum between -threshold and +threshold to -1 and 1
            return momentum / threshold


    def _check_volume_confirmation(self) -> float:
        """Checks if current volume confirms the potential trend."""
        current_volume = self.indicator_values.get("Volume") # Should be Decimal or NaN
        volume_ma_float = self.indicator_values.get("Volume_MA") # Should be float or NaN
        # Get multiplier from config, default to 1.5
        multiplier = float(self.config.get("volume_confirmation_multiplier", 1.5))

        # Check if values are available and valid
        if pd.isna(current_volume) or not isinstance(current_volume, Decimal) or \
           pd.isna(volume_ma_float) or volume_ma_float <= 0:
            return np.nan

        try:
            # Convert Volume MA float to Decimal for comparison
            volume_ma = Decimal(str(volume_ma_float))
            multiplier_decimal = Decimal(str(multiplier))

            # Compare current volume to MA * multiplier
            if current_volume > volume_ma * multiplier_decimal:
                # High volume can confirm trend (positive score, magnitude tunable)
                return 0.7
            elif current_volume < volume_ma / multiplier_decimal:
                # Low volume might indicate lack of confirmation (negative score)
                return -0.4
            else:
                # Neutral volume
                return 0.0
        except Exception as e:
            self.logger.warning(f"Error during volume confirmation check: {e}")
            return np.nan

    def _check_stoch_rsi(self) -> float:
        """Checks Stochastic RSI K and D lines."""
        k = self.indicator_values.get("StochRSI_K") # Float or NaN
        d = self.indicator_values.get("StochRSI_D") # Float or NaN

        if pd.isna(k) or pd.isna(d):
            return np.nan

        # Get thresholds from config
        oversold = float(self.config.get("stoch_rsi_oversold_threshold", 25))
        overbought = float(self.config.get("stoch_rsi_overbought_threshold", 75))

        score = 0.0
        # Oversold condition -> Bullish signal
        if k < oversold and d < oversold:
            score = 1.0
        # Overbought condition -> Bearish signal
        elif k > overbought and d > overbought:
            score = -1.0

        # Consider K/D crossing or relationship for additional nuance
        diff = k - d
        # Significant crossing potential (adjust threshold 5 if needed)
        if abs(diff) > 5:
             if diff > 0: # K crossing above D -> Bullish momentum
                  # Enhance existing score or set if neutral
                  score = max(score, 0.6) if score >= 0 else 0.6
             else: # K crossing below D -> Bearish momentum
                  # Enhance existing score or set if neutral
                  score = min(score, -0.6) if score <= 0 else -0.6
        # Weaker signal if K is just above/below D without strong crossing
        elif k > d :
             score = max(score, 0.2) # Mildly bullish
        elif k < d:
             score = min(score, -0.2) # Mildly bearish

        # Dampen score if in the mid-range (e.g., 40-60), less decisive
        if 40 < k < 60:
            score *= 0.5

        return score

    def _check_rsi(self) -> float:
        """Checks standard RSI."""
        rsi = self.indicator_values.get("RSI") # Float or NaN
        if pd.isna(rsi):
            return np.nan

        # Standard RSI interpretation
        if rsi <= 30: return 1.0   # Oversold -> Strong Buy Signal
        if rsi >= 70: return -1.0  # Overbought -> Strong Sell Signal
        # Intermediate levels for weaker signals
        if rsi < 40: return 0.5   # Approaching Oversold -> Moderate Buy
        if rsi > 60: return -0.5  # Approaching Overbought -> Moderate Sell
        # Mid-range (40-60) - potentially scale score linearly
        if 40 <= rsi <= 60:
             # Scale from 0.0 (at RSI 50) to +/- 0.2 at boundaries 40/60
             return (rsi - 50) / 50.0 # Results in -0.2 at 40, 0 at 50, 0.2 at 60
             # Alternative: Flat zero in mid-range
             # return 0.0
        return 0.0 # Should not be reached if logic covers all ranges


    def _check_cci(self) -> float:
        """Checks Commodity Channel Index (CCI)."""
        cci = self.indicator_values.get("CCI") # Float or NaN
        if pd.isna(cci):
            return np.nan

        # CCI Interpretation (Common thresholds: +/- 100, +/- 200)
        if cci <= -150: return 1.0  # Strongly Oversold -> Buy
        if cci >= 150: return -1.0 # Strongly Overbought -> Sell
        if cci < -80: return 0.6   # Moderately Oversold
        if cci > 80: return -0.6  # Moderately Overbought
        # Consider zero line cross or direction near zero
        if cci > 0: return -0.1  # Weak bearish (above zero)
        if cci < 0: return 0.1   # Weak bullish (below zero)
        return 0.0


    def _check_wr(self) -> float:
        """Checks Williams %R."""
        wr = self.indicator_values.get("Williams_R") # Float or NaN
        if pd.isna(wr):
            return np.nan

        # Williams %R Interpretation (Range -100 to 0)
        # Oversold: -100 to -80 -> Buy Signal
        # Overbought: -20 to 0 -> Sell Signal
        if wr <= -80: return 1.0
        if wr >= -20: return -1.0
        # Intermediate signals
        if wr < -50: return 0.4 # Moving out of oversold potentially
        if wr > -50: return -0.4 # Moving out of overbought potentially
        return 0.0

    def _check_psar(self) -> float:
        """Checks Parabolic SAR (PSAR) trend direction."""
        psar_long_signal = self.indicator_values.get("PSAR_long") # Price if long signal active, else NaN
        psar_short_signal = self.indicator_values.get("PSAR_short") # Price if short signal active, else NaN

        # Check which signal is active (non-NaN)
        long_active = pd.notna(psar_long_signal)
        short_active = pd.notna(psar_short_signal)

        if long_active and not short_active:
            return 1.0 # Uptrend indicated by PSAR
        elif short_active and not long_active:
            return -1.0 # Downtrend indicated by PSAR
        elif not long_active and not short_active:
            # This might happen at the start of data or if calculation failed
            return np.nan
        else:
            # Should not happen with standard PSAR calculation (both active simultaneously)
            self.logger.warning(f"PSAR check encountered unexpected state: Long={psar_long_signal}, Short={psar_short_signal}")
            return 0.0 # Neutral or error state


    def _check_sma_10(self) -> float:
        """Checks price position relative to SMA 10."""
        sma_10 = self.indicator_values.get("SMA10") # Float or NaN
        last_close_decimal = self.indicator_values.get("Close") # Decimal or NaN

        # Convert close to float for comparison, handle NaNs
        last_close_float = float(last_close_decimal) if isinstance(last_close_decimal, Decimal) else np.nan

        if pd.isna(sma_10) or pd.isna(last_close_float):
            return np.nan

        # Simple check: Price above SMA is bullish, below is bearish
        if last_close_float > sma_10:
            return 0.6 # Moderate bullish signal
        elif last_close_float < sma_10:
            return -0.6 # Moderate bearish signal
        else:
            return 0.0 # Price is exactly on SMA


    def _check_vwap(self) -> float:
        """Checks price position relative to VWAP."""
        vwap = self.indicator_values.get("VWAP") # Float or NaN
        last_close_decimal = self.indicator_values.get("Close") # Decimal or NaN

        # Convert close to float for comparison, handle NaNs
        last_close_float = float(last_close_decimal) if isinstance(last_close_decimal, Decimal) else np.nan

        if pd.isna(vwap) or pd.isna(last_close_float):
            return np.nan

        # Price above VWAP is generally considered bullish intraday, below is bearish
        if last_close_float > vwap:
            return 0.7 # Stronger bullish signal than SMA 10 perhaps
        elif last_close_float < vwap:
            return -0.7 # Stronger bearish signal
        else:
            return 0.0


    def _check_mfi(self) -> float:
        """Checks Money Flow Index (MFI)."""
        mfi = self.indicator_values.get("MFI") # Float or NaN
        if pd.isna(mfi):
            return np.nan

        # MFI Interpretation (Similar to RSI, but volume-weighted)
        # Oversold: < 20 -> Buy Signal
        # Overbought: > 80 -> Sell Signal
        if mfi <= 20: return 1.0
        if mfi >= 80: return -1.0
        # Intermediate levels
        if mfi < 40: return 0.4
        if mfi > 60: return -0.4
        return 0.0 # Mid-range


    def _check_bollinger_bands(self) -> float:
        """Checks price position relative to Bollinger Bands."""
        bb_lower = self.indicator_values.get("BB_Lower") # Float or NaN
        bb_middle = self.indicator_values.get("BB_Middle") # Float or NaN
        bb_upper = self.indicator_values.get("BB_Upper") # Float or NaN
        last_close_decimal = self.indicator_values.get("Close") # Decimal or NaN

        # Convert close to float for comparison, handle NaNs
        last_close_float = float(last_close_decimal) if isinstance(last_close_decimal, Decimal) else np.nan

        if pd.isna(bb_lower) or pd.isna(bb_middle) or pd.isna(bb_upper) or pd.isna(last_close_float):
            return np.nan

        # Check if price touches or crosses bands (potential reversal/breakout)
        if last_close_float <= bb_lower:
             # Price at or below lower band -> Potential bounce (Buy signal)
             return 1.0
        if last_close_float >= bb_upper:
             # Price at or above upper band -> Potential pullback (Sell signal)
             return -1.0

        # Check position relative to middle band (often an SMA)
        # Calculate distance relative to band width for scaling
        band_width = bb_upper - bb_lower
        if band_width > 0: # Avoid division by zero if bands collapse
            if last_close_float > bb_middle:
                 # Price above middle band, closer to upper band is less bullish
                 proximity_to_upper = (last_close_float - bb_middle) / (bb_upper - bb_middle) if (bb_upper - bb_middle) > 0 else 0
                 # Scale score from +0.5 (just above middle) down to 0 (near upper)
                 return 0.5 * (1 - proximity_to_upper)
            elif last_close_float < bb_middle:
                 # Price below middle band, closer to lower band is less bearish
                 proximity_to_lower = (bb_middle - last_close_float) / (bb_middle - bb_lower) if (bb_middle - bb_lower) > 0 else 0
                 # Scale score from -0.5 (just below middle) down to 0 (near lower)
                 return -0.5 * (1 - proximity_to_lower)
        # If price is exactly on middle band or bands collapsed
        return 0.0


    def _check_orderbook(self, orderbook_data: Optional[Dict], current_price: Decimal) -> float:
        """
        Analyzes order book depth (imbalance) as a sentiment indicator.
        Returns float score (-1.0 to 1.0) or NaN.
        """
        if not orderbook_data:
            self.logger.debug("Orderbook check skipped: No data provided.")
            return np.nan

        try:
            bids = orderbook_data.get('bids', [])
            asks = orderbook_data.get('asks', [])

            # Ensure we have both bids and asks to compare
            if not bids or not asks:
                self.logger.debug("Orderbook check skipped: Missing bids or asks.")
                return np.nan

            # --- Simple Order Book Imbalance (OBI) Calculation ---
            # Consider N levels deep (e.g., first 10 levels)
            num_levels_to_check = 10 # Make this configurable?
            top_bids = bids[:num_levels_to_check]
            top_asks = asks[:num_levels_to_check]

            # Sum the sizes (quantities) at these levels
            # Use Decimal for summation to maintain precision
            bid_volume_sum = sum(Decimal(str(bid[1])) for bid in top_bids if len(bid) == 2)
            ask_volume_sum = sum(Decimal(str(ask[1])) for ask in top_asks if len(ask) == 2)

            # Calculate total volume in the checked range
            total_volume = bid_volume_sum + ask_volume_sum

            # Avoid division by zero if total volume is zero (inactive market?)
            if total_volume == 0:
                self.logger.debug(f"Orderbook check ({self.symbol}): Zero total volume in top {num_levels_to_check} levels.")
                return 0.0 # Neutral signal

            # Calculate Order Book Imbalance ratio
            # OBI = (BidVolume - AskVolume) / TotalVolume
            # Ranges from -1 (all asks) to +1 (all bids)
            obi_decimal = (bid_volume_sum - ask_volume_sum) / total_volume

            # Convert OBI Decimal to float score
            score = float(obi_decimal)

            # --- Log the analysis ---
            self.logger.debug(
                f"Orderbook check ({self.symbol}): Top {num_levels_to_check} levels -> "
                f"BidVol={bid_volume_sum:.4f}, AskVol={ask_volume_sum:.4f}, "
                f"OBI={obi_decimal:.4f} -> Score={score:.4f}"
            )

            # --- Refinements (Optional) ---
            # 1. Weighted OBI: Give more weight to levels closer to the spread.
            # 2. Volume Clusters: Look for large individual orders ("walls").
            # 3. Spread Analysis: Consider the bid-ask spread size.

            # Return the calculated score
            return score

        except Exception as e:
            self.logger.warning(f"{NEON_YELLOW}Orderbook analysis failed for {self.symbol}: {e}{RESET}", exc_info=True)
            return np.nan # Return NaN on error


    # --- Risk Management Calculations ---
    def calculate_entry_tp_sl(
        self, entry_price_estimate: Decimal, signal: str
    ) -> Tuple[Optional[Decimal], Optional[Decimal], Optional[Decimal]]:
        """
        Calculates potential Take Profit (TP) and initial Stop Loss (SL) levels
        based on an estimated entry price, the signal direction, ATR, and config multipliers.

        This initial SL is primarily used for position sizing. The actual SL set on the
        exchange might be different (e.g., adjusted by BE logic or replaced by TSL).

        Args:
            entry_price_estimate: An estimated entry price (Decimal) for the trade.
                                  (Could be current price or anticipated limit fill price).
            signal: The trading signal ("BUY" or "SELL").

        Returns:
            A tuple containing: (entry_price_estimate, take_profit, stop_loss)
            All values are Decimals or None if calculation fails.
        """
        # Only calculate for valid BUY/SELL signals
        if signal not in ["BUY", "SELL"]:
            self.logger.debug(f"TP/SL calculation skipped: Signal is '{signal}'.")
            return entry_price_estimate, None, None

        # --- Retrieve necessary values ---
        atr_val = self.indicator_values.get("ATR") # Should be Decimal or NaN

        # --- Validate Inputs ---
        if not isinstance(atr_val, Decimal) or pd.isna(atr_val) or atr_val <= 0:
            self.logger.warning(f"{NEON_YELLOW}Cannot calculate TP/SL for {self.symbol} {signal}: Invalid or missing ATR ({atr_val}).{RESET}")
            return entry_price_estimate, None, None
        if not isinstance(entry_price_estimate, Decimal) or pd.isna(entry_price_estimate) or entry_price_estimate <= 0:
            self.logger.warning(f"{NEON_YELLOW}Cannot calculate TP/SL for {self.symbol} {signal}: Invalid entry price estimate ({entry_price_estimate}).{RESET}")
            return entry_price_estimate, None, None

        try:
            # --- Get Multipliers from Config ---
            # Convert multipliers to Decimal for precise calculations
            tp_multiple_str = self.config.get("take_profit_multiple", "1.0") # Default 1.0 if missing
            sl_multiple_str = self.config.get("stop_loss_multiple", "1.5")   # Default 1.5 if missing
            tp_multiple = Decimal(str(tp_multiple_str))
            sl_multiple = Decimal(str(sl_multiple_str))

            # --- Get Market Precision Info ---
            price_precision = self.get_price_precision()
            # Quantizer for rounding to the correct number of decimal places
            rounding_factor = Decimal('1e-' + str(price_precision))
            # Minimum price increment (tick size) for validation/adjustments
            min_tick = self.get_min_tick_size()

            # --- Calculate Offsets ---
            tp_offset = atr_val * tp_multiple
            sl_offset = atr_val * sl_multiple

            # --- Calculate Raw TP/SL Prices ---
            take_profit_raw: Optional[Decimal] = None
            stop_loss_raw: Optional[Decimal] = None

            if signal == "BUY":
                take_profit_raw = entry_price_estimate + tp_offset
                stop_loss_raw = entry_price_estimate - sl_offset
            elif signal == "SELL":
                take_profit_raw = entry_price_estimate - tp_offset
                stop_loss_raw = entry_price_estimate + sl_offset

            # --- Quantize TP/SL to Market Precision ---
            # Quantize TP towards profit direction (UP for BUY, DOWN for SELL)
            # Quantize SL towards loss direction (DOWN for BUY, UP for SELL) - more conservative SL
            take_profit_quantized: Optional[Decimal] = None
            stop_loss_quantized: Optional[Decimal] = None

            if take_profit_raw is not None:
                 tp_rounding = ROUND_UP if signal == "BUY" else ROUND_DOWN
                 take_profit_quantized = take_profit_raw.quantize(rounding_factor, rounding=tp_rounding)

            if stop_loss_raw is not None:
                 sl_rounding = ROUND_DOWN if signal == "BUY" else ROUND_UP
                 stop_loss_quantized = stop_loss_raw.quantize(rounding_factor, rounding=sl_rounding)

            # --- Validation and Adjustments ---
            final_tp = take_profit_quantized
            final_sl = stop_loss_quantized

            # 1. Ensure SL is strictly beyond entry by at least one tick
            if final_sl is not None:
                 if signal == "BUY" and final_sl >= entry_price_estimate:
                      original_sl = final_sl
                      final_sl = (entry_price_estimate - min_tick).quantize(rounding_factor, rounding=ROUND_DOWN)
                      self.logger.debug(f"Adjusted BUY SL below entry: {original_sl} -> {final_sl}")
                 elif signal == "SELL" and final_sl <= entry_price_estimate:
                      original_sl = final_sl
                      final_sl = (entry_price_estimate + min_tick).quantize(rounding_factor, rounding=ROUND_UP)
                      self.logger.debug(f"Adjusted SELL SL above entry: {original_sl} -> {final_sl}")

            # 2. Ensure TP provides potential profit (strictly beyond entry)
            if final_tp is not None:
                 if signal == "BUY" and final_tp <= entry_price_estimate:
                      self.logger.warning(f"{NEON_YELLOW}BUY TP calculation non-profitable (TP {final_tp} <= Entry {entry_price_estimate}). Setting TP to None.{RESET}")
                      final_tp = None
                 elif signal == "SELL" and final_tp >= entry_price_estimate:
                      self.logger.warning(f"{NEON_YELLOW}SELL TP calculation non-profitable (TP {final_tp} >= Entry {entry_price_estimate}). Setting TP to None.{RESET}")
                      final_tp = None

            # 3. Ensure SL/TP are positive prices
            if final_sl is not None and final_sl <= 0:
                self.logger.error(f"{NEON_RED}Stop loss calculation resulted in non-positive price ({final_sl}). Setting SL to None.{RESET}")
                final_sl = None
            if final_tp is not None and final_tp <= 0:
                self.logger.warning(f"{NEON_YELLOW}Take profit calculation resulted in non-positive price ({final_tp}). Setting TP to None.{RESET}")
                final_tp = None

            # --- Log Calculation Results ---
            tp_str = f"{final_tp:.{price_precision}f}" if final_tp else "None"
            sl_str = f"{final_sl:.{price_precision}f}" if final_sl else "None"
            self.logger.debug(
                f"Calculated TP/SL for {self.symbol} {signal}: "
                f"EntryEst={entry_price_estimate:.{price_precision}f}, "
                f"ATR={atr_val:.{price_precision+1}f}, " # Show ATR with more precision
                f"TP={tp_str} (Mult: {tp_multiple}), "
                f"SL={sl_str} (Mult: {sl_multiple})"
            )

            return entry_price_estimate, final_tp, final_sl

        except Exception as e:
             # Catch any unexpected errors during calculation
             self.logger.error(f"{NEON_RED}Error calculating TP/SL for {self.symbol} {signal}: {e}{RESET}", exc_info=True)
             return entry_price_estimate, None, None


# --- Trading Logic Helper Functions (Adapted from livexy.py) ---

def fetch_balance(exchange: ccxt.Exchange, currency: str, logger: logging.Logger) -> Optional[Decimal]:
    """Fetches the available balance for a specific currency with retries and robust parsing."""
    lg = logger
    for attempt in range(MAX_API_RETRIES + 1):
        try:
            balance_info = None
            # Prioritize specific account types if needed (e.g., Bybit V5)
            account_types_to_try = []
            if exchange.id == 'bybit':
                 account_types_to_try = ['CONTRACT', 'UNIFIED'] # Try V5 types first

            found_structure = False
            # Try specific account types first
            for acc_type in account_types_to_try:
                 try:
                     lg.debug(f"Fetching balance using params={{'type': '{acc_type}'}} for {currency}... (Attempt {attempt+1})")
                     balance_info = exchange.fetch_balance(params={'type': acc_type})
                     # Check standard CCXT structure first
                     if currency in balance_info and balance_info[currency].get('free') is not None:
                         found_structure = True; break
                     # Check Bybit V5 specific structure within 'info'
                     elif 'info' in balance_info and 'result' in balance_info['info'] and isinstance(balance_info['info']['result'].get('list'), list):
                         for account in balance_info['info']['result']['list']:
                             if isinstance(account.get('coin'), list):
                                 # Find the specific coin data within the list
                                 if any(coin_data.get('coin') == currency for coin_data in account['coin']):
                                     found_structure = True; break # Found the currency
                         if found_structure: break # Exit outer loop too
                     lg.debug(f"Currency '{currency}' not directly found using type '{acc_type}'. Checking V5 structure...")
                 except (ccxt.ExchangeError, ccxt.AuthenticationError) as e:
                     # Log specific errors but continue trying other types or default fetch
                     lg.debug(f"Error fetching balance for type '{acc_type}': {e}. Trying next.")
                     continue
                 except Exception as e:
                     lg.warning(f"Unexpected error fetching balance type '{acc_type}': {e}. Trying next.")
                     continue

            # If not found with specific types, try default fetch_balance
            if not found_structure:
                 lg.debug(f"Fetching balance using default parameters for {currency}... (Attempt {attempt+1})")
                 try:
                     balance_info = exchange.fetch_balance()
                 except Exception as e:
                     # If default fetch also fails, log and proceed to retry logic
                     lg.error(f"{NEON_RED}Failed to fetch balance using default parameters: {e}{RESET}")
                     raise e # Re-raise to trigger retry

            # --- Parse the final balance_info ---
            if balance_info:
                available_balance_str = None
                # 1. Standard CCXT: balance[currency]['free']
                if currency in balance_info and balance_info[currency].get('free') is not None:
                    available_balance_str = str(balance_info[currency]['free'])
                    lg.debug(f"Found balance via standard ['{currency}']['free']: {available_balance_str}")

                # 2. Bybit V5 Nested: info.result.list[].coin[].availableToWithdraw/availableBalance
                elif not available_balance_str and 'info' in balance_info and 'result' in balance_info['info'] and isinstance(balance_info['info']['result'].get('list'), list):
                    for account in balance_info['info']['result']['list']:
                        if isinstance(account.get('coin'), list):
                            for coin_data in account['coin']:
                                 if coin_data.get('coin') == currency:
                                     # Prioritize availableToWithdraw > availableBalance > walletBalance
                                     free = coin_data.get('availableToWithdraw') or coin_data.get('availableBalance') or coin_data.get('walletBalance')
                                     if free is not None:
                                         available_balance_str = str(free)
                                         lg.debug(f"Found balance via Bybit V5 nested ['available...']: {available_balance_str}")
                                         break # Found it
                            if available_balance_str is not None: break # Exit account loop
                    if not available_balance_str:
                         lg.warning(f"{currency} balance details not found within Bybit V5 'info.result.list[].coin[]'.")

                # 3. Fallback: Top-level 'free' dictionary
                elif not available_balance_str and 'free' in balance_info and currency in balance_info['free'] and balance_info['free'][currency] is not None:
                     available_balance_str = str(balance_info['free'][currency])
                     lg.debug(f"Found balance via top-level 'free' dict: {available_balance_str}")

                # 4. Final Fallback: Use 'total' balance if 'free' is unavailable
                if available_balance_str is None:
                     total_balance = balance_info.get(currency, {}).get('total')
                     if total_balance is not None:
                          lg.warning(f"{NEON_YELLOW}Using 'total' balance ({total_balance}) as fallback for available {currency}.{RESET}")
                          available_balance_str = str(total_balance)
                     else:
                          lg.error(f"{NEON_RED}Could not determine any balance ('free' or 'total') for {currency}.{RESET}")
                          lg.debug(f"Full balance_info structure: {balance_info}")
                          # Continue to retry logic or return None if retries exhausted

                # Convert the found string balance to Decimal
                if available_balance_str is not None:
                    try:
                        final_balance = Decimal(available_balance_str)
                        if final_balance >= 0:
                             lg.info(f"Available {currency} balance: {final_balance:.4f}")
                             return final_balance
                        else:
                             lg.error(f"Parsed balance for {currency} is negative ({final_balance}).")
                             # Treat negative balance as an error, may retry
                    except Exception as e:
                        lg.error(f"Failed to convert balance string '{available_balance_str}' to Decimal for {currency}: {e}")
                        # Treat conversion error as failure, may retry
            else:
                # If balance_info itself is None after attempts
                lg.error(f"Balance info was None after fetch attempt {attempt + 1}.")


            # If we got here, something failed in parsing or fetching, proceed to retry
            raise ccxt.ExchangeError("Balance parsing failed or data missing") # Trigger retry

        except (ccxt.NetworkError, ccxt.RequestTimeout) as e:
            lg.warning(f"Network error fetching balance: {e}. Retrying ({attempt+1}/{MAX_API_RETRIES})...")
        except ccxt.RateLimitExceeded as e:
            wait_time = RETRY_DELAY_SECONDS * 5
            lg.warning(f"Rate limit exceeded fetching balance: {e}. Waiting {wait_time}s ({attempt+1}/{MAX_API_RETRIES})...")
            time.sleep(wait_time)
            continue # Skip standard delay after rate limit wait
        except ccxt.AuthenticationError as e:
             lg.error(f"{NEON_RED}Authentication error fetching balance: {e}. Aborting balance fetch.{RESET}")
             return None # Don't retry auth errors
        except ccxt.ExchangeError as e:
            lg.warning(f"Exchange error fetching balance: {e}. Retrying ({attempt+1}/{MAX_API_RETRIES})...")
        except Exception as e:
            lg.error(f"{NEON_RED}Unexpected error fetching balance: {e}{RESET}", exc_info=True)
            # Decide if unexpected errors should be retried

        # Standard delay before next attempt
        if attempt < MAX_API_RETRIES:
            time.sleep(RETRY_DELAY_SECONDS)

    lg.error(f"{NEON_RED}Failed to fetch balance for {currency} after {MAX_API_RETRIES + 1} attempts.{RESET}")
    return None


def get_market_info(exchange: ccxt.Exchange, symbol: str, logger: logging.Logger) -> Optional[Dict]:
    """Gets market information (precision, limits, type) using exchange.market()."""
    lg = logger
    try:
        # Ensure markets are loaded
        if not exchange.markets or symbol not in exchange.markets:
             lg.info(f"Market info for {symbol} not loaded or symbol not found, reloading markets...")
             try:
                 exchange.load_markets(reload=True)
             except Exception as load_err:
                  lg.error(f"{NEON_RED}Failed to reload markets: {load_err}{RESET}")
                  return None # Cannot proceed without markets

        # Check again after reload
        if symbol not in exchange.markets:
             lg.error(f"{NEON_RED}Market {symbol} still not found after reloading.{RESET}")
             # Suggest alternatives if common variations exist (e.g., PERP)
             if '/' in symbol:
                 base, quote = symbol.split('/', 1)
                 perp_sym = f"{symbol}:USDT" # Example for Bybit linear perps
                 if perp_sym in exchange.markets:
                     lg.warning(f"{NEON_YELLOW}Did you mean '{perp_sym}'?{RESET}")
             return None

        # Retrieve market details
        market = exchange.market(symbol)
        if market:
            # --- Extract relevant details ---
            market_type = market.get('type', 'unknown') # spot, future, swap, option
            is_contract = market.get('contract', False) or market_type in ['swap', 'future']
            contract_type = "N/A"
            if is_contract:
                if market.get('linear'): contract_type = "Linear"
                elif market.get('inverse'): contract_type = "Inverse"
                else: contract_type = "Unknown Contract"

            # Log key details
            lg.debug(
                f"Market Info for {symbol}: ID={market.get('id')}, Base={market.get('base')}, Quote={market.get('quote')}, "
                f"Type={market_type}, IsContract={is_contract}, ContractType={contract_type}, "
                f"Precision(Price/Amount): {market.get('precision', {}).get('price')}/{market.get('precision', {}).get('amount')}, "
                f"Limits(Amount Min/Max): {market.get('limits', {}).get('amount', {}).get('min')}/{market.get('limits', {}).get('amount', {}).get('max')}, "
                f"Limits(Cost Min/Max): {market.get('limits', {}).get('cost', {}).get('min')}/{market.get('limits', {}).get('cost', {}).get('max')}, "
                f"Contract Size: {market.get('contractSize', 'N/A')}"
            )
            # Add custom 'is_contract' flag for easier checks later
            market['is_contract'] = is_contract
            return market
        else:
             # Should not happen if symbol is in exchange.markets, but handle defensively
             lg.error(f"{NEON_RED}Market dictionary unexpectedly not found for validated symbol {symbol}.{RESET}")
             return None

    except ccxt.BadSymbol as e:
         # This might occur if the symbol format is wrong despite passing initial checks
         lg.error(f"{NEON_RED}Symbol '{symbol}' is invalid or not supported by {exchange.id}: {e}{RESET}")
         return None
    except ccxt.NetworkError as e:
         lg.error(f"{NEON_RED}Network error getting market info for {symbol}: {e}{RESET}")
         return None # Network errors might be temporary, but critical for this step
    except Exception as e:
        # Catch any other unexpected errors
        lg.error(f"{NEON_RED}Unexpected error getting market info for {symbol}: {e}{RESET}", exc_info=True)
        return None


def calculate_position_size(
    balance: Decimal,
    risk_per_trade: float, # e.g., 0.01 for 1%
    initial_stop_loss_price: Decimal, # Calculated SL price (must be validated before calling)
    entry_price: Decimal, # Estimated or actual entry price
    market_info: Dict, # From get_market_info()
    exchange: ccxt.Exchange, # Needed for formatting helpers
    logger: Optional[logging.Logger] = None
) -> Optional[Decimal]:
    """
    Calculates the position size in base currency or contracts based on risk percentage,
    stop-loss distance, available balance, and market constraints (precision, limits).

    Args:
        balance: Available balance in QUOTE currency (Decimal).
        risk_per_trade: Risk percentage per trade (float, e.g., 0.01 for 1%).
        initial_stop_loss_price: The calculated stop-loss price (Decimal).
        entry_price: The estimated or actual entry price (Decimal).
        market_info: The market dictionary from CCXT.
        exchange: The CCXT exchange instance (for formatting).
        logger: Logger instance.

    Returns:
        Calculated position size (Decimal) in base currency (spot) or contracts (futures),
        or None if calculation fails or constraints are violated.
    """
    lg = logger or logging.getLogger(__name__)
    symbol = market_info.get('symbol', 'UNKNOWN_SYMBOL')
    quote_currency = market_info.get('quote', QUOTE_CURRENCY) # e.g., USDT
    base_currency = market_info.get('base', 'BASE')       # e.g., BTC
    is_contract = market_info.get('is_contract', False)
    # Determine unit based on market type
    size_unit = "Contracts" if is_contract else base_currency

    # --- Input Validation ---
    if balance is None or not isinstance(balance, Decimal) or balance <= 0:
        lg.error(f"Position sizing failed ({symbol}): Invalid or zero balance ({balance}).")
        return None
    if not isinstance(risk_per_trade, (float, int)) or not (0 < risk_per_trade < 1):
         lg.error(f"Position sizing failed ({symbol}): Invalid risk_per_trade ({risk_per_trade}). Must be between 0 and 1.")
         return None
    if initial_stop_loss_price is None or not isinstance(initial_stop_loss_price, Decimal) or initial_stop_loss_price <= 0:
        lg.error(f"Position sizing failed ({symbol}): Invalid initial_stop_loss_price ({initial_stop_loss_price}).")
        return None
    if entry_price is None or not isinstance(entry_price, Decimal) or entry_price <= 0:
         lg.error(f"Position sizing failed ({symbol}): Invalid entry_price ({entry_price}).")
         return None
    if initial_stop_loss_price == entry_price:
         lg.error(f"Position sizing failed ({symbol}): Stop loss price cannot be equal to entry price.")
         return None
    if 'limits' not in market_info or 'precision' not in market_info:
         lg.error(f"Position sizing failed ({symbol}): Market info missing 'limits' or 'precision'.")
         return None

    try:
        # --- Calculate Risk Amount ---
        risk_amount_quote = balance * Decimal(str(risk_per_trade))

        # --- Calculate SL Distance per Unit ---
        # This is the risk per unit (contract or base currency) in quote currency
        sl_distance_per_unit = abs(entry_price - initial_stop_loss_price)
        if sl_distance_per_unit <= 0: # Should be caught by earlier check, but defense-in-depth
             lg.error(f"Position sizing failed ({symbol}): Stop loss distance is zero or negative ({sl_distance_per_unit}).")
             return None

        # --- Get Contract Size (for contracts) ---
        # Defaults to 1 (for spot or if contractSize is missing/invalid)
        contract_size_str = market_info.get('contractSize', '1')
        try:
            contract_size = Decimal(str(contract_size_str))
            if contract_size <= 0: raise ValueError("Contract size must be positive")
        except Exception:
            lg.warning(f"Invalid contract size '{contract_size_str}' for {symbol}, using 1.")
            contract_size = Decimal('1')

        # --- Calculate Initial Size based on Risk ---
        # Formula: Size = RiskAmount / (StopLossDistancePerUnit * ValuePerUnit)
        # For Linear Contracts/Spot: ValuePerUnit is contract_size (in base currency value per contract)
        # For Inverse Contracts: ValuePerUnit depends on price, more complex. Assuming Linear/Spot here.

        calculated_size: Optional[Decimal] = None
        if market_info.get('linear', True) or not is_contract: # Assume linear or spot
             # Risk is in quote, SL distance is in quote, contract_size converts contracts to base value units
             # For Spot: contract_size is 1, Size = RiskQuote / SL_Quote_Per_Base
             # For Linear: contract_size is base_per_contract, Size = RiskQuote / (SL_Quote_Per_Contract)
             # SL_Quote_Per_Contract = SL_Quote_Per_Base * base_per_contract = sl_distance_per_unit * contract_size
             if sl_distance_per_unit * contract_size > 0:
                 calculated_size = risk_amount_quote / (sl_distance_per_unit * contract_size)
             else:
                 lg.error(f"Position sizing failed ({symbol}): Denominator zero/negative in size calculation.")
                 return None
        else: # Inverse Contract Placeholder
             # Sizing inverse contracts based on fixed quote risk is complex
             # Risk is in quote, but position is sized in contracts (valued in base)
             # Requires converting quote risk to base risk at entry price, then calculating contracts
             # Example (simplified, verify accuracy): BaseRisk = RiskQuote / EntryPrice
             # SizeInContracts = BaseRisk / (SL_Distance_Base * ContractValueBase)
             # This needs careful implementation based on exchange specifics.
             lg.error(f"{NEON_RED}Inverse contract sizing not fully implemented. Aborting sizing for {symbol}.{RESET}")
             # calculated_size = ... # Implement inverse logic here if needed
             return None # Abort for now

        if calculated_size is None or calculated_size <= 0:
             lg.error(f"Initial position size calculation resulted in zero or negative: {calculated_size}. RiskAmt={risk_amount_quote:.4f}, SLDist={sl_distance_per_unit}, ContractSize={contract_size}")
             return None

        lg.info(f"Position Sizing ({symbol}): Balance={balance:.2f}, Risk={risk_per_trade:.2%}, RiskAmt={risk_amount_quote:.4f} {quote_currency}")
        lg.info(f"  Entry={entry_price}, SL={initial_stop_loss_price}, SL Dist={sl_distance_per_unit}")
        lg.info(f"  ContractSize={contract_size}, Initial Calculated Size = {calculated_size:.8f} {size_unit}")

        # --- Apply Market Limits and Precision ---
        limits = market_info.get('limits', {})
        amount_limits = limits.get('amount', {})
        cost_limits = limits.get('cost', {}) # Cost limits are in Quote currency
        precision = market_info.get('precision', {})
        amount_precision_val = precision.get('amount') # Usually step size (float/str) or decimal places (int)

        # Min/Max Amount Limits (in base currency or contracts)
        min_amount_str = amount_limits.get('min')
        max_amount_str = amount_limits.get('max')
        # Use Decimal for limits, handle None with appropriate defaults
        min_amount = Decimal(str(min_amount_str)) if min_amount_str is not None else Decimal('0')
        max_amount = Decimal(str(max_amount_str)) if max_amount_str is not None else Decimal('inf')

        # Min/Max Cost Limits (in quote currency)
        min_cost_str = cost_limits.get('min')
        max_cost_str = cost_limits.get('max')
        min_cost = Decimal(str(min_cost_str)) if min_cost_str is not None else Decimal('0')
        max_cost = Decimal(str(max_cost_str)) if max_cost_str is not None else Decimal('inf')


        # 1. Adjust for MIN/MAX AMOUNT limits
        adjusted_size = calculated_size
        if adjusted_size < min_amount:
             lg.warning(f"{NEON_YELLOW}Calculated size {calculated_size:.8f} is below min amount {min_amount}. Adjusting to min amount.{RESET}")
             adjusted_size = min_amount
        elif adjusted_size > max_amount:
             lg.warning(f"{NEON_YELLOW}Calculated size {calculated_size:.8f} exceeds max amount {max_amount}. Adjusting to max amount.{RESET}")
             adjusted_size = max_amount


        # 2. Check COST limits (Estimate cost based on adjusted size)
        # Cost calculation assumes Linear/Spot: Cost = Size * EntryPrice * ContractSize
        estimated_cost = adjusted_size * entry_price * contract_size
        lg.debug(f"  Cost Check: Adjusted Size={adjusted_size:.8f}, Estimated Cost={estimated_cost:.4f} {quote_currency}")

        # Check Min Cost
        if min_cost > 0 and estimated_cost < min_cost :
             lg.warning(f"{NEON_YELLOW}Estimated cost {estimated_cost:.4f} is below min cost {min_cost}. Attempting to increase size.{RESET}")
             # Calculate the size needed to meet min cost
             required_size_for_min_cost: Optional[Decimal] = None
             denominator = entry_price * contract_size
             if denominator > 0:
                 required_size_for_min_cost = min_cost / denominator
             else:
                 lg.error("Cannot calculate required size for min cost: EntryPrice or ContractSize is zero/negative.")
                 return None

             if required_size_for_min_cost is None: return None # Should be caught above

             lg.info(f"  Required size to meet min cost: {required_size_for_min_cost:.8f} {size_unit}")

             # Check if required size violates other limits
             if required_size_for_min_cost > max_amount:
                  lg.error(f"{NEON_RED}Cannot meet min cost {min_cost} without exceeding max amount limit {max_amount}. Aborted.{RESET}")
                  return None
             # This check might be redundant if min_amount adjustment happened first, but good safety check
             if required_size_for_min_cost < min_amount:
                 lg.error(f"{NEON_RED}Cannot meet min cost: Required size {required_size_for_min_cost:.8f} is below min amount {min_amount}. Aborted.{RESET}")
                 # This indicates conflicting limits on the exchange
                 return None
             else:
                 # Adjust size up to meet min cost
                 lg.info(f"  Adjusting size to meet min cost: {adjusted_size:.8f} -> {required_size_for_min_cost:.8f}")
                 adjusted_size = required_size_for_min_cost
                 # Recalculate estimated cost with the new size for max cost check
                 estimated_cost = adjusted_size * entry_price * contract_size


        # Check Max Cost (after potential min cost adjustment)
        elif max_cost > 0 and estimated_cost > max_cost:
             lg.warning(f"{NEON_YELLOW}Estimated cost {estimated_cost:.4f} exceeds max cost {max_cost}. Reducing size.{RESET}")
             # Calculate the maximum size allowed by max cost
             adjusted_size_for_max_cost: Optional[Decimal] = None
             denominator = entry_price * contract_size
             if denominator > 0:
                 adjusted_size_for_max_cost = max_cost / denominator
             else:
                 lg.error("Cannot calculate max size for max cost: EntryPrice or ContractSize is zero/negative.")
                 return None

             if adjusted_size_for_max_cost is None: return None # Should be caught above

             lg.info(f"  Reduced size allowed by max cost: {adjusted_size_for_max_cost:.8f} {size_unit}")

             # Ensure the reduced size is still above the minimum amount
             if adjusted_size_for_max_cost < min_amount:
                  lg.error(f"{NEON_RED}Size reduced for max cost ({adjusted_size_for_max_cost:.8f}) is below min amount {min_amount}. Aborted.{RESET}")
                  return None
             else:
                 # Adjust size down to meet max cost
                 lg.info(f"  Adjusting size to meet max cost: {adjusted_size:.8f} -> {adjusted_size_for_max_cost:.8f}")
                 adjusted_size = adjusted_size_for_max_cost


        # 3. Apply Amount Precision/Step Size
        # Use ccxt's amount_to_precision for reliable formatting based on market info
        try:
            # Convert Decimal to float for ccxt function
            amount_float = float(adjusted_size)
            # Use TRUNCATE (rounding down) to be conservative with size
            formatted_size_str = exchange.amount_to_precision(symbol, amount_float) # Default rounding mode might be ok too
            # Some exchanges might require specific padding modes, check ccxt docs if needed
            # formatted_size_str = exchange.amount_to_precision(symbol, amount_float, padding_mode=exchange.TRUNCATE)

            final_size = Decimal(formatted_size_str)
            lg.info(f"Applied amount precision/step size: {adjusted_size:.8f} -> {final_size} {size_unit}")

        except ccxt.ExchangeError as fmt_err:
             lg.warning(f"{NEON_YELLOW}CCXT formatting error applying amount precision ({fmt_err}). Check market data or try manual rounding.{RESET}")
             # Fallback: Manual rounding using step size (if amount precision is step size)
             if isinstance(amount_precision_val, (float, str)):
                 try:
                     amount_step = Decimal(str(amount_precision_val))
                     if amount_step > 0:
                         # Round down to the nearest step size
                         final_size = (adjusted_size // amount_step) * amount_step
                         lg.info(f"Applied manual amount step size ({amount_step}): {adjusted_size:.8f} -> {final_size} {size_unit}")
                     else: raise ValueError("Amount step size is not positive")
                 except Exception as manual_err:
                     lg.error(f"Manual step size rounding failed: {manual_err}. Using unrounded size: {adjusted_size}", exc_info=True)
                     final_size = adjusted_size # Use unrounded as last resort
             else:
                 lg.error(f"Cannot determine amount step size for manual rounding. Using unrounded size: {adjusted_size}")
                 final_size = adjusted_size


        # --- Final Validation ---
        if final_size <= 0:
             lg.error(f"{NEON_RED}Position size became zero or negative ({final_size}) after adjustments. Aborted.{RESET}")
             return None
        # Final check against min amount after precision formatting
        if final_size < min_amount:
             # This can happen if min_amount itself doesn't align with step size
             lg.error(f"{NEON_RED}Final size {final_size} is below minimum amount {min_amount} after precision formatting. Aborted.{RESET}")
             return None
        # Final check against min cost after precision formatting
        final_cost = final_size * entry_price * contract_size
        if min_cost > 0 and final_cost < min_cost:
            # This implies the minimum amount constraint resulted in a cost below minimum cost
            lg.error(f"{NEON_RED}Final size {final_size} results in cost {final_cost:.4f} which is below minimum cost {min_cost}. Exchange limits conflict? Aborted.{RESET}")
            return None


        lg.info(f"{NEON_GREEN}Final calculated position size for {symbol}: {final_size} {size_unit}{RESET}")
        return final_size

    except Exception as e:
        # Catch any unexpected errors during the entire process
        lg.error(f"{NEON_RED}Unexpected error calculating position size for {symbol}: {e}{RESET}", exc_info=True)
        return None


def get_open_position(exchange: ccxt.Exchange, symbol: str, logger: logging.Logger) -> Optional[Dict]:
    """Checks for an open position for the given symbol using fetch_positions."""
    lg = logger
    try:
        lg.debug(f"Fetching positions for symbol: {symbol}")
        positions: List[Dict] = []
        fetch_all = False # Flag to fetch all symbols if single fetch fails

        # 1. Attempt to fetch position for the specific symbol (more efficient)
        # Some exchanges require a list of symbols, even for one
        if exchange.has.get('fetchPositions'):
            try:
                # Try fetching single symbol first (works on Bybit V5 unified, maybe others)
                positions = exchange.fetch_positions([symbol])
                lg.debug(f"Fetched single symbol position data for {symbol}. Count: {len(positions)}")
            except ccxt.ArgumentsRequired:
                 # If fetchPositions requires no args (fetches all), set flag
                 lg.debug(f"fetchPositions for {exchange.id} requires no arguments. Fetching all.")
                 fetch_all = True
            except ccxt.ExchangeError as e:
                 # Handle specific errors indicating no position exists cleanly
                 no_pos_codes_v5 = [110025] # Bybit V5: Position idx not match / Position is closed
                 no_pos_messages = ["position not found", "position is closed"]
                 err_str = str(e).lower()
                 bybit_code = getattr(e, 'code', None)

                 if any(msg in err_str for msg in no_pos_messages) or (bybit_code in no_pos_codes_v5):
                      lg.info(f"No position found for {symbol} (Exchange confirmed: {e}).")
                      return None # Confirmed no position
                 else:
                      # Log other exchange errors but consider them temporary failures
                      lg.error(f"Exchange error fetching single position for {symbol}: {e}", exc_info=False)
                      # Decide whether to fetch all as fallback or return None
                      fetch_all = True # Fallback to fetching all positions
                      # return None # Option: Treat error as failure
            except Exception as e:
                 # Handle other unexpected errors during single fetch
                 lg.error(f"Error fetching single position for {symbol}: {e}", exc_info=True)
                 fetch_all = True # Fallback to fetching all positions
                 # return None # Option: Treat error as failure
        else:
             lg.warning(f"Exchange {exchange.id} does not support fetchPositions. Cannot check position status.")
             return None


        # 2. Fetch all positions if single fetch failed or wasn't attempted
        if fetch_all:
            lg.debug(f"Attempting to fetch all positions for {exchange.id}...")
            try:
                 all_positions = exchange.fetch_positions()
                 # Filter for the target symbol
                 positions = [p for p in all_positions if p.get('symbol') == symbol]
                 lg.debug(f"Fetched {len(all_positions)} total positions, found {len(positions)} matching {symbol}.")
            except Exception as e:
                 lg.error(f"Error fetching all positions for {symbol}: {e}", exc_info=True)
                 return None # Failed to get any position data


        # --- Process the fetched positions list ---
        active_position = None
        # Define a small threshold to consider a position size non-zero
        size_threshold = Decimal('1e-9') # Adjust if needed based on minimum contract size

        for pos in positions:
            pos_size_str = None
            # Find position size - check standard 'contracts' and Bybit V5 'info.size'
            if pos.get('contracts') is not None:
                pos_size_str = str(pos['contracts'])
            elif isinstance(pos.get('info'), dict) and pos['info'].get('size') is not None:
                pos_size_str = str(pos['info']['size']) # Common in Bybit V5

            if pos_size_str is None:
                lg.debug(f"Skipping position entry, could not determine size: {pos}")
                continue # Skip if size cannot be determined

            try:
                position_size = Decimal(pos_size_str)
                # Check if the absolute size is greater than the threshold
                if abs(position_size) > size_threshold:
                    # Found an active position
                    active_position = pos
                    lg.debug(f"Found potential active position entry for {symbol} with size {position_size}.")
                    break # Assume only one position per symbol (or handle multiple if needed)
            except Exception as parse_err:
                lg.warning(f"Could not parse position size '{pos_size_str}' for {symbol}: {parse_err}")
                continue


        # --- Post-Process the found active position (if any) ---
        if active_position:
            # Ensure essential fields are present and standardized
            try:
                # Standardize Size
                size_decimal = Decimal(str(active_position.get('contracts', active_position.get('info',{}).get('size', '0'))))
                active_position['contractsDecimal'] = size_decimal # Store Decimal size

                # Standardize Side
                side = active_position.get('side')
                # Infer side from size if missing (common issue)
                if side not in ['long', 'short']:
                    if size_decimal > size_threshold: side = 'long'
                    elif size_decimal < -size_threshold: side = 'short'
                    else:
                        lg.warning(f"Position size {size_decimal} near zero for {symbol}, cannot reliably determine side.")
                        return None # Cannot use position if side unknown
                    active_position['side'] = side # Store inferred side
                    lg.debug(f"Inferred position side as '{side}' based on size {size_decimal}.")

                # Standardize Entry Price
                entry_price_str = active_position.get('entryPrice') or active_position.get('info', {}).get('avgPrice')
                if entry_price_str:
                    active_position['entryPriceDecimal'] = Decimal(str(entry_price_str))
                else: active_position['entryPriceDecimal'] = None

                # Standardize SL/TP/TSL from 'info' if not top-level
                info_dict = active_position.get('info', {})
                if active_position.get('stopLossPrice') is None: active_position['stopLossPrice'] = info_dict.get('stopLoss')
                if active_position.get('takeProfitPrice') is None: active_position['takeProfitPrice'] = info_dict.get('takeProfit')
                # TSL info might be in different fields depending on exchange/version
                active_position['trailingStopLossValue'] = info_dict.get('trailingStop') # Bybit V5: distance value
                active_position['trailingStopActivationPrice'] = info_dict.get('activePrice') # Bybit V5: activation price

                # Get timestamp (usually milliseconds)
                timestamp_ms = active_position.get('timestamp') or info_dict.get('updatedTime') # Use 'timestamp' or fallback
                active_position['timestamp_ms'] = timestamp_ms

                # --- Log Formatted Position Info ---
                # Helper to format values safely for logging
                def format_log_val(val, is_price=True, is_size=False):
                     if val is None or str(val).strip() == '' or str(val) == '0': return 'N/A'
                     try:
                          d_val = Decimal(str(val))
                          if is_size:
                              # Get amount precision dynamically if possible, else default
                              try: amt_prec = abs(Decimal(str(market_info['precision']['amount'])).normalize().as_tuple().exponent)
                              except: amt_prec = 8
                              return f"{abs(d_val):.{amt_prec}f}" # Show absolute size
                          elif is_price:
                              # Use market price precision
                              try: price_prec = TradingAnalyzer(pd.DataFrame(), lg, CONFIG, market_info).get_price_precision()
                              except: price_prec = 6 # Fallback precision
                              return f"{d_val:.{price_prec}f}"
                          else: # Other values like PNL
                              return f"{d_val:.4f}" # Default formatting
                     except: return str(val) # Fallback to string if conversion fails

                entry_price_fmt = format_log_val(active_position.get('entryPriceDecimal'))
                contracts_fmt = format_log_val(size_decimal, is_size=True)
                liq_price_fmt = format_log_val(active_position.get('liquidationPrice'))
                leverage_str = active_position.get('leverage', info_dict.get('leverage'))
                leverage_fmt = f"{Decimal(str(leverage_str)):.1f}x" if leverage_str is not None else 'N/A'
                pnl_fmt = format_log_val(active_position.get('unrealizedPnl'), is_price=False)
                sl_price_fmt = format_log_val(active_position.get('stopLossPrice'))
                tp_price_fmt = format_log_val(active_position.get('takeProfitPrice'))
                tsl_dist_fmt = format_log_val(active_position.get('trailingStopLossValue'), is_price=False) # TSL distance is a value/rate
                tsl_act_fmt = format_log_val(active_position.get('trailingStopActivationPrice'))

                logger.info(f"{NEON_GREEN}Active {side.upper()} position found ({symbol}):{RESET} "
                            f"Size={contracts_fmt}, Entry={entry_price_fmt}, Liq={liq_price_fmt}, "
                            f"Lev={leverage_fmt}, PnL={pnl_fmt}, SL={sl_price_fmt}, TP={tp_price_fmt}, "
                            f"TSL(Dist/Act): {tsl_dist_fmt}/{tsl_act_fmt}")
                logger.debug(f"Full position details for {symbol}: {active_position}")

                return active_position # Return the processed position dictionary

            except Exception as proc_err:
                 lg.error(f"Error processing active position details for {symbol}: {proc_err}", exc_info=True)
                 lg.debug(f"Problematic position data: {active_position}")
                 return None # Failed to process essential details

        else:
            # No position with size > threshold found
            logger.info(f"No active open position found for {symbol}.")
            return None

    except Exception as e:
        # Catch errors occurring outside the fetch loops (e.g., initial capability check)
        lg.error(f"{NEON_RED}Unexpected error fetching/processing positions for {symbol}: {e}{RESET}", exc_info=True)
    return None


def set_leverage_ccxt(exchange: ccxt.Exchange, symbol: str, leverage: int, market_info: Dict, logger: logging.Logger) -> bool:
    """Sets leverage for a symbol using CCXT, handling exchange specifics (like Bybit V5)."""
    lg = logger
    is_contract = market_info.get('is_contract', False)

    # Validate inputs and market type
    if not is_contract:
        lg.info(f"Leverage setting skipped for {symbol} (Not a contract market).")
        return True # No action needed, considered success
    if not isinstance(leverage, int) or leverage <= 0:
        lg.warning(f"Leverage setting skipped for {symbol}: Invalid leverage value ({leverage}). Must be a positive integer.")
        return False
    # Check if the exchange instance supports setting leverage
    if not exchange.has.get('setLeverage'):
         # Check if setMarginMode is an alternative (some exchanges combine them)
         if not exchange.has.get('setMarginMode'):
              lg.error(f"{NEON_RED}Exchange {exchange.id} does not support setLeverage or setMarginMode via CCXT. Cannot set leverage.{RESET}")
              return False
         else:
              lg.warning(f"{NEON_YELLOW}Exchange {exchange.id} uses setMarginMode for leverage. Attempting via setMarginMode...{RESET}")
              # Fall through to try setMarginMode logic if needed (though setLeverage is preferred)

    try:
        lg.info(f"Attempting to set leverage for {symbol} to {leverage}x...")
        # --- Prepare parameters ---
        params = {}
        # Handle Bybit V5 requirement for buy/sell leverage (needed even for same value)
        if 'bybit' in exchange.id.lower():
             # Ensure leverage is passed as string for Bybit V5 params
             leverage_str = str(leverage)
             params = {'buyLeverage': leverage_str, 'sellLeverage': leverage_str}
             lg.debug(f"Using Bybit V5 params for set_leverage: {params}")
        # Add other exchange-specific params here if necessary

        # --- Call setLeverage ---
        # Use the main leverage argument and the params dict
        response = exchange.set_leverage(leverage=leverage, symbol=symbol, params=params)
        lg.debug(f"Set leverage raw response for {symbol}: {response}")

        # --- Verification (Difficult without fetching position again) ---
        # CCXT setLeverage often doesn't return detailed confirmation.
        # Success is usually assumed if no exception is raised.
        # Some exchanges might return a confirmation message in the response.
        # Example check (adapt based on actual response structure):
        # if isinstance(response, dict) and response.get('info', {}).get('retMsg') == 'OK':
        #      lg.info(f"{NEON_GREEN}Leverage for {symbol} successfully set to {leverage}x (Confirmed by response).{RESET}")
        # else:
        lg.info(f"{NEON_GREEN}Leverage for {symbol} set/requested to {leverage}x (Check position details for confirmation).{RESET}")
        return True

    except ccxt.ExchangeError as e:
        # Handle specific exchange errors related to leverage setting
        err_str = str(e).lower()
        exchange_code = getattr(e, 'code', None) # Get exchange-specific error code if available
        lg.error(f"{NEON_RED}Exchange error setting leverage for {symbol}: {e} (Code: {exchange_code}){RESET}")

        # Add hints for common errors based on exchange and code
        if 'bybit' in exchange.id.lower():
             if exchange_code == 110045 or "leverage not modified" in err_str:
                 lg.info(f"{NEON_YELLOW}Leverage for {symbol} likely already set to {leverage}x (Exchange confirmation).{RESET}")
                 return True # Treat as success
             elif exchange_code in [110028, 110009, 110055] or "margin mode" in err_str:
                  lg.error(f"{NEON_YELLOW} >> Hint: Check Margin Mode (Isolated/Cross) compatibility with leverage setting. May need to set margin mode first.{RESET}")
             elif exchange_code == 110044 or "risk limit" in err_str:
                  lg.error(f"{NEON_YELLOW} >> Hint: Leverage {leverage}x may exceed the current risk limit tier for {symbol}. Check Bybit Risk Limits.{RESET}")
             elif exchange_code == 110013 or "parameter error" in err_str:
                  lg.error(f"{NEON_YELLOW} >> Hint: Leverage value {leverage}x might be invalid (e.g., too high) for {symbol}. Check allowed range.{RESET}")
             elif "set margin mode" in err_str:
                   lg.error(f"{NEON_YELLOW} >> Hint: Operation might require setting margin mode first/again using `set_margin_mode`.{RESET}")
        # Add hints for other exchanges if needed
        # elif 'binance' in exchange.id.lower(): ...

    except ccxt.NetworkError as e:
        lg.error(f"{NEON_RED}Network error setting leverage for {symbol}: {e}{RESET}")
        # Network errors are usually temporary, but setting leverage is critical
        # Consider retrying or aborting trade based on strategy
    except Exception as e:
        # Catch any other unexpected errors
        lg.error(f"{NEON_RED}Unexpected error setting leverage for {symbol}: {e}{RESET}", exc_info=True)

    # Return False if any error occurred that wasn't handled as success
    return False


def place_trade(
    exchange: ccxt.Exchange,
    symbol: str,
    trade_signal: str, # "BUY" or "SELL" (determines side)
    position_size: Decimal, # Size in base currency or contracts
    market_info: Dict, # Market details
    logger: Optional[logging.Logger] = None,
    order_type: str = 'market', # 'market' or 'limit'
    limit_price: Optional[Decimal] = None, # Required if order_type is 'limit'
    reduce_only: bool = False, # True for closing orders
    params: Optional[Dict] = None # Extra parameters for create_order
) -> Optional[Dict]:
    """
    Places an order (market or limit) using CCXT.

    Args:
        exchange: CCXT exchange instance.
        symbol: Trading symbol.
        trade_signal: "BUY" or "SELL".
        position_size: Order size (Decimal).
        market_info: Market dictionary.
        logger: Logger instance.
        order_type: 'market' or 'limit'.
        limit_price: Price for limit order (Decimal). Required if order_type='limit'.
        reduce_only: Set True for closing/reducing positions.
        params: Additional exchange-specific parameters.

    Returns:
        The order dictionary from CCXT on success, None on failure.
    """
    lg = logger or logging.getLogger(__name__)
    side = 'buy' if trade_signal == "BUY" else 'sell'
    is_contract = market_info.get('is_contract', False)
    size_unit = "Contracts" if is_contract else market_info.get('base', '')
    action_desc = "Close/Reduce" if reduce_only else "Open/Increase"

    # --- Validate Inputs ---
    try:
        amount_float = float(position_size)
        if amount_float <= 0:
            lg.error(f"Trade aborted ({symbol} {side} {action_desc}): Invalid position size ({position_size}).")
            return None
    except Exception as e:
        lg.error(f"Trade aborted ({symbol} {side} {action_desc}): Failed to convert size {position_size} to float: {e}")
        return None

    if order_type == 'limit' and (limit_price is None or not isinstance(limit_price, Decimal) or limit_price <= 0):
        lg.error(f"Trade aborted ({symbol} {side} {action_desc}): Limit order requested but invalid limit_price ({limit_price}) provided.")
        return None

    # --- Prepare Parameters ---
    order_params = {
        # Bybit V5 specific: positionIdx=0 for one-way mode is often required
        #'positionIdx': 0, # Uncomment if explicitly needed for your Bybit mode
        'reduceOnly': reduce_only,
    }
    # Merge external params, ensuring internal ones (like reduceOnly) take precedence if conflict
    if params:
         order_params.update(params) # External params added first
         order_params['reduceOnly'] = reduce_only # Ensure our flag overrides external

    # Adjust params for closing orders if needed
    if reduce_only:
        # Using IOC for market close orders helps prevent partial fills hanging
        if order_type == 'market':
             order_params['timeInForce'] = 'IOC' # ImmediateOrCancel

    # --- Log Order Details ---
    log_price = f"Limit @ {limit_price}" if order_type == 'limit' else "Market"
    lg.info(f"Attempting to place {action_desc} {side.upper()} {order_type.upper()} order for {symbol}:")
    lg.info(f"  Size: {amount_float:.8f} {size_unit}")
    if order_type == 'limit': lg.info(f"  Limit Price: {limit_price}")
    lg.info(f"  ReduceOnly: {reduce_only}")
    lg.info(f"  Params: {order_params}")


    # --- Execute Order ---
    try:
        order: Optional[Dict] = None
        if order_type == 'market':
            order = exchange.create_order(
                symbol=symbol,
                type='market',
                side=side,
                amount=amount_float,
                price=None, # Market orders don't have a price argument
                params=order_params
            )
        elif order_type == 'limit':
            # Ensure limit_price is converted to float for CCXT
            price_float = float(limit_price) if limit_price else None
            if price_float:
                order = exchange.create_order(
                    symbol=symbol,
                    type='limit',
                    side=side,
                    amount=amount_float,
                    price=price_float, # Price is required for limit orders
                    params=order_params
                )
            else: # Should be caught by validation, but double-check
                 lg.error("Internal Error: Limit order type but price_float is invalid.")
                 return None
        else:
            lg.error(f"Unsupported order type '{order_type}' in place_trade function.")
            return None

        # --- Log Success ---
        if order:
            order_id = order.get('id', 'N/A')
            order_status = order.get('status', 'N/A') # e.g., 'open', 'closed', 'canceled'
            filled_amount = order.get('filled', 0.0)
            avg_price = order.get('average') # Price at which it was filled (if applicable)

            lg.info(f"{NEON_GREEN}{action_desc} Trade Placed Successfully!{RESET}")
            lg.info(f"  Order ID: {order_id}, Initial Status: {order_status}")
            if filled_amount > 0: lg.info(f"  Filled Amount: {filled_amount}")
            if avg_price: lg.info(f"  Average Fill Price: {avg_price}")
            lg.debug(f"Raw order response ({symbol} {side} {action_desc}): {order}")
            return order
        else:
             # This case should ideally not be reached if create_order worked without error
             lg.error(f"{NEON_RED}Order placement call returned None without raising an exception for {symbol}.{RESET}")
             return None

    # --- Handle Specific CCXT Exceptions ---
    except ccxt.InsufficientFunds as e:
        lg.error(f"{NEON_RED}Insufficient funds to place {side} {order_type} order ({symbol}): {e}{RESET}")
        # Log current balance if possible/helpful
        try: balance = fetch_balance(exchange, QUOTE_CURRENCY, lg); lg.info(f"Current Balance: {balance} {QUOTE_CURRENCY}")
        except: pass
    except ccxt.InvalidOrder as e:
        lg.error(f"{NEON_RED}Invalid order parameters for {side} {order_type} order ({symbol}): {e}{RESET}")
        lg.error(f"  > Used Parameters: amount={amount_float}, price={limit_price}, params={order_params}")
        # Add hints based on common InvalidOrder reasons
        if "Order price is not following the tick size" in str(e): lg.error("  >> Hint: Check limit_price alignment with market tick size.")
        if "Order size is not following the step size" in str(e): lg.error("  >> Hint: Check position_size alignment with market amount step size.")
        if "minNotional" in str(e) or "cost" in str(e).lower(): lg.error("  >> Hint: Order cost might be below the minimum required by the exchange.")
        # Handle reduce-only specific errors
        exchange_code = getattr(e, 'code', None)
        if reduce_only and exchange_code == 110014: # Bybit: Reduce-only order failed
             lg.error(f"{NEON_YELLOW}  >> Hint (Bybit 110014): Reduce-only order failed. Position might be closed, size incorrect, or side wrong?{RESET}")
    except ccxt.NetworkError as e:
        lg.error(f"{NEON_RED}Network error placing {action_desc} order ({symbol}): {e}{RESET}")
        # Network errors might warrant a retry mechanism outside this function or careful state management
    except ccxt.ExchangeError as e:
        exchange_code = getattr(e, 'code', None)
        lg.error(f"{NEON_RED}Exchange error placing {action_desc} order ({symbol}): {e} (Code: {exchange_code}){RESET}")
        # Add hints for common exchange errors
        if reduce_only and exchange_code == 110025: # Bybit: Position not found/closed
            lg.warning(f"{NEON_YELLOW} >> Hint (Bybit 110025): Position might have been closed already when trying to place reduce-only order.{RESET}")
        # Add more specific hints...
    except Exception as e:
        lg.error(f"{NEON_RED}Unexpected error placing {action_desc} order ({symbol}): {e}{RESET}", exc_info=True)

    # Return None if any exception occurred
    return None


def _set_position_protection(
    exchange: ccxt.Exchange,
    symbol: str,
    market_info: Dict,
    position_info: Dict, # Required for positionIdx and context
    logger: logging.Logger,
    stop_loss_price: Optional[Decimal] = None,
    take_profit_price: Optional[Decimal] = None,
    trailing_stop_distance: Optional[Decimal] = None, # Distance in price points (Decimal)
    tsl_activation_price: Optional[Decimal] = None, # Price to activate TSL (Decimal)
) -> bool:
    """
    Internal helper to set SL, TP, or TSL for an existing position using Bybit's V5 API endpoint.
    This function handles the specific parameter formatting and API call structure for Bybit.

    NOTE: This uses a direct API call (`private_post`) because setting SL/TP/TSL simultaneously
    or setting TSL often requires specific endpoints not fully standardized in base CCXT yet.

    Args:
        exchange: CCXT Bybit instance.
        symbol: Trading symbol.
        market_info: Market dictionary.
        position_info: The dictionary representing the open position from `get_open_position`.
        logger: Logger instance.
        stop_loss_price: Target SL price (Decimal).
        take_profit_price: Target TP price (Decimal).
        trailing_stop_distance: Target TSL distance/offset (Decimal).
        tsl_activation_price: Target TSL activation price (Decimal).

    Returns:
        True if the API call was successful (or likely successful), False otherwise.
    """
    lg = logger
    # Ensure this is only called for Bybit (or adapt for other exchanges)
    if 'bybit' not in exchange.id.lower():
        lg.error(f"Protection setting via private_post is currently implemented only for Bybit. Cannot set for {exchange.id}.")
        return False
    # Ensure it's a contract market
    if not market_info.get('is_contract', False):
        lg.warning(f"Protection setting skipped for {symbol} (Not a contract market).")
        return False # Or True? If no action needed, maybe True. Let's use False as intent failed.
    # Ensure we have position info
    if not position_info:
        lg.error(f"Cannot set protection for {symbol}: Missing position information.")
        return False

    # --- Get Position Context ---
    pos_side = position_info.get('side')
    if pos_side not in ['long', 'short']:
         lg.error(f"Cannot set protection for {symbol}: Invalid or missing position side ('{pos_side}') in position_info.")
         return False
    # Get position index (Crucial for Bybit Hedge Mode, default 0 for One-Way)
    position_idx = 0 # Default for One-Way mode
    try:
        # Bybit V5 often has positionIdx in info dict
        pos_idx_val = position_info.get('info', {}).get('positionIdx')
        if pos_idx_val is not None:
             position_idx = int(pos_idx_val)
             lg.debug(f"Using positionIdx: {position_idx} from position info.")
        # Add logic here if positionIdx is stored differently for your Bybit mode/version
    except Exception as idx_err:
        lg.warning(f"Could not parse positionIdx from position info ({idx_err}), using default {position_idx}.")

    # --- Validate Input Protection Values ---
    # Check if they are positive Decimals if provided
    has_sl = isinstance(stop_loss_price, Decimal) and stop_loss_price > 0
    has_tp = isinstance(take_profit_price, Decimal) and take_profit_price > 0
    # TSL requires both distance and activation price
    has_tsl = (isinstance(trailing_stop_distance, Decimal) and trailing_stop_distance > 0 and
               isinstance(tsl_activation_price, Decimal) and tsl_activation_price > 0)

    # If no valid protection parameters are given, no need to call API
    if not has_sl and not has_tp and not has_tsl:
         lg.info(f"No valid protection parameters provided for {symbol} (PosIdx: {position_idx}). No protection set/updated.")
         # Consider this success as no action was needed/intended
         return True

    # --- Prepare API Parameters for Bybit V5 /v5/position/set-trading-stop ---
    category = 'linear' if market_info.get('linear', True) else 'inverse'
    # Base parameters for the API call
    params = {
        'category': category,
        'symbol': market_info['id'], # Use exchange-specific ID
        'tpslMode': 'Full',          # Apply to the entire position ('Full' or 'Partial')
        'slTriggerBy': 'LastPrice',  # Trigger SL based on LastPrice (or MarkPrice, IndexPrice)
        'tpTriggerBy': 'LastPrice',  # Trigger TP based on LastPrice (or MarkPrice, IndexPrice)
        # Note: Bybit V5 uses Market orders for SL/TP triggers by default via this endpoint.
        # If Limit orders are needed, different endpoints or parameters might be required.
        # 'slOrderType': 'Market', # Often implicit for this endpoint
        # 'tpOrderType': 'Market', # Often implicit
        'positionIdx': position_idx  # Crucial for hedge mode, 0 for one-way
    }
    log_parts = [f"Attempting to set protection for {symbol} ({pos_side.upper()} PosIdx: {position_idx}):"]

    # --- Format and Add Protection Parameters ---
    try:
        # Create a temporary analyzer instance to access precision/tick helpers
        analyzer = TradingAnalyzer(pd.DataFrame(), lg, CONFIG, market_info) # Needs dummy DF
        price_prec = analyzer.get_price_precision()
        min_tick = analyzer.get_min_tick_size()

        # Helper to format price using ccxt's price_to_precision
        def format_price(price_decimal: Optional[Decimal]) -> Optional[str]:
            if not isinstance(price_decimal, Decimal) or price_decimal <= 0: return None
            try:
                # Convert Decimal to float for ccxt helper
                return exchange.price_to_precision(symbol, float(price_decimal))
            except Exception as e:
                 lg.warning(f"Failed to format price {price_decimal} using price_to_precision: {e}. Price will not be set.")
                 return None

        # --- Trailing Stop Handling ---
        # Bybit V5: Setting 'trailingStop' often overrides 'stopLoss'. Set TSL first if applicable.
        formatted_tsl_distance = None
        formatted_activation_price = None
        if has_tsl:
            # Format TSL distance (requires precision relative to tick size)
            try:
                 # Determine the number of decimal places for the distance based on tick size
                 dist_prec = abs(min_tick.normalize().as_tuple().exponent)
                 # Use decimal_to_precision to format the distance value
                 formatted_tsl_distance = exchange.decimal_to_precision(
                     trailing_stop_distance,
                     exchange.ROUND, # Use standard rounding for distance
                     precision=dist_prec,
                     padding_mode=exchange.NO_PADDING # No extra zeros needed usually
                 )
                 # Ensure the formatted distance is at least the minimum tick size
                 if Decimal(formatted_tsl_distance) < min_tick:
                      lg.warning(f"Calculated TSL distance {formatted_tsl_distance} is less than min tick {min_tick}. Adjusting to min tick.")
                      formatted_tsl_distance = str(min_tick) # Use min tick as string
            except Exception as e:
                 lg.warning(f"Failed to format TSL distance {trailing_stop_distance} using decimal_to_precision: {e}. TSL distance will not be set.")
                 formatted_tsl_distance = None # Mark as failed

            # Format activation price
            formatted_activation_price = format_price(tsl_activation_price)

            # Add to params only if both parts are valid
            if formatted_tsl_distance and formatted_activation_price and Decimal(formatted_tsl_distance) > 0:
                params['trailingStop'] = formatted_tsl_distance
                params['activePrice'] = formatted_activation_price
                log_parts.append(f"  Trailing SL: Dist={formatted_tsl_distance}, Act={formatted_activation_price}")
                # If TSL is successfully set, the exchange usually ignores 'stopLoss' param.
                # We mark `has_sl` as False to prevent adding the 'stopLoss' param later.
                has_sl = False
                lg.debug("TSL parameters added. Fixed SL will be ignored by the exchange.")
            else:
                lg.error(f"Failed to format valid TSL parameters for {symbol}. TSL will not be set.")
                has_tsl = False # Mark TSL setting as failed

        # --- Fixed Stop Loss Handling ---
        # Add 'stopLoss' only if TSL was *not* successfully prepared to be set.
        if has_sl:
            formatted_sl = format_price(stop_loss_price)
            if formatted_sl:
                params['stopLoss'] = formatted_sl
                log_parts.append(f"  Fixed SL: {formatted_sl}")
            else:
                has_sl = False # Mark SL setting as failed if formatting failed

        # --- Fixed Take Profit Handling ---
        if has_tp:
            formatted_tp = format_price(take_profit_price)
            if formatted_tp:
                params['takeProfit'] = formatted_tp
                log_parts.append(f"  Fixed TP: {formatted_tp}")
            else:
                has_tp = False # Mark TP setting as failed if formatting failed

    except Exception as fmt_err:
         lg.error(f"Error during formatting/preparation of protection parameters for {symbol}: {fmt_err}", exc_info=True)
         return False # Cannot proceed if formatting fails


    # --- Check if any protection parameters remain to be set ---
    # Check the actual keys added to the params dictionary
    if not params.get('stopLoss') and not params.get('takeProfit') and not params.get('trailingStop'):
        lg.warning(f"No valid protection parameters could be formatted or remained after adjustments for {symbol} (PosIdx: {position_idx}). No API call made.")
        # If the intent was to set nothing (e.g., all inputs were invalid/None), return True.
        # If formatting failed for valid inputs, it should return False.
        # Let's assume if we reach here with no params, it was due to formatting failures or intent=None.
        # We return False if any *initial* valid protection was requested but failed formatting.
        # If no initial protection was requested, we already returned True earlier.
        return False if (stop_loss_price or take_profit_price or (trailing_stop_distance and tsl_activation_price)) else True


    # --- Make the API Call ---
    lg.info("\n".join(log_parts))
    lg.debug(f"  API Call: exchange.private_post('/v5/position/set-trading-stop', params={params})")

    try:
        # Use CCXT's generic private_post method to call the specific Bybit endpoint
        response = exchange.private_post('/v5/position/set-trading-stop', params)
        lg.debug(f"Set protection raw response for {symbol}: {response}")

        # --- Parse Bybit V5 Response ---
        ret_code = response.get('retCode')
        ret_msg = response.get('retMsg', 'Unknown Error')
        ret_ext = response.get('retExtInfo', {}) # Extra info, often empty

        if ret_code == 0:
            # Success code 0, but check message for nuances
            if "not modified" in ret_msg.lower():
                 # This happens if the SL/TP/TSL are already set to the target values
                 lg.info(f"{NEON_YELLOW}Position protection already set to target values or only partially modified for {symbol} (PosIdx: {position_idx}). Response: {ret_msg}{RESET}")
            else:
                 # Generic success message
                 lg.info(f"{NEON_GREEN}Position protection (SL/TP/TSL) set/updated successfully for {symbol} (PosIdx: {position_idx}).{RESET}")
            return True # Success
        else:
            # API call failed, log error details
            lg.error(f"{NEON_RED}Failed to set protection for {symbol} (PosIdx: {position_idx}): {ret_msg} (Code: {ret_code}) Ext: {ret_ext}{RESET}")
            # Add hints for common Bybit V5 error codes for this endpoint
            if ret_code == 110013: # Parameter error
                 lg.error(f"{NEON_YELLOW} >> Hint (110013 - Parameter Error): Check SL/TP prices vs entry price, TSL distance/activation validity, tick size compliance, tpslMode.{RESET}")
            elif ret_code == 110036: # TSL Active price invalid
                 lg.error(f"{NEON_YELLOW} >> Hint (110036 - TSL Price Invalid): TSL Activation price '{params.get('activePrice')}' likely invalid (already passed? wrong side? too close to current price?).{RESET}")
            elif ret_code == 110086: # SL Price cannot be equal to TP price
                 lg.error(f"{NEON_YELLOW} >> Hint (110086): Stop Loss price cannot be equal to Take Profit price.{RESET}")
            elif ret_code == 110043: # Position status is not normal
                  lg.error(f"{NEON_YELLOW} >> Hint (110043): Position status prevents modification (e.g., during liquidation?).{RESET}")
            elif ret_code == 110025: # Position not found / closed
                 lg.error(f"{NEON_YELLOW} >> Hint (110025): Position may have closed before protection could be set, or positionIdx mismatch?{RESET}")
            elif "trailing stop value invalid" in ret_msg.lower(): # Check message substring
                 lg.error(f"{NEON_YELLOW} >> Hint: Trailing Stop distance '{params.get('trailingStop')}' likely invalid (too small? too large? violates tick size rules?).{RESET}")
            # Add more specific error code handling as encountered...
            return False # Failure

    except ccxt.AuthenticationError as e:
         lg.error(f"{NEON_RED}Authentication error during protection API call for {symbol}: {e}{RESET}")
         # Auth errors usually mean API keys are wrong/expired, not retryable
         return False
    except ccxt.NetworkError as e:
         lg.error(f"{NEON_RED}Network error during protection API call for {symbol}: {e}{RESET}")
         # Network errors might be temporary, but failure could leave position unprotected.
         # Consider state management or manual intervention flags.
         return False # Assume failure for now
    except Exception as e:
        # Catch any other unexpected errors during the API call
        lg.error(f"{NEON_RED}Unexpected error during protection API call for {symbol}: {e}{RESET}", exc_info=True)
        return False # Failure

    # Fallthrough case, should ideally not be reached
    return False


def set_trailing_stop_loss(
    exchange: ccxt.Exchange,
    symbol: str,
    market_info: Dict,
    position_info: Dict, # Confirmed position dict from get_open_position
    config: Dict[str, Any], # Bot configuration
    logger: logging.Logger,
    take_profit_price: Optional[Decimal] = None # Optional: Set TP alongside TSL
) -> bool:
    """
    Calculates Trailing Stop Loss parameters based on configuration and position details,
    then calls the internal helper `_set_position_protection` to set the TSL (and optionally TP)
    on the exchange (specifically implemented for Bybit V5).

    Args:
        exchange: CCXT Bybit instance.
        symbol: Trading symbol.
        market_info: Market dictionary.
        position_info: Dictionary representing the open position.
        config: Bot configuration dictionary.
        logger: Logger instance.
        take_profit_price: Optional target TP price (Decimal) to set simultaneously.

    Returns:
        True if TSL (and TP if provided) was successfully set/requested, False otherwise.
    """
    lg = logger

    # Check if TSL is enabled in config
    if not config.get("enable_trailing_stop", False):
        lg.info(f"Trailing Stop Loss is disabled in config for {symbol}. Skipping TSL setup.")
        # Return True because no action was intended, or False because TSL wasn't set?
        # Let's return False to indicate TSL specifically was not actioned.
        return False

    # --- Validate TSL Config Parameters ---
    try:
        # Convert config values to Decimal for calculation
        callback_rate_str = config.get("trailing_stop_callback_rate", "0.005") # e.g., 0.5%
        activation_perc_str = config.get("trailing_stop_activation_percentage", "0.003") # e.g., 0.3% profit move
        callback_rate = Decimal(str(callback_rate_str))
        activation_percentage = Decimal(str(activation_perc_str))
    except Exception as e:
        lg.error(f"{NEON_RED}Invalid TSL parameter format in config ({symbol}): {e}. Cannot calculate TSL.{RESET}")
        lg.error(f"  >> Check 'trailing_stop_callback_rate' ({callback_rate_str}) and 'trailing_stop_activation_percentage' ({activation_perc_str}).")
        return False
    # Ensure callback rate is positive
    if callback_rate <= 0:
        lg.error(f"{NEON_RED}Invalid 'trailing_stop_callback_rate' ({callback_rate}) in config. Must be positive for {symbol}.{RESET}")
        return False
    # Ensure activation percentage is non-negative
    if activation_percentage < 0:
         lg.error(f"{NEON_RED}Invalid 'trailing_stop_activation_percentage' ({activation_percentage}) in config. Cannot be negative for {symbol}.{RESET}")
         return False

    # --- Get Required Position Info ---
    try:
        # Use the processed Decimal entry price if available
        entry_price = position_info.get('entryPriceDecimal')
        side = position_info.get('side')

        # Check if essential info is present and valid
        if entry_price is None or not isinstance(entry_price, Decimal) or entry_price <= 0:
            lg.error(f"{NEON_RED}Missing or invalid entry price ({entry_price}) in position info for TSL calc ({symbol}).{RESET}")
            return False
        if side not in ['long', 'short']:
            lg.error(f"{NEON_RED}Missing or invalid position side ('{side}') in position info for TSL calc ({symbol}).{RESET}")
            return False
    except Exception as e:
        # Catch errors if position_info structure is unexpected
        lg.error(f"{NEON_RED}Error accessing position info for TSL calculation ({symbol}): {e}.{RESET}")
        lg.debug(f"Position info received: {position_info}")
        return False

    # --- Calculate TSL Parameters ---
    try:
        # Need market helpers for precision and tick size
        analyzer = TradingAnalyzer(pd.DataFrame(), lg, config, market_info) # Temp instance
        price_precision = analyzer.get_price_precision()
        price_rounding = Decimal('1e-' + str(price_precision)) # Quantizer for price
        min_tick_size = analyzer.get_min_tick_size()

        # 1. Calculate Activation Price
        activation_price: Optional[Decimal] = None
        # Calculate offset based on percentage of entry price
        activation_offset = entry_price * activation_percentage

        if side == 'long':
            # Activation price is entry + offset, rounded UP towards profit
            raw_activation = entry_price + activation_offset
            activation_price = raw_activation.quantize(price_rounding, rounding=ROUND_UP)
            # Ensure activation is strictly > entry if percentage > 0
            if activation_percentage > 0 and activation_price <= entry_price:
                activation_price = (entry_price + min_tick_size).quantize(price_rounding, rounding=ROUND_UP)
                lg.debug(f"Adjusted LONG TSL activation price to be at least one tick above entry: {activation_price}")
            # For immediate activation (0%), set slightly above entry to meet exchange requirement (usually needs to be different from entry)
            elif activation_percentage == 0:
                 activation_price = (entry_price + min_tick_size).quantize(price_rounding, rounding=ROUND_UP)
                 lg.debug(f"Immediate TSL activation (0%) requested. Setting activation slightly above entry: {activation_price}")

        else: # side == 'short'
            # Activation price is entry - offset, rounded DOWN towards profit
            raw_activation = entry_price - activation_offset
            activation_price = raw_activation.quantize(price_rounding, rounding=ROUND_DOWN)
            # Ensure activation is strictly < entry if percentage > 0
            if activation_percentage > 0 and activation_price >= entry_price:
                 activation_price = (entry_price - min_tick_size).quantize(price_rounding, rounding=ROUND_DOWN)
                 lg.debug(f"Adjusted SHORT TSL activation price to be at least one tick below entry: {activation_price}")
            # For immediate activation (0%), set slightly below entry
            elif activation_percentage == 0:
                 activation_price = (entry_price - min_tick_size).quantize(price_rounding, rounding=ROUND_DOWN)
                 lg.debug(f"Immediate TSL activation (0%) requested. Setting activation slightly below entry: {activation_price}")

        # Validate calculated activation price
        if activation_price is None or activation_price <= 0:
             lg.error(f"{NEON_RED}Calculated TSL activation price ({activation_price}) is invalid for {symbol}. Cannot set TSL.{RESET}")
             return False

        # 2. Calculate Trailing Stop Distance (based on callback rate * activation price)
        # Bybit V5 'trailingStop' parameter is the distance/offset value.
        # The distance should ideally align with tick size.
        trailing_distance_raw = activation_price * callback_rate
        # Round the distance UP to the nearest tick size increment (more conservative trail)
        if min_tick_size > 0:
            trailing_distance = (trailing_distance_raw / min_tick_size).quantize(Decimal('1'), rounding=ROUND_UP) * min_tick_size
        else:
            # Should not happen, but fallback if tick size is zero
            lg.warning("Min tick size is zero, cannot round trailing distance accurately.")
            trailing_distance = trailing_distance_raw # Use raw value

        # Ensure distance is at least one tick size
        if min_tick_size > 0 and trailing_distance < min_tick_size:
            lg.warning(f"Calculated TSL distance {trailing_distance} is smaller than min tick {min_tick_size}. Adjusting to min tick.")
            trailing_distance = min_tick_size
        # Ensure distance is positive
        if trailing_distance <= 0:
             lg.error(f"{NEON_RED}Calculated TSL distance is zero or negative ({trailing_distance}) for {symbol}. Cannot set TSL.{RESET}")
             return False

        # --- Log Calculated Parameters ---
        lg.info(f"Calculated TSL Parameters for {symbol} ({side.upper()}):")
        lg.info(f"  Entry={entry_price:.{price_precision}f}, Act%={activation_percentage:.3%}, Callback%={callback_rate:.3%}")
        lg.info(f"  => Activation Price (Target): {activation_price:.{price_precision}f}")
        lg.info(f"  => Trailing Distance (Target): {trailing_distance:.{price_precision}f}") # Log distance with price precision
        # Log TP if it's being set alongside
        if isinstance(take_profit_price, Decimal) and take_profit_price > 0:
             tp_fmt = f"{take_profit_price:.{price_precision}f}"
             lg.info(f"  Take Profit Price (Target): {tp_fmt} (Will be set simultaneously)")
        else:
            lg.debug("  Take Profit: Not being set or updated with TSL.")


        # 3. Call the internal helper function to set TSL (and TP if provided)
        # Pass None for stop_loss_price as TSL overrides it on Bybit V5
        return _set_position_protection(
            exchange=exchange,
            symbol=symbol,
            market_info=market_info,
            position_info=position_info, # Pass the whole position dict
            logger=lg,
            stop_loss_price=None, # Explicitly None when setting TSL
            take_profit_price=take_profit_price if isinstance(take_profit_price, Decimal) and take_profit_price > 0 else None,
            trailing_stop_distance=trailing_distance,
            tsl_activation_price=activation_price
        )

    except Exception as e:
        # Catch any unexpected errors during calculation or the API call preparation
        lg.error(f"{NEON_RED}Unexpected error calculating or preparing TSL parameters for {symbol}: {e}{RESET}", exc_info=True)
        return False


# --- Main Analysis and Trading Loop ---

def analyze_and_trade_symbol(exchange: ccxt.Exchange, symbol: str, config: Dict[str, Any], logger: logging.Logger) -> None:
    """
    Performs one cycle of analysis and trading logic for a single symbol.
    Fetches data, analyzes indicators, generates signals, manages positions (entry, exit, BE, TSL).
    """
    lg = logger
    lg.info(f"---== Analyzing {symbol} ({config['interval']}) Cycle Start ==---")
    cycle_start_time = time.monotonic()

    # --- Get Market Info ---
    market_info = get_market_info(exchange, symbol, lg)
    if not market_info:
        lg.error(f"{NEON_RED}Failed to get market info for {symbol}. Skipping cycle.{RESET}")
        return # Cannot proceed without market info

    # --- Fetch Data ---
    ccxt_interval = CCXT_INTERVAL_MAP.get(config["interval"])
    if not ccxt_interval:
         lg.error(f"Invalid interval '{config['interval']}' in config. Cannot map to CCXT timeframe for {symbol}. Skipping cycle.")
         return

    kline_limit = 500 # Fetch ample data for indicators
    klines_df = fetch_klines_ccxt(exchange, symbol, ccxt_interval, limit=kline_limit, logger=lg)
    if klines_df.empty or len(klines_df) < 50: # Check for minimum reasonable data length
        lg.error(f"{NEON_RED}Failed to fetch sufficient kline data for {symbol} (fetched {len(klines_df)}). Skipping cycle.{RESET}")
        return

    current_price = fetch_current_price_ccxt(exchange, symbol, lg)
    if current_price is None:
         lg.warning(f"{NEON_YELLOW}Failed to fetch current ticker price for {symbol}. Using last close from klines as fallback.{RESET}")
         try:
             # Ensure index is datetime and sorted
             if isinstance(klines_df.index, pd.DatetimeIndex):
                 last_close_val = klines_df['close'].iloc[-1]
                 if pd.notna(last_close_val) and last_close_val > 0:
                      current_price = Decimal(str(last_close_val))
                      lg.info(f"Using last close price as current price: {current_price}")
                 else:
                     lg.error(f"{NEON_RED}Last close price from klines is invalid ({last_close_val}). Cannot proceed without current price.{RESET}")
                     return
             else:
                 lg.error(f"{NEON_RED}Kline DataFrame index is not DatetimeIndex. Cannot reliably get last close.{RESET}"); return
         except IndexError:
             lg.error(f"{NEON_RED}Kline DataFrame is empty or index error getting last close.{RESET}"); return
         except Exception as e:
             lg.error(f"{NEON_RED}Error getting last close price from klines: {e}. Cannot proceed.{RESET}"); return

    # Fetch order book data only if the indicator is enabled and weighted
    orderbook_data = None
    active_weights = config.get("weight_sets", {}).get(config.get("active_weight_set", "default"), {})
    orderbook_enabled = config.get("indicators",{}).get("orderbook", False)
    orderbook_weight = Decimal(str(active_weights.get("orderbook", "0"))) # Default weight 0
    if orderbook_enabled and orderbook_weight != 0:
         lg.debug(f"Fetching order book for {symbol} (Weight: {orderbook_weight})...")
         orderbook_data = fetch_orderbook_ccxt(exchange, symbol, config["orderbook_limit"], lg)
         if not orderbook_data:
             lg.warning(f"{NEON_YELLOW}Failed to fetch orderbook data for {symbol}, proceeding without it.{RESET}")
    else:
         lg.debug(f"Orderbook analysis skipped (Disabled or Zero Weight).")


    # --- Analyze Data ---
    analyzer = TradingAnalyzer(klines_df.copy(), lg, config, market_info)
    if not analyzer.indicator_values:
         lg.error(f"{NEON_RED}Indicator calculation failed or produced no values for {symbol}. Skipping signal generation.{RESET}")
         return

    # --- Generate Signal ---
    signal = analyzer.generate_trading_signal(current_price, orderbook_data) # Returns "BUY", "SELL", or "HOLD"

    # --- Calculate Potential TP/SL (based on current price estimate) ---
    # This SL is primarily for position sizing calculation.
    _, tp_calc, sl_calc = analyzer.calculate_entry_tp_sl(current_price, signal)
    price_precision = analyzer.get_price_precision()
    min_tick_size = analyzer.get_min_tick_size()
    current_atr = analyzer.indicator_values.get("ATR") # Should be Decimal

    # --- Log Analysis Summary ---
    lg.info(f"Current Price: {current_price:.{price_precision}f}")
    lg.info(f"ATR: {current_atr:.{price_precision+1}f}" if isinstance(current_atr, Decimal) else 'ATR: N/A')
    lg.info(f"Calculated Initial SL (for sizing): {sl_calc if sl_calc else 'N/A'}")
    lg.info(f"Calculated Initial TP (potential target): {tp_calc if tp_calc else 'N/A'}")
    tsl_enabled = config.get('enable_trailing_stop')
    be_enabled = config.get('enable_break_even')
    time_exit_minutes = config.get('time_based_exit_minutes')
    time_exit_str = f"{time_exit_minutes} min" if time_exit_minutes else "Disabled"
    lg.info(f"Position Management: TSL={'Enabled' if tsl_enabled else 'Disabled'}, BE={'Enabled' if be_enabled else 'Disabled'}, TimeExit={time_exit_str}")


    # --- Trading Execution Logic ---
    if not config.get("enable_trading", False):
        lg.debug(f"Trading is disabled in config. Analysis complete for {symbol}.")
        cycle_end_time = time.monotonic()
        lg.debug(f"---== Analysis Cycle End ({symbol}, {cycle_end_time - cycle_start_time:.2f}s) ==---")
        return

    # --- Check Existing Position ---
    # Use a clean fetch here to get the latest state before making decisions
    open_position = get_open_position(exchange, symbol, lg) # Returns dict or None

    # ==============================================
    # === Scenario 1: No Open Position           ===
    # ==============================================
    if open_position is None:
        if len(open_position) >= config.get("max_concurrent_positions", 1):
            lg.info(f"Max concurrent positions ({config.get('max_concurrent_positions', 1)}) reached. Not entering new position for {symbol}.")

        elif signal in ["BUY", "SELL"]:
            lg.info(f"*** {signal} Signal & No Position: Initiating Trade Sequence for {symbol} ***")

            # 1. Fetch Balance
            balance = fetch_balance(exchange, QUOTE_CURRENCY, lg)
            if balance is None or balance <= 0:
                lg.error(f"{NEON_RED}Trade Aborted ({symbol} {signal}): Cannot fetch balance or balance is zero/negative.{RESET}")
                return # Stop trade sequence

            # 2. Check if Initial SL for sizing is valid
            if sl_calc is None:
                 lg.error(f"{NEON_RED}Trade Aborted ({symbol} {signal}): Initial SL calculation failed (ATR invalid?). Cannot calculate position size.{RESET}")
                 return # Stop trade sequence

            # 3. Set Leverage (if applicable)
            if market_info.get('is_contract', False):
                leverage = int(config.get("leverage", 1)) # Default to 1x if not set
                if leverage > 0:
                    if not set_leverage_ccxt(exchange, symbol, leverage, market_info, lg):
                         lg.error(f"{NEON_RED}Trade Aborted ({symbol} {signal}): Failed to set leverage to {leverage}x.{RESET}")
                         return # Stop trade sequence
                else: lg.info(f"Leverage setting skipped: Leverage config is zero or negative ({leverage}).")
            else:
                lg.info(f"Leverage setting skipped (Spot market).")

            # 4. Calculate Position Size
            # Use the initial SL calculated earlier for sizing
            # Use current_price as the entry price estimate for sizing
            position_size = calculate_position_size(
                balance=balance,
                risk_per_trade=config["risk_per_trade"],
                initial_stop_loss_price=sl_calc,
                entry_price=current_price,
                market_info=market_info,
                exchange=exchange,
                logger=lg
            )
            if position_size is None or position_size <= 0:
                lg.error(f"{NEON_RED}Trade Aborted ({symbol} {signal}): Position size calculation failed or resulted in zero/negative ({position_size}).{RESET}")
                return # Stop trade sequence

            # 5. Determine Order Type and Price
            entry_order_type = config.get("entry_order_type", "market")
            limit_entry_price: Optional[Decimal] = None

            if entry_order_type == "limit":
                 offset_buy = Decimal(str(config.get("limit_order_offset_buy", "0.0005")))
                 offset_sell = Decimal(str(config.get("limit_order_offset_sell", "0.0005")))
                 rounding_factor = Decimal('1e-' + str(price_precision))

                 if signal == "BUY":
                      raw_limit = current_price * (Decimal(1) - offset_buy)
                      # Round down for buy limit (get a potentially better price)
                      limit_entry_price = raw_limit.quantize(rounding_factor, rounding=ROUND_DOWN)
                 else: # SELL
                      raw_limit = current_price * (Decimal(1) + offset_sell)
                      # Round up for sell limit (get a potentially better price)
                      limit_entry_price = raw_limit.quantize(rounding_factor, rounding=ROUND_UP)

                 # Ensure limit price is positive
                 if limit_entry_price <= 0:
                      lg.error(f"{NEON_RED}Trade Aborted ({symbol} {signal}): Calculated limit entry price is non-positive ({limit_entry_price}). Switching to Market order.{RESET}")
                      entry_order_type = "market"
                      limit_entry_price = None
                 else:
                      lg.info(f"Calculated Limit Entry Price for {signal}: {limit_entry_price}")

            # 6. Place Entry Order
            lg.info(f"==> Placing {signal} {entry_order_type.upper()} order | Size: {position_size} <==")
            trade_order = place_trade(
                exchange=exchange,
                symbol=symbol,
                trade_signal=signal,
                position_size=position_size,
                market_info=market_info,
                logger=lg,
                order_type=entry_order_type,
                limit_price=limit_entry_price, # Will be None for market orders
                reduce_only=False,
                params=None # Add specific entry params if needed
            )

            # 7. Handle Order Placement Result
            if trade_order and trade_order.get('id'):
                order_id = trade_order['id']
                order_status = trade_order.get('status') # 'open', 'closed', 'canceled', etc.

                # If Market Order -> Confirm Position Immediately
                if entry_order_type == 'market':
                    confirm_delay = config.get("position_confirm_delay_seconds", POSITION_CONFIRM_DELAY_SECONDS)
                    lg.info(f"Market order {order_id} placed. Waiting {confirm_delay}s for position confirmation...")
                    time.sleep(confirm_delay)

                    lg.info(f"Attempting position confirmation for {symbol} after market order {order_id}...")
                    confirmed_position = get_open_position(exchange, symbol, lg)

                    if confirmed_position:
                        lg.info(f"{NEON_GREEN}Position Confirmed after Market Order!{RESET}")
                        # Proceed to set protection based on actual entry price
                        try:
                            entry_price_actual = confirmed_position.get('entryPriceDecimal')
                            if entry_price_actual is None or entry_price_actual <= 0:
                                lg.warning(f"Could not get valid actual entry price from confirmed position. Using initial estimate {current_price} for protection.")
                                entry_price_actual = current_price # Fallback

                            lg.info(f"Actual Entry Price: ~{entry_price_actual:.{price_precision}f}")

                            # Recalculate protection levels based on ACTUAL entry price
                            _, tp_final, sl_final = analyzer.calculate_entry_tp_sl(entry_price_actual, signal)

                            # Set Protection (TSL or Fixed SL/TP)
                            protection_set_success = False
                            if config.get("enable_trailing_stop", False):
                                 lg.info(f"Setting Exchange Trailing Stop Loss (TP target: {tp_final})...")
                                 protection_set_success = set_trailing_stop_loss(
                                     exchange=exchange, symbol=symbol, market_info=market_info,
                                     position_info=confirmed_position, config=config, logger=lg,
                                     take_profit_price=tp_final # Pass recalculated TP target
                                 )
                            else:
                                 # Set Fixed SL/TP if TSL is disabled
                                 lg.info(f"Setting Fixed SL ({sl_final}) and TP ({tp_final})...")
                                 if sl_final or tp_final: # Only set if values are valid
                                     protection_set_success = _set_position_protection(
                                         exchange=exchange, symbol=symbol, market_info=market_info,
                                         position_info=confirmed_position, logger=lg,
                                         stop_loss_price=sl_final, take_profit_price=tp_final
                                     )
                                 else:
                                     lg.warning(f"{NEON_YELLOW}Fixed SL/TP calculation failed based on actual entry or returned None. No fixed protection set.{RESET}")

                            # Log final status
                            if protection_set_success:
                                 lg.info(f"{NEON_GREEN}=== TRADE ENTRY & PROTECTION SETUP COMPLETE ({symbol} {signal}) ===")
                            else:
                                 lg.error(f"{NEON_RED}=== TRADE placed BUT FAILED TO SET PROTECTION ({symbol} {signal}) ===")
                                 lg.warning(f"{NEON_YELLOW}>>> MANUAL MONITORING REQUIRED! <<<")

                        except Exception as post_trade_err:
                             lg.error(f"{NEON_RED}Error during post-trade protection setting ({symbol}): {post_trade_err}{RESET}", exc_info=True)
                             lg.warning(f"{NEON_YELLOW}Position is open but protection setup failed. Manual check needed!{RESET}")
                    else:
                        # Market order placed, but position not confirmed
                        lg.error(f"{NEON_RED}Market trade order {order_id} placed, but FAILED TO CONFIRM open position after {confirm_delay}s delay!{RESET}")
                        lg.warning(f"{NEON_YELLOW}Order may have failed, been rejected, or API/exchange delay. Manual investigation required!{RESET}")

                # If Limit Order -> Log and wait for next cycle (or implement order monitoring)
                elif entry_order_type == 'limit':
                     if order_status == 'open':
                         lg.info(f"Limit order {order_id} placed successfully and is OPEN.")
                         lg.info("Will check status and set protection on next cycle if filled.")
                         # Optional: Add logic here to monitor the open limit order specifically
                         # e.g., store order_id and check its status in subsequent loops
                     elif order_status == 'closed':
                          lg.warning(f"Limit order {order_id} filled immediately (status: {order_status}). Attempting confirmation...")
                          # Treat like market order - try to confirm and set protection
                          # (Add similar confirmation/protection logic as above)
                          lg.info(f"Attempting position confirmation for {symbol} after immediate limit fill {order_id}...")
                          confirmed_position = get_open_position(exchange, symbol, lg)
                          if confirmed_position:
                              # ... (Add protection setting logic here, identical to market order success path) ...
                               lg.info(f"{NEON_GREEN}Position Confirmed after Immediate Limit Fill!{RESET}")
                               # Proceed to set protection based on actual entry price
                               try:
                                   entry_price_actual = confirmed_position.get('entryPriceDecimal')
                                   if entry_price_actual is None or entry_price_actual <= 0:
                                       lg.warning(f"Could not get valid actual entry price from confirmed position. Using limit price {limit_entry_price} for protection.")
                                       entry_price_actual = limit_entry_price # Fallback to intended limit

                                   lg.info(f"Actual Entry Price: ~{entry_price_actual:.{price_precision}f}")
                                   _, tp_final, sl_final = analyzer.calculate_entry_tp_sl(entry_price_actual, signal)

                                   protection_set_success = False
                                   if config.get("enable_trailing_stop", False):
                                        lg.info(f"Setting Exchange Trailing Stop Loss (TP target: {tp_final})...")
                                        protection_set_success = set_trailing_stop_loss(
                                            exchange=exchange, symbol=symbol, market_info=market_info,
                                            position_info=confirmed_position, config=config, logger=lg,
                                            take_profit_price=tp_final
                                        )
                                   else:
                                        lg.info(f"Setting Fixed SL ({sl_final}) and TP ({tp_final})...")
                                        if sl_final or tp_final:
                                            protection_set_success = _set_position_protection(
                                                exchange=exchange, symbol=symbol, market_info=market_info,
                                                position_info=confirmed_position, logger=lg,
                                                stop_loss_price=sl_final, take_profit_price=tp_final
                                            )
                                        else: lg.warning(f"{NEON_YELLOW}Fixed SL/TP calculation failed. No fixed protection set.{RESET}")

                                   if protection_set_success: lg.info(f"{NEON_GREEN}=== TRADE ENTRY & PROTECTION SETUP COMPLETE ({symbol} {signal}) ===")
                                   else: lg.error(f"{NEON_RED}=== TRADE placed BUT FAILED TO SET PROTECTION ({symbol} {signal}) ==="); lg.warning(f"{NEON_YELLOW}>>> MANUAL MONITORING REQUIRED! <<<")
                               except Exception as post_trade_err:
                                    lg.error(f"{NEON_RED}Error during post-trade protection setting ({symbol}): {post_trade_err}{RESET}", exc_info=True)
                                    lg.warning(f"{NEON_YELLOW}Position open but protection setup failed. Manual check needed!{RESET}")
                          else:
                              lg.error(f"{NEON_RED}Limit order {order_id} reported 'closed', but FAILED TO CONFIRM open position! Manual check needed!{RESET}")
                     else:
                          # Limit order failed or was cancelled immediately
                          lg.error(f"Limit order {order_id} placement resulted in status: {order_status}. Trade did not open.")
            else:
                # place_trade returned None
                lg.error(f"{NEON_RED}=== TRADE EXECUTION FAILED ({symbol} {signal}). Order placement function returned None. See previous logs. ===")
        else: # signal == HOLD
            lg.info(f"Signal is HOLD and no open position for {symbol}. No entry action taken.")

    # ==============================================
    # === Scenario 2: Existing Open Position     ===
    # ==============================================
    else: # open_position is not None
        pos_side = open_position.get('side', 'unknown')
        pos_size = open_position.get('contractsDecimal', Decimal('0'))
        entry_price = open_position.get('entryPriceDecimal')
        pos_timestamp_ms = open_position.get('timestamp_ms') # Get timestamp in ms

        lg.info(f"Managing existing {pos_side.upper()} position for {symbol}. Size: {pos_size}, Entry: {entry_price}")

        # --- Check for Exit Signal ---
        exit_signal_triggered = (pos_side == 'long' and signal == "SELL") or \
                                (pos_side == 'short' and signal == "BUY")

        if exit_signal_triggered:
            lg.warning(f"{NEON_YELLOW}*** EXIT Signal Triggered: New signal ({signal}) opposes existing {pos_side} position. Closing position... ***{RESET}")
            try:
                # Determine close side based on position side
                close_side_signal = "SELL" if pos_side == 'long' else "BUY"
                size_to_close = abs(pos_size) # Close the absolute size
                if size_to_close <= 0:
                    raise ValueError(f"Position size to close is zero or negative ({size_to_close}). Cannot close.")

                lg.info(f"==> Placing {close_side_signal} MARKET order (reduceOnly=True) | Size: {size_to_close} <==")
                # Use market order for closing to ensure exit
                close_order = place_trade(
                    exchange=exchange, symbol=symbol, trade_signal=close_side_signal,
                    position_size=size_to_close, market_info=market_info, logger=lg,
                    order_type='market', reduce_only=True
                )

                if close_order:
                    lg.info(f"{NEON_GREEN}Position CLOSE order placed successfully for {symbol}. Order ID: {close_order.get('id', 'N/A')}{RESET}")
                    # Assuming market close is effective. Further checks could poll position status again.
                    # Important: Exit the current cycle after placing close order to avoid conflicting actions
                    return
                else:
                    lg.error(f"{NEON_RED}Failed to place CLOSE order for {symbol}. Manual check/intervention required!{RESET}")
                    # Consider what state the bot should be in - maybe skip further management this cycle

            except Exception as close_err:
                 lg.error(f"{NEON_RED}Error attempting to close position {symbol}: {close_err}{RESET}", exc_info=True)
                 lg.warning(f"{NEON_YELLOW}Manual intervention may be needed to close the position!{RESET}")
            # After attempting close, exit the management logic for this cycle
            return

        # --- If No Exit Signal, Proceed with Position Management ---
        else:
            lg.info(f"Signal ({signal}) allows holding the existing {pos_side} position. Performing position management checks...")

            # --- Check for Time-Based Exit ---
            time_exit_minutes_config = config.get("time_based_exit_minutes")
            if time_exit_minutes_config and time_exit_minutes_config > 0:
                if pos_timestamp_ms:
                    try:
                        current_time_ms = time.time() * 1000
                        time_elapsed_ms = current_time_ms - pos_timestamp_ms
                        time_elapsed_minutes = time_elapsed_ms / (1000 * 60)

                        lg.debug(f"Time-Based Exit Check: Elapsed = {time_elapsed_minutes:.2f} min, Limit = {time_exit_minutes_config} min")

                        if time_elapsed_minutes >= time_exit_minutes_config:
                            lg.warning(f"{NEON_YELLOW}*** TIME-BASED EXIT Triggered ({time_elapsed_minutes:.1f} >= {time_exit_minutes_config} min). Closing position... ***{RESET}")
                            # --- Execute Close Logic (similar to above) ---
                            close_side_signal = "SELL" if pos_side == 'long' else "BUY"
                            size_to_close = abs(pos_size)
                            if size_to_close > 0:
                                close_order = place_trade(exchange, symbol, close_side_signal, size_to_close, market_info, lg, order_type='market', reduce_only=True)
                                if close_order: lg.info(f"{NEON_GREEN}Time-based CLOSE order placed successfully for {symbol}. ID: {close_order.get('id', 'N/A')}{RESET}")
                                else: lg.error(f"{NEON_RED}Failed to place time-based CLOSE order for {symbol}. Manual check required!{RESET}")
                            else: lg.warning("Time-based exit triggered but position size is zero. No close order placed.")
                            # Exit management logic after triggering time-based close
                            return
                    except Exception as time_err:
                         lg.error(f"{NEON_RED}Error during time-based exit check: {time_err}{RESET}")
                else:
                    lg.warning("Time-based exit enabled, but position timestamp not found. Cannot perform check.")


            # --- Check if TSL is Active on the Exchange ---
            # We need to rely on the 'trailingStopLossValue' field populated by get_open_position
            is_tsl_active_exchange = False
            try:
                 # Check if the trailing stop distance value is present and positive
                 tsl_value_str = open_position.get('trailingStopLossValue')
                 if tsl_value_str and str(tsl_value_str) != '0': # Check if not None, empty or '0' string
                      tsl_value = Decimal(str(tsl_value_str))
                      if tsl_value > 0:
                           is_tsl_active_exchange = True
                           lg.debug("Exchange Trailing Stop Loss appears to be active for this position.")
            except Exception as tsl_check_err:
                 lg.warning(f"Could not reliably determine if exchange TSL is active: {tsl_check_err}")


            # --- Check Break-Even Conditions ---
            # Only run BE check if:
            # 1. BE is enabled in config.
            # 2. Exchange TSL is NOT currently active (BE usually gets disabled once TSL takes over).
            if config.get("enable_break_even", False) and not is_tsl_active_exchange:
                lg.debug(f"Checking Break-Even conditions for {symbol}...")
                try:
                    # Ensure we have valid entry price and ATR
                    if entry_price is None or entry_price <= 0: raise ValueError("Invalid entry price for BE check")
                    if not isinstance(current_atr, Decimal) or current_atr <= 0: raise ValueError("Invalid ATR for BE check")

                    # Get BE config parameters
                    be_trigger_atr_mult_str = config.get("break_even_trigger_atr_multiple", "1.0")
                    be_offset_ticks = int(config.get("break_even_offset_ticks", 2))
                    profit_target_atr = Decimal(str(be_trigger_atr_mult_str))

                    # Calculate current profit/loss in price points and ATR multiples
                    price_diff = (current_price - entry_price) if pos_side == 'long' else (entry_price - current_price)
                    # Avoid division by zero if ATR is somehow zero
                    profit_in_atr = price_diff / current_atr if current_atr > 0 else Decimal('0')

                    lg.debug(f"BE Check: CurrentPrice={current_price:.{price_precision}f}, Entry={entry_price:.{price_precision}f}")
                    lg.debug(f"BE Check: Price Diff={price_diff:.{price_precision}f}, Profit ATRs={profit_in_atr:.2f}, Target ATRs={profit_target_atr}")

                    # Check if profit target is reached
                    if profit_in_atr >= profit_target_atr:
                        # --- Calculate Target Break-Even Stop Price ---
                        # Add/subtract a small offset (in ticks) from entry price
                        tick_offset = min_tick_size * be_offset_ticks
                        be_stop_price: Optional[Decimal] = None
                        if pos_side == 'long':
                            # Place BE SL slightly above entry
                            be_stop_price = (entry_price + tick_offset).quantize(min_tick_size, rounding=ROUND_UP)
                        else: # short
                            # Place BE SL slightly below entry
                            be_stop_price = (entry_price - tick_offset).quantize(min_tick_size, rounding=ROUND_DOWN)

                        if be_stop_price is None or be_stop_price <= 0:
                             raise ValueError(f"Calculated BE stop price invalid: {be_stop_price}")

                        # --- Get Current Stop Loss from Position Info ---
                        current_sl_price: Optional[Decimal] = None
                        # Check both standard field and info dict fallback
                        current_sl_str = open_position.get('stopLossPrice') or open_position.get('info', {}).get('stopLoss')
                        # Ensure it's not None, empty string, or '0' string before converting
                        if current_sl_str and str(current_sl_str) != '0':
                            try:
                                current_sl_price = Decimal(str(current_sl_str))
                            except Exception as sl_parse_err:
                                lg.warning(f"Could not parse current stop loss '{current_sl_str}': {sl_parse_err}")

                        # --- Determine if SL Update is Needed ---
                        update_be_sl = False
                        if current_sl_price is None:
                            # No current SL set, so set the BE SL
                            update_be_sl = True
                            lg.info("BE triggered: No current SL found. Setting BE SL.")
                        elif pos_side == 'long' and be_stop_price > current_sl_price:
                            # Current SL is below target BE SL, move it up
                            update_be_sl = True
                            lg.info(f"BE triggered: Target BE SL {be_stop_price} is tighter than Current SL {current_sl_price}. Updating.")
                        elif pos_side == 'short' and be_stop_price < current_sl_price:
                            # Current SL is above target BE SL, move it down
                            update_be_sl = True
                            lg.info(f"BE triggered: Target BE SL {be_stop_price} is tighter than Current SL {current_sl_price}. Updating.")
                        else:
                            # BE triggered, but current SL is already at or better than BE target
                            lg.debug(f"BE Triggered, but current SL ({current_sl_price}) is already better than or equal to target BE SL ({be_stop_price}). No SL update needed.")

                        # --- Execute SL Update if Needed ---
                        if update_be_sl:
                            lg.warning(f"{NEON_PURPLE}*** Moving Stop Loss to Break-Even for {symbol} at {be_stop_price} ***{RESET}")
                            # Preserve existing Take Profit if one is set
                            current_tp_price: Optional[Decimal] = None
                            current_tp_str = open_position.get('takeProfitPrice') or open_position.get('info', {}).get('takeProfit')
                            if current_tp_str and str(current_tp_str) != '0':
                                 try: current_tp_price = Decimal(str(current_tp_str))
                                 except: pass # Ignore parsing error for TP

                            # Call the protection function to update SL (and preserve TP)
                            success = _set_position_protection(
                                exchange=exchange, symbol=symbol, market_info=market_info,
                                position_info=open_position, logger=lg,
                                stop_loss_price=be_stop_price,
                                take_profit_price=current_tp_price # Pass existing TP to preserve it
                            )
                            if success: lg.info(f"{NEON_GREEN}Break-Even SL set/updated successfully.{RESET}")
                            else: lg.error(f"{NEON_RED}Failed to set/update Break-Even SL.{RESET}")
                            # Optional: If BE SL set successfully, maybe disable further BE checks for this position?

                    else:
                        # Profit target not yet reached
                        lg.debug(f"BE Profit target not reached ({profit_in_atr:.2f} < {profit_target_atr} ATRs).")

                except ValueError as ve: # Catch validation errors for entry price/ATR
                     lg.warning(f"BE Check skipped for {symbol}: {ve}")
                except Exception as be_err:
                    lg.error(f"{NEON_RED}Error during break-even check ({symbol}): {be_err}{RESET}", exc_info=True)
            elif is_tsl_active_exchange:
                 lg.debug(f"Break-even check skipped: Exchange Trailing Stop Loss is active.")
            else: # BE disabled in config
                 lg.debug(f"Break-even check skipped: Disabled in config.")

            # --- Placeholder for other potential management logic ---
            # - Check if TSL activation price hit, but TSL failed to set previously? Retry?
            # - Partial profit taking?
            # - Adding to position? (Requires careful risk management adjustment)


    # --- Cycle End Logging ---
    cycle_end_time = time.monotonic()
    lg.debug(f"---== Analysis Cycle End ({symbol}, {cycle_end_time - cycle_start_time:.2f}s) ==---")


def main() -> None:
    """Main function to initialize the bot and run the analysis loop."""
    global CONFIG, QUOTE_CURRENCY # Allow modification of globals

    # Use a general logger for initial setup
    setup_logger("init") # Create logger for initialization phase
    init_logger = logging.getLogger("init") # Get the logger instance

    init_logger.info(f"--- Starting XR Scalper Bot ({datetime.now(TIMEZONE).strftime('%Y-%m-%d %H:%M:%S %Z')}) ---")
    # Load/Update config at start
    CONFIG = load_config(CONFIG_FILE)
    QUOTE_CURRENCY = CONFIG.get("quote_currency", "USDT") # Update global QUOTE_CURRENCY
    init_logger.info(f"Config loaded from {CONFIG_FILE}. Quote Currency: {QUOTE_CURRENCY}")
    init_logger.info(f"Versions: CCXT={ccxt.__version__}, Pandas={pd.__version__}, PandasTA={ta.version if hasattr(ta, 'version') else 'N/A'}")


    # --- Trading Enabled Warning ---
    if CONFIG.get("enable_trading"):
         init_logger.warning(f"{NEON_YELLOW}!!! LIVE TRADING IS ENABLED !!!{RESET}")
         if CONFIG.get("use_sandbox"):
              init_logger.warning(f"{NEON_YELLOW}Using SANDBOX (Testnet) Environment.{RESET}")
         else:
              # Extra warning for real money
              init_logger.warning(f"{NEON_RED}!!! CAUTION: USING REAL MONEY ENVIRONMENT !!!{RESET}")

         # Display critical settings before proceeding
         risk_pct = CONFIG.get('risk_per_trade', 0) * 100
         leverage = CONFIG.get('
# scalpxrx.py
# Enhanced and Upgraded Scalping Bot Framework
# Derived from xrscalper.py, focusing on robust execution, error handling,
# advanced position management (BE, TSL), and Bybit V5 compatibility.

import hashlib
import hmac
import json
import logging
import math
import os
import time
from datetime import datetime, timedelta, timezone
from decimal import ROUND_DOWN, ROUND_UP, Decimal, InvalidOperation, getcontext
from logging.handlers import RotatingFileHandler
from typing import Any, Dict, List, Optional, Tuple, Union

import ccxt
import numpy as np
import pandas as pd
import pandas_ta as ta  # Import pandas_ta
import requests
from colorama import Fore, Style, init
from dotenv import load_dotenv
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from zoneinfo import ZoneInfo

# Initialize colorama and set Decimal precision
getcontext().prec = 36  # Increased precision for complex calculations
init(autoreset=True)
load_dotenv()

# Neon Color Scheme
NEON_GREEN = Fore.LIGHTGREEN_EX
NEON_BLUE = Fore.CYAN
NEON_PURPLE = Fore.MAGENTA
NEON_YELLOW = Fore.YELLOW
NEON_RED = Fore.LIGHTRED_EX
NEON_CYAN = Fore.CYAN
RESET = Style.RESET_ALL

# --- Constants ---
API_KEY = os.getenv("BYBIT_API_KEY")
API_SECRET = os.getenv("BYBIT_API_SECRET")
if not API_KEY or not API_SECRET:
    raise ValueError("BYBIT_API_KEY and BYBIT_API_SECRET must be set in .env")

CONFIG_FILE = "config.json"
LOG_DIRECTORY = "bot_logs"
# Timezone for logging and display
TIMEZONE = ZoneInfo("America/Chicago")  # Adjust as needed
MAX_API_RETRIES = 5  # Max retries for recoverable API errors
RETRY_DELAY_SECONDS = 7  # Increased delay between retries
VALID_INTERVALS = ["1", "3", "5", "15", "30", "60", "120", "240", "D", "W", "M"]
CCXT_INTERVAL_MAP = { # Map our intervals to ccxt's expected format
    "1": "1m", "3": "3m", "5": "5m", "15": "15m", "30": "30m",
    "60": "1h", "120": "2h", "240": "4h", "D": "1d", "W": "1w", "M": "1M"
}
RETRY_ERROR_CODES = [429, 500, 502, 503, 504] # HTTP status codes considered retryable
# Default indicator periods (can be overridden by config.json)
DEFAULT_ATR_PERIOD = 14
DEFAULT_CCI_WINDOW = 20
DEFAULT_WILLIAMS_R_WINDOW = 14
DEFAULT_MFI_WINDOW = 14
DEFAULT_STOCH_RSI_WINDOW = 14
DEFAULT_STOCH_WINDOW = 12
DEFAULT_K_WINDOW = 3
DEFAULT_D_WINDOW = 3
DEFAULT_RSI_WINDOW = 14
DEFAULT_BOLLINGER_BANDS_PERIOD = 20
DEFAULT_BOLLINGER_BANDS_STD_DEV = 2.0
DEFAULT_SMA_10_WINDOW = 10
DEFAULT_EMA_SHORT_PERIOD = 9
DEFAULT_EMA_LONG_PERIOD = 21
DEFAULT_MOMENTUM_PERIOD = 7
DEFAULT_VOLUME_MA_PERIOD = 15
DEFAULT_FIB_WINDOW = 50
DEFAULT_PSAR_AF = 0.02
DEFAULT_PSAR_MAX_AF = 0.2

FIB_LEVELS = [0.0, 0.236, 0.382, 0.5, 0.618, 0.786, 1.0] # Standard Fibonacci levels
LOOP_DELAY_SECONDS = 10 # Time between the end of one cycle and the start of the next
POSITION_CONFIRM_DELAY_SECONDS = 10 # Increased wait time after placing order before confirming position
# QUOTE_CURRENCY dynamically loaded from config

os.makedirs(LOG_DIRECTORY, exist_ok=True)

class SensitiveFormatter(logging.Formatter):
    """Formatter to redact sensitive information (API keys) from logs."""
    def format(self, record: logging.LogRecord) -> str:
        msg = super().format(record)
        if API_KEY:
            msg = msg.replace(API_KEY, "***API_KEY***")
        if API_SECRET:
            msg = msg.replace(API_SECRET, "***API_SECRET***")
        return msg

def load_config(filepath: str) -> Dict[str, Any]:
    """Load configuration from JSON file, creating default if not found,
       and ensuring all default keys are present with validation."""
    default_config = {
        "symbol": "BTC/USDT:USDT", # Specify the full symbol including contract type if needed
        "interval": "5",
        "retry_delay": RETRY_DELAY_SECONDS,
        "atr_period": DEFAULT_ATR_PERIOD,
        "ema_short_period": DEFAULT_EMA_SHORT_PERIOD,
        "ema_long_period": DEFAULT_EMA_LONG_PERIOD,
        "rsi_period": DEFAULT_RSI_WINDOW,
        "bollinger_bands_period": DEFAULT_BOLLINGER_BANDS_PERIOD,
        "bollinger_bands_std_dev": DEFAULT_BOLLINGER_BANDS_STD_DEV,
        "cci_window": DEFAULT_CCI_WINDOW,
        "williams_r_window": DEFAULT_WILLIAMS_R_WINDOW,
        "mfi_window": DEFAULT_MFI_WINDOW,
        "stoch_rsi_window": DEFAULT_STOCH_RSI_WINDOW,
        "stoch_rsi_rsi_window": DEFAULT_STOCH_WINDOW,
        "stoch_rsi_k": DEFAULT_K_WINDOW,
        "stoch_rsi_d": DEFAULT_D_WINDOW,
        "psar_af": DEFAULT_PSAR_AF,
        "psar_max_af": DEFAULT_PSAR_MAX_AF,
        "sma_10_window": DEFAULT_SMA_10_WINDOW,
        "momentum_period": DEFAULT_MOMENTUM_PERIOD,
        "volume_ma_period": DEFAULT_VOLUME_MA_PERIOD,
        "orderbook_limit": 25,
        "signal_score_threshold": 1.5,
        "stoch_rsi_oversold_threshold": 25,
        "stoch_rsi_overbought_threshold": 75,
        "stop_loss_multiple": 1.8, # ATR multiple for initial SL (used for sizing)
        "take_profit_multiple": 0.7, # ATR multiple for TP
        "volume_confirmation_multiplier": 1.5,
        "scalping_signal_threshold": 2.5,
        "fibonacci_window": DEFAULT_FIB_WINDOW,
        "enable_trading": False,
        "use_sandbox": True,
        "risk_per_trade": 0.01, # e.g., 1%
        "leverage": 20,
        "max_concurrent_positions": 1, # Per symbol managed by this instance
        "quote_currency": "USDT",
        "entry_order_type": "market", # "market" or "limit"
        "limit_order_offset_buy": 0.0005, # Percentage offset (0.05%)
        "limit_order_offset_sell": 0.0005, # Percentage offset (0.05%)
        "enable_trailing_stop": True,
        "trailing_stop_callback_rate": 0.005, # e.g., 0.5% trail distance
        "trailing_stop_activation_percentage": 0.003, # e.g., Activate when profit reaches 0.3%
        "enable_break_even": True,
        "break_even_trigger_atr_multiple": 1.0,
        "break_even_offset_ticks": 2, # Place BE SL X ticks beyond entry
        "position_confirm_delay_seconds": POSITION_CONFIRM_DELAY_SECONDS,
        "time_based_exit_minutes": None, # e.g., 60 to exit after 1 hour
        "indicators": {
            "ema_alignment": True, "momentum": True, "volume_confirmation": True,
            "stoch_rsi": True, "rsi": True, "bollinger_bands": True, "vwap": True,
            "cci": True, "wr": True, "psar": True, "sma_10": True, "mfi": True,
            "orderbook": True,
        },
        "weight_sets": {
            "scalping": {
                "ema_alignment": 0.2, "momentum": 0.3, "volume_confirmation": 0.2,
                "stoch_rsi": 0.6, "rsi": 0.2, "bollinger_bands": 0.3, "vwap": 0.4,
                "cci": 0.3, "wr": 0.3, "psar": 0.2, "sma_10": 0.1, "mfi": 0.2, "orderbook": 0.15,
            },
            "default": {
                "ema_alignment": 0.3, "momentum": 0.2, "volume_confirmation": 0.1,
                "stoch_rsi": 0.4, "rsi": 0.3, "bollinger_bands": 0.2, "vwap": 0.3,
                "cci": 0.2, "wr": 0.2, "psar": 0.3, "sma_10": 0.1, "mfi": 0.2, "orderbook": 0.1,
            }
        },
        "active_weight_set": "default"
    }

    config = default_config.copy()
    if os.path.exists(filepath):
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                loaded_config = json.load(f)
            config = _merge_configs(loaded_config, default_config)
            print(f"{NEON_GREEN}Loaded configuration from {filepath}{RESET}")
        except (json.JSONDecodeError, IOError) as e:
            print(f"{NEON_RED}Error loading config file {filepath}: {e}. Using default config.{RESET}")
            # Optionally recreate default if load failed badly
            try:
                with open(filepath, "w", encoding="utf-8") as f_write:
                    json.dump(default_config, f_write, indent=4)
                print(f"{NEON_YELLOW}Recreated default config file: {filepath}{RESET}")
            except IOError as e_create:
                print(f"{NEON_RED}Error recreating default config file: {e_create}{RESET}")
    else:
        print(f"{NEON_YELLOW}Config file not found. Creating default config at {filepath}{RESET}")
        try:
            with open(filepath, "w", encoding="utf-8") as f:
                json.dump(default_config, f, indent=4)
            config = default_config
        except IOError as e:
            print(f"{NEON_RED}Error creating default config file {filepath}: {e}{RESET}")
            # Continue with in-memory default config

    # --- Validation ---
    updated = False
    if config.get("interval") not in VALID_INTERVALS:
        print(f"{NEON_RED}Invalid interval '{config.get('interval')}' in config. Resetting to default '{default_config['interval']}'.{RESET}")
        config["interval"] = default_config["interval"]
        updated = True
    if config.get("entry_order_type") not in ["market", "limit"]:
        print(f"{NEON_RED}Invalid entry_order_type '{config.get('entry_order_type')}' in config. Resetting to 'market'.{RESET}")
        config["entry_order_type"] = "market"
        updated = True
    if config.get("active_weight_set") not in config.get("weight_sets", {}):
         print(f"{NEON_RED}Active weight set '{config.get('active_weight_set')}' not found in 'weight_sets'. Resetting to 'default'.{RESET}")
         config["active_weight_set"] = "default" # Assume 'default' exists
         updated = True
    # Add more validation (numeric ranges, types) as needed
    for key in ["risk_per_trade", "leverage", "stop_loss_multiple", "take_profit_multiple",
                "trailing_stop_callback_rate", "trailing_stop_activation_percentage",
                "break_even_trigger_atr_multiple", "break_even_offset_ticks"]:
        try:
             val = config[key]
             # Check basic numeric types and ranges
             if key == "risk_per_trade" and not (0 < float(val) < 1): raise ValueError("must be between 0 and 1")
             if key == "leverage" and not (int(val) >= 1): raise ValueError("must be >= 1")
             if key in ["stop_loss_multiple", "take_profit_multiple", "break_even_trigger_atr_multiple"] and not (float(val) > 0): raise ValueError("must be > 0")
             if key in ["trailing_stop_callback_rate", "trailing_stop_activation_percentage"] and not (float(val) >= 0): raise ValueError("must be >= 0")
             if key == "break_even_offset_ticks" and not (int(val) >= 0): raise ValueError("must be >= 0")
        except (ValueError, TypeError, KeyError) as e:
            print(f"{NEON_RED}Invalid value for '{key}' ({config.get(key)}): {e}. Resetting to default '{default_config[key]}'.{RESET}")
            config[key] = default_config[key]
            updated = True

    # If config was updated due to invalid values, save it back
    if updated:
        try:
            with open(filepath, "w", encoding="utf-8") as f_write:
                json.dump(config, f_write, indent=4)
            print(f"{NEON_YELLOW}Updated config file {filepath} with corrected/default values.{RESET}")
        except IOError as e:
            print(f"{NEON_RED}Error writing updated config file {filepath}: {e}{RESET}")

    return config

def _merge_configs(loaded_config: Dict, default_config: Dict) -> Dict:
    """Recursively merges loaded config with defaults, ensuring all keys exist."""
    merged = default_config.copy()
    for key, value in loaded_config.items():
        if isinstance(value, dict) and isinstance(merged.get(key), dict):
            merged[key] = _merge_configs(value, merged[key])
        else:
            merged[key] = value
    return merged

def setup_logger(name: str, level: int = logging.DEBUG) -> logging.Logger:
    """Sets up a logger with file and console handlers."""
    logger = logging.getLogger(name)
    # Prevent duplicate handlers if called multiple times
    if logger.hasHandlers():
        # Clear existing handlers to ensure clean setup
        for handler in logger.handlers[:]:
            handler.close()
            logger.removeHandler(handler)
        # return logger # Option: return existing logger

    logger.setLevel(level)

    # File Handler (Rotating)
    log_filename = os.path.join(LOG_DIRECTORY, f"{name}.log")
    try:
        file_handler = RotatingFileHandler(
            log_filename, maxBytes=10 * 1024 * 1024, backupCount=5, encoding='utf-8'
        )
        file_formatter = SensitiveFormatter("%(asctime)s - %(levelname)s - [%(name)s:%(lineno)d] - %(message)s")
        file_handler.setFormatter(file_formatter)
        file_handler.setLevel(logging.DEBUG) # Log all levels to file
        logger.addHandler(file_handler)
    except Exception as e:
        print(f"Error setting up file logger {log_filename}: {e}")

    # Console Handler
    stream_handler = logging.StreamHandler()
    stream_formatter = SensitiveFormatter(
        f"{NEON_BLUE}%(asctime)s{RESET} - {NEON_YELLOW}%(levelname)-8s{RESET} - {NEON_PURPLE}[%(name)s]{RESET} - %(message)s",
        datefmt='%Y-%m-%d %H:%M:%S %Z' # Include Timezone
    )
    stream_formatter.converter = lambda *args: datetime.now(TIMEZONE).timetuple()
    stream_handler.setFormatter(stream_formatter)
    # Set console level (e.g., INFO for less verbosity, DEBUG for more)
    console_log_level = logging.INFO
    stream_handler.setLevel(console_log_level)
    logger.addHandler(stream_handler)

    logger.propagate = False # Prevent duplicate messages in parent loggers
    return logger

# --- CCXT Exchange Setup ---
def initialize_exchange(logger: logging.Logger) -> Optional[ccxt.Exchange]:
    """Initializes the CCXT Bybit exchange object with enhanced error handling."""
    lg = logger
    try:
        exchange_options = {
            'apiKey': API_KEY,
            'secret': API_SECRET,
            'enableRateLimit': True,
            'options': {
                'defaultType': 'linear', # Assume linear for Bybit V5
                'adjustForTimeDifference': True,
                # Increased timeouts
                'fetchTickerTimeout': 15000, # 15s
                'fetchBalanceTimeout': 20000, # 20s
                'createOrderTimeout': 25000, # 25s
                'cancelOrderTimeout': 20000, # 20s
                'fetchPositionsTimeout': 20000, # 20s
                'fetchOHLCVTimeout': 20000, # 20s
                # Bybit V5 specific options might be needed here if issues persist
                # 'recvWindow': 10000 # Example: Increase recvWindow if needed
            }
        }

        # Default to Bybit, can be made dynamic if needed
        exchange_id = "bybit"
        exchange_class = getattr(ccxt, exchange_id)
        exchange = exchange_class(exchange_options)

        if CONFIG.get('use_sandbox'):
            lg.warning(f"{NEON_YELLOW}USING SANDBOX MODE (Testnet){RESET}")
            try:
                exchange.set_sandbox_mode(True)
                lg.info(f"Sandbox mode explicitly enabled for {exchange.id}.")
            except AttributeError:
                lg.warning(f"{exchange.id} does not support set_sandbox_mode via ccxt. Ensure API keys are for Testnet.")
                # Attempt to set URLs manually for Bybit if needed
                if exchange.id == 'bybit':
                    exchange.urls['api'] = 'https://api-testnet.bybit.com'
                    lg.info("Manually set Bybit API URL to Testnet.")
            except Exception as e:
                lg.error(f"Error enabling sandbox mode: {e}")

        lg.info(f"Initializing {exchange.id}...")
        # Test connection and API keys by fetching balance early
        account_type_to_test = 'CONTRACT' # For Bybit V5, try CONTRACT or UNIFIED
        lg.info(f"Attempting initial balance fetch (Account Type: {account_type_to_test})...")
        try:
            params = {'type': account_type_to_test} if exchange.id == 'bybit' else {}
            balance = exchange.fetch_balance(params=params)
            # Check common quote currencies for available balance display
            quote_curr = CONFIG.get("quote_currency", "USDT")
            available_quote = balance.get(quote_curr, {}).get('free', 'N/A')
            lg.info(f"{NEON_GREEN}Successfully connected and fetched initial balance.{RESET} (Example: {quote_curr} available: {available_quote})")

        except ccxt.AuthenticationError as auth_err:
             lg.error(f"{NEON_RED}CCXT Authentication Error during initial balance fetch: {auth_err}{RESET}")
             lg.error(f"{NEON_RED}>> Ensure API keys are correct, have necessary permissions (Read, Trade), match the account type (Real/Testnet), and IP whitelist is correctly set if enabled on the exchange.{RESET}")
             return None
        except ccxt.ExchangeError as balance_err:
             lg.warning(f"{NEON_YELLOW}Exchange error during initial balance fetch ({account_type_to_test}): {balance_err}. Trying default fetch...{RESET}")
             try:
                  balance = exchange.fetch_balance()
                  quote_curr = CONFIG.get("quote_currency", "USDT")
                  available_quote = balance.get(quote_curr, {}).get('free', 'N/A')
                  lg.info(f"{NEON_GREEN}Successfully fetched balance using default parameters.{RESET} (Example: {quote_curr} available: {available_quote})")
             except Exception as fallback_err:
                  lg.warning(f"{NEON_YELLOW}Default balance fetch also failed: {fallback_err}. Check API permissions/account type/network.{RESET}")
        except ccxt.NetworkError as net_err:
             lg.error(f"{NEON_RED}Network Error during initial balance fetch: {net_err}{RESET}")
             lg.warning("Proceeding, but balance checks might fail later.")
             # Decide if we should return None here or allow proceeding cautiously
             # return None
        except Exception as balance_err:
             lg.warning(f"{NEON_YELLOW}Could not perform initial balance fetch: {balance_err}. Check API permissions/account type/network. Proceeding cautiously.{RESET}")


        # Load markets after initial connection test
        lg.info(f"Loading markets for {exchange.id}...")
        exchange.load_markets()
        lg.info(f"CCXT exchange initialized ({exchange.id}). Sandbox: {CONFIG.get('use_sandbox')}")
        return exchange

    except ccxt.AuthenticationError as e:
        lg.error(f"{NEON_RED}CCXT Authentication Error during initialization: {e}{RESET}")
        lg.error(f"{NEON_RED}>> Check API Key/Secret format and validity in your .env file.{RESET}")
    except ccxt.ExchangeError as e:
        lg.error(f"{NEON_RED}CCXT Exchange Error initializing: {e}{RESET}")
    except ccxt.NetworkError as e:
        lg.error(f"{NEON_RED}CCXT Network Error initializing: {e}{RESET}")
    except Exception as e:
        lg.error(f"{NEON_RED}Failed to initialize CCXT exchange: {e}{RESET}", exc_info=True)

    return None

# --- API Call Wrapper with Retries ---
def safe_api_call(func, logger: logging.Logger, *args, **kwargs):
    """Wraps an API call with retry logic for network/rate limit errors."""
    lg = logger
    attempts = 0
    while attempts <= MAX_API_RETRIES:
        try:
            result = func(*args, **kwargs)
            return result # Success
        except (ccxt.NetworkError, ccxt.RequestTimeout, requests.exceptions.ConnectionError, requests.exceptions.Timeout) as e:
            lg.warning(f"{NEON_YELLOW}Network error in {func.__name__}: {e}. Retrying ({attempts+1}/{MAX_API_RETRIES})...{RESET}")
        except ccxt.RateLimitExceeded as e:
            wait_time = RETRY_DELAY_SECONDS * (2 ** attempts) # Exponential backoff
            lg.warning(f"{NEON_YELLOW}Rate limit exceeded in {func.__name__}: {e}. Waiting {wait_time:.1f}s ({attempts+1}/{MAX_API_RETRIES})...{RESET}")
            time.sleep(wait_time)
            attempts += 1 # Consume attempt after wait
            continue # Skip standard delay
        except ccxt.ExchangeNotAvailable as e: # Server maintenance or outage
             wait_time = RETRY_DELAY_SECONDS * 5 * (2 ** attempts) # Longer exponential backoff
             lg.error(f"{NEON_RED}Exchange not available ({func.__name__}): {e}. Waiting {wait_time:.1f}s ({attempts+1}/{MAX_API_RETRIES})...{RESET}")
             time.sleep(wait_time)
             attempts += 1
             continue
        except ccxt.AuthenticationError as e:
             # Don't retry auth errors, they need fixing
             lg.error(f"{NEON_RED}Authentication Error in {func.__name__}: {e}. Aborting call.{RESET}")
             raise e # Re-raise to be caught by caller
        except ccxt.ExchangeError as e:
            # Decide if specific exchange errors are retryable
            # Example: Bybit internal server error (e.g., code 10001) might be temporary
            bybit_retry_codes = [10001, 10006] # Example: Internal error, Rate limit system error
            exchange_code = getattr(e, 'code', None)
            err_str = str(e).lower()
            if exchange_code in bybit_retry_codes or "internal server error" in err_str:
                 lg.warning(f"{NEON_YELLOW}Retryable exchange error in {func.__name__}: {e} (Code: {exchange_code}). Retrying ({attempts+1}/{MAX_API_RETRIES})...{RESET}")
            else:
                 # Non-retryable ExchangeError
                 lg.error(f"{NEON_RED}Non-retryable Exchange Error in {func.__name__}: {e} (Code: {exchange_code}){RESET}")
                 raise e # Re-raise
        except Exception as e:
            # Unexpected errors - typically don't retry these
            lg.error(f"{NEON_RED}Unexpected error in {func.__name__}: {e}{RESET}", exc_info=True)
            raise e # Re-raise

        # Standard delay before next attempt
        attempts += 1
        if attempts <= MAX_API_RETRIES:
             delay = RETRY_DELAY_SECONDS * (1.5 ** (attempts -1)) # Mild exponential backoff
             time.sleep(delay)

    lg.error(f"{NEON_RED}Max retries ({MAX_API_RETRIES}) exceeded for {func.__name__}.{RESET}")
    # Raise the last exception encountered after exhausting retries
    # Using 'e' from the last loop iteration might be problematic if the last error wasn't caught by a specific type
    # It's better to explicitly raise a custom error or return None/False indicating failure
    raise ccxt.RequestTimeout(f"Max retries exceeded for {func.__name__}")


# --- CCXT Data Fetching (Using safe_api_call) ---
def fetch_current_price_ccxt(exchange: ccxt.Exchange, symbol: str, logger: logging.Logger) -> Optional[Decimal]:
    """Fetch the current price of a trading symbol using CCXT ticker with fallbacks and retries."""
    lg = logger
    try:
        ticker = safe_api_call(exchange.fetch_ticker, lg, symbol)
        if not ticker:
            lg.error(f"Failed to fetch ticker for {symbol} after retries.")
            return None

        lg.debug(f"Ticker data for {symbol}: {ticker}")
        price = None
        # Prioritize 'last', then mid-price, then ask/bid
        last_price = ticker.get('last')
        bid_price = ticker.get('bid')
        ask_price = ticker.get('ask')

        # Try converting to Decimal robustly
        def to_decimal(value) -> Optional[Decimal]:
            if value is None: return None
            try:
                d = Decimal(str(value))
                return d if d > 0 else None # Ensure positive price
            except InvalidOperation:
                lg.warning(f"Invalid price format: {value}")
                return None

        p_last = to_decimal(last_price)
        p_bid = to_decimal(bid_price)
        p_ask = to_decimal(ask_price)

        if p_last:
            price = p_last; lg.debug(f"Using 'last' price: {price}")
        elif p_bid and p_ask:
            price = (p_bid + p_ask) / 2; lg.debug(f"Using bid/ask midpoint: {price}")
        elif p_ask:
            price = p_ask; lg.warning(f"Using 'ask' price fallback: {price}")
        elif p_bid:
            price = p_bid; lg.warning(f"Using 'bid' price fallback: {price}")

        if price is not None and price > 0:
            return price
        else:
            lg.error(f"{NEON_RED}Failed to get a valid price from ticker data for {symbol}. Ticker: {ticker}{RESET}")
            return None

    except Exception as e:
        # Catch errors raised by safe_api_call (like AuthError or max retries exceeded) or parsing issues
        lg.error(f"{NEON_RED}Error fetching current price for {symbol}: {e}{RESET}", exc_info=False) # Don't need full trace if safe_api_call logged it
        return None

def fetch_klines_ccxt(exchange: ccxt.Exchange, symbol: str, timeframe: str, limit: int = 250, logger: logging.Logger = None) -> pd.DataFrame:
    """Fetch OHLCV kline data using CCXT with retries and robust validation."""
    lg = logger or logging.getLogger(__name__)
    if not exchange.has['fetchOHLCV']:
        lg.error(f"Exchange {exchange.id} does not support fetchOHLCV.")
        return pd.DataFrame()

    try:
        # Use safe_api_call to handle retries
        ohlcv = safe_api_call(exchange.fetch_ohlcv, lg, symbol, timeframe=timeframe, limit=limit)

        if ohlcv is None or not isinstance(ohlcv, list) or len(ohlcv) == 0:
            lg.warning(f"{NEON_YELLOW}No valid kline data returned for {symbol} {timeframe} after retries.{RESET}")
            return pd.DataFrame()

        # Process the data into a pandas DataFrame
        df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])

        # Basic validation of the DataFrame structure
        if df.empty:
            lg.warning(f"{NEON_YELLOW}Kline data DataFrame is empty for {symbol} {timeframe}.{RESET}")
            return df

        # Convert timestamp to datetime objects (UTC), coerce errors
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms', errors='coerce', utc=True)
        df.dropna(subset=['timestamp'], inplace=True)
        df.set_index('timestamp', inplace=True)

        # Convert price/volume columns to numeric Decimal, coercing errors
        for col in ['open', 'high', 'low', 'close', 'volume']:
             try:
                  # Use Decimal for price/volume columns for precision
                  df[col] = df[col].apply(lambda x: Decimal(str(x)) if pd.notna(x) else Decimal('NaN'))
             except (TypeError, ValueError, InvalidOperation) as conv_err:
                  lg.warning(f"Could not convert column '{col}' to Decimal, attempting numeric: {conv_err}")
                  df[col] = pd.to_numeric(df[col], errors='coerce') # Fallback to numeric

        # Data Cleaning: Drop rows with NaN in essential price columns or zero close price
        initial_len = len(df)
        df.dropna(subset=['open', 'high', 'low', 'close'], inplace=True)
        # Ensure close price is positive Decimal or float
        df = df[df['close'] > Decimal(0) if isinstance(df['close'].iloc[0], Decimal) else df['close'] > 0]
        rows_dropped = initial_len - len(df)
        if rows_dropped > 0:
            lg.debug(f"Dropped {rows_dropped} rows with NaN/invalid price data for {symbol}.")

        if df.empty:
            lg.warning(f"{NEON_YELLOW}Kline data for {symbol} {timeframe} empty after cleaning.{RESET}")
            return pd.DataFrame()

        # Sort by timestamp index
        df.sort_index(inplace=True)
        # Ensure no duplicate timestamps remain
        df = df[~df.index.duplicated(keep='last')]

        lg.info(f"Successfully fetched and processed {len(df)} klines for {symbol} {timeframe}")
        return df

    except Exception as e:
        lg.error(f"{NEON_RED}Error processing klines for {symbol}: {e}{RESET}", exc_info=True)
        return pd.DataFrame()


def fetch_orderbook_ccxt(exchange: ccxt.Exchange, symbol: str, limit: int, logger: logging.Logger) -> Optional[Dict]:
    """Fetch orderbook data using ccxt with retries and validation."""
    lg = logger
    if not exchange.has['fetchOrderBook']:
        lg.error(f"Exchange {exchange.id} does not support fetchOrderBook.")
        return None

    try:
        orderbook = safe_api_call(exchange.fetch_order_book, lg, symbol, limit=limit)

        # Validate structure
        if not orderbook:
            lg.warning(f"fetch_order_book returned None/empty for {symbol} after retries.")
            return None
        elif not isinstance(orderbook, dict):
            lg.warning(f"Invalid orderbook type received for {symbol}. Expected dict, got {type(orderbook)}.")
            return None
        elif 'bids' not in orderbook or 'asks' not in orderbook:
            lg.warning(f"Invalid orderbook structure for {symbol}: missing 'bids' or 'asks'. Keys: {list(orderbook.keys())}")
            return None
        elif not isinstance(orderbook['bids'], list) or not isinstance(orderbook['asks'], list):
            lg.warning(f"Invalid orderbook structure for {symbol}: 'bids'/'asks' not lists. Types: bid={type(orderbook['bids'])}, ask={type(orderbook['asks'])}")
            return None
        elif not orderbook['bids'] and not orderbook['asks']:
            lg.warning(f"Orderbook received but both bids and asks lists are empty for {symbol}.")
            # Return the empty but validly structured book
            return orderbook
        else:
            lg.debug(f"Successfully fetched orderbook for {symbol} with {len(orderbook['bids'])} bids, {len(orderbook['asks'])} asks.")
            # Add basic validation of bid/ask format (price, size)
            valid = True
            for side in ['bids', 'asks']:
                 if orderbook[side]: # Check first entry if list is not empty
                      entry = orderbook[side][0]
                      if not (isinstance(entry, list) and len(entry) == 2):
                           lg.warning(f"Invalid {side[:-1]} entry format in orderbook: {entry}")
                           valid = False; break
                      try:
                           # Attempt conversion to float/Decimal to check numeric format
                           _ = float(entry[0]); _ = float(entry[1])
                           # Or: _ = Decimal(str(entry[0])); _ = Decimal(str(entry[1]))
                      except (ValueError, TypeError, InvalidOperation):
                           lg.warning(f"Non-numeric data in {side[:-1]} entry: {entry}")
                           valid = False; break
            if not valid:
                 lg.error("Orderbook data format validation failed.")
                 return None # Reject invalid format
            return orderbook

    except Exception as e:
        # Catch errors raised by safe_api_call or validation
        lg.error(f"{NEON_RED}Error fetching order book for {symbol}: {e}{RESET}", exc_info=False)
        return None

# --- Trading Analyzer Class ---
class TradingAnalyzer:
    """Analyzes trading data using pandas_ta and generates weighted signals."""

    def __init__(
        self,
        df: pd.DataFrame,
        logger: logging.Logger,
        config: Dict[str, Any],
        market_info: Dict[str, Any],
    ) -> None:
        self.df = df
        self.logger = logger
        self.config = config
        self.market_info = market_info
        self.symbol = market_info.get('symbol', 'UNKNOWN_SYMBOL')
        self.interval = config.get("interval", "5")
        self.ccxt_interval = CCXT_INTERVAL_MAP.get(self.interval)
        if not self.ccxt_interval:
            self.logger.error(f"Invalid interval '{self.interval}' in config, cannot map to CCXT timeframe for {self.symbol}.")
            # Consider raising an error or handling fallback more explicitly

        # Stores latest calculated indicator values (Decimal for prices/ATR, float for others)
        self.indicator_values: Dict[str, Union[Decimal, float, Any]] = {}
        self.signals: Dict[str, int] = {"BUY": 0, "SELL": 0, "HOLD": 1}
        self.active_weight_set_name = config.get("active_weight_set", "default")
        self.weights = config.get("weight_sets", {}).get(self.active_weight_set_name, {})
        self.fib_levels_data: Dict[str, Decimal] = {}
        self.ta_column_names: Dict[str, Optional[str]] = {} # Maps internal name to actual DataFrame column name

        if not self.weights:
            logger.error(f"Active weight set '{self.active_weight_set_name}' not found or empty in config for {self.symbol}.")
            # Fallback to an empty dict to avoid errors, but scoring will be zero
            self.weights = {}

        # Initial calculations
        self._calculate_all_indicators()
        self._update_latest_indicator_values() # Needs to run after indicator calc
        self.calculate_fibonacci_levels()

    def _get_ta_col_name(self, base_name: str, result_df: pd.DataFrame) -> Optional[str]:
        """Helper to find the actual column name generated by pandas_ta."""
        # Define expected patterns, potentially using f-strings for dynamic parts
        expected_patterns = {
            "ATR": [f"ATRr_{self.config.get('atr_period', DEFAULT_ATR_PERIOD)}"],
            "EMA_Short": [f"EMA_{self.config.get('ema_short_period', DEFAULT_EMA_SHORT_PERIOD)}"],
            "EMA_Long": [f"EMA_{self.config.get('ema_long_period', DEFAULT_EMA_LONG_PERIOD)}"],
            "Momentum": [f"MOM_{self.config.get('momentum_period', DEFAULT_MOMENTUM_PERIOD)}"],
            # CCI often includes the constant (e.g., 100.0) which pandas_ta adds
            "CCI": [f"CCI_{self.config.get('cci_window', DEFAULT_CCI_WINDOW)}"],
            "Williams_R": [f"WILLR_{self.config.get('williams_r_window', DEFAULT_WILLIAMS_R_WINDOW)}"],
            "MFI": [f"MFI_{self.config.get('mfi_window', DEFAULT_MFI_WINDOW)}"],
            "VWAP": ["VWAP_D"], # Default pandas_ta VWAP often daily anchored
            "PSAR_long": [f"PSARl_{self.config.get('psar_af', DEFAULT_PSAR_AF)}_{self.config.get('psar_max_af', DEFAULT_PSAR_MAX_AF)}"],
            "PSAR_short": [f"PSARs_{self.config.get('psar_af', DEFAULT_PSAR_AF)}_{self.config.get('psar_max_af', DEFAULT_PSAR_MAX_AF)}"],
            "SMA10": [f"SMA_{self.config.get('sma_10_window', DEFAULT_SMA_10_WINDOW)}"],
            # StochRSI names can be complex, include core parameters
            "StochRSI_K": [f"STOCHRSIk_{self.config.get('stoch_rsi_window', DEFAULT_STOCH_RSI_WINDOW)}_{self.config.get('stoch_rsi_rsi_window', DEFAULT_STOCH_WINDOW)}_{self.config.get('stoch_rsi_k', DEFAULT_K_WINDOW)}"],
            "StochRSI_D": [f"STOCHRSId_{self.config.get('stoch_rsi_window', DEFAULT_STOCH_RSI_WINDOW)}_{self.config.get('stoch_rsi_rsi_window', DEFAULT_STOCH_WINDOW)}_{self.config.get('stoch_rsi_k', DEFAULT_K_WINDOW)}_{self.config.get('stoch_rsi_d', DEFAULT_D_WINDOW)}"],
            "RSI": [f"RSI_{self.config.get('rsi_period', DEFAULT_RSI_WINDOW)}"],
            # BBands names include period and std dev (formatted to 1 decimal place by default)
            "BB_Lower": [f"BBL_{self.config.get('bollinger_bands_period', DEFAULT_BOLLINGER_BANDS_PERIOD)}_{float(self.config.get('bollinger_bands_std_dev', DEFAULT_BOLLINGER_BANDS_STD_DEV)):.1f}"],
            "BB_Middle": [f"BBM_{self.config.get('bollinger_bands_period', DEFAULT_BOLLINGER_BANDS_PERIOD)}_{float(self.config.get('bollinger_bands_std_dev', DEFAULT_BOLLINGER_BANDS_STD_DEV)):.1f}"],
            "BB_Upper": [f"BBU_{self.config.get('bollinger_bands_period', DEFAULT_BOLLINGER_BANDS_PERIOD)}_{float(self.config.get('bollinger_bands_std_dev', DEFAULT_BOLLINGER_BANDS_STD_DEV)):.1f}"],
            # Custom name used for Volume MA
            "Volume_MA": [f"VOL_SMA_{self.config.get('volume_ma_period', DEFAULT_VOLUME_MA_PERIOD)}"]
        }

        patterns = expected_patterns.get(base_name, [])
        df_cols = result_df.columns.tolist()

        # Exact match or startswith preferred
        for col in df_cols:
            for pattern in patterns:
                # Use startswith for flexibility (e.g., CCI_20_100.0 matches CCI_20)
                if col.startswith(pattern):
                    self.logger.debug(f"Mapped '{base_name}' to column '{col}'")
                    return col

        # Fallback: Simple case-insensitive substring search
        # This is less reliable but might catch unexpected variations
        # Convert base name to lower for comparison
        base_lower = base_name.lower()
        # Split common indicator names if needed (e.g., "EMA_Short" -> "ema")
        simple_base = base_lower.split('_')[0]
        for col in df_cols:
            col_lower = col.lower()
            if base_lower in col_lower or simple_base in col_lower:
                # Be cautious with very short base names (e.g., 'r' in 'atr', 'wr')
                if len(simple_base) > 1 and simple_base in col_lower:
                     self.logger.debug(f"Found column '{col}' for base '{base_name}' using fallback substring search ('{simple_base}').")
                     return col
                elif base_lower in col_lower:
                     self.logger.debug(f"Found column '{col}' for base '{base_name}' using fallback substring search ('{base_lower}').")
                     return col


        self.logger.warning(f"Could not find column name for indicator '{base_name}' in DataFrame columns: {df_cols}")
        return None

    def _calculate_all_indicators(self):
        """Calculates all enabled indicators using pandas_ta."""
        if self.df.empty:
            self.logger.warning(f"DataFrame is empty, cannot calculate indicators for {self.symbol}.")
            return

        # Determine minimum required data length
        required_periods = []
        indicators_config = self.config.get("indicators", {})
        active_weights = self.config.get("weight_sets", {}).get(self.active_weight_set_name, {})

        # Add period only if indicator is enabled AND has a non-zero weight
        def add_req(key, default):
            if indicators_config.get(key, False) and float(active_weights.get(key, 0)) != 0:
                required_periods.append(self.config.get(key.replace("window", "period").replace("period","period"), default)) # Basic key mapping

        # Add specific periods based on config keys
        add_req("atr_period", DEFAULT_ATR_PERIOD)
        if indicators_config.get("ema_alignment", False) and float(active_weights.get("ema_alignment", 0)) != 0:
             required_periods.append(self.config.get("ema_short_period", DEFAULT_EMA_SHORT_PERIOD))
             required_periods.append(self.config.get("ema_long_period", DEFAULT_EMA_LONG_PERIOD))
        add_req("momentum_period", DEFAULT_MOMENTUM_PERIOD)
        add_req("cci_window", DEFAULT_CCI_WINDOW)
        add_req("williams_r_window", DEFAULT_WILLIAMS_R_WINDOW)
        add_req("mfi_window", DEFAULT_MFI_WINDOW)
        add_req("sma_10_window", DEFAULT_SMA_10_WINDOW)
        if indicators_config.get("stoch_rsi", False) and float(active_weights.get("stoch_rsi", 0)) != 0:
            required_periods.append(self.config.get("stoch_rsi_window", DEFAULT_STOCH_RSI_WINDOW))
            required_periods.append(self.config.get("stoch_rsi_rsi_window", DEFAULT_STOCH_WINDOW))
        add_req("rsi_period", DEFAULT_RSI_WINDOW)
        add_req("bollinger_bands_period", DEFAULT_BOLLINGER_BANDS_PERIOD)
        add_req("volume_ma_period", DEFAULT_VOLUME_MA_PERIOD)
        # Fibonacci window for price range
        required_periods.append(self.config.get("fibonacci_window", DEFAULT_FIB_WINDOW))

        min_required_data = max(required_periods) + 30 if required_periods else 50 # Add more buffer

        if len(self.df) < min_required_data:
             self.logger.warning(f"{NEON_YELLOW}Insufficient data ({len(self.df)} points) for {self.symbol} to calculate all indicators reliably (min recommended: {min_required_data}). Results may contain NaNs.{RESET}")
             # Continue calculation, but expect NaNs

        try:
            # Work on a copy
            df_calc = self.df.copy()
            # Ensure OHLCV columns are numeric (float or Decimal) for ta library
            for col in ['open', 'high', 'low', 'close', 'volume']:
                 if col in df_calc.columns and not pd.api.types.is_numeric_dtype(df_calc[col]):
                      self.logger.debug(f"Converting column '{col}' to numeric for TA calculations.")
                      # Convert Decimal to float if needed by pandas_ta
                      if isinstance(df_calc[col].iloc[0], Decimal):
                           df_calc[col] = df_calc[col].astype(float)
                      else: # Handle other non-numeric types
                           df_calc[col] = pd.to_numeric(df_calc[col], errors='coerce')

            # --- Always calculate ATR ---
            atr_period = self.config.get("atr_period", DEFAULT_ATR_PERIOD)
            df_calc.ta.atr(length=atr_period, append=True)
            self.ta_column_names["ATR"] = self._get_ta_col_name("ATR", df_calc)

            # --- Calculate other indicators based on config and weight ---
            if indicators_config.get("ema_alignment", False) and float(active_weights.get("ema_alignment", 0)) != 0:
                ema_short = self.config.get("ema_short_period", DEFAULT_EMA_SHORT_PERIOD)
                ema_long = self.config.get("ema_long_period", DEFAULT_EMA_LONG_PERIOD)
                df_calc.ta.ema(length=ema_short, append=True)
                self.ta_column_names["EMA_Short"] = self._get_ta_col_name("EMA_Short", df_calc)
                df_calc.ta.ema(length=ema_long, append=True)
                self.ta_column_names["EMA_Long"] = self._get_ta_col_name("EMA_Long", df_calc)

            if indicators_config.get("momentum", False) and float(active_weights.get("momentum", 0)) != 0:
                mom_period = self.config.get("momentum_period", DEFAULT_MOMENTUM_PERIOD)
                df_calc.ta.mom(length=mom_period, append=True)
                self.ta_column_names["Momentum"] = self._get_ta_col_name("Momentum", df_calc)

            if indicators_config.get("cci", False) and float(active_weights.get("cci", 0)) != 0:
                cci_period = self.config.get("cci_window", DEFAULT_CCI_WINDOW)
                df_calc.ta.cci(length=cci_period, append=True)
                self.ta_column_names["CCI"] = self._get_ta_col_name("CCI", df_calc)

            if indicators_config.get("wr", False) and float(active_weights.get("wr", 0)) != 0:
                wr_period = self.config.get("williams_r_window", DEFAULT_WILLIAMS_R_WINDOW)
                df_calc.ta.willr(length=wr_period, append=True)
                self.ta_column_names["Williams_R"] = self._get_ta_col_name("Williams_R", df_calc)

            if indicators_config.get("mfi", False) and float(active_weights.get("mfi", 0)) != 0:
                mfi_period = self.config.get("mfi_window", DEFAULT_MFI_WINDOW)
                df_calc.ta.mfi(length=mfi_period, append=True)
                self.ta_column_names["MFI"] = self._get_ta_col_name("MFI", df_calc)

            if indicators_config.get("vwap", False) and float(active_weights.get("vwap", 0)) != 0:
                df_calc.ta.vwap(append=True)
                self.ta_column_names["VWAP"] = self._get_ta_col_name("VWAP", df_calc)

            if indicators_config.get("psar", False) and float(active_weights.get("psar", 0)) != 0:
                psar_af = self.config.get("psar_af", DEFAULT_PSAR_AF)
                psar_max_af = self.config.get("psar_max_af", DEFAULT_PSAR_MAX_AF)
                psar_result = df_calc.ta.psar(af=psar_af, max_af=psar_max_af)
                if psar_result is not None and not psar_result.empty:
                    df_calc = pd.concat([df_calc, psar_result], axis=1)
                    self.ta_column_names["PSAR_long"] = self._get_ta_col_name("PSAR_long", df_calc)
                    self.ta_column_names["PSAR_short"] = self._get_ta_col_name("PSAR_short", df_calc)

            if indicators_config.get("sma_10", False) and float(active_weights.get("sma_10", 0)) != 0:
                sma10_period = self.config.get("sma_10_window", DEFAULT_SMA_10_WINDOW)
                df_calc.ta.sma(length=sma10_period, append=True)
                self.ta_column_names["SMA10"] = self._get_ta_col_name("SMA10", df_calc)

            if indicators_config.get("stoch_rsi", False) and float(active_weights.get("stoch_rsi", 0)) != 0:
                stoch_rsi_len = self.config.get("stoch_rsi_window", DEFAULT_STOCH_RSI_WINDOW)
                stoch_rsi_rsi_len = self.config.get("stoch_rsi_rsi_window", DEFAULT_STOCH_WINDOW)
                stoch_rsi_k = self.config.get("stoch_rsi_k", DEFAULT_K_WINDOW)
                stoch_rsi_d = self.config.get("stoch_rsi_d", DEFAULT_D_WINDOW)
                stochrsi_result = df_calc.ta.stochrsi(length=stoch_rsi_len, rsi_length=stoch_rsi_rsi_len, k=stoch_rsi_k, d=stoch_rsi_d)
                if stochrsi_result is not None and not stochrsi_result.empty:
                    df_calc = pd.concat([df_calc, stochrsi_result], axis=1)
                    self.ta_column_names["StochRSI_K"] = self._get_ta_col_name("StochRSI_K", df_calc)
                    self.ta_column_names["StochRSI_D"] = self._get_ta_col_name("StochRSI_D", df_calc)

            if indicators_config.get("rsi", False) and float(active_weights.get("rsi", 0)) != 0:
                rsi_period = self.config.get("rsi_period", DEFAULT_RSI_WINDOW)
                df_calc.ta.rsi(length=rsi_period, append=True)
                self.ta_column_names["RSI"] = self._get_ta_col_name("RSI", df_calc)

            if indicators_config.get("bollinger_bands", False) and float(active_weights.get("bollinger_bands", 0)) != 0:
                bb_period = self.config.get("bollinger_bands_period", DEFAULT_BOLLINGER_BANDS_PERIOD)
                bb_std = float(self.config.get("bollinger_bands_std_dev", DEFAULT_BOLLINGER_BANDS_STD_DEV))
                bbands_result = df_calc.ta.bbands(length=bb_period, std=bb_std)
                if bbands_result is not None and not bbands_result.empty:
                    df_calc = pd.concat([df_calc, bbands_result], axis=1)
                    self.ta_column_names["BB_Lower"] = self._get_ta_col_name("BB_Lower", df_calc)
                    self.ta_column_names["BB_Middle"] = self._get_ta_col_name("BB_Middle", df_calc)
                    self.ta_column_names["BB_Upper"] = self._get_ta_col_name("BB_Upper", df_calc)

            if indicators_config.get("volume_confirmation", False) and float(active_weights.get("volume_confirmation", 0)) != 0:
                vol_ma_period = self.config.get("volume_ma_period", DEFAULT_VOLUME_MA_PERIOD)
                vol_ma_col_name = f"VOL_SMA_{vol_ma_period}"
                # Ensure volume is float for SMA calculation
                vol_series = df_calc['volume'].astype(float) if isinstance(df_calc['volume'].iloc[0], Decimal) else df_calc['volume']
                df_calc[vol_ma_col_name] = ta.sma(vol_series.fillna(0), length=vol_ma_period)
                self.ta_column_names["Volume_MA"] = vol_ma_col_name

            # Convert calculated indicator columns (usually float) back to Decimal if desired?
            # For now, keep them as float, except ATR which needs Decimal precision.
            # Convert ATR column to Decimal if it's not already
            atr_col = self.ta_column_names.get("ATR")
            if atr_col and atr_col in df_calc.columns and not isinstance(df_calc[atr_col].iloc[-1], Decimal):
                 self.logger.debug(f"Converting calculated ATR column '{atr_col}' to Decimal.")
                 df_calc[atr_col] = df_calc[atr_col].apply(lambda x: Decimal(str(x)) if pd.notna(x) else Decimal('NaN'))


            # Update the instance's DataFrame
            self.df = df_calc
            self.logger.debug(f"Finished indicator calculations for {self.symbol}. Final DF columns: {self.df.columns.tolist()}")

        except AttributeError as e:
             self.logger.error(f"{NEON_RED}AttributeError calculating indicators for {self.symbol}: {e}{RESET}. Check pandas_ta usage and data.", exc_info=True)
        except Exception as e:
            self.logger.error(f"{NEON_RED}Error calculating indicators with pandas_ta for {self.symbol}: {e}{RESET}", exc_info=True)


    def _update_latest_indicator_values(self):
        """Updates indicator_values dict with latest values, handling types."""
        if self.df.empty:
            self.logger.warning(f"Cannot update latest values: DataFrame empty for {self.symbol}.")
            self.indicator_values = {k: np.nan for k in list(self.ta_column_names.keys()) + ["Open", "High", "Low", "Close", "Volume"]}
            return
        try:
            latest = self.df.iloc[-1]
        except IndexError:
            self.logger.error(f"Error accessing latest row (iloc[-1]) for {self.symbol}. DataFrame might be empty or too short.")
            self.indicator_values = {k: np.nan for k in list(self.ta_column_names.keys()) + ["Open", "High", "Low", "Close", "Volume"]}
            return

        if latest.isnull().all():
            self.logger.warning(f"Cannot update latest values: Last row contains all NaNs for {self.symbol}.")
            self.indicator_values = {k: np.nan for k in list(self.ta_column_names.keys()) + ["Open", "High", "Low", "Close", "Volume"]}
            return

        updated_values = {}
        # --- Process TA indicators ---
        for key, col_name in self.ta_column_names.items():
            if col_name and col_name in latest.index:
                value = latest[col_name]
                if pd.notna(value):
                    try:
                        # Store ATR as Decimal, others as float
                        if key == "ATR":
                            updated_values[key] = Decimal(str(value)) if not isinstance(value, Decimal) else value
                        else:
                            updated_values[key] = float(value)
                    except (ValueError, TypeError, InvalidOperation) as conv_err:
                        self.logger.warning(f"Could not convert value for {key} ('{col_name}': {value}): {conv_err}. Storing NaN.")
                        updated_values[key] = np.nan
                else:
                    updated_values[key] = np.nan
            else:
                 if key in self.ta_column_names: # Only log if calc was attempted
                     self.logger.debug(f"Indicator column '{col_name}' for '{key}' not found in latest data. Storing NaN.")
                 updated_values[key] = np.nan

        # --- Process Base OHLCV (ensure Decimal) ---
        for base_col in ['open', 'high', 'low', 'close', 'volume']:
            key_name = base_col.capitalize()
            value = latest.get(base_col)
            if pd.notna(value):
                 try:
                      # Ensure base values are stored as Decimal
                      updated_values[key_name] = Decimal(str(value)) if not isinstance(value, Decimal) else value
                 except (ValueError, TypeError, InvalidOperation) as conv_err:
                      self.logger.warning(f"Could not convert base '{base_col}' ({value}) to Decimal: {conv_err}. Storing NaN.")
                      updated_values[key_name] = np.nan
            else:
                 updated_values[key_name] = np.nan

        self.indicator_values = updated_values

        # --- Log Summary (formatted) ---
        log_vals = {}
        price_prec = self.get_price_precision()
        for k, v in self.indicator_values.items():
            if pd.notna(v):
                if isinstance(v, Decimal):
                    # Use appropriate precision for Decimals
                    prec = price_prec if k in ['Open', 'High', 'Low', 'Close', 'ATR'] else 8 # More precision for vol/others
                    log_vals[k] = f"{v:.{prec}f}"
                elif isinstance(v, float):
                    log_vals[k] = f"{v:.5f}" # Standard float precision
                else:
                    log_vals[k] = str(v)
            # else: log_vals[k] = "NaN" # Optionally log NaNs

        self.logger.debug(f"Latest indicator values updated for {self.symbol}: {log_vals}")


    def calculate_fibonacci_levels(self, window: Optional[int] = None) -> Dict[str, Decimal]:
        """Calculates Fibonacci levels using Decimal precision."""
        window = window or self.config.get("fibonacci_window", DEFAULT_FIB_WINDOW)
        if len(self.df) < window:
            self.logger.debug(f"Not enough data ({len(self.df)} points) for Fibonacci window ({window}) on {self.symbol}.")
            self.fib_levels_data = {}
            return {}

        df_slice = self.df.tail(window)
        try:
            # Ensure 'high' and 'low' are numeric before max/min
            high_series = pd.to_numeric(df_slice["high"], errors='coerce')
            low_series = pd.to_numeric(df_slice["low"], errors='coerce')

            high_price_raw = high_series.dropna().max()
            low_price_raw = low_series.dropna().min()

            if pd.isna(high_price_raw) or pd.isna(low_price_raw):
                self.logger.warning(f"Could not find valid high/low for Fibonacci calculation (Window: {window}) on {self.symbol}.")
                self.fib_levels_data = {}
                return {}

            high = Decimal(str(high_price_raw))
            low = Decimal(str(low_price_raw))
            diff = high - low

            levels = {}
            price_precision = self.get_price_precision()
            rounding_factor = Decimal('1e-' + str(price_precision))

            if diff > 0:
                for level_pct in FIB_LEVELS:
                    level_name = f"Fib_{level_pct * 100:.1f}%"
                    level_price = high - (diff * Decimal(str(level_pct)))
                    levels[level_name] = level_price.quantize(rounding_factor, rounding=ROUND_DOWN)
            else: # Handle zero range
                self.logger.debug(f"Fibonacci range is zero (High=Low={high}) for {self.symbol} (Window: {window}).")
                level_price_quantized = high.quantize(rounding_factor, rounding=ROUND_DOWN)
                for level_pct in FIB_LEVELS:
                    levels[f"Fib_{level_pct * 100:.1f}%"] = level_price_quantized

            self.fib_levels_data = levels
            log_levels = {k: str(v) for k, v in levels.items()}
            self.logger.debug(f"Calculated Fibonacci levels for {self.symbol} (Window: {window}): {log_levels}")
            return levels

        except KeyError as e:
            self.logger.error(f"{NEON_RED}Fibonacci error for {self.symbol}: Missing column '{e}'. Ensure 'high'/'low' exist.{RESET}")
            self.fib_levels_data = {}
            return {}
        except Exception as e:
            self.logger.error(f"{NEON_RED}Unexpected Fibonacci calculation error for {self.symbol}: {e}{RESET}", exc_info=True)
            self.fib_levels_data = {}
            return {}

    def get_price_precision(self) -> int:
        """Determines price precision (decimal places) from market info."""
        try:
            # 1. Check precision.price (most reliable)
            precision_info = self.market_info.get('precision', {})
            price_precision_val = precision_info.get('price')
            if price_precision_val is not None:
                if isinstance(price_precision_val, int) and price_precision_val >= 0:
                    return price_precision_val # Direct decimal places
                try: # Assume it represents tick size
                    tick_size = Decimal(str(price_precision_val))
                    if tick_size > 0:
                        precision = abs(tick_size.normalize().as_tuple().exponent)
                        return precision
                except (TypeError, ValueError, InvalidOperation) as e:
                     self.logger.debug(f"Could not parse precision.price '{price_precision_val}' as tick size: {e}")

            # 2. Fallback: Infer from limits.price.min (less reliable)
            min_price_val = self.market_info.get('limits', {}).get('price', {}).get('min')
            if min_price_val is not None:
                try:
                    min_price_tick = Decimal(str(min_price_val))
                    if 0 < min_price_tick < Decimal('0.1'): # Heuristic: looks like tick size
                        precision = abs(min_price_tick.normalize().as_tuple().exponent)
                        return precision
                except (TypeError, ValueError, InvalidOperation) as e:
                    self.logger.debug(f"Could not parse limits.price.min '{min_price_val}' for precision: {e}")

            # 3. Fallback: Infer from last close price (least reliable)
            last_close = self.indicator_values.get("Close")
            if isinstance(last_close, Decimal) and last_close > 0:
                try:
                    precision = abs(last_close.normalize().as_tuple().exponent)
                    if 0 <= precision < 10: return precision # Sanity check
                except Exception: pass

        except Exception as e:
            self.logger.warning(f"Error determining price precision for {self.symbol}: {e}. Falling back.")

        default_precision = 4
        self.logger.warning(f"Could not determine price precision for {self.symbol}. Using default: {default_precision}.")
        return default_precision

    def get_min_tick_size(self) -> Decimal:
        """Gets the minimum price increment (tick size) from market info."""
        try:
            # 1. Try precision.price
            precision_info = self.market_info.get('precision', {})
            price_precision_val = precision_info.get('price')
            if price_precision_val is not None:
                if isinstance(price_precision_val, (float, str, int)):
                     try:
                          # If int, it's decimal places, calculate tick size
                          if isinstance(price_precision_val, int):
                               if price_precision_val >= 0:
                                    tick = Decimal('1e-' + str(price_precision_val))
                                    if tick > 0: return tick
                          else: # float or str, assume it IS the tick size
                               tick = Decimal(str(price_precision_val))
                               if tick > 0: return tick
                     except (TypeError, ValueError, InvalidOperation) as e:
                          self.logger.debug(f"Could not parse precision.price '{price_precision_val}' as tick size: {e}")

            # 2. Fallback: Try limits.price.min
            min_price_val = self.market_info.get('limits', {}).get('price', {}).get('min')
            if min_price_val is not None:
                try:
                    min_tick = Decimal(str(min_price_val))
                    if 0 < min_tick < Decimal('0.1'): # Heuristic check
                        return min_tick
                except (TypeError, ValueError, InvalidOperation) as e:
                     self.logger.debug(f"Could not parse limits.price.min '{min_price_val}' for tick size: {e}")

        except Exception as e:
            self.logger.warning(f"Could not determine min tick size for {self.symbol} from market info: {e}. Using precision fallback.")

        # --- Final Fallback: Calculate from derived decimal places ---
        price_precision_places = self.get_price_precision()
        fallback_tick = Decimal('1e-' + str(price_precision_places))
        self.logger.debug(f"Using fallback tick size based on derived precision ({price_precision_places}): {fallback_tick}")
        return fallback_tick

    def get_amount_precision_places(self) -> int:
        """Determines amount precision (decimal places) from market info."""
        # Similar logic to get_price_precision, but using 'amount' field
        try:
            precision_info = self.market_info.get('precision', {})
            amount_precision_val = precision_info.get('amount')
            if amount_precision_val is not None:
                if isinstance(amount_precision_val, int) and amount_precision_val >= 0:
                    return amount_precision_val # Direct decimal places
                try: # Assume it represents step size
                    step_size = Decimal(str(amount_precision_val))
                    if step_size > 0:
                        precision = abs(step_size.normalize().as_tuple().exponent)
                        return precision
                except (TypeError, ValueError, InvalidOperation): pass

            min_amount_val = self.market_info.get('limits', {}).get('amount', {}).get('min')
            if min_amount_val is not None:
                try:
                    min_amount_step = Decimal(str(min_amount_val))
                    if 0 < min_amount_step < Decimal('1'): # Heuristic
                        precision = abs(min_amount_step.normalize().as_tuple().exponent)
                        return precision
                except (TypeError, ValueError, InvalidOperation): pass

        except Exception as e:
            self.logger.warning(f"Error determining amount precision for {self.symbol}: {e}.")

        default_precision = 8 # Common default for crypto amounts
        self.logger.warning(f"Could not determine amount precision for {self.symbol}. Using default: {default_precision}.")
        return default_precision

    def get_min_amount_step(self) -> Decimal:
        """Gets the minimum amount increment (step size) from market info."""
        # Similar logic to get_min_tick_size, using 'amount' field
        try:
            precision_info = self.market_info.get('precision', {})
            amount_precision_val = precision_info.get('amount')
            if amount_precision_val is not None:
                if isinstance(amount_precision_val, (float, str, int)):
                     try:
                          if isinstance(amount_precision_val, int):
                               if amount_precision_val >= 0:
                                    step = Decimal('1e-' + str(amount_precision_val))
                                    if step > 0: return step
                          else:
                               step = Decimal(str(amount_precision_val))
                               if step > 0: return step
                     except (TypeError, ValueError, InvalidOperation): pass

            min_amount_val = self.market_info.get('limits', {}).get('amount', {}).get('min')
            if min_amount_val is not None:
                try:
                    min_step = Decimal(str(min_amount_val))
                    # Assume min limit might be the step size if it's small
                    if 0 < min_step < Decimal('1'): return min_step
                except (TypeError, ValueError, InvalidOperation): pass

        except Exception as e:
            self.logger.warning(f"Could not determine min amount step for {self.symbol}: {e}.")

        amount_precision_places = self.get_amount_precision_places()
        fallback_step = Decimal('1e-' + str(amount_precision_places))
        self.logger.debug(f"Using fallback amount step based on derived precision ({amount_precision_places}): {fallback_step}")
        return fallback_step


    def get_nearest_fibonacci_levels(self, current_price: Decimal, num_levels: int = 5) -> List[Tuple[str, Decimal]]:
        """Finds the N nearest Fibonacci levels to the current price."""
        if not self.fib_levels_data:
            self.logger.debug(f"Fibonacci levels not calculated for {self.symbol}.")
            return []
        if not isinstance(current_price, Decimal) or pd.isna(current_price) or current_price <= 0:
            self.logger.warning(f"Invalid current price ({current_price}) for Fibonacci comparison on {self.symbol}.")
            return []

        try:
            level_distances = []
            for name, level_price in self.fib_levels_data.items():
                if isinstance(level_price, Decimal) and level_price > 0:
                    distance = abs(current_price - level_price)
                    level_distances.append({'name': name, 'level': level_price, 'distance': distance})
                else:
                    self.logger.warning(f"Invalid Fib level value: {name}={level_price}. Skipping.")

            level_distances.sort(key=lambda x: x['distance'])
            return [(item['name'], item['level']) for item in level_distances[:num_levels]]

        except Exception as e:
            self.logger.error(f"{NEON_RED}Error finding nearest Fibonacci levels for {self.symbol}: {e}{RESET}", exc_info=True)
            return []

    def calculate_ema_alignment_score(self) -> float:
        """Calculates EMA alignment score."""
        ema_short = self.indicator_values.get("EMA_Short")
        ema_long = self.indicator_values.get("EMA_Long")
        close_decimal = self.indicator_values.get("Close")
        # Convert close to float for comparison, default to NaN
        current_price_float = float(close_decimal) if isinstance(close_decimal, Decimal) else np.nan

        if pd.isna(ema_short) or pd.isna(ema_long) or pd.isna(current_price_float):
            self.logger.debug("EMA alignment check skipped: Missing values.")
            return np.nan

        if current_price_float > ema_short > ema_long: return 1.0 # Strong Bullish
        elif current_price_float < ema_short < ema_long: return -1.0 # Strong Bearish
        else: return 0.0 # Mixed / Crossing

    def generate_trading_signal(self, current_price: Decimal, orderbook_data: Optional[Dict]) -> str:
        """Generates final trading signal (BUY/SELL/HOLD) based on weighted score."""
        self.signals = {"BUY": 0, "SELL": 0, "HOLD": 1}
        final_signal_score = Decimal("0.0")
        total_weight_applied = Decimal("0.0")
        active_indicator_count = 0
        nan_indicator_count = 0
        debug_scores = {}

        if not self.indicator_values:
            self.logger.warning(f"Cannot generate signal for {self.symbol}: Indicator values empty.")
            return "HOLD"
        core_indicators_present = any(
            pd.notna(v) for k, v in self.indicator_values.items()
            if k not in ['Open', 'High', 'Low', 'Close', 'Volume']
        )
        if not core_indicators_present:
            self.logger.warning(f"Cannot generate signal for {self.symbol}: All core indicator values are NaN.")
            return "HOLD"
        if pd.isna(current_price) or not isinstance(current_price, Decimal) or current_price <= 0:
            self.logger.warning(f"Cannot generate signal for {self.symbol}: Invalid current price ({current_price}).")
            return "HOLD"

        active_weights = self.weights # Already fetched in __init__
        if not active_weights:
            self.logger.error(f"Active weight set '{self.active_weight_set_name}' missing or empty. Cannot generate signal.")
            return "HOLD"

        # --- Iterate through configured indicators ---
        for indicator_key, enabled in self.config.get("indicators", {}).items():
            if not enabled: continue
            weight_str = active_weights.get(indicator_key)
            if weight_str is None: continue # Skip if no weight defined

            try:
                weight = Decimal(str(weight_str))
                if weight == 0: continue # Skip zero weight indicators
            except (ValueError, TypeError, InvalidOperation):
                self.logger.warning(f"Invalid weight format '{weight_str}' for '{indicator_key}'. Skipping.")
                continue

            check_method_name = f"_check_{indicator_key}"
            if hasattr(self, check_method_name) and callable(getattr(self, check_method_name)):
                method_to_call = getattr(self, check_method_name)
                indicator_score_float = np.nan

                try:
                    if indicator_key == "orderbook":
                        if orderbook_data:
                            indicator_score_float = method_to_call(orderbook_data, current_price)
                        elif weight != 0:
                             self.logger.debug(f"Orderbook check skipped: No data provided.")
                    else:
                        indicator_score_float = method_to_call()

                except Exception as e:
                    self.logger.error(f"Error executing check {check_method_name}: {e}", exc_info=True)

                # Store score for debugging
                debug_scores[indicator_key] = f"{indicator_score_float:.3f}" if pd.notna(indicator_score_float) else "NaN"

                if pd.notna(indicator_score_float):
                    try:
                        score_decimal = Decimal(str(indicator_score_float))
                        # Clamp score to [-1, 1]
                        clamped_score = max(Decimal("-1.0"), min(Decimal("1.0"), score_decimal))
                        final_signal_score += clamped_score * weight
                        total_weight_applied += weight
                        active_indicator_count += 1
                    except (ValueError, TypeError, InvalidOperation) as calc_err:
                        self.logger.error(f"Error processing score for {indicator_key} (Score: {indicator_score_float}, Weight: {weight}): {calc_err}")
                        nan_indicator_count += 1
                else:
                    nan_indicator_count += 1
            elif weight != 0: # Log only if weighted but missing
                self.logger.warning(f"Indicator check method '{check_method_name}' not found for enabled/weighted indicator: {indicator_key}")

        # --- Determine Final Signal ---
        final_signal = "HOLD"
        if total_weight_applied == 0:
            self.logger.warning(f"No indicators contributed valid scores for {self.symbol}. Defaulting to HOLD.")
        else:
            try:
                threshold_str = self.config.get("signal_score_threshold", "1.5")
                threshold = Decimal(str(threshold_str))
            except (ValueError, TypeError, InvalidOperation):
                self.logger.warning(f"Invalid signal_score_threshold '{threshold_str}'. Using default 1.5.")
                threshold = Decimal("1.5")

            if final_signal_score >= threshold: final_signal = "BUY"
            elif final_signal_score <= -threshold: final_signal = "SELL"

        # --- Log Summary ---
        price_prec = self.get_price_precision()
        log_msg = (
            f"Signal Summary ({self.symbol} @ {current_price:.{price_prec}f}): "
            f"Set='{self.active_weight_set_name}', Indicators=[Active:{active_indicator_count}, NaN:{nan_indicator_count}], "
            f"TotalWeight={total_weight_applied:.2f}, "
            f"FinalScore={final_signal_score:.4f} (Threshold: +/-{threshold:.2f}) "
            f"==> {NEON_GREEN if final_signal == 'BUY' else NEON_RED if final_signal == 'SELL' else NEON_YELLOW}{final_signal}{RESET}"
        )
        self.logger.info(log_msg)
        self.logger.debug(f"  Indicator Scores ({self.symbol}): {debug_scores}")

        if final_signal == "BUY": self.signals = {"BUY": 1, "SELL": 0, "HOLD": 0}
        elif final_signal == "SELL": self.signals = {"BUY": 0, "SELL": 1, "HOLD": 0}
        else: self.signals = {"BUY": 0, "SELL": 0, "HOLD": 1}

        return final_signal

    # --- Indicator Check Methods (return float score -1.0 to 1.0 or np.nan) ---
    def _check_ema_alignment(self) -> float:
        if "EMA_Short" not in self.indicator_values or "EMA_Long" not in self.indicator_values:
             self.logger.debug("EMA Alignment check skipped: Values not found.")
             return np.nan
        return self.calculate_ema_alignment_score()

    def _check_momentum(self) -> float:
        momentum = self.indicator_values.get("Momentum")
        if pd.isna(momentum): return np.nan
        threshold = 0.1 # Example threshold, needs tuning
        if momentum > threshold: return 1.0
        elif momentum < -threshold: return -1.0
        else: return float(momentum / threshold) # Scale within threshold

    def _check_volume_confirmation(self) -> float:
        current_volume = self.indicator_values.get("Volume") # Decimal
        volume_ma_float = self.indicator_values.get("Volume_MA") # Float
        multiplier = float(self.config.get("volume_confirmation_multiplier", 1.5))

        if pd.isna(current_volume) or not isinstance(current_volume, Decimal) or \
           pd.isna(volume_ma_float) or volume_ma_float <= 0:
            return np.nan
        try:
            volume_ma = Decimal(str(volume_ma_float))
            multiplier_decimal = Decimal(str(multiplier))
            if current_volume > volume_ma * multiplier_decimal: return 0.7 # High volume confirmation
            elif current_volume < volume_ma / multiplier_decimal: return -0.4 # Low volume lack of confirmation
            else: return 0.0 # Neutral volume
        except (ValueError, TypeError, InvalidOperation) as e:
            self.logger.warning(f"Error during volume confirmation check: {e}")
            return np.nan

    def _check_stoch_rsi(self) -> float:
        k = self.indicator_values.get("StochRSI_K")
        d = self.indicator_values.get("StochRSI_D")
        if pd.isna(k) or pd.isna(d): return np.nan
        oversold = float(self.config.get("stoch_rsi_oversold_threshold", 25))
        overbought = float(self.config.get("stoch_rsi_overbought_threshold", 75))

        score = 0.0
        if k < oversold and d < oversold: score = 1.0
        elif k > overbought and d > overbought: score = -1.0

        diff = k - d
        if abs(diff) > 5: # Significant crossing potential
             score = max(score, 0.6) if diff > 0 else min(score, -0.6)
        elif k > d: score = max(score, 0.2) # Mildly bullish momentum
        elif k < d: score = min(score, -0.2) # Mildly bearish momentum

        if 40 < k < 60: score *= 0.5 # Dampen score in mid-range
        return score

    def _check_rsi(self) -> float:
        rsi = self.indicator_values.get("RSI")
        if pd.isna(rsi): return np.nan
        if rsi <= 30: return 1.0   # Oversold
        if rsi >= 70: return -1.0  # Overbought
        if rsi < 40: return 0.5
        if rsi > 60: return -0.5
        if 40 <= rsi <= 60: return (rsi - 50) / 50.0 # Scale mid-range
        return 0.0

    def _check_cci(self) -> float:
        cci = self.indicator_values.get("CCI")
        if pd.isna(cci): return np.nan
        if cci <= -150: return 1.0
        if cci >= 150: return -1.0
        if cci < -80: return 0.6
        if cci > 80: return -0.6
        if cci > 0: return -0.1 # Slightly bearish tendency above zero
        if cci < 0: return 0.1  # Slightly bullish tendency below zero
        return 0.0

    def _check_wr(self) -> float:
        wr = self.indicator_values.get("Williams_R")
        if pd.isna(wr): return np.nan
        # WR range is -100 to 0
        if wr <= -80: return 1.0   # Oversold -> Buy
        if wr >= -20: return -1.0  # Overbought -> Sell
        if wr < -50: return 0.4    # Approaching midpoint from oversold
        if wr > -50: return -0.4    # Approaching midpoint from overbought
        return 0.0

    def _check_psar(self) -> float:
        psar_long = self.indicator_values.get("PSAR_long") # Price if long active, else NaN
        psar_short = self.indicator_values.get("PSAR_short") # Price if short active, else NaN

        long_active = pd.notna(psar_long)
        short_active = pd.notna(psar_short)

        if long_active and not short_active: return 1.0 # Uptrend
        elif short_active and not long_active: return -1.0 # Downtrend
        elif not long_active and not short_active: return np.nan # Indeterminate / Start of data
        else: # Should not happen (both active)
             self.logger.warning(f"PSAR check unusual state: Long={psar_long}, Short={psar_short}")
             return 0.0

    def _check_sma_10(self) -> float:
        sma_10 = self.indicator_values.get("SMA10")
        last_close = self.indicator_values.get("Close") # Decimal
        if pd.isna(sma_10) or pd.isna(last_close) or not isinstance(last_close, Decimal): return np.nan
        # Convert SMA float to Decimal for comparison
        sma_10_dec = Decimal(str(sma_10))
        if last_close > sma_10_dec: return 0.6
        elif last_close < sma_10_dec: return -0.6
        else: return 0.0

    def _check_vwap(self) -> float:
        vwap = self.indicator_values.get("VWAP")
        last_close = self.indicator_values.get("Close") # Decimal
        if pd.isna(vwap) or pd.isna(last_close) or not isinstance(last_close, Decimal): return np.nan
        vwap_dec = Decimal(str(vwap))
        if last_close > vwap_dec: return 0.7
        elif last_close < vwap_dec: return -0.7
        else: return 0.0

    def _check_mfi(self) -> float:
        mfi = self.indicator_values.get("MFI")
        if pd.isna(mfi): return np.nan
        if mfi <= 20: return 1.0
        if mfi >= 80: return -1.0
        if mfi < 40: return 0.4
        if mfi > 60: return -0.4
        return 0.0

    def _check_bollinger_bands(self) -> float:
        bb_lower = self.indicator_values.get("BB_Lower")
        bb_middle = self.indicator_values.get("BB_Middle")
        bb_upper = self.indicator_values.get("BB_Upper")
        last_close = self.indicator_values.get("Close") # Decimal
        if pd.isna(bb_lower) or pd.isna(bb_middle) or pd.isna(bb_upper) or \
           pd.isna(last_close) or not isinstance(last_close, Decimal): return np.nan

        # Convert band floats to Decimal
        try:
             bb_l, bb_m, bb_u = Decimal(str(bb_lower)), Decimal(str(bb_middle)), Decimal(str(bb_upper))
        except (ValueError, TypeError, InvalidOperation):
             self.logger.warning("Could not convert BB values to Decimal.")
             return np.nan

        if last_close <= bb_l: return 1.0 # Touch/Below Lower Band -> Buy Signal
        if last_close >= bb_u: return -1.0 # Touch/Above Upper Band -> Sell Signal

        # Position relative to middle band
        band_width = bb_u - bb_l
        if band_width > 0:
             # Scale score based on proximity to bands within the middle range
             if last_close > bb_m: # Above middle
                  proximity_to_upper = (last_close - bb_m) / (bb_u - bb_m) if (bb_u - bb_m) > 0 else Decimal(0)
                  return float(Decimal(0.5) * (1 - proximity_to_upper)) # Score decreases closer to upper band
             elif last_close < bb_m: # Below middle
                  proximity_to_lower = (bb_m - last_close) / (bb_m - bb_l) if (bb_m - bb_l) > 0 else Decimal(0)
                  return float(Decimal(-0.5) * (1 - proximity_to_lower)) # Score increases (less negative) closer to lower band
        return 0.0 # On middle band or bands collapsed

    def _check_orderbook(self, orderbook_data: Optional[Dict], current_price: Decimal) -> float:
        """Analyzes order book imbalance."""
        if not orderbook_data or not orderbook_data.get('bids') or not orderbook_data.get('asks'):
            self.logger.debug("Orderbook check skipped: No data or missing bids/asks.")
            return np.nan
        try:
            bids = orderbook_data['bids']
            asks = orderbook_data['asks']
            num_levels = min(len(bids), len(asks), 10) # Check top 10 levels, or fewer if available
            if num_levels == 0: return 0.0 # Neutral if no common levels

            # Sum sizes (Decimal) within N levels
            bid_vol = sum(Decimal(str(b[1])) for b in bids[:num_levels] if len(b) == 2)
            ask_vol = sum(Decimal(str(a[1])) for a in asks[:num_levels] if len(a) == 2)
            total_vol = bid_vol + ask_vol

            if total_vol == 0: return 0.0 # Avoid division by zero

            # Order Book Imbalance (OBI)
            obi = (bid_vol - ask_vol) / total_vol
            score = float(obi) # Convert final ratio to float score

            self.logger.debug(
                f"Orderbook check ({self.symbol}): Top {num_levels} levels -> "
                f"BidVol={bid_vol:.4f}, AskVol={ask_vol:.4f}, OBI={obi:.4f} -> Score={score:.4f}"
            )
            # Clamp score just in case (should already be -1 to 1)
            return max(-1.0, min(1.0, score))

        except (IndexError, ValueError, TypeError, InvalidOperation) as e:
            self.logger.warning(f"Orderbook analysis failed for {self.symbol}: {e}", exc_info=True)
            return np.nan

    def calculate_entry_tp_sl(
        self, entry_price_estimate: Decimal, signal: str
    ) -> Tuple[Optional[Decimal], Optional[Decimal], Optional[Decimal]]:
        """Calculates potential TP and initial SL based on entry estimate, signal, and ATR."""
        if signal not in ["BUY", "SELL"]:
            return entry_price_estimate, None, None

        atr_val = self.indicator_values.get("ATR") # Should be Decimal
        if not isinstance(atr_val, Decimal) or pd.isna(atr_val) or atr_val <= 0:
            self.logger.warning(f"Cannot calculate TP/SL for {signal}: Invalid ATR ({atr_val}).")
            return entry_price_estimate, None, None
        if not isinstance(entry_price_estimate, Decimal) or pd.isna(entry_price_estimate) or entry_price_estimate <= 0:
            self.logger.warning(f"Cannot calculate TP/SL for {signal}: Invalid entry price estimate ({entry_price_estimate}).")
            return entry_price_estimate, None, None

        try:
            tp_multiple = Decimal(str(self.config.get("take_profit_multiple", "1.0")))
            sl_multiple = Decimal(str(self.config.get("stop_loss_multiple", "1.5")))
            price_precision = self.get_price_precision()
            rounding_factor = Decimal('1e-' + str(price_precision))
            min_tick = self.get_min_tick_size()

            tp_offset = atr_val * tp_multiple
            sl_offset = atr_val * sl_multiple

            take_profit_raw: Optional[Decimal] = None
            stop_loss_raw: Optional[Decimal] = None

            if signal == "BUY":
                take_profit_raw = entry_price_estimate + tp_offset
                stop_loss_raw = entry_price_estimate - sl_offset
            elif signal == "SELL":
                take_profit_raw = entry_price_estimate - tp_offset
                stop_loss_raw = entry_price_estimate + sl_offset

            # Quantize TP/SL to Market Precision
            take_profit_quantized: Optional[Decimal] = None
            stop_loss_quantized: Optional[Decimal] = None

            if take_profit_raw is not None:
                 # Quantize TP conservatively (ROUND_DOWN for BUY, ROUND_UP for SELL - less profit potential)
                 # Or round normally? Let's round normally first.
                 # tp_rounding = ROUND_DOWN if signal == "BUY" else ROUND_UP # Conservative
                 tp_rounding = ROUND_HALF_UP # Standard rounding
                 take_profit_quantized = take_profit_raw.quantize(rounding_factor, rounding=tp_rounding)

            if stop_loss_raw is not None:
                 # Quantize SL conservatively (ROUND_DOWN for BUY, ROUND_UP for SELL - wider SL)
                 sl_rounding = ROUND_DOWN if signal == "BUY" else ROUND_UP
                 stop_loss_quantized = stop_loss_raw.quantize(rounding_factor, rounding=sl_rounding)

            # --- Validation and Adjustments ---
            final_tp = take_profit_quantized
            final_sl = stop_loss_quantized

            # 1. Ensure SL is strictly beyond entry by at least one tick
            if final_sl is not None:
                if signal == "BUY" and final_sl >= entry_price_estimate:
                    final_sl = (entry_price_estimate - min_tick).quantize(rounding_factor, rounding=ROUND_DOWN)
                    self.logger.debug(f"Adjusted BUY SL below entry: {stop_loss_quantized} -> {final_sl}")
                elif signal == "SELL" and final_sl <= entry_price_estimate:
                    final_sl = (entry_price_estimate + min_tick).quantize(rounding_factor, rounding=ROUND_UP)
                    self.logger.debug(f"Adjusted SELL SL above entry: {stop_loss_quantized} -> {final_sl}")

            # 2. Ensure TP provides potential profit (strictly beyond entry)
            if final_tp is not None:
                if signal == "BUY" and final_tp <= entry_price_estimate:
                    self.logger.warning(f"{NEON_YELLOW}BUY TP calculation non-profitable (TP {final_tp} <= Entry {entry_price_estimate}). Setting TP to None.{RESET}")
                    final_tp = None
                elif signal == "SELL" and final_tp >= entry_price_estimate:
                    self.logger.warning(f"{NEON_YELLOW}SELL TP calculation non-profitable (TP {final_tp} >= Entry {entry_price_estimate}). Setting TP to None.{RESET}")
                    final_tp = None

            # 3. Ensure SL/TP are positive
            if final_sl is not None and final_sl <= 0:
                self.logger.error(f"{NEON_RED}Stop loss calculation resulted in non-positive price ({final_sl}). Setting SL to None.{RESET}")
                final_sl = None
            if final_tp is not None and final_tp <= 0:
                self.logger.warning(f"{NEON_YELLOW}Take profit calculation resulted in non-positive price ({final_tp}). Setting TP to None.{RESET}")
                final_tp = None

            tp_str = f"{final_tp:.{price_precision}f}" if final_tp else "None"
            sl_str = f"{final_sl:.{price_precision}f}" if final_sl else "None"
            self.logger.debug(
                f"Calculated TP/SL for {signal}: EntryEst={entry_price_estimate:.{price_precision}f}, "
                f"ATR={atr_val:.{price_precision+2}f}, TP={tp_str} (Mult: {tp_multiple}), SL={sl_str} (Mult: {sl_multiple})"
            )
            return entry_price_estimate, final_tp, final_sl

        except (ValueError, TypeError, InvalidOperation) as e:
            self.logger.error(f"{NEON_RED}Error converting values during TP/SL calculation for {signal}: {e}{RESET}")
            return entry_price_estimate, None, None
        except Exception as e:
            self.logger.error(f"{NEON_RED}Unexpected error calculating TP/SL for {signal}: {e}{RESET}", exc_info=True)
            return entry_price_estimate, None, None

# --- Trading Logic Helper Functions ---

def fetch_balance(exchange: ccxt.Exchange, currency: str, logger: logging.Logger) -> Optional[Decimal]:
    """Fetches available balance for a specific currency with retries and robust parsing."""
    lg = logger
    try:
        balance_info = None
        # Prioritize specific account types for Bybit V5
        params = {}
        account_type_to_log = "default"
        if exchange.id == 'bybit':
            # Use 'CONTRACT' for derivatives, could also try 'UNIFIED'
            params = {'type': 'CONTRACT'}
            account_type_to_log = 'CONTRACT'

        lg.debug(f"Fetching balance for {currency} (Account: {account_type_to_log})...")
        # Use safe_api_call for fetching
        balance_info = safe_api_call(exchange.fetch_balance, lg, params=params)

        if not balance_info:
             lg.error(f"Failed to fetch balance info for {currency} after retries.")
             # Optionally try default fetch without params as fallback
             lg.debug("Attempting balance fetch with default parameters as fallback...")
             balance_info = safe_api_call(exchange.fetch_balance, lg)
             if not balance_info:
                  lg.error(f"Fallback balance fetch also failed for {currency}.")
                  return None

        # --- Parse the balance_info ---
        available_balance_str = None
        free_balance = None

        # 1. Standard CCXT: balance[currency]['free']
        if currency in balance_info and balance_info[currency].get('free') is not None:
            free_balance = balance_info[currency]['free']
            lg.debug(f"Found balance via standard ['{currency}']['free']: {free_balance}")

        # 2. Bybit V5 Nested: info.result.list[].coin[].availableToWithdraw / availableBalance
        elif not free_balance and exchange.id == 'bybit' and 'info' in balance_info and 'result' in balance_info['info'] and isinstance(balance_info['info']['result'].get('list'), list):
            for account in balance_info['info']['result']['list']:
                if isinstance(account.get('coin'), list):
                    for coin_data in account['coin']:
                        if coin_data.get('coin') == currency:
                            # Prefer availableToWithdraw > availableBalance > walletBalance
                            free = coin_data.get('availableToWithdraw') or coin_data.get('availableBalance') or coin_data.get('walletBalance')
                            if free is not None:
                                free_balance = free
                                lg.debug(f"Found balance via Bybit V5 nested ['available...']: {free_balance}")
                                break
                    if free_balance is not None: break
            if free_balance is None:
                lg.warning(f"{currency} balance details not found within Bybit V5 'info.result.list[].coin[]'.")

        # 3. Fallback: Top-level 'free' dictionary (less common)
        elif not free_balance and 'free' in balance_info and currency in balance_info['free'] and balance_info['free'][currency] is not None:
             free_balance = balance_info['free'][currency]
             lg.debug(f"Found balance via top-level 'free' dict: {free_balance}")

        # 4. Fallback: Use 'total' if 'free' is unavailable (use with caution)
        if free_balance is None:
             total_balance = balance_info.get(currency, {}).get('total')
             if total_balance is not None:
                  lg.warning(f"{NEON_YELLOW}Using 'total' balance ({total_balance}) as fallback for available {currency}. This might include collateral.{RESET}")
                  free_balance = total_balance
             else:
                  lg.error(f"{NEON_RED}Could not determine any balance ('free' or 'total') for {currency}.{RESET}")
                  lg.debug(f"Full balance_info structure: {json.dumps(balance_info, indent=2)}")
                  return None # No balance found

        # Convert the found balance to Decimal
        try:
            final_balance = Decimal(str(free_balance))
            # Allow zero balance, but log warning if negative
            if final_balance < 0:
                 lg.error(f"Parsed balance for {currency} is negative ({final_balance}). Treating as zero.")
                 final_balance = Decimal('0')
            lg.info(f"Available {currency} balance: {final_balance:.4f}")
            return final_balance
        except (ValueError, TypeError, InvalidOperation) as e:
            lg.error(f"Failed to convert balance string '{free_balance}' to Decimal for {currency}: {e}")
            return None

    except Exception as e:
        # Catch errors raised by safe_api_call or during parsing
        lg.error(f"{NEON_RED}Error fetching balance for {currency}: {e}{RESET}", exc_info=False)
        return None


def get_market_info(exchange: ccxt.Exchange, symbol: str, logger: logging.Logger) -> Optional[Dict]:
    """Gets market information with retries for loading."""
    lg = logger
    try:
        # Ensure markets are loaded, reload if necessary with retries
        if not exchange.markets or symbol not in exchange.markets:
             lg.info(f"Market info for {symbol} not loaded or symbol not found, attempting to load/reload markets...")
             try:
                 safe_api_call(exchange.load_markets, lg, reload=True)
             except Exception as load_err:
                  lg.error(f"{NEON_RED}Failed to load/reload markets after retries: {load_err}{RESET}")
                  return None # Cannot proceed without markets

        if symbol not in exchange.markets:
             lg.error(f"{NEON_RED}Market {symbol} still not found after reloading.{RESET}")
             # Suggest alternatives for common symbols
             if symbol == "BTC/USDT": lg.warning(f"{NEON_YELLOW}Hint: For Bybit linear perpetual, try '{symbol}:USDT'{RESET}")
             return None

        market = exchange.market(symbol)
        if market:
            # --- Extract and Log Details ---
            market_type = market.get('type', 'unknown') # spot, future, swap, option
            is_contract = market.get('contract', False) or market_type in ['swap', 'future']
            is_linear = market.get('linear', False)
            is_inverse = market.get('inverse', False)
            contract_type = "Linear" if is_linear else "Inverse" if is_inverse else "N/A" if not is_contract else "Unknown Contract"
            price_prec_val = market.get('precision', {}).get('price')
            amount_prec_val = market.get('precision', {}).get('amount')
            min_amount = market.get('limits', {}).get('amount', {}).get('min')
            max_amount = market.get('limits', {}).get('amount', {}).get('max')
            min_cost = market.get('limits', {}).get('cost', {}).get('min')
            max_cost = market.get('limits', {}).get('cost', {}).get('max')
            contract_size = market.get('contractSize', 'N/A')

            lg.debug(
                f"Market Info ({symbol}): ID={market.get('id')}, Base={market.get('base')}, Quote={market.get('quote')}, "
                f"Type={market_type}, Contract={is_contract}, ContractType={contract_type}, Size={contract_size}, "
                f"Precision(Price/Amount): {price_prec_val}/{amount_prec_val}, "
                f"Limits(Amount Min/Max): {min_amount}/{max_amount}, "
                f"Limits(Cost Min/Max): {min_cost}/{max_cost}"
            )
            # Add custom flags for easier checks
            market['is_contract'] = is_contract
            market['is_linear'] = is_linear
            market['is_inverse'] = is_inverse
            return market
        else:
             lg.error(f"{NEON_RED}Market dictionary unexpectedly not found for validated symbol {symbol}.{RESET}")
             return None

    except ccxt.BadSymbol as e:
         lg.error(f"{NEON_RED}Symbol '{symbol}' is invalid or not supported by {exchange.id}: {e}{RESET}")
         return None
    except Exception as e:
        lg.error(f"{NEON_RED}Unexpected error getting market info for {symbol}: {e}{RESET}", exc_info=True)
        return None


def calculate_position_size(
    balance: Decimal,
    risk_per_trade: float,
    initial_stop_loss_price: Decimal,
    entry_price: Decimal,
    market_info: Dict,
    exchange: ccxt.Exchange, # Needed for formatting helpers
    logger: Optional[logging.Logger] = None
) -> Optional[Decimal]:
    """Calculates position size based on risk, SL, balance, and market constraints."""
    lg = logger or logging.getLogger(__name__)
    symbol = market_info.get('symbol', 'UNKNOWN')
    quote_currency = market_info.get('quote', QUOTE_CURRENCY)
    base_currency = market_info.get('base', 'BASE')
    is_contract = market_info.get('is_contract', False)
    is_inverse = market_info.get('is_inverse', False)
    size_unit = "Contracts" if is_contract else base_currency

    # --- Input Validation ---
    if balance is None or not isinstance(balance, Decimal) or balance <= 0:
        lg.error(f"Size Calc Fail ({symbol}): Invalid balance ({balance}).")
        return None
    if not (0 < risk_per_trade < 1):
        lg.error(f"Size Calc Fail ({symbol}): Invalid risk_per_trade ({risk_per_trade}).")
        return None
    if initial_stop_loss_price is None or initial_stop_loss_price <= 0:
        lg.error(f"Size Calc Fail ({symbol}): Invalid initial_stop_loss_price ({initial_stop_loss_price}).")
        return None
    if entry_price is None or entry_price <= 0:
        lg.error(f"Size Calc Fail ({symbol}): Invalid entry_price ({entry_price}).")
        return None
    if initial_stop_loss_price == entry_price:
        lg.error(f"Size Calc Fail ({symbol}): SL price equals entry price.")
        return None
    if 'limits' not in market_info or 'precision' not in market_info:
        lg.error(f"Size Calc Fail ({symbol}): Market info missing 'limits' or 'precision'.")
        return None
    if is_inverse:
        lg.error(f"{NEON_RED}Inverse contract sizing not fully implemented. Aborting sizing for {symbol}.{RESET}")
        return None # Exit for inverse contracts

    try:
        risk_amount_quote = balance * Decimal(str(risk_per_trade))
        sl_distance_per_unit = abs(entry_price - initial_stop_loss_price)
        if sl_distance_per_unit <= 0:
            lg.error(f"Size Calc Fail ({symbol}): SL distance is zero/negative.")
            return None

        # Get Contract Size (value per contract, usually in base currency)
        contract_size_str = market_info.get('contractSize', '1') # Defaults to 1 for spot/linear if not specified
        try:
            contract_size = Decimal(str(contract_size_str))
            if contract_size <= 0: raise ValueError("Contract size must be positive")
        except (ValueError, TypeError, InvalidOperation):
            lg.warning(f"Invalid contract size '{contract_size_str}' for {symbol}, using 1.")
            contract_size = Decimal('1')

        # --- Calculate Initial Size (Assuming Linear/Spot) ---
        # Formula: Size = RiskAmountQuote / RiskPerUnitQuote
        # RiskPerUnitQuote = StopLossDistanceQuote * ContractSizeValueQuote
        # For Linear: ContractSizeValueQuote = contract_size (in base) * entry_price (quote/base) -> this is wrong.
        # Let's simplify: RiskPerUnitQuote = SL_Distance_Quote_Per_Unit * ContractSize_Base_Units
        # For Spot: Size = RiskQuote / SL_Quote_Per_Base
        # For Linear: Contract represents 'contract_size' amount of Base currency.
        #             Risk per contract (in Quote) = SL_Distance_Quote_Per_Base * ContractSize_Base
        #             SizeInContracts = RiskQuote / (SL_Distance_Quote_Per_Base * ContractSize_Base)
        risk_per_contract_quote = sl_distance_per_unit * contract_size
        if risk_per_contract_quote <= 0:
             lg.error(f"Size Calc Fail ({symbol}): Denominator zero/negative in size calc (risk per contract: {risk_per_contract_quote}).")
             return None

        calculated_size = risk_amount_quote / risk_per_contract_quote

        if calculated_size <= 0:
            lg.error(f"Initial size calc resulted in zero/negative: {calculated_size}. RiskAmt={risk_amount_quote:.4f}, SLDist={sl_distance_per_unit}, ContrSize={contract_size}")
            return None

        lg.info(f"Position Sizing ({symbol}): Balance={balance:.2f}, Risk={risk_per_trade:.2%}, RiskAmt={risk_amount_quote:.4f} {quote_currency}")
        lg.info(f"  Entry={entry_price}, SL={initial_stop_loss_price}, SL Dist={sl_distance_per_unit}")
        lg.info(f"  ContractSize={contract_size}, Initial Calc. Size = {calculated_size:.8f} {size_unit}")

        # --- Apply Market Limits and Precision ---
        limits = market_info.get('limits', {})
        amount_limits = limits.get('amount', {})
        cost_limits = limits.get('cost', {})
        # Use helper functions to get Decimal values for limits
        analyzer = TradingAnalyzer(pd.DataFrame(), lg, CONFIG, market_info) # Temp instance for helpers
        min_amount = Decimal(str(amount_limits.get('min', '0')))
        max_amount = Decimal(str(amount_limits.get('max', 'inf')))
        min_cost = Decimal(str(cost_limits.get('min', '0')))
        max_cost = Decimal(str(cost_limits.get('max', 'inf')))
        amount_step = analyzer.get_min_amount_step()

        adjusted_size = calculated_size

        # 1. Clamp by MIN/MAX AMOUNT limits (before step size adjustment)
        original_size = adjusted_size
        if adjusted_size < min_amount: adjusted_size = min_amount
        if adjusted_size > max_amount: adjusted_size = max_amount
        if adjusted_size != original_size:
             lg.warning(f"{NEON_YELLOW}Size adjusted by Amount Limits: {original_size:.8f} -> {adjusted_size:.8f} {size_unit} (Min: {min_amount}, Max: {max_amount}){RESET}")

        # 2. Apply Amount Step Size (Round DOWN - conservative)
        if amount_step > 0:
            original_size = adjusted_size
            adjusted_size = (adjusted_size // amount_step) * amount_step
            if adjusted_size != original_size:
                 lg.info(f"Applied Amount Step Size ({amount_step}): {original_size:.8f} -> {adjusted_size:.8f} {size_unit}")
        else:
            lg.warning(f"Amount step size is zero or negative ({amount_step}). Skipping step size adjustment.")

        # Re-check MIN amount after step-size rounding
        if adjusted_size < min_amount:
             lg.error(f"{NEON_RED}Size ({adjusted_size}) is below Min Amount ({min_amount}) after step size adjustment. Cannot place order.{RESET}")
             # This can happen if min_amount is not a multiple of amount_step
             return None

        # 3. Check COST limits with the step-adjusted size
        # Cost = Size * EntryPrice (for spot) or Size * EntryPrice * ContractSize (for linear)
        estimated_cost = adjusted_size * entry_price * contract_size
        lg.debug(f"  Cost Check: Final Adjusted Size={adjusted_size:.8f}, Estimated Cost={estimated_cost:.4f} {quote_currency} (Min: {min_cost}, Max: {max_cost})")

        if min_cost > 0 and estimated_cost < min_cost:
            lg.error(f"{NEON_RED}Estimated cost {estimated_cost:.4f} is below Min Cost {min_cost} after all adjustments. Cannot place order.{RESET}")
            lg.error(f"  >> Check if Min Amount ({min_amount}) and Min Cost ({min_cost}) limits conflict for this price/size.")
            return None
        if max_cost > 0 and estimated_cost > max_cost:
            lg.error(f"{NEON_RED}Estimated cost {estimated_cost:.4f} exceeds Max Cost {max_cost} after all adjustments. Cannot place order.{RESET}")
            # This implies risk % or balance leads to too large an order even after max amount check
            return None

        # --- Final Validation ---
        final_size = adjusted_size
        if final_size <= 0:
             lg.error(f"{NEON_RED}Final position size became zero or negative ({final_size}) after adjustments. Aborted.{RESET}")
             return None

        lg.info(f"{NEON_GREEN}Final calculated position size for {symbol}: {final_size} {size_unit}{RESET}")
        return final_size

    except Exception as e:
        lg.error(f"{NEON_RED}Unexpected error calculating position size for {symbol}: {e}{RESET}", exc_info=True)
        return None


def get_open_position(exchange: ccxt.Exchange, symbol: str, logger: logging.Logger) -> Optional[Dict]:
    """Checks for an open position using fetch_positions with robust parsing for Bybit V5."""
    lg = logger
    if not exchange.has.get('fetchPositions'):
        lg.warning(f"Exchange {exchange.id} does not support fetchPositions. Cannot check position status.")
        return None

    try:
        lg.debug(f"Fetching positions for symbol: {symbol}")
        # Some exchanges require symbols list, others fetch all if symbol omitted
        # Bybit V5: Can fetch specific symbol or category=linear/inverse
        params = {}
        if exchange.id == 'bybit':
            # Try fetching specific symbol directly, which works for unified/contract v5
            params = {'symbol': symbol} # Should use the exchange's ID for the symbol
            # Alternative: params = {'category': 'linear'} # Fetch all linear positions

        # Use safe_api_call for the fetch operation
        positions: List[Dict] = safe_api_call(exchange.fetch_positions, lg, symbols=[symbol], params=params) # Pass symbol in list

        if positions is None: # safe_api_call failed after retries
             lg.error("Position fetch failed after retries.")
             # Option: Try fetching all positions as a fallback?
             lg.debug("Attempting to fetch ALL positions as fallback...")
             all_positions = safe_api_call(exchange.fetch_positions, lg)
             if all_positions:
                  positions = [p for p in all_positions if p.get('symbol') == symbol]
                  lg.debug(f"Fetched {len(all_positions)} total positions, found {len(positions)} matching {symbol}.")
             else:
                  lg.error("Fallback fetch of all positions also failed.")
                  return None

        # --- Process the fetched positions list ---
        active_position = None
        size_threshold = Decimal('1e-9') # Threshold for considering size non-zero

        for pos in positions:
            pos_symbol = pos.get('symbol')
            if pos_symbol != symbol: continue # Ensure correct symbol

            pos_size_str = None
            # Try standard 'contracts', fallback to 'info.size' (Bybit V5)
            if pos.get('contracts') is not None: pos_size_str = str(pos['contracts'])
            elif isinstance(pos.get('info'), dict) and pos['info'].get('size') is not None:
                 pos_size_str = str(pos['info']['size'])

            if pos_size_str is None: continue # Skip if size unavailable

            try:
                position_size = Decimal(pos_size_str)
                if abs(position_size) > size_threshold:
                    active_position = pos
                    lg.debug(f"Found potential active position entry for {symbol} with size {position_size}.")
                    break # Assume only one position per symbol/side/mode needed
            except (ValueError, TypeError, InvalidOperation) as parse_err:
                lg.warning(f"Could not parse position size '{pos_size_str}' for {symbol}: {parse_err}")

        # --- Post-Process the found active position ---
        if active_position:
            try:
                market = exchange.market(symbol) # Get market info again for context
                analyzer = TradingAnalyzer(pd.DataFrame(), lg, CONFIG, market) # Temp instance for helpers
                price_prec = analyzer.get_price_precision()
                amt_prec = analyzer.get_amount_precision_places()

                # Standardize Size (always Decimal)
                size_decimal = Decimal(str(active_position.get('contracts', active_position.get('info',{}).get('size', '0'))))
                active_position['contractsDecimal'] = size_decimal

                # Standardize Side
                side = active_position.get('side')
                if side not in ['long', 'short']:
                    if size_decimal > size_threshold: side = 'long'
                    elif size_decimal < -size_threshold: side = 'short'
                    else: lg.warning(f"Position size {size_decimal} near zero, cannot determine side."); return None
                    active_position['side'] = side
                    lg.debug(f"Inferred position side as '{side}' based on size.")

                # Standardize Entry Price (Decimal)
                entry_price_str = active_position.get('entryPrice') or active_position.get('info', {}).get('avgPrice')
                active_position['entryPriceDecimal'] = Decimal(str(entry_price_str)) if entry_price_str else None

                # Standardize Liq Price (Decimal)
                liq_price_str = active_position.get('liquidationPrice') or active_position.get('info', {}).get('liqPrice')
                active_position['liquidationPriceDecimal'] = Decimal(str(liq_price_str)) if liq_price_str else None

                # Standardize PNL (Decimal)
                pnl_str = active_position.get('unrealizedPnl') or active_position.get('info', {}).get('unrealisedPnl')
                active_position['unrealizedPnlDecimal'] = Decimal(str(pnl_str)) if pnl_str else None

                # Extract SL/TP/TSL from 'info' (Bybit V5) and store as Decimal where applicable
                info_dict = active_position.get('info', {})
                sl_str = info_dict.get('stopLoss')
                tp_str = info_dict.get('takeProfit')
                tsl_dist_str = info_dict.get('trailingStop') # Distance value
                tsl_act_str = info_dict.get('activePrice') # Activation price

                active_position['stopLossPriceDecimal'] = Decimal(str(sl_str)) if sl_str and str(sl_str) != '0' else None
                active_position['takeProfitPriceDecimal'] = Decimal(str(tp_str)) if tp_str and str(tp_str) != '0' else None
                active_position['trailingStopLossValueDecimal'] = Decimal(str(tsl_dist_str)) if tsl_dist_str and str(tsl_dist_str) != '0' else None
                active_position['trailingStopActivationPriceDecimal'] = Decimal(str(tsl_act_str)) if tsl_act_str and str(tsl_act_str) != '0' else None

                # Get timestamp (prefer updatedTime from info for Bybit V5)
                timestamp_ms = info_dict.get('updatedTime') or active_position.get('timestamp')
                active_position['timestamp_ms'] = int(timestamp_ms) if timestamp_ms else None
                timestamp_dt_str = datetime.fromtimestamp(timestamp_ms / 1000, tz=timezone.utc).strftime('%Y-%m-%d %H:%M:%S %Z') if timestamp_ms else "N/A"

                # Log Formatted Info
                entry_fmt = f"{active_position['entryPriceDecimal']:.{price_prec}f}" if active_position['entryPriceDecimal'] else 'N/A'
                size_fmt = f"{abs(size_decimal):.{amt_prec}f}"
                liq_fmt = f"{active_position['liquidationPriceDecimal']:.{price_prec}f}" if active_position['liquidationPriceDecimal'] else 'N/A'
                lev_str = info_dict.get('leverage', active_position.get('leverage'))
                lev_fmt = f"{Decimal(str(lev_str)):.1f}x" if lev_str else 'N/A'
                pnl_fmt = f"{active_position['unrealizedPnlDecimal']:.{price_prec}f}" if active_position['unrealizedPnlDecimal'] else 'N/A' # Use price precision for PNL
                sl_fmt = f"{active_position['stopLossPriceDecimal']:.{price_prec}f}" if active_position['stopLossPriceDecimal'] else 'N/A'
                tp_fmt = f"{active_position['takeProfitPriceDecimal']:.{price_prec}f}" if active_position['takeProfitPriceDecimal'] else 'N/A'
                tsl_d_fmt = f"{active_position['trailingStopLossValueDecimal']:.{price_prec}f}" if active_position['trailingStopLossValueDecimal'] else 'N/A' # Format distance like price
                tsl_a_fmt = f"{active_position['trailingStopActivationPriceDecimal']:.{price_prec}f}" if active_position['trailingStopActivationPriceDecimal'] else 'N/A'

                logger.info(f"{NEON_GREEN}Active {side.upper()} position found ({symbol}):{RESET} "
                            f"Size={size_fmt}, Entry={entry_fmt}, Liq={liq_fmt}, Lev={lev_fmt}, PnL={pnl_fmt}, "
                            f"SL={sl_fmt}, TP={tp_fmt}, TSL(Dist/Act): {tsl_d_fmt}/{tsl_a_fmt} (Updated: {timestamp_dt_str})")
                logger.debug(f"Full processed position details: {active_position}")
                return active_position

            except (ValueError, TypeError, InvalidOperation, KeyError) as proc_err:
                 lg.error(f"Error processing active position details for {symbol}: {proc_err}", exc_info=True)
                 lg.debug(f"Problematic raw position data: {active_position}")
                 return None

        else:
            logger.info(f"No active open position found for {symbol}.")
            return None

    except ccxt.ArgumentsRequired as e:
         # Handle cases where fetching single symbol isn't supported
         lg.warning(f"Fetching single position failed ({e}). Trying to fetch all positions...")
         try:
             all_positions = safe_api_call(exchange.fetch_positions, lg) # Fetch all
             if all_positions:
                  positions = [p for p in all_positions if p.get('symbol') == symbol]
                  lg.debug(f"Fetched {len(all_positions)} total positions, found {len(positions)} matching {symbol}.")
                  # Now re-run the processing logic from above
                  # This part is duplicated, consider refactoring into a helper
                  active_position = None
                  size_threshold = Decimal('1e-9')
                  for pos in positions:
                      # ... (repeat processing logic as above) ...
                      # Standardize Size (always Decimal)
                        pos_size_str = None
                        if pos.get('contracts') is not None: pos_size_str = str(pos['contracts'])
                        elif isinstance(pos.get('info'), dict) and pos['info'].get('size') is not None: pos_size_str = str(pos['info']['size'])
                        if pos_size_str is None: continue
                        try:
                            position_size = Decimal(pos_size_str)
                            if abs(position_size) > size_threshold:
                                active_position = pos
                                break
                        except (ValueError, TypeError, InvalidOperation): continue
                  if active_position:
                      # ... (repeat post-processing logic as above) ...
                       return active_position # Return processed position
                  else: logger.info(f"No active open position found for {symbol} in fallback fetch."); return None
             else:
                 lg.error("Fallback fetch of all positions also failed.")
                 return None
         except Exception as fallback_e:
              lg.error(f"Error during fallback fetch of all positions: {fallback_e}", exc_info=True)
              return None
    except Exception as e:
        # Catch errors raised by safe_api_call or other unexpected issues
        lg.error(f"{NEON_RED}Unexpected error fetching/processing positions for {symbol}: {e}{RESET}", exc_info=True)
        return None


def set_leverage_ccxt(exchange: ccxt.Exchange, symbol: str, leverage: int, market_info: Dict, logger: logging.Logger) -> bool:
    """Sets leverage using CCXT, handling Bybit V5 specifics."""
    lg = logger
    if not market_info.get('is_contract', False):
        lg.debug(f"Leverage setting skipped for {symbol} (Not a contract market).")
        return True # No action needed
    if not isinstance(leverage, int) or leverage <= 0:
        lg.warning(f"Leverage setting skipped: Invalid leverage value ({leverage}). Must be positive integer.")
        return False
    if not exchange.has.get('setLeverage') and not exchange.has.get('setMarginMode'):
        lg.error(f"Exchange {exchange.id} supports neither setLeverage nor setMarginMode. Cannot set leverage.")
        return False

    try:
        lg.info(f"Attempting to set leverage for {symbol} to {leverage}x...")
        params = {}
        # Bybit V5 requires buy/sell leverage, ensure string format
        if exchange.id == 'bybit':
            leverage_str = str(leverage)
            params = {'buyLeverage': leverage_str, 'sellLeverage': leverage_str}
            lg.debug(f"Using Bybit V5 params for set_leverage: {params}")

        # Use safe_api_call to wrap the exchange call
        response = safe_api_call(exchange.set_leverage, lg, leverage, symbol, params)
        lg.debug(f"Set leverage raw response for {symbol}: {response}")

        # Basic success check (no exception raised by safe_api_call)
        lg.info(f"{NEON_GREEN}Leverage for {symbol} set/requested to {leverage}x (Check position details for confirmation).{RESET}")
        return True

    except ccxt.ExchangeError as e:
        # Handle specific errors more informatively
        err_str = str(e).lower()
        code = getattr(e, 'code', None)
        lg.error(f"{NEON_RED}Exchange error setting leverage for {symbol}: {e} (Code: {code}){RESET}")
        if exchange.id == 'bybit':
            if code == 110045 or "leverage not modified" in err_str:
                 lg.info(f"{NEON_YELLOW}Leverage for {symbol} likely already set to {leverage}x (Exchange: {e}).{RESET}")
                 return True # Treat as success
            elif code in [110028, 110009, 110055] or "margin mode" in err_str:
                  lg.error(f"{NEON_YELLOW} >> Hint: Check Margin Mode (Isolated/Cross) setting. May need `set_margin_mode` first or ensure compatibility.{RESET}")
            elif code == 110044 or "risk limit" in err_str:
                  lg.error(f"{NEON_YELLOW} >> Hint: Leverage {leverage}x may exceed Risk Limit tier. Check Bybit Risk Limits.{RESET}")
            elif code == 110013 or "parameter error" in err_str:
                  lg.error(f"{NEON_YELLOW} >> Hint: Leverage value {leverage}x might be invalid/out of range for {symbol}.{RESET}")
    except Exception as e:
        # Catch errors raised by safe_api_call (like AuthError, Max Retries) or unexpected ones
        lg.error(f"{NEON_RED}Failed to set leverage for {symbol} after retries or due to unexpected error: {e}{RESET}", exc_info=False)

    return False


def place_trade(
    exchange: ccxt.Exchange,
    symbol: str,
    trade_signal: str, # "BUY" or "SELL"
    position_size: Decimal,
    market_info: Dict,
    logger: Optional[logging.Logger] = None,
    order_type: str = 'market',
    limit_price: Optional[Decimal] = None,
    reduce_only: bool = False,
    params: Optional[Dict] = None # For extra exchange-specific params
) -> Optional[Dict]:
    """Places an order (market or limit) using CCXT with retries and enhanced logging."""
    lg = logger or logging.getLogger(__name__)
    side = 'buy' if trade_signal == "BUY" else 'sell'
    is_contract = market_info.get('is_contract', False)
    size_unit = "Contracts" if is_contract else market_info.get('base', '')
    action_desc = "Close/Reduce" if reduce_only else "Open/Increase"

    # --- Validate Inputs ---
    try:
        amount_float = float(position_size) # CCXT generally requires float amount
        if amount_float <= 0: raise ValueError("Position size must be positive")
    except (ValueError, TypeError) as e:
        lg.error(f"Trade Aborted ({action_desc} {side} {symbol}): Invalid size {position_size}: {e}")
        return None
    if order_type == 'limit':
         if limit_price is None or not isinstance(limit_price, Decimal) or limit_price <= 0:
             lg.error(f"Trade Aborted ({action_desc} {side} {symbol}): Limit order needs valid positive limit_price.")
             return None
         try: # CCXT needs price as float
              price_float = float(limit_price)
         except (ValueError, TypeError):
              lg.error(f"Trade Aborted ({action_desc} {side} {symbol}): Invalid limit_price format {limit_price}.")
              return None
    else: price_float = None


    # --- Prepare Parameters ---
    # Base parameters needed by many exchanges/modes
    order_params = {
        'reduceOnly': reduce_only,
        # Bybit V5: positionIdx often needed (0 for one-way, 1/2 for hedge buy/sell)
        # Assume one-way mode if not specified otherwise
        # 'positionIdx': 0, # Uncomment or make configurable if needed
    }
    if order_type == 'market' and reduce_only:
         # Use IOC or FOK for market close to avoid unexpected partial fills hanging
         order_params['timeInForce'] = 'IOC' # ImmediateOrCancel
         # order_params['timeInForce'] = 'FOK' # FillOrKill (alternative)

    # Merge external params carefully
    if params:
        base_params = order_params.copy() # Keep our base settings safe
        base_params.update(params) # Add external ones
        order_params = base_params # Use the merged dict


    # --- Log Order Details ---
    log_price = f"Limit @ {limit_price}" if order_type == 'limit' else "Market"
    amt_prec = TradingAnalyzer(pd.DataFrame(), lg, CONFIG, market_info).get_amount_precision_places()
    lg.info(f"Attempting to place {action_desc} {side.upper()} {order_type.upper()} order for {symbol}:")
    lg.info(f"  Size: {amount_float:.{amt_prec}f} {size_unit}")
    if order_type == 'limit': lg.info(f"  Limit Price: {limit_price}")
    lg.info(f"  ReduceOnly: {reduce_only}")
    lg.info(f"  Params: {order_params}")

    # --- Execute Order via safe_api_call ---
    try:
        order = safe_api_call(
            exchange.create_order, lg,
            symbol=symbol,
            type=order_type,
            side=side,
            amount=amount_float,
            price=price_float, # Will be None for market orders
            params=order_params
        )

        if order and order.get('id'):
            order_id = order.get('id')
            status = order.get('status', 'unknown')
            filled = order.get('filled', 0.0)
            avg_price = order.get('average')
            lg.info(f"{NEON_GREEN}{action_desc} Order Placed Successfully!{RESET}")
            lg.info(f"  ID: {order_id}, Initial Status: {status}, Filled: {filled}, AvgPrice: {avg_price}")
            lg.debug(f"Raw order response ({action_desc} {side} {symbol}): {order}")
            return order
        elif order is None: # safe_api_call failed after retries
             lg.error(f"{NEON_RED}Order placement failed for {symbol} after retries.{RESET}")
             return None
        else: # Call succeeded but response missing ID (unusual)
             lg.error(f"{NEON_RED}Order placement call succeeded but response lacks ID for {symbol}. Response: {order}{RESET}")
             return None

    # --- Handle Specific CCXT Exceptions Raised by safe_api_call ---
    except ccxt.InsufficientFunds as e:
        lg.error(f"{NEON_RED}Insufficient funds for {action_desc} {side} {symbol}: {e}{RESET}")
        try: balance = fetch_balance(exchange, QUOTE_CURRENCY, lg); lg.info(f"Current Balance: {balance} {QUOTE_CURRENCY}")
        except: pass
    except ccxt.InvalidOrder as e:
        lg.error(f"{NEON_RED}Invalid order parameters for {action_desc} {side} {symbol}: {e}{RESET}")
        lg.error(f"  > Used: amount={amount_float}, price={limit_price}, params={order_params}")
        err_str = str(e).lower()
        if "tick size" in err_str: lg.error("  >> Hint: Check limit_price aligns with market tick size.")
        if "step size" in err_str: lg.error("  >> Hint: Check position_size aligns with market amount step size.")
        if "minnotional" in err_str or "cost" in err_str: lg.error("  >> Hint: Order cost (size*price) might be below minimum required.")
        if "reduce-only" in err_str or (getattr(e, 'code', None) == 110014 and exchange.id == 'bybit'):
             lg.error(f"{NEON_YELLOW}  >> Hint: Reduce-only failed. Position closed? Size/side wrong?{RESET}")
    except ccxt.ExchangeError as e:
        code = getattr(e, 'code', None)
        lg.error(f"{NEON_RED}Exchange error placing {action_desc} order ({symbol}): {e} (Code: {code}){RESET}")
        if reduce_only and code == 110025 and exchange.id == 'bybit': # Position closed/not found
            lg.warning(f"{NEON_YELLOW} >> Hint (Bybit 110025): Position might have closed before reduce-only order placed.{RESET}")
    except Exception as e:
        # Catch other errors (like AuthError, RequestTimeout from safe_api_call, or unexpected)
        lg.error(f"{NEON_RED}Failed to place {action_desc} order for {symbol}: {e}{RESET}", exc_info=False)

    return None


def _set_position_protection(
    exchange: ccxt.Exchange,
    symbol: str,
    market_info: Dict,
    position_info: Dict, # Contains needed context like side, positionIdx
    logger: logging.Logger,
    stop_loss_price: Optional[Decimal] = None,
    take_profit_price: Optional[Decimal] = None,
    trailing_stop_distance: Optional[Decimal] = None, # Price distance/offset
    tsl_activation_price: Optional[Decimal] = None,
) -> bool:
    """Internal helper using Bybit V5 API to set SL, TP, or TSL."""
    lg = logger
    if 'bybit' not in exchange.id.lower():
        lg.error(f"Protection setting via private_post currently only for Bybit.")
        return False
    if not market_info.get('is_contract', False):
        lg.warning(f"Protection setting skipped for {symbol} (Not contract).")
        return False
    if not position_info:
        lg.error(f"Cannot set protection for {symbol}: Missing position info.")
        return False

    pos_side = position_info.get('side')
    entry_price = position_info.get('entryPriceDecimal')
    pos_idx = 0 # Default for One-Way
    try: # Get positionIdx from info if available (for Hedge Mode)
        pos_idx_val = position_info.get('info', {}).get('positionIdx')
        if pos_idx_val is not None: pos_idx = int(pos_idx_val)
    except (ValueError, TypeError): lg.warning("Could not parse positionIdx, using default 0.")

    if pos_side not in ['long', 'short']:
        lg.error(f"Cannot set protection: Invalid position side ('{pos_side}').")
        return False
    if entry_price is None:
        lg.error(f"Cannot set protection: Missing entry price in position info.")
        return False

    # --- Validate Protection Parameters ---
    has_sl = isinstance(stop_loss_price, Decimal) and stop_loss_price > 0
    has_tp = isinstance(take_profit_price, Decimal) and take_profit_price > 0
    has_tsl = (isinstance(trailing_stop_distance, Decimal) and trailing_stop_distance > 0 and
               isinstance(tsl_activation_price, Decimal) and tsl_activation_price > 0)

    # Validate SL/TP relative to entry price and side
    if has_sl:
         if pos_side == 'long' and stop_loss_price >= entry_price:
              lg.error(f"Invalid SL for LONG: SL price {stop_loss_price} >= Entry price {entry_price}. Ignoring SL.")
              has_sl = False
         elif pos_side == 'short' and stop_loss_price <= entry_price:
              lg.error(f"Invalid SL for SHORT: SL price {stop_loss_price} <= Entry price {entry_price}. Ignoring SL.")
              has_sl = False
    if has_tp:
         if pos_side == 'long' and take_profit_price <= entry_price:
              lg.error(f"Invalid TP for LONG: TP price {take_profit_price} <= Entry price {entry_price}. Ignoring TP.")
              has_tp = False
         elif pos_side == 'short' and take_profit_price >= entry_price:
              lg.error(f"Invalid TP for SHORT: TP price {take_profit_price} >= Entry price {entry_price}. Ignoring TP.")
              has_tp = False
    # Validate TSL Activation relative to entry
    if has_tsl:
        if pos_side == 'long' and tsl_activation_price <= entry_price:
            lg.error(f"Invalid TSL Act. for LONG: Act. price {tsl_activation_price} <= Entry price {entry_price}. Ignoring TSL.")
            has_tsl = False
        elif pos_side == 'short' and tsl_activation_price >= entry_price:
            lg.error(f"Invalid TSL Act. for SHORT: Act. price {tsl_activation_price} >= Entry price {entry_price}. Ignoring TSL.")
            has_tsl = False
    # Check if SL and TP are the same
    if has_sl and has_tp and stop_loss_price == take_profit_price:
         lg.error(f"Invalid protection: Stop Loss price ({stop_loss_price}) cannot be equal to Take Profit price ({take_profit_price}). Ignoring both.")
         has_sl = False
         has_tp = False

    if not has_sl and not has_tp and not has_tsl:
         lg.info(f"No valid protection parameters provided or remaining after validation for {symbol} (PosIdx: {pos_idx}).")
         return True # No action needed/possible

    # --- Prepare API Parameters ---
    category = 'linear' if market_info.get('is_linear', True) else 'inverse'
    params = {
        'category': category,
        'symbol': market_info['id'], # Use exchange-specific ID
        'tpslMode': 'Full', # Apply to whole position
        'tpTriggerBy': 'LastPrice',
        'slTriggerBy': 'LastPrice',
        'positionIdx': pos_idx
    }
    log_parts = [f"Attempting to set protection for {symbol} ({pos_side.upper()} PosIdx: {pos_idx}):"]

    # --- Format and Add Protection Params ---
    try:
        analyzer = TradingAnalyzer(pd.DataFrame(), lg, CONFIG, market_info) # Temp instance for helpers
        price_prec = analyzer.get_price_precision()
        min_tick = analyzer.get_min_tick_size()

        # Helper to format price string using ccxt price_to_precision
        def format_price_str(price_decimal: Optional[Decimal]) -> Optional[str]:
            if not isinstance(price_decimal, Decimal) or price_decimal <= 0: return None
            try: return exchange.price_to_precision(symbol, float(price_decimal))
            except Exception as e: lg.warning(f"Failed price formatting ({price_decimal}): {e}"); return None

        # Helper to format distance value string using decimal_to_precision based on tick size
        def format_distance_str(dist_decimal: Optional[Decimal]) -> Optional[str]:
             if not isinstance(dist_decimal, Decimal) or dist_decimal <= 0: return None
             try:
                 dist_prec = abs(min_tick.normalize().as_tuple().exponent) if min_tick > 0 else price_prec
                 formatted = exchange.decimal_to_precision(dist_decimal, exchange.ROUND, dist_prec, exchange.NO_PADDING)
                 # Ensure formatted distance is at least min tick
                 if min_tick > 0 and Decimal(formatted) < min_tick:
                      formatted = str(min_tick)
                 return formatted
             except Exception as e: lg.warning(f"Failed distance formatting ({dist_decimal}): {e}"); return None

        # Set TSL first (overrides SL on Bybit V5 if set)
        if has_tsl:
            tsl_dist_fmt = format_distance_str(trailing_stop_distance)
            tsl_act_fmt = format_price_str(tsl_activation_price)
            if tsl_dist_fmt and tsl_act_fmt:
                params['trailingStop'] = tsl_dist_fmt
                params['activePrice'] = tsl_act_fmt
                log_parts.append(f"  Trailing SL: Dist={tsl_dist_fmt}, Act={tsl_act_fmt}")
                has_sl = False # Mark fixed SL as inactive if TSL is set
                lg.debug("TSL parameters added. Fixed SL will be ignored by Bybit V5.")
            else: lg.error("Failed to format TSL parameters. TSL will not be set.")

        # Set Fixed SL only if TSL was NOT set
        if has_sl:
            sl_fmt = format_price_str(stop_loss_price)
            if sl_fmt: params['stopLoss'] = sl_fmt; log_parts.append(f"  Fixed SL: {sl_fmt}")
            else: lg.error("Failed to format Fixed SL price. Fixed SL will not be set.")

        # Set Fixed TP
        if has_tp:
            tp_fmt = format_price_str(take_profit_price)
            if tp_fmt: params['takeProfit'] = tp_fmt; log_parts.append(f"  Fixed TP: {tp_fmt}")
            else: lg.error("Failed to format Fixed TP price. Fixed TP will not be set.")

    except Exception as fmt_err:
         lg.error(f"Error during formatting of protection parameters: {fmt_err}", exc_info=True)
         return False

    # --- Check if any protection parameters were successfully added ---
    if not params.get('stopLoss') and not params.get('takeProfit') and not params.get('trailingStop'):
        lg.warning(f"No valid protection parameters could be formatted for {symbol} (PosIdx: {pos_idx}). No API call made.")
        return False # Failed to format intended protection

    # --- Make the API Call via safe_api_call ---
    lg.info("\n".join(log_parts))
    lg.debug(f"  API Call: private_post('/v5/position/set-trading-stop', {params})")
    try:
        response = safe_api_call(exchange.private_post, lg, '/v5/position/set-trading-stop', params)
        lg.debug(f"Set protection raw response: {response}")

        # --- Parse Bybit V5 Response ---
        ret_code = response.get('retCode')
        ret_msg = response.get('retMsg', 'Unknown Error')
        ret_ext = response.get('retExtInfo', {})

        if ret_code == 0:
            if "not modified" in ret_msg.lower():
                 lg.info(f"{NEON_YELLOW}Position protection already set or only partially modified for {symbol} (PosIdx: {pos_idx}). Response: {ret_msg}{RESET}")
            else:
                 lg.info(f"{NEON_GREEN}Position protection set/updated successfully for {symbol} (PosIdx: {pos_idx}).{RESET}")
            return True
        else:
            lg.error(f"{NEON_RED}Failed to set protection for {symbol} (PosIdx: {pos_idx}): {ret_msg} (Code: {ret_code}) Ext: {ret_ext}{RESET}")
            # Add specific hints based on error codes
            if ret_code == 110013: lg.error(f"{NEON_YELLOW} >> Hint (110013 - Param Error): Check prices vs entry/current, tick size, TSL values.{RESET}")
            elif ret_code == 110036: lg.error(f"{NEON_YELLOW} >> Hint (110036 - TSL Price Invalid): Activation price '{params.get('activePrice')}' likely invalid.{RESET}")
            elif ret_code == 110086: lg.error(f"{NEON_YELLOW} >> Hint (110086): SL price equals TP price.{RESET}")
            elif ret_code == 110043: lg.error(f"{NEON_YELLOW} >> Hint (110043): Position status prevents modification (liquidation?).{RESET}")
            elif ret_code == 110025: lg.error(f"{NEON_YELLOW} >> Hint (110025): Position not found/closed, or positionIdx mismatch?{RESET}")
            elif "trailing stop value invalid" in ret_msg.lower(): lg.error(f"{NEON_YELLOW} >> Hint: TSL distance '{params.get('trailingStop')}' likely invalid (size/tick).{RESET}")
            return False

    except Exception as e:
        # Catches errors from safe_api_call (Max retries, AuthError, etc.)
        lg.error(f"{NEON_RED}Failed protection API call for {symbol}: {e}{RESET}", exc_info=False)
        return False


def set_trailing_stop_loss(
    exchange: ccxt.Exchange,
    symbol: str,
    market_info: Dict,
    position_info: Dict,
    config: Dict[str, Any],
    logger: logging.Logger,
    take_profit_price: Optional[Decimal] = None # Optional TP to set alongside
) -> bool:
    """Calculates and sets Exchange-Native Trailing Stop Loss using _set_position_protection."""
    lg = logger
    if not config.get("enable_trailing_stop", False):
        lg.debug(f"TSL disabled in config for {symbol}. Skipping setup.")
        return False # Indicate TSL not set

    try:
        callback_rate = Decimal(str(config["trailing_stop_callback_rate"]))
        activation_percentage = Decimal(str(config["trailing_stop_activation_percentage"]))
        entry_price = position_info.get('entryPriceDecimal')
        side = position_info.get('side')

        if callback_rate <= 0: raise ValueError("callback_rate must be positive")
        if activation_percentage < 0: raise ValueError("activation_percentage cannot be negative")
        if entry_price is None or entry_price <= 0: raise ValueError("Missing/invalid entry price")
        if side not in ['long', 'short']: raise ValueError("Missing/invalid position side")

    except (ValueError, TypeError, KeyError, InvalidOperation) as e:
        lg.error(f"{NEON_RED}Invalid TSL config or position info ({symbol}): {e}. Cannot calculate TSL.{RESET}")
        return False

    try:
        analyzer = TradingAnalyzer(pd.DataFrame(), lg, config, market_info) # Temp instance
        price_prec = analyzer.get_price_precision()
        price_rounding = Decimal('1e-' + str(price_prec))
        min_tick_size = analyzer.get_min_tick_size()

        # 1. Calculate Activation Price
        activation_offset = entry_price * activation_percentage
        activation_price: Optional[Decimal] = None
        if side == 'long':
            raw_activation = entry_price + activation_offset
            activation_price = raw_activation.quantize(price_rounding, rounding=ROUND_UP)
            # Ensure activation > entry (by at least one tick)
            if activation_price <= entry_price:
                 activation_price = (entry_price + min_tick_size).quantize(price_rounding, rounding=ROUND_UP)
                 lg.debug(f"Adjusted LONG TSL activation to tick above entry: {activation_price}")
        else: # short
            raw_activation = entry_price - activation_offset
            activation_price = raw_activation.quantize(price_rounding, rounding=ROUND_DOWN)
            # Ensure activation < entry (by at least one tick)
            if activation_price >= entry_price:
                 activation_price = (entry_price - min_tick_size).quantize(price_rounding, rounding=ROUND_DOWN)
                 lg.debug(f"Adjusted SHORT TSL activation to tick below entry: {activation_price}")

        if activation_price is None or activation_price <= 0:
             lg.error(f"{NEON_RED}Invalid TSL activation price calculated ({activation_price}). Cannot set TSL.{RESET}")
             return False

        # 2. Calculate Trailing Distance (based on callback * ACTIVATION price)
        # Bybit V5 requires the distance value. Round to tick size.
        trailing_distance_raw = activation_price * callback_rate
        trailing_distance: Optional[Decimal] = None
        if min_tick_size > 0:
             # Round distance UP to nearest tick increment (conservative trail)
             trailing_distance = (trailing_distance_raw / min_tick_size).quantize(Decimal('1'), rounding=ROUND_UP) * min_tick_size
             # Ensure distance is at least one tick
             if trailing_distance < min_tick_size: trailing_distance = min_tick_size
        else: # Fallback if tick size is zero (shouldn't happen)
             trailing_distance = trailing_distance_raw.quantize(price_rounding, rounding=ROUND_UP) # Round like price

        if trailing_distance is None or trailing_distance <= 0:
             lg.error(f"{NEON_RED}Invalid TSL distance calculated ({trailing_distance}). Cannot set TSL.{RESET}")
             return False

        lg.info(f"Calculated TSL Parameters for {symbol} ({side.upper()}):")
        lg.info(f"  Entry={entry_price:.{price_prec}f}, Act%={activation_percentage:.3%}, Callback%={callback_rate:.3%}")
        lg.info(f"  => Activation Price (Target): {activation_price:.{price_prec}f}")
        lg.info(f"  => Trailing Distance (Target): {trailing_distance:.{price_prec}f}")
        if isinstance(take_profit_price, Decimal) and take_profit_price > 0:
             lg.info(f"  Take Profit (Target): {take_profit_price:.{price_prec}f}")

        # 3. Call internal helper to set protection
        return _set_position_protection(
            exchange=exchange, symbol=symbol, market_info=market_info,
            position_info=position_info, logger=lg,
            stop_loss_price=None, # TSL overrides fixed SL on Bybit V5
            take_profit_price=take_profit_price if isinstance(take_profit_price, Decimal) and take_profit_price > 0 else None,
            trailing_stop_distance=trailing_distance,
            tsl_activation_price=activation_price
        )

    except Exception as e:
        lg.error(f"{NEON_RED}Unexpected error calculating/setting TSL for {symbol}: {e}{RESET}", exc_info=True)
        return False


# --- Main Analysis and Trading Loop ---
def analyze_and_trade_symbol(exchange: ccxt.Exchange, symbol: str, config: Dict[str, Any], logger: logging.Logger) -> None:
    """Performs one cycle of analysis and trading logic for a single symbol."""
    lg = logger
    lg.info(f"---== Analyzing {symbol} ({config['interval']}) Cycle Start ==---")
    cycle_start_time = time.monotonic()

    try:
        # --- Get Market Info ---
        market_info = get_market_info(exchange, symbol, lg)
        if not market_info: raise ValueError(f"Failed to get market info for {symbol}.")

        # --- Fetch Data ---
        ccxt_interval = CCXT_INTERVAL_MAP.get(config["interval"])
        if not ccxt_interval: raise ValueError(f"Invalid interval '{config['interval']}'.")

        kline_limit = 500 # Ample data for indicators
        klines_df = fetch_klines_ccxt(exchange, symbol, ccxt_interval, limit=kline_limit, logger=lg)
        if klines_df.empty or len(klines_df) < 50:
            raise ValueError(f"Insufficient kline data ({len(klines_df)}) for {symbol}.")

        current_price = fetch_current_price_ccxt(exchange, symbol, lg)
        if current_price is None:
            lg.warning(f"Failed ticker price fetch. Using last close from klines.")
            try:
                # Check if 'close' column is Decimal or float before converting
                last_close_val = klines_df['close'].iloc[-1]
                if pd.notna(last_close_val):
                    current_price = Decimal(str(last_close_val))
                    if current_price <= 0: raise ValueError("Last close price is non-positive.")
                    lg.info(f"Using last close price: {current_price}")
                else: raise ValueError("Last close price is NaN.")
            except (IndexError, KeyError, ValueError, TypeError, InvalidOperation) as e:
                raise ValueError(f"Failed to get valid last close price from klines: {e}")

        # Fetch order book if needed
        orderbook_data = None
        active_weights = config.get("weight_sets", {}).get(config.get("active_weight_set", "default"), {})
        if config.get("indicators",{}).get("orderbook", False) and float(active_weights.get("orderbook", 0)) != 0:
            lg.debug(f"Fetching order book for {symbol}...")
            orderbook_data = fetch_orderbook_ccxt(exchange, symbol, config["orderbook_limit"], lg)
            if not orderbook_data: lg.warning(f"Failed to fetch orderbook for {symbol}, proceeding without.")
        else: lg.debug(f"Orderbook analysis skipped (Disabled/Zero Weight).")

        # --- Analyze Data ---
        analyzer = TradingAnalyzer(klines_df.copy(), lg, config, market_info)
        if not analyzer.indicator_values:
            raise ValueError(f"Indicator calculation failed for {symbol}.")

        # --- Generate Signal ---
        signal = analyzer.generate_trading_signal(current_price, orderbook_data)

        # --- Calculate Potential TP/SL (based on current price estimate) ---
        _, tp_calc, sl_calc = analyzer.calculate_entry_tp_sl(current_price, signal)
        price_prec = analyzer.get_price_precision()
        min_tick_size = analyzer.get_min_tick_size()
        current_atr = analyzer.indicator_values.get("ATR") # Decimal

        # --- Log Analysis Summary ---
        lg.info(f"Current Price: {current_price:.{price_prec}f}")
        lg.info(f"ATR: {current_atr:.{price_prec+2}f}" if isinstance(current_atr, Decimal) else 'ATR: N/A')
        lg.info(f"Calc. Initial SL (sizing): {sl_calc if sl_calc else 'N/A'}")
        lg.info(f"Calc. Initial TP (target): {tp_calc if tp_calc else 'N/A'}")
        tsl_enabled = config.get('enable_trailing_stop')
        be_enabled = config.get('enable_break_even')
        time_exit_minutes = config.get('time_based_exit_minutes')
        time_exit_str = f"{time_exit_minutes} min" if time_exit_minutes else "Disabled"
        lg.info(f"Position Mgmt: TSL={'On' if tsl_enabled else 'Off'}, BE={'On' if be_enabled else 'Off'}, TimeExit={time_exit_str}")

        # --- Trading Execution Check ---
        if not config.get("enable_trading", False):
            lg.debug(f"Trading disabled. Analysis complete for {symbol}.")
            return # Exit function here

        # ==============================================
        # === Position Management Logic            ===
        # ==============================================
        open_position = get_open_position(exchange, symbol, lg)

        # --- Scenario 1: No Open Position ---
        if open_position is None:
            # Check concurrent positions (this simplistic check assumes this script is the only one trading this symbol)
            # A more robust check might involve querying all orders or using external state management.
            # For now, rely on get_open_position returning None as indication we can enter.
            # If max_concurrent_positions > 1, this logic needs modification.
            if config.get("max_concurrent_positions", 1) > 1:
                 lg.warning("max_concurrent_positions > 1 logic not fully implemented in this basic check.")

            if signal in ["BUY", "SELL"]:
                lg.info(f"*** {signal} Signal & No Position: Initiating Trade Sequence for {symbol} ***")

                balance = fetch_balance(exchange, QUOTE_CURRENCY, lg)
                if balance is None or balance <= 0:
                    raise ValueError("Cannot fetch balance or balance is zero/negative.")
                if sl_calc is None:
                    raise ValueError("Initial SL calculation failed. Cannot calculate position size.")

                if market_info.get('is_contract', False):
                    leverage = int(config.get("leverage", 1))
                    if leverage > 0:
                        if not set_leverage_ccxt(exchange, symbol, leverage, market_info, lg):
                            raise ValueError(f"Failed to set leverage to {leverage}x.")
                    else: lg.info(f"Leverage setting skipped (Config: {leverage}).")

                position_size = calculate_position_size(balance, config["risk_per_trade"], sl_calc, current_price, market_info, exchange, lg)
                if position_size is None or position_size <= 0:
                    raise ValueError(f"Position size calculation failed ({position_size}).")

                entry_order_type = config.get("entry_order_type", "market")
                limit_entry_price: Optional[Decimal] = None
                if entry_order_type == "limit":
                    offset_buy = Decimal(str(config.get("limit_order_offset_buy", "0.0005")))
                    offset_sell = Decimal(str(config.get("limit_order_offset_sell", "0.0005")))
                    rounding_factor = Decimal('1e-' + str(price_prec))
                    if signal == "BUY":
                        raw_limit = current_price * (Decimal(1) - offset_buy)
                        limit_entry_price = raw_limit.quantize(rounding_factor, rounding=ROUND_DOWN)
                    else: # SELL
                        raw_limit = current_price * (Decimal(1) + offset_sell)
                        limit_entry_price = raw_limit.quantize(rounding_factor, rounding=ROUND_UP)
                    if limit_entry_price <= 0:
                         lg.error(f"Limit price calc resulted in {limit_entry_price}. Switching to Market order.")
                         entry_order_type = "market"; limit_entry_price = None
                    else: lg.info(f"Calculated Limit Entry Price for {signal}: {limit_entry_price}")

                lg.info(f"==> Placing {signal} {entry_order_type.upper()} order | Size: {position_size} <==")
                trade_order = place_trade(exchange, symbol, signal, position_size, market_info, lg, entry_order_type, limit_entry_price, reduce_only=False)

                if trade_order and trade_order.get('id'):
                    order_id = trade_order['id']
                    order_status = trade_order.get('status')

                    # Post-order actions depend on type and status
                    # Market orders: Wait and confirm position, then set protection
                    # Limit orders (open): Wait for next cycle
                    # Limit orders (closed immediately): Treat like market order
                    if order_status == 'closed' or entry_order_type == 'market':
                         if entry_order_type == 'market':
                              confirm_delay = config.get("position_confirm_delay_seconds", POSITION_CONFIRM_DELAY_SECONDS)
                              lg.info(f"Market order {order_id} placed. Waiting {confirm_delay}s for confirmation...")
                              time.sleep(confirm_delay)
                         else: # Limit filled immediately
                              lg.info(f"Limit order {order_id} filled immediately. Confirming position...")
                              time.sleep(2) # Short delay

                         lg.info(f"Attempting position confirmation for {symbol}...")
                         confirmed_position = get_open_position(exchange, symbol, lg)

                         if confirmed_position:
                             lg.info(f"{NEON_GREEN}Position Confirmed after order {order_id}!{RESET}")
                             # --- Set Protection Based on Actual Entry ---
                             try:
                                 entry_price_actual = confirmed_position.get('entryPriceDecimal')
                                 if not isinstance(entry_price_actual, Decimal) or entry_price_actual <= 0:
                                     lg.warning(f"Could not get valid actual entry price. Using estimate {current_price} for protection.")
                                     entry_price_actual = current_price # Fallback

                                 lg.info(f"Actual Entry Price: ~{entry_price_actual:.{price_prec}f}")
                                 _, tp_final, sl_final = analyzer.calculate_entry_tp_sl(entry_price_actual, signal)

                                 protection_set = False
                                 if config.get("enable_trailing_stop", False):
                                      lg.info(f"Setting Exchange Trailing Stop Loss (TP target: {tp_final})...")
                                      protection_set = set_trailing_stop_loss(exchange, symbol, market_info, confirmed_position, config, lg, tp_final)
                                 else:
                                      lg.info(f"Setting Fixed SL ({sl_final}) and TP ({tp_final})...")
                                      if sl_final or tp_final:
                                          protection_set = _set_position_protection(exchange, symbol, market_info, confirmed_position, lg, sl_final, tp_final)
                                      else: lg.warning("Fixed SL/TP calculation failed. No fixed protection set.")

                                 if protection_set: lg.info(f"{NEON_GREEN}=== TRADE ENTRY & PROTECTION SETUP COMPLETE ({symbol} {signal}) ===")
                                 else: lg.error(f"{NEON_RED}=== TRADE placed BUT FAILED TO SET PROTECTION ({symbol} {signal}) ===\n{NEON_YELLOW}>>> MANUAL MONITORING REQUIRED! <<<")
                             except Exception as post_trade_err:
                                  lg.error(f"{NEON_RED}Error during post-trade protection setting ({symbol}): {post_trade_err}{RESET}", exc_info=True)
                                  lg.warning(f"{NEON_YELLOW}Position open but protection setup failed. Manual check needed!")
                         else:
                             lg.error(f"{NEON_RED}Order {order_id} placed/filled, but FAILED TO CONFIRM open position! Manual check needed!{RESET}")

                    elif order_status == 'open' and entry_order_type == 'limit':
                        lg.info(f"Limit order {order_id} placed and is OPEN. Will check status next cycle.")
                        # Store order_id if monitoring specific orders is needed

                    else: # Order failed, cancelled, rejected etc.
                        lg.error(f"Order {order_id} placement resulted in status: {order_status}. Trade did not open as expected.")
                else:
                    lg.error(f"{NEON_RED}=== TRADE EXECUTION FAILED ({symbol} {signal}). See previous logs. ===")
            else: # signal == HOLD
                lg.info(f"Signal is HOLD and no position exists for {symbol}. No action.")

        # --- Scenario 2: Existing Open Position ---
        else:
            pos_side = open_position.get('side', 'unknown')
            pos_size = open_position.get('contractsDecimal', Decimal('0'))
            entry_price = open_position.get('entryPriceDecimal')
            pos_timestamp_ms = open_position.get('timestamp_ms')

            lg.info(f"Managing existing {pos_side.upper()} position. Size: {pos_size}, Entry: {entry_price}")

            # --- Check for Exit Signal ---
            exit_signal_triggered = (pos_side == 'long' and signal == "SELL") or \
                                    (pos_side == 'short' and signal == "BUY")
            if exit_signal_triggered:
                lg.warning(f"{NEON_YELLOW}*** EXIT Signal ({signal}) opposes existing {pos_side} position. Closing position... ***{RESET}")
                try:
                    close_side_signal = "SELL" if pos_side == 'long' else "BUY"
                    size_to_close = abs(pos_size)
                    if size_to_close <= 0: raise ValueError(f"Position size zero/negative ({size_to_close}).")

                    lg.info(f"==> Placing {close_side_signal} MARKET order (reduceOnly=True) | Size: {size_to_close} <==")
                    close_order = place_trade(exchange, symbol, close_side_signal, size_to_close, market_info, lg, 'market', reduce_only=True)
                    if close_order: lg.info(f"{NEON_GREEN}Position CLOSE order placed successfully. ID: {close_order.get('id', 'N/A')}{RESET}")
                    else: lg.error(f"{NEON_RED}Failed to place CLOSE order. Manual check required!{RESET}")
                    return # Exit management after close attempt
                except Exception as close_err:
                    lg.error(f"{NEON_RED}Error attempting to close position {symbol}: {close_err}{RESET}", exc_info=True)
                    lg.warning(f"{NEON_YELLOW}Manual intervention likely needed!{RESET}")
                return # Exit management after close attempt

            # --- Check for Time-Based Exit ---
            time_exit_minutes_config = config.get("time_based_exit_minutes")
            if isinstance(time_exit_minutes_config, (int, float)) and time_exit_minutes_config > 0:
                 if pos_timestamp_ms:
                      try:
                           current_time_ms = time.time() * 1000
                           time_elapsed_ms = current_time_ms - pos_timestamp_ms
                           time_elapsed_minutes = time_elapsed_ms / (1000 * 60)
                           lg.debug(f"Time Exit Check: Elapsed={time_elapsed_minutes:.2f}m, Limit={time_exit_minutes_config}m")
                           if time_elapsed_minutes >= time_exit_minutes_config:
                                lg.warning(f"{NEON_YELLOW}*** TIME-BASED EXIT Triggered ({time_elapsed_minutes:.1f} >= {time_exit_minutes_config} min). Closing position... ***{RESET}")
                                # Execute Close Logic (same as above)
                                close_side_signal = "SELL" if pos_side == 'long' else "BUY"
                                size_to_close = abs(pos_size)
                                if size_to_close > 0:
                                     close_order = place_trade(exchange, symbol, close_side_signal, size_to_close, market_info, lg, 'market', reduce_only=True)
                                     if close_order: lg.info(f"{NEON_GREEN}Time-based CLOSE order placed successfully. ID: {close_order.get('id', 'N/A')}{RESET}")
                                     else: lg.error(f"{NEON_RED}Failed time-based CLOSE order. Manual check!{RESET}")
                                else: lg.warning("Time exit triggered but size is zero.")
                                return # Exit management after close attempt
                      except Exception as time_err: lg.error(f"Error in time exit check: {time_err}")
                 else: lg.warning("Time exit enabled, but position timestamp missing.")

            # --- If Holding, Manage Position (BE / TSL Update?) ---
            if not exit_signal_triggered:
                 lg.info(f"Signal ({signal}) allows holding {pos_side} position. Performing management checks...")

                 is_tsl_active_exchange = open_position.get('trailingStopLossValueDecimal') is not None

                 # --- Check Break-Even ---
                 if config.get("enable_break_even", False) and not is_tsl_active_exchange:
                     lg.debug(f"Checking Break-Even conditions for {symbol}...")
                     try:
                         if entry_price is None or entry_price <= 0: raise ValueError("Invalid entry price for BE")
                         if not isinstance(current_atr, Decimal) or current_atr <= 0: raise ValueError("Invalid ATR for BE")

                         be_trigger_atr_mult = Decimal(str(config.get("break_even_trigger_atr_multiple", "1.0")))
                         be_offset_ticks = int(config.get("break_even_offset_ticks", 2))
                         profit_target_atr = be_trigger_atr_mult

                         price_diff = (current_price - entry_price) if pos_side == 'long' else (entry_price - current_price)
                         profit_in_atr = price_diff / current_atr if current_atr > 0 else Decimal('0')

                         lg.debug(f"BE Check: PriceDiff={price_diff:.{price_prec}f}, ProfitATRs={profit_in_atr:.2f}, TargetATRs={profit_target_atr}")

                         if profit_in_atr >= profit_target_atr:
                              tick_offset = min_tick_size * be_offset_ticks
                              be_stop_price: Optional[Decimal] = None
                              if pos_side == 'long':
                                   be_stop_price = (entry_price + tick_offset).quantize(min_tick_size, rounding=ROUND_UP)
                              else: # short
                                   be_stop_price = (entry_price - tick_offset).quantize(min_tick_size, rounding=ROUND_DOWN)

                              if be_stop_price is None or be_stop_price <= 0: raise ValueError("Invalid BE stop price calc.")

                              current_sl_price = open_position.get('stopLossPriceDecimal')
                              update_be_sl = False
                              if current_sl_price is None: update_be_sl = True; lg.info("BE triggered: No current SL found.")
                              elif pos_side == 'long' and be_stop_price > current_sl_price: update_be_sl = True; lg.info(f"BE triggered: Target {be_stop_price} > Current {current_sl_price}.")
                              elif pos_side == 'short' and be_stop_price < current_sl_price: update_be_sl = True; lg.info(f"BE triggered: Target {be_stop_price} < Current {current_sl_price}.")
                              else: lg.debug(f"BE Triggered, but current SL ({current_sl_price}) already >= target BE SL ({be_stop_price}).")

                              if update_be_sl:
                                   lg.warning(f"{NEON_PURPLE}*** Moving Stop Loss to Break-Even for {symbol} at {be_stop_price} ***{RESET}")
                                   current_tp_price = open_position.get('takeProfitPriceDecimal')
                                   success = _set_position_protection(exchange, symbol, market_info, open_position, lg, be_stop_price, current_tp_price)
                                   if success: lg.info(f"{NEON_GREEN}Break-Even SL set/updated successfully.{RESET}")
                                   else: lg.error(f"{NEON_RED}Failed to set/update Break-Even SL.{RESET}")
                         else: lg.debug(f"BE Profit target not reached.")
                     except ValueError as ve: lg.warning(f"BE Check skipped: {ve}")
                     except Exception as be_err: lg.error(f"Error during BE check: {be_err}", exc_info=True)
                 elif is_tsl_active_exchange: lg.debug("BE check skipped: Exchange TSL is active.")
                 else: lg.debug("BE check skipped: Disabled in config.")

                 # --- Placeholder for other management ---
                 # E.g., Re-evaluate TSL settings if config changed? Partial TP?

    except ValueError as data_err:
        lg.error(f"{NEON_RED}Data Error for {symbol}: {data_err}. Skipping cycle.{RESET}")
    except ccxt.AuthenticationError as auth_err:
         lg.critical(f"{NEON_RED}CRITICAL: Authentication Failed during cycle: {auth_err}. Stopping bot.{RESET}")
         # Consider raising a specific exception to stop the main loop gracefully
         raise SystemExit("Authentication Failed")
    except Exception as cycle_err:
        lg.error(f"{NEON_RED}Unexpected error during analysis/trading cycle for {symbol}: {cycle_err}{RESET}", exc_info=True)
        # Decide if this error should stop the bot or just skip the cycle

    finally:```python
# scalpxrx.py
# Enhanced and Upgraded Scalping Bot Framework
# Derived from xrscalper.py, focusing on robust execution, error handling,
# advanced position management (BE, TSL), and Bybit V5 compatibility.

import hashlib
import hmac
import json
import logging
import math
import os
import time
from datetime import datetime, timedelta, timezone
from decimal import ROUND_DOWN, ROUND_UP, Decimal, InvalidOperation, getcontext
from logging.handlers import RotatingFileHandler
from typing import Any, Dict, List, Optional, Tuple, Union

import ccxt
import numpy as np
import pandas as pd
import pandas_ta as ta  # Import pandas_ta
import requests
from colorama import Fore, Style, init
from dotenv import load_dotenv
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from zoneinfo import ZoneInfo

# Initialize colorama and set Decimal precision
getcontext().prec = 36  # Increased precision for complex calculations
init(autoreset=True)
load_dotenv()

# Neon Color Scheme
NEON_GREEN = Fore.LIGHTGREEN_EX
NEON_BLUE = Fore.CYAN
NEON_PURPLE = Fore.MAGENTA
NEON_YELLOW = Fore.YELLOW
NEON_RED = Fore.LIGHTRED_EX
NEON_CYAN = Fore.CYAN
RESET = Style.RESET_ALL

# --- Constants ---
API_KEY = os.getenv("BYBIT_API_KEY")
API_SECRET = os.getenv("BYBIT_API_SECRET")
if not API_KEY or not API_SECRET:
    raise ValueError("BYBIT_API_KEY and BYBIT_API_SECRET must be set in .env")

CONFIG_FILE = "config.json"
LOG_DIRECTORY = "bot_logs"
# Timezone for logging and display
TIMEZONE = ZoneInfo("America/Chicago")  # Adjust as needed
MAX_API_RETRIES = 5  # Max retries for recoverable API errors
RETRY_DELAY_SECONDS = 7  # Increased delay between retries
VALID_INTERVALS = ["1", "3", "5", "15", "30", "60", "120", "240", "D", "W", "M"]
CCXT_INTERVAL_MAP = { # Map our intervals to ccxt's expected format
    "1": "1m", "3": "3m", "5": "5m", "15": "15m", "30": "30m",
    "60": "1h", "120": "2h", "240": "4h", "D": "1d", "W": "1w", "M": "1M"
}
RETRY_ERROR_CODES = [429, 500, 502, 503, 504] # HTTP status codes considered retryable
# Default indicator periods (can be overridden by config.json)
DEFAULT_ATR_PERIOD = 14
DEFAULT_CCI_WINDOW = 20
DEFAULT_WILLIAMS_R_WINDOW = 14
DEFAULT_MFI_WINDOW = 14
DEFAULT_STOCH_RSI_WINDOW = 14
DEFAULT_STOCH_WINDOW = 12
DEFAULT_K_WINDOW = 3
DEFAULT_D_WINDOW = 3
DEFAULT_RSI_WINDOW = 14
DEFAULT_BOLLINGER_BANDS_PERIOD = 20
DEFAULT_BOLLINGER_BANDS_STD_DEV = 2.0
DEFAULT_SMA_10_WINDOW = 10
DEFAULT_EMA_SHORT_PERIOD = 9
DEFAULT_EMA_LONG_PERIOD = 21
DEFAULT_MOMENTUM_PERIOD = 7
DEFAULT_VOLUME_MA_PERIOD = 15
DEFAULT_FIB_WINDOW = 50
DEFAULT_PSAR_AF = 0.02
DEFAULT_PSAR_MAX_AF = 0.2

FIB_LEVELS = [0.0, 0.236, 0.382, 0.5, 0.618, 0.786, 1.0] # Standard Fibonacci levels
LOOP_DELAY_SECONDS = 10 # Time between the end of one cycle and the start of the next
POSITION_CONFIRM_DELAY_SECONDS = 10 # Increased wait time after placing order before confirming position
# QUOTE_CURRENCY dynamically loaded from config

os.makedirs(LOG_DIRECTORY, exist_ok=True)

class SensitiveFormatter(logging.Formatter):
    """Formatter to redact sensitive information (API keys) from logs."""
    def format(self, record: logging.LogRecord) -> str:
        msg = super().format(record)
        if API_KEY:
            msg = msg.replace(API_KEY, "***API_KEY***")
        if API_SECRET:
            msg = msg.replace(API_SECRET, "***API_SECRET***")
        return msg

def load_config(filepath: str) -> Dict[str, Any]:
    """
    Load configuration from JSON file, creating default if not found,
    and ensuring all default keys are present with validation.
    """
    # Define the default configuration structure and values
    default_config = {
        # Trading pair and timeframe
        "symbol": "BTC/USDT:USDT", # Bybit linear perpetual example
        "interval": "5", # Default timeframe (e.g., "5" for 5 minutes)

        # API and Bot Behavior
        "retry_delay": RETRY_DELAY_SECONDS, # Delay between API retries
        "enable_trading": False, # Safety Feature: Must be explicitly set to true to trade
        "use_sandbox": True, # Safety Feature: Use testnet by default
        "max_concurrent_positions": 1, # Max open positions for this symbol instance
        "quote_currency": "USDT", # Quote currency for balance checks and sizing
        "position_confirm_delay_seconds": POSITION_CONFIRM_DELAY_SECONDS, # Delay after order before confirming position
        "loop_delay_seconds": LOOP_DELAY_SECONDS, # Delay between main loop cycles

        # Risk Management
        "risk_per_trade": 0.01, # Fraction of balance to risk (e.g., 0.01 = 1%)
        "leverage": 20, # Desired leverage (Ensure supported by exchange/market)
        "stop_loss_multiple": 1.8, # ATR multiple for initial SL (used for sizing/initial fixed SL)
        "take_profit_multiple": 0.7, # ATR multiple for initial TP

        # Order Execution
        "entry_order_type": "market", # "market" or "limit"
        "limit_order_offset_buy": 0.0005, # % offset from price for BUY limit (0.0005 = 0.05%)
        "limit_order_offset_sell": 0.0005, # % offset from price for SELL limit

        # Advanced Position Management
        "enable_trailing_stop": True, # Use exchange-native Trailing Stop Loss
        "trailing_stop_callback_rate": 0.005, # Trail distance % (e.g., 0.005 = 0.5%)
        "trailing_stop_activation_percentage": 0.003, # % profit move from entry to activate TSL
        "enable_break_even": True, # Enable moving SL to break-even point
        "break_even_trigger_atr_multiple": 1.0, # Move SL when profit >= X * ATR
        "break_even_offset_ticks": 2, # Place BE SL X ticks beyond entry price
        "time_based_exit_minutes": None, # Optional: Exit after X minutes (e.g., 60)

        # Indicator Periods & Parameters
        "atr_period": DEFAULT_ATR_PERIOD,
        "ema_short_period": DEFAULT_EMA_SHORT_PERIOD,
        "ema_long_period": DEFAULT_EMA_LONG_PERIOD,
        "rsi_period": DEFAULT_RSI_WINDOW,
        "bollinger_bands_period": DEFAULT_BOLLINGER_BANDS_PERIOD,
        "bollinger_bands_std_dev": DEFAULT_BOLLINGER_BANDS_STD_DEV,
        "cci_window": DEFAULT_CCI_WINDOW,
        "williams_r_window": DEFAULT_WILLIAMS_R_WINDOW,
        "mfi_window": DEFAULT_MFI_WINDOW,
        "stoch_rsi_window": DEFAULT_STOCH_RSI_WINDOW, # StochRSI main window
        "stoch_rsi_rsi_window": DEFAULT_STOCH_WINDOW, # Underlying RSI window for StochRSI
        "stoch_rsi_k": DEFAULT_K_WINDOW, # StochRSI K period
        "stoch_rsi_d": DEFAULT_D_WINDOW, # StochRSI D period
        "psar_af": DEFAULT_PSAR_AF, # PSAR Acceleration Factor
        "psar_max_af": DEFAULT_PSAR_MAX_AF, # PSAR Max Acceleration Factor
        "sma_10_window": DEFAULT_SMA_10_WINDOW,
        "momentum_period": DEFAULT_MOMENTUM_PERIOD,
        "volume_ma_period": DEFAULT_VOLUME_MA_PERIOD,
        "fibonacci_window": DEFAULT_FIB_WINDOW,

        # Indicator Calculation & Scoring Control
        "orderbook_limit": 25, # Depth of order book levels to fetch/analyze
        "signal_score_threshold": 1.5, # Score needed to trigger BUY/SELL signal
        "stoch_rsi_oversold_threshold": 25, # Threshold for StochRSI oversold score
        "stoch_rsi_overbought_threshold": 75, # Threshold for StochRSI overbought score
        "volume_confirmation_multiplier": 1.5, # Volume > Multiplier * VolMA for confirmation
        "scalping_signal_threshold": 2.5, # Alternative threshold for specific weight sets (if needed)
        "indicators": { # Toggle calculation and scoring contribution
            "ema_alignment": True, "momentum": True, "volume_confirmation": True,
            "stoch_rsi": True, "rsi": True, "bollinger_bands": True, "vwap": True,
            "cci": True, "wr": True, "psar": True, "sma_10": True, "mfi": True,
            "orderbook": True,
        },
        "weight_sets": { # Define scoring weights for different strategies
            "scalping": { # Example: Faster, momentum-focused
                "ema_alignment": 0.2, "momentum": 0.3, "volume_confirmation": 0.2,
                "stoch_rsi": 0.6, "rsi": 0.2, "bollinger_bands": 0.3, "vwap": 0.4,
                "cci": 0.3, "wr": 0.3, "psar": 0.2, "sma_10": 0.1, "mfi": 0.2, "orderbook": 0.15,
            },
            "default": { # Example: Balanced
                "ema_alignment": 0.3, "momentum": 0.2, "volume_confirmation": 0.1,
                "stoch_rsi": 0.4, "rsi": 0.3, "bollinger_bands": 0.2, "vwap": 0.3,
                "cci": 0.2, "wr": 0.2, "psar": 0.3, "sma_10": 0.1, "mfi": 0.2, "orderbook": 0.1,
            }
        },
        "active_weight_set": "default" # Select .the active weight set
    }

    config = default_config.copy()
    if os.path.exists(filepath):
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                loaded_config = json.load(f)
            # Merge loaded config with defaults, ensuring all keys exist
            config = _merge_configs(loaded_config, default_config)
            print(f"{NEON_GREEN}Loaded configuration from {filepath}{RESET}")
        except (json.JSONDecodeError, IOError) as e:
            print(f"{NEON_RED}Error loading config file {filepath}: {e}. Using default config.{RESET}")
            # Attempt to recreate default file if loading failed
            try:
                with open(filepath, "w", encoding="utf-8") as f_write:
                    json.dump(default_config, f_write, indent=4)
                print(f"{NEON_YELLOW}Recreated default config file: {filepath}{RESET}")
            except IOError as e_create:
                print(f"{NEON_RED}Error recreating default config file: {e_create}{RESET}")
            config = default_config # Use in-memory default
    else:
        # Config file doesn't exist, create it with defaults
        print(f"{NEON_YELLOW}Config file not found. Creating default config at {filepath}{RESET}")
        try:
            with open(filepath, "w", encoding="utf-8") as f:
                json.dump(default_config, f, indent=4)
            config = default_config
        except IOError as e:
            print(f"{NEON_RED}Error creating default config file {filepath}: {e}{RESET}")
            # Continue with in-memory default config if creation fails

    # --- Validation Section ---
    updated = False # Flag to track if config needs saving back

    # Validate symbol
    if not config.get("symbol") or not isinstance(config.get("symbol"), str):
         print(f"{NEON_RED}CRITICAL: 'symbol' is missing, empty, or invalid in config. Resetting to default: '{default_config['symbol']}'{RESET}")
         config["symbol"] = default_config["symbol"]
         updated = True

    # Validate interval
    if config.get("interval") not in VALID_INTERVALS:
        print(f"{NEON_RED}Invalid interval '{config.get('interval')}' in config. Resetting to default '{default_config['interval']}'. Valid: {VALID_INTERVALS}{RESET}")
        config["interval"] = default_config["interval"]
        updated = True

    # Validate entry order type
    if config.get("entry_order_type") not in ["market", "limit"]:
        print(f"{NEON_RED}Invalid entry_order_type '{config.get('entry_order_type')}' in config. Resetting to 'market'.{RESET}")
        config["entry_order_type"] = "market"
        updated = True

    # Validate active weight set exists
    if config.get("active_weight_set") not in config.get("weight_sets", {}):
         print(f"{NEON_RED}Active weight set '{config.get('active_weight_set')}' not found in 'weight_sets'. Resetting to 'default'.{RESET}")
         config["active_weight_set"] = "default" # Ensure 'default' exists in defaults
         updated = True

    # Validate numeric parameters (ranges and types)
    numeric_params = {
        # key: (min_val, max_val, allow_min_equal, allow_max_equal, is_integer)
        "risk_per_trade": (0, 1, False, False, False),
        "leverage": (1, 1000, True, True, True), # Adjust max leverage realistically
        "stop_loss_multiple": (0, float('inf'), False, True, False),
        "take_profit_multiple": (0, float('inf'), False, True, False),
        "trailing_stop_callback_rate": (0, 1, False, False, False),
        "trailing_stop_activation_percentage": (0, 1, True, False, False), # Allow 0%
        "break_even_trigger_atr_multiple": (0, float('inf'), False, True, False),
        "break_even_offset_ticks": (0, 100, True, True, True),
        "signal_score_threshold": (0, float('inf'), False, True, False),
        "atr_period": (1, 1000, True, True, True),
        "ema_short_period": (1, 1000, True, True, True),
        "ema_long_period": (1, 1000, True, True, True),
        "rsi_period": (1, 1000, True, True, True),
        "bollinger_bands_period": (1, 1000, True, True, True),
        "bollinger_bands_std_dev": (0, 10, False, True, False),
        "cci_window": (1, 1000, True, True, True),
        "williams_r_window": (1, 1000, True, True, True),
        "mfi_window": (1, 1000, True, True, True),
        "stoch_rsi_window": (1, 1000, True, True, True),
        "stoch_rsi_rsi_window": (1, 1000, True, True, True),
        "stoch_rsi_k": (1, 1000, True, True, True),
        "stoch_rsi_d": (1, 1000, True, True, True),
        "psar_af": (0, 1, False, False, False),
        "psar_max_af": (0, 1, False, False, False),
        "sma_10_window": (1, 1000, True, True, True),
        "momentum_period": (1, 1000, True, True, True),
        "volume_ma_period": (1, 1000, True, True, True),
        "fibonacci_window": (2, 1000, True, True, True), # Need at least 2 points
        "orderbook_limit": (1, 100, True, True, True),
        "position_confirm_delay_seconds": (0, 60, True, True, False),
        "loop_delay_seconds": (1, 300, True, True, False),
        "stoch_rsi_oversold_threshold": (0, 100, True, False, False),
        "stoch_rsi_overbought_threshold": (0, 100, False, True, False),
        "volume_confirmation_multiplier": (0, float('inf'), False, True, False),
        "limit_order_offset_buy": (0, 0.1, True, False, False), # 10% offset max?
        "limit_order_offset_sell": (0, 0.1, True, False, False),
    }
    for key, (min_val, max_val, allow_min, allow_max, is_integer) in numeric_params.items():
        try:
            value_str = str(config[key]) # Convert potential int/float to str first
            value = Decimal(value_str) if not is_integer else int(Decimal(value_str))

            # Check bounds
            lower_bound_ok = value >= min_val if allow_min else value > min_val
            upper_bound_ok = value <= max_val if allow_max else value < max_val

            if not (lower_bound_ok and upper_bound_ok):
                raise ValueError(f"Value {value} out of range "
                                 f"({min_val} {'<=' if allow_min else '<'} x {'<=' if allow_max else '<'} {max_val})")

            # Store the validated value (could be int or float/Decimal)
            config[key] = int(value) if is_integer else float(value) # Store float for simplicity unless int needed

        except (ValueError, TypeError, KeyError, InvalidOperation) as e:
            print(f"{NEON_RED}Invalid value for '{key}' ({config.get(key)}): {e}. Resetting to default '{default_config[key]}'.{RESET}")
            config[key] = default_config[key]
            updated = True

    # Specific validation for time_based_exit_minutes (allow None or positive number)
    time_exit = config.get("time_based_exit_minutes")
    if time_exit is not None:
        try:
            time_exit_val = float(time_exit)
            if time_exit_val <= 0: raise ValueError("Must be positive if set")
            config["time_based_exit_minutes"] = time_exit_val # Store as float
        except (ValueError, TypeError) as e:
             print(f"{NEON_RED}Invalid value for 'time_based_exit_minutes' ({time_exit}): {e}. Resetting to default (None).{RESET}")
             config["time_based_exit_minutes"] = None
             updated = True

    # If config was updated due to invalid values, save it back
    if updated:
        try:
            with open(filepath, "w", encoding="utf-8") as f_write:
                # Use ensure_ascii=False for better readability if non-ASCII chars exist
                json.dump(config, f_write, indent=4, ensure_ascii=False)
            print(f"{NEON_YELLOW}Updated config file {filepath} with corrected/default values.{RESET}")
        except IOError as e:
            print(f"{NEON_RED}Error writing updated config file {filepath}: {e}{RESET}")

    return config

def _merge_configs(loaded_config: Dict, default_config: Dict) -> Dict:
    """
    Recursively merges the loaded configuration with default values.
    Ensures all keys from the default config exist in the final config.
    Prioritizes values from the loaded config.
    """
    merged = default_config.copy()
    for key, value in loaded_config.items():
        # If key exists in both and both values are dicts, recurse
        if isinstance(value, dict) and isinstance(merged.get(key), dict):
            merged[key] = _merge_configs(value, merged[key])
        else:
            # Otherwise, overwrite default with loaded value
            merged[key] = value
    return merged

def setup_logger(name: str, level: int = logging.INFO) -> logging.Logger:
    """Sets up a logger with rotating file and colored console handlers."""
    logger = logging.getLogger(name)
    # Prevent adding multiple handlers if logger is reused
    if logger.hasHandlers():
        for handler in logger.handlers[:]:
            try: handler.close()
            except: pass # Ignore errors closing handlers
            logger.removeHandler(handler)

    logger.setLevel(logging.DEBUG) # Capture all levels at the logger level

    # File Handler (Rotating)
    log_filename = os.path.join(LOG_DIRECTORY, f"{name}.log")
    try:
        file_handler = RotatingFileHandler(
            log_filename, maxBytes=10 * 1024 * 1024, backupCount=5, encoding='utf-8'
        )
        file_formatter = SensitiveFormatter(
            "%(asctime)s.%(msecs)03d %(levelname)-8s [%(name)s:%(lineno)d] %(message)s",
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        file_handler.setFormatter(file_formatter)
        file_handler.setLevel(logging.DEBUG) # Log DEBUG and above to file
        logger.addHandler(file_handler)
    except Exception as e:
        print(f"Error setting up file logger {log_filename}: {e}")

    # Console Handler (Colored)
    stream_handler = logging.StreamHandler()
    stream_formatter = SensitiveFormatter(
        f"{NEON_BLUE}%(asctime)s{RESET} - {NEON_YELLOW}%(levelname)-8s{RESET} - {NEON_PURPLE}[%(name)s]{RESET} - %(message)s",
        datefmt='%Y-%m-%d %H:%M:%S %Z' # Include Timezone abbreviation
    )
    # Use UTC internally for consistency, display local time in logs via formatter
    stream_formatter.converter = time.gmtime # Log record times in UTC
    # Set the formatter's timezone for display purposes (using datefmt %Z)
    # Ensure the TIMEZONE object is used correctly by the formatter
    logging.Formatter.converter = lambda *args: datetime.now(TIMEZONE).timetuple()

    stream_handler.setFormatter(stream_formatter)
    stream_handler.setLevel(level) # Set console level (e.g., INFO)
    logger.addHandler(stream_handler)

    logger.propagate = False # Prevent duplicate logs in root logger
    return logger

# --- CCXT Exchange Setup ---
def initialize_exchange(config: Dict[str, Any], logger: logging.Logger) -> Optional[ccxt.Exchange]:
    """Initializes the CCXT Bybit exchange object with enhanced error handling."""
    lg = logger
    try:
        exchange_options = {
            'apiKey': API_KEY,
            'secret': API_SECRET,
            'enableRateLimit': True, # Use CCXT's built-in rate limiter
            'rateLimit': 150, # Adjust based on Bybit V5 limits (e.g., 100ms for 10/s might be safer)
            'options': {
                'defaultType': 'linear', # Essential for Bybit V5 USDT perpetuals
                'adjustForTimeDifference': True, # Helps with timestamp sync issues
                # Increased timeouts
                'fetchTickerTimeout': 15000, 'fetchBalanceTimeout': 20000,
                'createOrderTimeout': 25000, 'cancelOrderTimeout': 20000,
                'fetchPositionsTimeout': 20000, 'fetchOHLCVTimeout': 20000,
                # Add user agent for potential identification
                'user-agent': 'ScalpXRX Bot v1.0',
                # Consider Bybit V5 specific options if needed
                # 'recvWindow': 10000 # Example: Increase if timestamp errors persist
            }
        }

        # Default to Bybit, could be made configurable
        exchange_id = "bybit"
        exchange_class = getattr(ccxt, exchange_id)
        exchange = exchange_class(exchange_options)

        # --- Sandbox Mode Setup ---
        if config.get('use_sandbox'):
            lg.warning(f"{NEON_YELLOW}USING SANDBOX MODE (Testnet){RESET}")
            try:
                exchange.set_sandbox_mode(True)
                lg.info(f"Sandbox mode explicitly enabled for {exchange.id}.")
            except AttributeError:
                lg.warning(f"{exchange.id} does not support set_sandbox_mode via ccxt. Ensuring API keys are for Testnet.")
                # Manually set Bybit testnet URL if needed
                if exchange.id == 'bybit':
                    exchange.urls['api'] = 'https://api-testnet.bybit.com'
                    lg.info("Manually set Bybit API URL to Testnet.")
            except Exception as e:
                lg.error(f"Error enabling sandbox mode: {e}")
        else:
            lg.info(f"{NEON_GREEN}Using LIVE (Real Money) Environment.{RESET}")


        lg.info(f"Initializing {exchange.id}...")
        # --- Initial Connection & Permissions Test (Fetch Balance) ---
        account_type_to_test = 'CONTRACT' # Prioritize CONTRACT for V5 derivatives
        lg.info(f"Attempting initial balance fetch (Account Type: {account_type_to_test})...")
        try:
            params = {'type': account_type_to_test} if exchange.id == 'bybit' else {}
            # Use safe_api_call for robustness
            balance = safe_api_call(exchange.fetch_balance, lg, params=params)

            if balance:
                quote_curr = config.get("quote_currency", "USDT")
                # Handle potential differences in balance structure more robustly
                available_quote_val = None
                if quote_curr in balance:
                    available_quote_val = balance[quote_curr].get('free')
                if available_quote_val is None and 'free' in balance and quote_curr in balance['free']:
                    available_quote_val = balance['free'][quote_curr]
                # Add check for Bybit V5 structure if needed (though fetch_balance often standardizes)

                available_quote_str = str(available_quote_val) if available_quote_val is not None else 'N/A'
                lg.info(f"{NEON_GREEN}Successfully connected and fetched initial balance.{RESET} (Example: {quote_curr} available: {available_quote_str})")
            else:
                 lg.warning(f"{NEON_YELLOW}Initial balance fetch (Type: {account_type_to_test}) returned no data. Check connection/permissions.{RESET}")

        except ccxt.AuthenticationError as auth_err:
             lg.error(f"{NEON_RED}Authentication Error during initial balance fetch: {auth_err}{RESET}")
             lg.error(f"{NEON_RED}>> Ensure API keys (in .env) are correct, have permissions (Read, Trade), match environment (Real/Testnet), and IP whitelist is correct.{RESET}")
             return None # Fatal error
        except ccxt.ExchangeError as balance_err:
             # Fallback if specific account type failed
             lg.warning(f"{NEON_YELLOW}Exchange error fetching balance (Type: {account_type_to_test}): {balance_err}. Trying default fetch...{RESET}")
             try:
                  balance = safe_api_call(exchange.fetch_balance, lg)
                  if balance:
                       quote_curr = config.get("quote_currency", "USDT")
                       available_quote_val = None
                       if quote_curr in balance:
                           available_quote_val = balance[quote_curr].get('free')
                       if available_quote_val is None and 'free' in balance and quote_curr in balance['free']:
                           available_quote_val = balance['free'][quote_curr]
                       available_quote_str = str(available_quote_val) if available_quote_val is not None else 'N/A'
                       lg.info(f"{NEON_GREEN}Successfully fetched balance using default parameters.{RESET} (Example: {quote_curr} available: {available_quote_str})")
                  else:
                       lg.warning(f"{NEON_YELLOW}Default balance fetch also returned no data.{RESET}")
             except Exception as fallback_err:
                  lg.warning(f"{NEON_YELLOW}Default balance fetch also failed: {fallback_err}. Check API permissions/account type/network.{RESET}")
        except Exception as balance_err: # Catches errors from safe_api_call
             lg.warning(f"{NEON_YELLOW}Could not perform initial balance fetch after retries or due to error: {balance_err}. Proceeding cautiously.{RESET}")


        # --- Load Markets (Crucial for market info, precision, etc.) ---
        lg.info(f"Loading markets for {exchange.id}...")
        try:
             safe_api_call(exchange.load_markets, lg, reload=True) # Force reload
             lg.info(f"Markets loaded successfully for {exchange.id}.")
        except Exception as market_err:
             lg.error(f"{NEON_RED}Failed to load markets after retries: {market_err}. Cannot operate without market data. Exiting.{RESET}")
             return None # Fatal error if markets cannot be loaded

        lg.info(f"CCXT exchange initialized ({exchange.id}). Sandbox: {config.get('use_sandbox')}")
        return exchange

    except ccxt.AuthenticationError as e: # Catch auth errors during class instantiation
        lg.error(f"{NEON_RED}CCXT Authentication Error during initialization: {e}{RESET}")
        lg.error(f"{NEON_RED}>> Check API Key/Secret format and validity in your .env file.{RESET}")
    except ccxt.ExchangeError as e:
        lg.error(f"{NEON_RED}CCXT Exchange Error initializing: {e}{RESET}")
    except ccxt.NetworkError as e:
        lg.error(f"{NEON_RED}CCXT Network Error initializing: {e}{RESET}")
    except Exception as e:
        lg.error(f"{NEON_RED}Failed to initialize CCXT exchange: {e}{RESET}", exc_info=True)

    return None

# --- API Call Wrapper with Retries ---
def safe_api_call(func, logger: logging.Logger, *args, **kwargs):
    """Wraps an API call with retry logic for network/rate limit/specific exchange errors."""
    lg = logger
    attempts = 0
    last_exception = None
    while attempts <= MAX_API_RETRIES:
        try:
            result = func(*args, **kwargs)
            # lg.debug(f"API call {func.__name__} successful.") # Optional success log
            return result # Success
        except (ccxt.NetworkError, ccxt.RequestTimeout, requests.exceptions.ConnectionError, requests.exceptions.Timeout, ccxt.ExchangeNotAvailable, ccxt.DDoSProtection) as e:
            last_exception = e
            wait_time = RETRY_DELAY_SECONDS * (1.5 ** attempts) # Exponential backoff
            lg.warning(f"{NEON_YELLOW}Retryable network/availability error in {func.__name__}: {type(e).__name__}. Waiting {wait_time:.1f}s (Attempt {attempts+1}/{MAX_API_RETRIES}). Error: {e}{RESET}")
            time.sleep(wait_time)
        except ccxt.RateLimitExceeded as e:
            last_exception = e
            wait_time_header = getattr(e, 'retry_after', None)
            wait_time = RETRY_DELAY_SECONDS * (2 ** attempts) # Stronger backoff
            if wait_time_header:
                try: wait_time = max(wait_time, float(wait_time_header) + 0.5) # Add buffer
                except: pass # Ignore invalid header
            lg.warning(f"{NEON_YELLOW}Rate limit exceeded in {func.__name__}. Waiting {wait_time:.1f}s (Attempt {attempts+1}/{MAX_API_RETRIES}). Error: {e}{RESET}")
            time.sleep(wait_time)
        except ccxt.AuthenticationError as e:
             lg.error(f"{NEON_RED}Authentication Error in {func.__name__}: {e}. Aborting call.{RESET}")
             raise e # Don't retry, re-raise immediately
        except ccxt.ExchangeError as e:
            last_exception = e
            bybit_retry_codes = [
                10001, # Internal server error
                10006, # Request frequent
                # Add other transient error codes based on Bybit docs/experience
            ]
            exchange_code = getattr(e, 'code', None)
            err_str = str(e).lower()
            is_retryable_exchange_err = exchange_code in bybit_retry_codes or \
                                        "internal server error" in err_str or \
                                        "request validation failed" in err_str # Check message too

            if is_retryable_exchange_err:
                 wait_time = RETRY_DELAY_SECONDS * (1.5 ** attempts)
                 lg.warning(f"{NEON_YELLOW}Potentially retryable exchange error in {func.__name__}: {e} (Code: {exchange_code}). Waiting {wait_time:.1f}s (Attempt {attempts+1}/{MAX_API_RETRIES})...{RESET}")
                 time.sleep(wait_time)
            else:
                 lg.error(f"{NEON_RED}Non-retryable Exchange Error in {func.__name__}: {e} (Code: {exchange_code}){RESET}")
                 raise e # Re-raise non-retryable ones
        except Exception as e:
            last_exception = e
            lg.error(f"{NEON_RED}Unexpected error in {func.__name__}: {e}{RESET}", exc_info=True)
            raise e # Re-raise unexpected errors immediately

        attempts += 1

    # If loop completes, max retries exceeded
    lg.error(f"{NEON_RED}Max retries ({MAX_API_RETRIES}) exceeded for {func.__name__}.{RESET}")
    if last_exception:
        raise last_exception # Raise the last known exception
    else:
        # Fallback if no exception was captured (shouldn't normally happen)
        raise ccxt.RequestTimeout(f"Max retries exceeded for {func.__name__} (no specific exception captured)")


# --- CCXT Data Fetching (Using safe_api_call) ---
def fetch_current_price_ccxt(exchange: ccxt.Exchange, symbol: str, logger: logging.Logger) -> Optional[Decimal]:
    """Fetch the current price of a trading symbol using CCXT ticker with fallbacks and retries."""
    lg = logger
    try:
        ticker = safe_api_call(exchange.fetch_ticker, lg, symbol)
        if not ticker:
            return None # Error logged by safe_api_call

        lg.debug(f"Ticker data for {symbol}: {ticker}")
        price = None
        # Prioritize 'last', then 'average', then mid-price, then ask/bid
        last_price = ticker.get('last')
        bid_price = ticker.get('bid')
        ask_price = ticker.get('ask')
        avg_price = ticker.get('average')

        # Robust Decimal conversion helper
        def to_decimal(value) -> Optional[Decimal]:
            if value is None: return None
            try:
                d = Decimal(str(value))
                return d if d.is_finite() and d > 0 else None
            except (InvalidOperation, ValueError, TypeError):
                lg.warning(f"Invalid price format encountered: {value}")
                return None

        p_last = to_decimal(last_price)
        p_bid = to_decimal(bid_price)
        p_ask = to_decimal(ask_price)
        p_avg = to_decimal(avg_price)

        # Determine price with priority
        if p_last:
            price = p_last; lg.debug(f"Using 'last' price: {price}")
        elif p_avg:
            price = p_avg; lg.debug(f"Using 'average' price: {price}")
        elif p_bid and p_ask:
            price = (p_bid + p_ask) / 2; lg.debug(f"Using bid/ask midpoint: {price}")
        elif p_ask:
            price = p_ask; lg.warning(f"Using 'ask' price fallback (bid invalid/missing): {price}")
        elif p_bid:
            price = p_bid; lg.warning(f"Using 'bid' price fallback (ask invalid/missing): {price}")

        # Final validation
        if price is not None and price.is_finite() and price > 0:
            return price
        else:
            lg.error(f"{NEON_RED}Failed to extract a valid price from ticker data for {symbol}. Ticker: {ticker}{RESET}")
            return None

    except Exception as e:
        lg.error(f"{NEON_RED}Error fetching current price for {symbol}: {e}{RESET}", exc_info=False)
        return None

def fetch_klines_ccxt(exchange: ccxt.Exchange, symbol: str, timeframe: str, limit: int = 250, logger: logging.Logger = None) -> pd.DataFrame:
    """Fetch OHLCV kline data using CCXT with retries and robust validation."""
    lg = logger or logging.getLogger(__name__)
    if not exchange.has['fetchOHLCV']:
        lg.error(f"Exchange {exchange.id} does not support fetchOHLCV.")
        return pd.DataFrame()

    try:
        ohlcv = safe_api_call(exchange.fetch_ohlcv, lg, symbol, timeframe=timeframe, limit=limit)

        if ohlcv is None or not isinstance(ohlcv, list) or len(ohlcv) == 0:
            if ohlcv is not None:
                lg.warning(f"{NEON_YELLOW}No valid kline data returned for {symbol} {timeframe}.{RESET}")
            return pd.DataFrame()

        df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])

        if df.empty:
            lg.warning(f"Kline data DataFrame is empty for {symbol} {timeframe}.")
            return df

        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms', errors='coerce', utc=True)
        df.dropna(subset=['timestamp'], inplace=True)
        df.set_index('timestamp', inplace=True)

        # Convert price/volume columns to numeric Decimal
        for col in ['open', 'high', 'low', 'close', 'volume']:
             try:
                  df[col] = df[col].apply(lambda x: Decimal(str(x)) if pd.notna(x) and str(x).strip() != '' else Decimal('NaN'))
             except (TypeError, ValueError, InvalidOperation) as conv_err:
                  lg.warning(f"Could not convert column '{col}' to Decimal, attempting numeric fallback: {conv_err}")
                  df[col] = pd.to_numeric(df[col], errors='coerce')

        # Data Cleaning
        initial_len = len(df)
        close_col = df['close']
        df.dropna(subset=['open', 'high', 'low', 'close'], inplace=True)

        if not df.empty:
            if isinstance(close_col.iloc[0], Decimal):
                df = df[close_col.apply(lambda x: x.is_finite() and x > 0)]
            elif pd.api.types.is_numeric_dtype(close_col.dtype):
                df = df[np.isfinite(close_col) & (close_col > 0)]

        rows_dropped = initial_len - len(df)
        if rows_dropped > 0:
            lg.debug(f"Dropped {rows_dropped} rows with NaN/invalid price data for {symbol}.")

        if df.empty:
            lg.warning(f"Kline data for {symbol} {timeframe} empty after cleaning.")
            return pd.DataFrame()

        df.sort_index(inplace=True)
        df = df[~df.index.duplicated(keep='last')]

        lg.info(f"Successfully fetched and processed {len(df)} klines for {symbol} {timeframe}")
        return df

    except Exception as e:
        lg.error(f"{NEON_RED}Error fetching/processing klines for {symbol}: {e}{RESET}", exc_info=True)
        return pd.DataFrame()


def fetch_orderbook_ccxt(exchange: ccxt.Exchange, symbol: str, limit: int, logger: logging.Logger) -> Optional[Dict]:
    """Fetch orderbook data using ccxt with retries and validation."""
    lg = logger
    if not exchange.has['fetchOrderBook']:
        lg.error(f"Exchange {exchange.id} does not support fetchOrderBook.")
        return None

    try:
        orderbook = safe_api_call(exchange.fetch_order_book, lg, symbol, limit=limit)

        if not orderbook:
            return None
        if not isinstance(orderbook, dict) or 'bids' not in orderbook or 'asks' not in orderbook or \
           not isinstance(orderbook['bids'], list) or not isinstance(orderbook['asks'], list):
            lg.warning(f"Invalid orderbook structure received for {symbol}. Data: {orderbook}")
            return None

        if not orderbook['bids'] and not orderbook['asks']:
            lg.warning(f"Orderbook received but both bids and asks lists are empty for {symbol}.")
            return orderbook # Return empty but valid book

        # Basic validation of entry format
        valid = True
        for side in ['bids', 'asks']:
             if orderbook[side]:
                  entry = orderbook[side][0]
                  if not (isinstance(entry, list) and len(entry) == 2):
                       lg.warning(f"Invalid {side[:-1]} entry format: {entry}"); valid = False; break
                  try: # Check numeric format
                       _ = float(entry[0]); _ = float(entry[1])
                  except (ValueError, TypeError):
                       lg.warning(f"Non-numeric data in {side[:-1]} entry: {entry}"); valid = False; break
        if not valid:
             lg.error("Orderbook data format validation failed."); return None

        lg.debug(f"Successfully fetched orderbook for {symbol} ({len(orderbook['bids'])} bids, {len(orderbook['asks'])} asks).")
        return orderbook

    except Exception as e:
        lg.error(f"{NEON_RED}Error fetching order book for {symbol}: {e}{RESET}", exc_info=False)
        return None

# --- Trading Analyzer Class (Enhancements Incorporated) ---
# Assuming TradingAnalyzer class definition is identical to the input sx.py
# with the enhancements already discussed (robust TA conversion, precision handling, etc.)
# (Class definition omitted here for brevity, assuming it's the enhanced version from sx.py)
# ... [TradingAnalyzer class definition from sx.py goes here] ...

# --- Trading Logic Helper Functions (Enhancements Incorporated) ---
# Assuming these functions are identical to the input sx.py
# with the enhancements already discussed (robust parsing, validation, error handling)
# (Function definitions omitted here for brevity, assuming they are the enhanced versions from sx.py)
# ... [fetch_balance function definition from sx.py goes here] ...
# ... [get_market_info function definition from sx.py goes here] ...
# ... [calculate_position_size function definition from sx.py goes here] ...
# ... [get_open_position function definition from sx.py goes here] ...
# ... [set_leverage_ccxt function definition from sx.py goes here] ...
# ... [place_trade function definition from sx.py goes here] ...
# ... [_set_position_protection function definition from sx.py goes here] ...
# ... [set_trailing_stop_loss function definition from sx.py goes here] ...

# --- Main Analysis and Trading Loop (Enhancements Incorporated) ---
def analyze_and_trade_symbol(exchange: ccxt.Exchange, symbol: str, config: Dict[str, Any], logger: logging.Logger) -> None:
    """Performs one cycle of analysis and trading logic for a single symbol."""
    lg = logger
    lg.info(f"---== Analyzing {symbol} ({config['interval']}) Cycle Start ==---")
    cycle_start_time = time.monotonic()

    try:
        # --- Get Market Info (Critical) ---
        market_info = get_market_info(exchange, symbol, lg)
        if not market_info: raise ValueError(f"Fatal: Failed to get market info for {symbol}.")

        # --- Fetch Data ---
        ccxt_interval = CCXT_INTERVAL_MAP.get(config["interval"])
        if not ccxt_interval: raise ValueError(f"Invalid interval '{config['interval']}'.")
        klines_df = fetch_klines_ccxt(exchange, symbol, ccxt_interval, limit=500, logger=lg)
        if klines_df.empty or len(klines_df) < 50: raise ValueError(f"Insufficient kline data ({len(klines_df)}).")

        current_price = fetch_current_price_ccxt(exchange, symbol, lg)
        if current_price is None: # Fallback to last close
             lg.warning("Using last close from klines as current price.")
             try:
                 last_close = klines_df['close'].iloc[-1] # Assumes klines_df uses Decimal
                 if not isinstance(last_close, Decimal) or not last_close.is_finite():
                     raise ValueError("Last close is not a valid Decimal.")
                 current_price = last_close
                 if current_price <= 0: raise ValueError("Last close price non-positive.")
             except (IndexError, KeyError, ValueError, TypeError, InvalidOperation) as e:
                 raise ValueError(f"Failed to get valid last close price: {e}")

        # Fetch order book if needed for scoring
        orderbook_data = None
        active_weights = config.get("weight_sets", {}).get(config.get("active_weight_set", "default"), {})
        if config.get("indicators",{}).get("orderbook", False) and float(active_weights.get("orderbook", 0)) != 0:
            orderbook_data = fetch_orderbook_ccxt(exchange, symbol, config["orderbook_limit"], lg)
            if not orderbook_data: lg.warning(f"Failed orderbook fetch for {symbol}. Proceeding without.")

        # --- Analyze Data & Generate Signal ---
        analyzer = TradingAnalyzer(klines_df.copy(), lg, config, market_info)
        if not analyzer.indicator_values: raise ValueError("Indicator calculation failed.")
        signal = analyzer.generate_trading_signal(current_price, orderbook_data)

        # --- Calculate Potential TP/SL & Log Summary ---
        _, tp_calc, sl_calc = analyzer.calculate_entry_tp_sl(current_price, signal)
        price_prec = analyzer.get_price_precision(); current_atr = analyzer.indicator_values.get("ATR")
        lg.info(f"Current Price: {current_price:.{price_prec}f}")
        lg.info(f"ATR: {current_atr:.{price_prec+2}f}" if isinstance(current_atr, Decimal) else 'ATR: N/A')
        lg.info(f"Calc Initial SL (sizing): {sl_calc or 'N/A'}, TP (target): {tp_calc or 'N/A'}")
        lg.info(f"Mgmt: TSL={'On' if config['enable_trailing_stop'] else 'Off'}, BE={'On' if config['enable_break_even'] else 'Off'}, TimeExit={config.get('time_based_exit_minutes') or 'Off'}")

        # --- Trading Execution Logic ---
        if not config.get("enable_trading"):
            lg.debug("Trading disabled. Cycle complete."); return

        open_position = get_open_position(exchange, symbol, lg)

        # --- Scenario 1: No Open Position ---
        if open_position is None:
            if signal in ["BUY", "SELL"]:
                lg.info(f"*** {signal} Signal & No Position: Initiating Trade Sequence ***")
                balance = fetch_balance(exchange, config["quote_currency"], lg)
                if balance is None or balance <= 0: raise ValueError("Balance fetch failed or zero/negative.")
                if sl_calc is None: raise ValueError("Initial SL calculation failed (required for sizing).")

                if market_info.get('is_contract') and int(config.get("leverage", 0)) > 0:
                    if not set_leverage_ccxt(exchange, symbol, int(config["leverage"]), market_info, lg):
                        raise ValueError("Failed to set leverage.")

                pos_size = calculate_position_size(balance, config["risk_per_trade"], sl_calc, current_price, market_info, exchange, lg)
                if pos_size is None or pos_size <= 0: raise ValueError(f"Position size calculation failed ({pos_size}).")

                # --- Place Order (Market or Limit) ---
                entry_type = config.get("entry_order_type", "market"); limit_px = None
                if entry_type == "limit":
                     try:
                         offset = Decimal(str(config[f"limit_order_offset_{signal.lower()}"]))
                         rnd_f = Decimal(f'1e-{price_prec}')
                         raw_px = current_price * (1 - offset if signal=='BUY' else 1 + offset)
                         limit_px = raw_px.quantize(rnd_f, rounding=ROUND_DOWN if signal=='BUY' else ROUND_UP)
                         if limit_px <= 0: raise ValueError("Limit price non-positive")
                         lg.info(f"Calc Limit Entry for {signal}: {limit_px}")
                     except (KeyError, ValueError, InvalidOperation) as e:
                          lg.error(f"Limit price calc failed ({e}). Switching to Market."); entry_type="market"; limit_px=None

                trade_order = place_trade(exchange, symbol, signal, pos_size, market_info, lg, entry_type, limit_px)

                # --- Post-Order Handling ---
                if trade_order and trade_order.get('id'):
                    order_id, status = trade_order['id'], trade_order.get('status')
                    # If filled immediately (market or fast limit)
                    if status == 'closed' or entry_type == 'market':
                        delay = config.get("position_confirm_delay_seconds", POSITION_CONFIRM_DELAY_SECONDS)
                        lg.info(f"Order {order_id} placed/filled. Waiting {delay}s for confirmation...")
                        time.sleep(delay)
                        confirmed_pos = get_open_position(exchange, symbol, lg)
                        if confirmed_pos:
                            lg.info(f"{NEON_GREEN}Position Confirmed!{RESET}")
                            # --- Set Protection ---
                            try:
                                entry_act = confirmed_pos.get('entryPriceDecimal') or current_price # Use actual or estimate
                                lg.info(f"Actual Entry ~ {entry_act:.{price_prec}f}")
                                _, tp_final, sl_final = analyzer.calculate_entry_tp_sl(entry_act, signal) # Recalculate based on actual entry
                                protection_ok = False
                                if config["enable_trailing_stop"]:
                                     lg.info(f"Setting TSL (TP target: {tp_final})...")
                                     protection_ok = set_trailing_stop_loss(exchange, symbol, market_info, confirmed_pos, config, lg, tp_final)
                                elif sl_final or tp_final: # Use fixed if TSL disabled AND calc valid
                                     lg.info(f"Setting Fixed SL ({sl_final}) / TP ({tp_final})...")
                                     protection_ok = _set_position_protection(exchange, symbol, market_info, confirmed_pos, lg, sl_final, tp_final)
                                else: lg.warning("No valid protection calculated (TSL disabled or calc failed).")

                                if protection_ok: lg.info(f"{NEON_GREEN}=== TRADE ENTRY & PROTECTION COMPLETE ({symbol} {signal}) ===")
                                else: lg.error(f"{NEON_RED}=== TRADE PLACED BUT PROTECTION FAILED ({symbol} {signal}) ===\n{NEON_YELLOW}>>> MANUAL MONITORING REQUIRED! <<<")
                            except Exception as post_err:
                                 lg.error(f"Error setting protection: {post_err}", exc_info=True); lg.warning(f"{NEON_YELLOW}Position open, manual check needed!{RESET}")
                        else: lg.error(f"{NEON_RED}Order {order_id} placed/filled BUT POSITION NOT CONFIRMED! Manual check!{RESET}")
                    # If limit order is open
                    elif status == 'open' and entry_type == 'limit':
                         lg.info(f"Limit order {order_id} OPEN. Will check status next cycle.")
                         # TODO: Optionally add logic to track open orders and cancel if stale
                    else: # Order failed or other status
                         lg.error(f"Order {order_id} status: {status}. Trade did not open as expected.")
                else: # place_trade failed
                     lg.error(f"{NEON_RED}=== TRADE EXECUTION FAILED. Order placement error. ===")
            else: lg.info("Signal HOLD, no position. No action.")

        # --- Scenario 2: Existing Open Position ---
        else:
            pos_side = open_position['side']; pos_size = open_position['contractsDecimal']
            entry_price = open_position['entryPriceDecimal']; pos_ts_ms = open_position['timestamp_ms']
            lg.info(f"Managing existing {pos_side.upper()} position. Size: {pos_size}, Entry: {entry_price}")

            # --- Check for Exit Signal (Opposite Direction) ---
            if (pos_side == 'long' and signal == "SELL") or (pos_side == 'short' and signal == "BUY"):
                lg.warning(f"{NEON_YELLOW}*** EXIT Signal ({signal}) opposes {pos_side} position. Closing... ***{RESET}")
                try:
                    close_sig = "SELL" if pos_side == 'long' else "BUY"
                    size_close = abs(pos_size)
                    if size_close <= 0: raise ValueError("Position size is zero/negative.")
                    lg.info(f"==> Placing {close_sig} MARKET order (reduceOnly=True) | Size: {size_close} <==")
                    close_order = place_trade(exchange, symbol, close_sig, size_close, market_info, lg, 'market', reduce_only=True)
                    if close_order: lg.info(f"{NEON_GREEN}Close order placed successfully. ID: {close_order.get('id','?')}{RESET}")
                    else: lg.error(f"{NEON_RED}Failed placing CLOSE order! Manual check!{RESET}")
                except Exception as close_err:
                    lg.error(f"Error closing position: {close_err}", exc_info=True); lg.warning(f"{NEON_YELLOW}Manual close may be needed!{RESET}")
                return # Exit cycle after close attempt

            # --- Check for Time-Based Exit ---
            time_exit = config.get("time_based_exit_minutes")
            if isinstance(time_exit, (int, float)) and time_exit > 0 and pos_ts_ms:
                 try:
                      elapsed_mins = (time.time() * 1000 - pos_ts_ms) / 60000
                      lg.debug(f"Time Exit Check: Elapsed={elapsed_mins:.2f}m, Limit={time_exit}m")
                      if elapsed_mins >= time_exit:
                           lg.warning(f"{NEON_YELLOW}*** TIME-BASED EXIT ({elapsed_mins:.1f} >= {time_exit}m). Closing... ***{RESET}")
                           # Execute Close Logic (identical to signal-based exit)
                           close_sig = "SELL" if pos_side == 'long' else "BUY"
                           size_close = abs(pos_size)
                           if size_close <= 0: raise ValueError("Position size is zero/negative.")
                           close_order = place_trade(exchange, symbol, close_sig, size_close, market_info, lg, 'market', reduce_only=True)
                           if close_order: lg.info(f"{NEON_GREEN}Time-based CLOSE order placed. ID: {close_order.get('id','?')}{RESET}")
                           else: lg.error(f"{NEON_RED}Failed time-based CLOSE order! Manual check!{RESET}")
                           return # Exit cycle
                 except Exception as time_err: lg.error(f"Error in time exit check: {time_err}")

            # --- Position Management (Break-Even) ---
            # Check if TSL is already active on the exchange
            is_tsl_active = open_position.get('trailingStopLossValueDecimal') is not None
            if config["enable_break_even"] and not is_tsl_active:
                 lg.debug("Checking Break-Even conditions...")
                 try:
                     if entry_price is None or not entry_price.is_finite() or entry_price <= 0: raise ValueError("Invalid entry price for BE")
                     if not isinstance(current_atr, Decimal) or not current_atr.is_finite() or current_atr <= 0: raise ValueError("Invalid ATR for BE")

                     be_trig_atr = Decimal(str(config["break_even_trigger_atr_multiple"]))
                     be_off_ticks = int(config["break_even_offset_ticks"])
                     min_tick = analyzer.get_min_tick_size()

                     price_diff = current_price - entry_price if pos_side == 'long' else entry_price - current_price
                     profit_atr = price_diff / current_atr if current_atr > 0 else Decimal(0)
                     lg.debug(f"BE Check: ProfitATRs={profit_atr:.2f}, TargetATRs={be_trig_atr}")

                     if profit_atr >= be_trig_atr:
                          tick_offset = min_tick * be_off_ticks
                          be_sl = (entry_price + tick_offset).quantize(min_tick, rounding=ROUND_UP) if pos_side=='long' else \
                                  (entry_price - tick_offset).quantize(min_tick, rounding=ROUND_DOWN)
                          if not be_sl.is_finite() or be_sl <= 0: raise ValueError(f"Calculated BE SL non-positive/finite ({be_sl})")

                          curr_sl = open_position.get('stopLossPriceDecimal')
                          update_needed = False
                          if curr_sl is None: update_needed = True; lg.info("BE triggered: No current SL.")
                          elif pos_side=='long' and be_sl > curr_sl: update_needed = True; lg.info(f"BE triggered: Target {be_sl} > Current {curr_sl}.")
                          elif pos_side=='short' and be_sl < curr_sl: update_needed = True; lg.info(f"BE triggered: Target {be_sl} < Current {curr_sl}.")
                          else: lg.debug(f"BE triggered but current SL {curr_sl} already adequate.")

                          if update_needed:
                               lg.warning(f"{NEON_PURPLE}*** Moving SL to Break-Even ({symbol} @ {be_sl}) ***{RESET}")
                               curr_tp = open_position.get('takeProfitPriceDecimal') # Preserve existing TP
                               success = _set_position_protection(exchange, symbol, market_info, open_position, lg, be_sl, curr_tp)
                               if success: lg.info(f"{NEON_GREEN}Break-Even SL updated.{RESET}")
                               else: lg.error(f"{NEON_RED}Failed updating Break-Even SL.{RESET}")
                     else: lg.debug("BE Profit target not reached.")
                 except ValueError as ve: lg.warning(f"BE Check skipped: {ve}")
                 except Exception as be_err: lg.error(f"Error during BE check: {be_err}", exc_info=True)
            elif is_tsl_active: lg.debug("BE check skipped: TSL active.")
            else: lg.debug("BE check skipped: Disabled in config.")

            # Placeholder for other potential management logic (e.g., TSL adjustments)
            # lg.debug("End of position management checks.")

    # --- Error Handling for the entire cycle ---
    except ValueError as data_err: # Catch data/config related errors
        lg.error(f"{NEON_RED}Data/Config Error ({symbol}): {data_err}. Skipping cycle.{RESET}")
    except ccxt.AuthenticationError as auth_err: # Catch critical auth errors
         lg.critical(f"{NEON_RED}CRITICAL: Authentication Failed: {auth_err}. Stopping bot.{RESET}")
         raise SystemExit("Authentication Failed") # Stop the bot
    except (ccxt.NetworkError, ccxt.RequestTimeout, ccxt.ExchangeNotAvailable, ccxt.DDoSProtection) as net_err:
         lg.error(f"{NEON_RED}Network/Exchange Availability Error ({symbol}): {net_err}. Skipping cycle.{RESET}")
    except Exception as cycle_err: # Catch unexpected errors
        lg.error(f"{NEON_RED}Unexpected Cycle Error ({symbol}): {cycle_err}{RESET}", exc_info=True)
        # Decide behavior: continue or stop? For now, just log and continue.

    finally:
        # --- Cycle End Logging ---
        cycle_end_time = time.monotonic()
        lg.debug(f"---== Analysis Cycle End ({symbol}, {cycle_end_time - cycle_start_time:.2f}s) ==---")


def main() -> None:
    """Main function to initialize the bot and run the analysis loop."""
    global CONFIG, QUOTE_CURRENCY # Allow modification of globals

    # Setup initial logger
    init_logger = setup_logger("ScalpXRX_Init", level=logging.INFO)
    start_time_str = datetime.now(TIMEZONE).strftime('%Y-%m-%d %H:%M:%S %Z')
    init_logger.info(f"--- Starting ScalpXRX Bot ({start_time_str}) ---")

    try:
        CONFIG = load_config(CONFIG_FILE)
        QUOTE_CURRENCY = CONFIG.get("quote_currency", "USDT")
        TARGET_SYMBOL = CONFIG.get("symbol")

        if not TARGET_SYMBOL:
            init_logger.critical("CRITICAL: 'symbol' not defined in config.json. Exiting.")
            return

        # Setup logger specific to the target symbol for the main loop
        safe_symbol_name = TARGET_SYMBOL.replace('/', '_').replace(':', '-')
        symbol_logger_name = f"ScalpXRX_{safe_symbol_name}"
        main_logger = setup_logger(symbol_logger_name, level=logging.INFO) # Use INFO for console by default
        main_logger.info(f"Logging initialized for symbol: {TARGET_SYMBOL}")
        main_logger.info(f"Config loaded. Quote: {QUOTE_CURRENCY}, Interval: {CONFIG['interval']}")
        try: ta_version = ta.version
        except AttributeError: ta_version = "N/A" # Handle if version attribute is missing
        main_logger.info(f"Versions: CCXT={ccxt.__version__}, Pandas={pd.__version__}, PandasTA={ta_version}")


        # --- Trading Enabled Warning ---
        if CONFIG.get("enable_trading"):
            main_logger.warning(f"{NEON_YELLOW}!!! LIVE TRADING IS ENABLED !!!{RESET}")
            env_type = "SANDBOX (Testnet)" if CONFIG.get("use_sandbox") else f"{NEON_RED}!!! REAL MONEY !!!"
            main_logger.warning(f"Environment: {env_type}{RESET}")
            risk_pct = CONFIG.get('risk_per_trade', 0) * 100
            lev = CONFIG.get('leverage', 1)
            main_logger.warning(f"Settings: Risk/Trade={risk_pct:.2f}%, Leverage={lev}x")
            for i in range(3, 0, -1):
                main_logger.warning(f"Starting in {i}...")
                time.sleep(1)
        else:
            main_logger.info("Trading is disabled in config. Running in analysis-only mode.")

        # --- Initialize Exchange ---
        exchange = initialize_exchange(CONFIG, main_logger)
        if not exchange:
            main_logger.critical("Failed to initialize exchange. Exiting.")
            return

        # --- Main Loop ---
        main_logger.info(f"Starting main analysis loop for {TARGET_SYMBOL}...")
        loop_interval = max(1, CONFIG.get("loop_delay_seconds", LOOP_DELAY_SECONDS)) # Ensure positive delay
        while True:
            try:
                analyze_and_trade_symbol(exchange, TARGET_SYMBOL, CONFIG, main_logger)
            except SystemExit as e: # Catch SystemExit for clean shutdown
                 main_logger.critical(f"SystemExit triggered: {e}. Shutting down.")
                 break
            except KeyboardInterrupt: # Allow Ctrl+C to break loop
                 main_logger.info("KeyboardInterrupt detected in loop. Shutting down.")
                 break
            except Exception as loop_err:
                # Catch unexpected errors from analyze_and_trade_symbol if they weren't caught internally
                main_logger.error(f"{NEON_RED}Error in main loop iteration: {loop_err}{RESET}", exc_info=True)
                # Decide whether to continue or stop based on the error type?
                # For now, log and continue, but could add logic to stop on critical errors.

            # Delay before next cycle
            main_logger.debug(f"Waiting {loop_interval} seconds before next cycle...")
            time.sleep(loop_interval)

    except KeyboardInterrupt:
        init_logger.info("KeyboardInterrupt received during startup/shutdown. Shutting down...")
    except Exception as startup_err:
        init_logger.critical(f"Critical error during startup: {startup_err}", exc_info=True)
    finally:
        end_time_str = datetime.now(TIMEZONE).strftime('%Y-%m-%d %H:%M:%S %Z')
        init_logger.info(f"--- ScalpXRX Bot Shutdown ({end_time_str}) ---")
        logging.shutdown() # Ensure all logs are flushed


if __name__ == "__main__":
    main()
```# scalpxrx.py
# Enhanced and Upgraded Scalping Bot Framework
# Derived from xrscalper.py, focusing on robust execution, error handling,
# advanced position management (BE, TSL), and Bybit V5 compatibility.

import hashlib
import hmac
import json
import logging
import math
import os
import time
from datetime import datetime, timedelta, timezone
from decimal import ROUND_DOWN, ROUND_UP, Decimal, InvalidOperation, getcontext
from logging.handlers import RotatingFileHandler
from typing import Any, Dict, List, Optional, Tuple, Union

import ccxt
import numpy as np
import pandas as pd
import pandas_ta as ta  # Import pandas_ta
import requests
from colorama import Fore, Style, init
from dotenv import load_dotenv
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from zoneinfo import ZoneInfo

# Initialize colorama and set Decimal precision
getcontext().prec = 36  # Increased precision for complex calculations
init(autoreset=True)
load_dotenv()

# Neon Color Scheme
NEON_GREEN = Fore.LIGHTGREEN_EX
NEON_BLUE = Fore.CYAN
NEON_PURPLE = Fore.MAGENTA
NEON_YELLOW = Fore.YELLOW
NEON_RED = Fore.LIGHTRED_EX
NEON_CYAN = Fore.CYAN
RESET = Style.RESET_ALL

# --- Constants ---
API_KEY = os.getenv("BYBIT_API_KEY")
API_SECRET = os.getenv("BYBIT_API_SECRET")
if not API_KEY or not API_SECRET:
    raise ValueError("BYBIT_API_KEY and BYBIT_API_SECRET must be set in .env")

CONFIG_FILE = "config.json"
LOG_DIRECTORY = "bot_logs"
# Timezone for logging and display
TIMEZONE = ZoneInfo("America/Chicago")  # Adjust as needed
MAX_API_RETRIES = 5  # Max retries for recoverable API errors
RETRY_DELAY_SECONDS = 7  # Increased delay between retries
VALID_INTERVALS = ["1", "3", "5", "15", "30", "60", "120", "240", "D", "W", "M"]
CCXT_INTERVAL_MAP = { # Map our intervals to ccxt's expected format
    "1": "1m", "3": "3m", "5": "5m", "15": "15m", "30": "30m",
    "60": "1h", "120": "2h", "240": "4h", "D": "1d", "W": "1w", "M": "1M"
}
RETRY_ERROR_CODES = [429, 500, 502, 503, 504] # HTTP status codes considered retryable
# Default indicator periods (can be overridden by config.json)
DEFAULT_ATR_PERIOD = 14
DEFAULT_CCI_WINDOW = 20
DEFAULT_WILLIAMS_R_WINDOW = 14
DEFAULT_MFI_WINDOW = 14
DEFAULT_STOCH_RSI_WINDOW = 14
DEFAULT_STOCH_WINDOW = 12
DEFAULT_K_WINDOW = 3
DEFAULT_D_WINDOW = 3
DEFAULT_RSI_WINDOW = 14
DEFAULT_BOLLINGER_BANDS_PERIOD = 20
DEFAULT_BOLLINGER_BANDS_STD_DEV = 2.0
DEFAULT_SMA_10_WINDOW = 10
DEFAULT_EMA_SHORT_PERIOD = 9
DEFAULT_EMA_LONG_PERIOD = 21
DEFAULT_MOMENTUM_PERIOD = 7
DEFAULT_VOLUME_MA_PERIOD = 15
DEFAULT_FIB_WINDOW = 50
DEFAULT_PSAR_AF = 0.02
DEFAULT_PSAR_MAX_AF = 0.2

FIB_LEVELS = [0.0, 0.236, 0.382, 0.5, 0.618, 0.786, 1.0] # Standard Fibonacci levels
LOOP_DELAY_SECONDS = 10 # Time between the end of one cycle and the start of the next
POSITION_CONFIRM_DELAY_SECONDS = 10 # Increased wait time after placing order before confirming position
# QUOTE_CURRENCY dynamically loaded from config

os.makedirs(LOG_DIRECTORY, exist_ok=True)

class SensitiveFormatter(logging.Formatter):
    """Formatter to redact sensitive information (API keys) from logs."""
    def format(self, record: logging.LogRecord) -> str:
        msg = super().format(record)
        if API_KEY:
            msg = msg.replace(API_KEY, "***API_KEY***")
        if API_SECRET:
            msg = msg.replace(API_SECRET, "***API_SECRET***")
        return msg

def load_config(filepath: str) -> Dict[str, Any]:
    """
    Load configuration from JSON file, creating default if not found,
    and ensuring all default keys are present with validation.
    """
    # Define the default configuration structure and values
    default_config = {
        # Trading pair and timeframe
        "symbol": "BTC/USDT:USDT", # Bybit linear perpetual example
        "interval": "5", # Default timeframe (e.g., "5" for 5 minutes)

        # API and Bot Behavior
        "retry_delay": RETRY_DELAY_SECONDS, # Delay between API retries
        "enable_trading": False, # Safety Feature: Must be explicitly set to true to trade
        "use_sandbox": True, # Safety Feature: Use testnet by default
        "max_concurrent_positions": 1, # Max open positions for this symbol instance
        "quote_currency": "USDT", # Quote currency for balance checks and sizing
        "position_confirm_delay_seconds": POSITION_CONFIRM_DELAY_SECONDS, # Delay after order before confirming position
        "loop_delay_seconds": LOOP_DELAY_SECONDS, # Delay between main loop cycles

        # Risk Management
        "risk_per_trade": 0.01, # Fraction of balance to risk (e.g., 0.01 = 1%)
        "leverage": 20, # Desired leverage (Ensure supported by exchange/market)
        "stop_loss_multiple": 1.8, # ATR multiple for initial SL (used for sizing/initial fixed SL)
        "take_profit_multiple": 0.7, # ATR multiple for initial TP

        # Order Execution
        "entry_order_type": "market", # "market" or "limit"
        "limit_order_offset_buy": 0.0005, # % offset from price for BUY limit (0.0005 = 0.05%)
        "limit_order_offset_sell": 0.0005, # % offset from price for SELL limit

        # Advanced Position Management
        "enable_trailing_stop": True, # Use exchange-native Trailing Stop Loss
        "trailing_stop_callback_rate": 0.005, # Trail distance % (e.g., 0.005 = 0.5%)
        "trailing_stop_activation_percentage": 0.003, # % profit move from entry to activate TSL
        "enable_break_even": True, # Enable moving SL to break-even point
        "break_even_trigger_atr_multiple": 1.0, # Move SL when profit >= X * ATR
        "break_even_offset_ticks": 2, # Place BE SL X ticks beyond entry price
        "time_based_exit_minutes": None, # Optional: Exit after X minutes (e.g., 60)

        # Indicator Periods & Parameters
        "atr_period": DEFAULT_ATR_PERIOD,
        "ema_short_period": DEFAULT_EMA_SHORT_PERIOD,
        "ema_long_period": DEFAULT_EMA_LONG_PERIOD,
        "rsi_period": DEFAULT_RSI_WINDOW,
        "bollinger_bands_period": DEFAULT_BOLLINGER_BANDS_PERIOD,
        "bollinger_bands_std_dev": DEFAULT_BOLLINGER_BANDS_STD_DEV,
        "cci_window": DEFAULT_CCI_WINDOW,
        "williams_r_window": DEFAULT_WILLIAMS_R_WINDOW,
        "mfi_window": DEFAULT_MFI_WINDOW,
        "stoch_rsi_window": DEFAULT_STOCH_RSI_WINDOW, # StochRSI main window
        "stoch_rsi_rsi_window": DEFAULT_STOCH_WINDOW, # Underlying RSI window for StochRSI
        "stoch_rsi_k": DEFAULT_K_WINDOW, # StochRSI K period
        "stoch_rsi_d": DEFAULT_D_WINDOW, # StochRSI D period
        "psar_af": DEFAULT_PSAR_AF, # PSAR Acceleration Factor
        "psar_max_af": DEFAULT_PSAR_MAX_AF, # PSAR Max Acceleration Factor
        "sma_10_window": DEFAULT_SMA_10_WINDOW,
        "momentum_period": DEFAULT_MOMENTUM_PERIOD,
        "volume_ma_period": DEFAULT_VOLUME_MA_PERIOD,
        "fibonacci_window": DEFAULT_FIB_WINDOW,

        # Indicator Calculation & Scoring Control
        "orderbook_limit": 25, # Depth of order book levels to fetch/analyze
        "signal_score_threshold": 1.5, # Score needed to trigger BUY/SELL signal
        "stoch_rsi_oversold_threshold": 25, # Threshold for StochRSI oversold score
        "stoch_rsi_overbought_threshold": 75, # Threshold for StochRSI overbought score
        "volume_confirmation_multiplier": 1.5, # Volume > Multiplier * VolMA for confirmation
        "scalping_signal_threshold": 2.5, # Alternative threshold for specific weight sets (if needed)
        "indicators": { # Toggle calculation and scoring contribution
            "ema_alignment": True, "momentum": True, "volume_confirmation": True,
            "stoch_rsi": True, "rsi": True, "bollinger_bands": True, "vwap": True,
            "cci": True, "wr": True, "psar": True, "sma_10": True, "mfi": True,
            "orderbook": True,
        },
        "weight_sets": { # Define scoring weights for different strategies
            "scalping": { # Example: Faster, momentum-focused
                "ema_alignment": 0.2, "momentum": 0.3, "volume_confirmation": 0.2,
                "stoch_rsi": 0.6, "rsi": 0.2, "bollinger_bands": 0.3, "vwap": 0.4,
                "cci": 0.3, "wr": 0.3, "psar": 0.2, "sma_10": 0.1, "mfi": 0.2, "orderbook": 0.15,
            },
            "default": { # Example: Balanced
                "ema_alignment": 0.3, "momentum": 0.2, "volume_confirmation": 0.1,
                "stoch_rsi": 0.4, "rsi": 0.3, "bollinger_bands": 0.2, "vwap": 0.3,
                "cci": 0.2, "wr": 0.2, "psar": 0.3, "sma_10": 0.1, "mfi": 0.2, "orderbook": 0.1,
            }
        },
        "active_weight_set": "default" # Select the active weight set
    }

    config = default_config.copy()
    if os.path.exists(filepath):
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                loaded_config = json.load(f)
            # Merge loaded config with defaults, ensuring all keys exist
            config = _merge_configs(loaded_config, default_config)
            print(f"{NEON_GREEN}Loaded configuration from {filepath}{RESET}")
        except (json.JSONDecodeError, IOError) as e:
            print(f"{NEON_RED}Error loading config file {filepath}: {e}. Using default config.{RESET}")
            # Attempt to recreate default file if loading failed
            try:
                with open(filepath, "w", encoding="utf-8") as f_write:
                    json.dump(default_config, f_write, indent=4)
                print(f"{NEON_YELLOW}Recreated default config file: {filepath}{RESET}")
            except IOError as e_create:
                print(f"{NEON_RED}Error recreating default config file: {e_create}{RESET}")
            config = default_config # Use in-memory default
    else:
        # Config file doesn't exist, create it with defaults
        print(f"{NEON_YELLOW}Config file not found. Creating default config at {filepath}{RESET}")
        try:
            with open(filepath, "w", encoding="utf-8") as f:
                json.dump(default_config, f, indent=4)
            config = default_config
        except IOError as e:
            print(f"{NEON_RED}Error creating default config file {filepath}: {e}{RESET}")
            # Continue with in-memory default config if creation fails

    # --- Validation Section ---
    updated = False # Flag to track if config needs saving back

    # Validate symbol
    if not config.get("symbol") or not isinstance(config.get("symbol"), str):
         print(f"{NEON_RED}CRITICAL: 'symbol' is missing, empty, or invalid in config. Resetting to default: '{default_config['symbol']}'{RESET}")
         config["symbol"] = default_config["symbol"]
         updated = True

    # Validate interval
    if config.get("interval") not in VALID_INTERVALS:
        print(f"{NEON_RED}Invalid interval '{config.get('interval')}' in config. Resetting to default '{default_config['interval']}'. Valid: {VALID_INTERVALS}{RESET}")
        config["interval"] = default_config["interval"]
        updated = True

    # Validate entry order type
    if config.get("entry_order_type") not in ["market", "limit"]:
        print(f"{NEON_RED}Invalid entry_order_type '{config.get('entry_order_type')}' in config. Resetting to 'market'.{RESET}")
        config["entry_order_type"] = "market"
        updated = True

    # Validate active weight set exists
    if config.get("active_weight_set") not in config.get("weight_sets", {}):
         print(f"{NEON_RED}Active weight set '{config.get('active_weight_set')}' not found in 'weight_sets'. Resetting to 'default'.{RESET}")
         config["active_weight_set"] = "default" # Ensure 'default' exists in defaults
         updated = True

    # Validate numeric parameters (ranges and types)
    numeric_params = {
        "risk_per_trade": (0, 1, False, False), # key: (min, max, allow_min, allow_max)
        "leverage": (1, 1000, True, True), # Adjust max leverage as needed
        "stop_loss_multiple": (0, float('inf'), False, True),
        "take_profit_multiple": (0, float('inf'), False, True),
        "trailing_stop_callback_rate": (0, 1, False, False),
        "trailing_stop_activation_percentage": (0, 1, True, False), # Allow 0 for immediate activation
        "break_even_trigger_atr_multiple": (0, float('inf'), False, True),
        "break_even_offset_ticks": (0, 100, True, True), # Allow 0 ticks
        "signal_score_threshold": (0, float('inf'), False, True),
        "atr_period": (1, 1000, True, True),
        # Add other numeric params like EMA periods, etc.
    }
    for key, (min_val, max_val, allow_min, allow_max) in numeric_params.items():
        try:
            value = float(config[key]) # Attempt conversion to float
            valid = False
            if allow_min and allow_max: valid = min_val <= value <= max_val
            elif allow_min: valid = min_val <= value < max_val
            elif allow_max: valid = min_val < value <= max_val
            else: valid = min_val < value < max_val

            if not valid:
                raise ValueError(f"Value {value} out of range ({min_val} {'<=' if allow_min else '<'} x {'<=' if allow_max else '<'} {max_val})")
            # Convert back to int if needed (e.g., leverage, ticks, periods)
            if key in ["leverage", "break_even_offset_ticks", "atr_period"]: # Add other integer params
                 config[key] = int(value) # Store as int if valid

        except (ValueError, TypeError, KeyError) as e:
            print(f"{NEON_RED}Invalid value for '{key}' ({config.get(key)}): {e}. Resetting to default '{default_config[key]}'.{RESET}")
            config[key] = default_config[key]
            updated = True

    # If config was updated due to invalid values, save it back
    if updated:
        try:
            with open(filepath, "w", encoding="utf-8") as f_write:
                json.dump(config, f_write, indent=4, ensure_ascii=False)
            print(f"{NEON_YELLOW}Updated config file {filepath} with corrected/default values.{RESET}")
        except IOError as e:
            print(f"{NEON_RED}Error writing updated config file {filepath}: {e}{RESET}")

    return config

def _merge_configs(loaded_config: Dict, default_config: Dict) -> Dict:
    """
    Recursively merges the loaded configuration with default values.
    Ensures all keys from the default config exist in the final config.
    Prioritizes values from the loaded config.
    """
    merged = default_config.copy()
    for key, value in loaded_config.items():
        # If key exists in both and both values are dicts, recurse
        if isinstance(value, dict) and isinstance(merged.get(key), dict):
            merged[key] = _merge_configs(value, merged[key])
        else:
            # Otherwise, overwrite default with loaded value (even if key didn't exist in default)
            # This allows adding new config options without updating defaults immediately
            merged[key] = value
    return merged

def setup_logger(name: str, level: int = logging.INFO) -> logging.Logger:
    """Sets up a logger with rotating file and colored console handlers."""
    logger = logging.getLogger(name)
    # Prevent adding multiple handlers if logger is reused
    if logger.hasHandlers():
        for handler in logger.handlers[:]:
            try: handler.close()
            except: pass
            logger.removeHandler(handler)

    logger.setLevel(logging.DEBUG) # Capture all levels at the logger level

    # File Handler (Rotating)
    log_filename = os.path.join(LOG_DIRECTORY, f"{name}.log")
    try:
        file_handler = RotatingFileHandler(
            log_filename, maxBytes=10 * 1024 * 1024, backupCount=5, encoding='utf-8'
        )
        file_formatter = SensitiveFormatter(
            "%(asctime)s.%(msecs)03d %(levelname)-8s [%(name)s:%(lineno)d] %(message)s",
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        file_handler.setFormatter(file_formatter)
        file_handler.setLevel(logging.DEBUG) # Log DEBUG and above to file
        logger.addHandler(file_handler)
    except Exception as e:
        print(f"Error setting up file logger {log_filename}: {e}")

    # Console Handler (Colored)
    stream_handler = logging.StreamHandler()
    stream_formatter = SensitiveFormatter(
        f"{NEON_BLUE}%(asctime)s{RESET} - {NEON_YELLOW}%(levelname)-8s{RESET} - {NEON_PURPLE}[%(name)s]{RESET} - %(message)s",
        datefmt='%Y-%m-%d %H:%M:%S %Z' # Include Timezone abbreviation
    )
    # Use UTC internally for consistency, display local time in logs via formatter
    stream_formatter.converter = time.gmtime # Log record times in UTC
    # Set the formatter's timezone for display purposes (using datefmt %Z)
    logging.Formatter.converter = lambda *args: datetime.now(TIMEZONE).timetuple() # Make sure %Z uses correct TZ

    stream_handler.setFormatter(stream_formatter)
    stream_handler.setLevel(level) # Set console level (e.g., INFO)
    logger.addHandler(stream_handler)

    logger.propagate = False # Prevent duplicate logs in root logger
    return logger

# --- CCXT Exchange Setup ---
def initialize_exchange(config: Dict[str, Any], logger: logging.Logger) -> Optional[ccxt.Exchange]:
    """Initializes the CCXT Bybit exchange object with enhanced error handling."""
    lg = logger
    try:
        exchange_options = {
            'apiKey': API_KEY,
            'secret': API_SECRET,
            'enableRateLimit': True, # Use CCXT's built-in rate limiter
            'rateLimit': 150, # Adjust based on Bybit V5 limits (e.g., 100ms for 10/s might be safer)
            'options': {
                'defaultType': 'linear', # Essential for Bybit V5 USDT perpetuals
                'adjustForTimeDifference': True, # Helps with timestamp sync issues
                # Increased timeouts
                'fetchTickerTimeout': 15000, 'fetchBalanceTimeout': 20000,
                'createOrderTimeout': 25000, 'cancelOrderTimeout': 20000,
                'fetchPositionsTimeout': 20000, 'fetchOHLCVTimeout': 20000,
                # Add user agent for potential identification
                'user-agent': 'ScalpXRX Bot v1.0',
                # Consider Bybit V5 specific options if needed
                # 'recvWindow': 10000 # Example: Increase if timestamp errors persist
            }
        }

        # Default to Bybit, could be made configurable
        exchange_id = "bybit"
        exchange_class = getattr(ccxt, exchange_id)
        exchange = exchange_class(exchange_options)

        # --- Sandbox Mode Setup ---
        if config.get('use_sandbox'):
            lg.warning(f"{NEON_YELLOW}USING SANDBOX MODE (Testnet){RESET}")
            try:
                exchange.set_sandbox_mode(True)
                lg.info(f"Sandbox mode explicitly enabled for {exchange.id}.")
            except AttributeError:
                lg.warning(f"{exchange.id} does not support set_sandbox_mode via ccxt. Ensuring API keys are for Testnet.")
                # Manually set Bybit testnet URL if needed
                if exchange.id == 'bybit':
                    exchange.urls['api'] = 'https://api-testnet.bybit.com'
                    lg.info("Manually set Bybit API URL to Testnet.")
            except Exception as e:
                lg.error(f"Error enabling sandbox mode: {e}")
        else:
            lg.info(f"{NEON_GREEN}Using LIVE (Real Money) Environment.{RESET}")


        lg.info(f"Initializing {exchange.id}...")
        # --- Initial Connection & Permissions Test (Fetch Balance) ---
        account_type_to_test = 'CONTRACT' # Prioritize CONTRACT for V5 derivatives
        lg.info(f"Attempting initial balance fetch (Account Type: {account_type_to_test})...")
        try:
            params = {'type': account_type_to_test} if exchange.id == 'bybit' else {}
            # Use safe_api_call for robustness
            balance = safe_api_call(exchange.fetch_balance, lg, params=params)

            if balance:
                quote_curr = config.get("quote_currency", "USDT")
                # Handle potential differences in balance structure
                available_quote = balance.get(quote_curr, {}).get('free', 'N/A')
                if available_quote == 'N/A' and quote_curr in balance.get('free', {}): # Check top-level free dict
                    available_quote = balance['free'][quote_curr]

                lg.info(f"{NEON_GREEN}Successfully connected and fetched initial balance.{RESET} (Example: {quote_curr} available: {available_quote})")
            else:
                 lg.warning(f"{NEON_YELLOW}Initial balance fetch (Type: {account_type_to_test}) returned no data. Check connection/permissions.{RESET}")

        except ccxt.AuthenticationError as auth_err:
             lg.error(f"{NEON_RED}Authentication Error during initial balance fetch: {auth_err}{RESET}")
             lg.error(f"{NEON_RED}>> Ensure API keys (in .env) are correct, have permissions (Read, Trade), match environment (Real/Testnet), and IP whitelist is correct.{RESET}")
             return None # Fatal error
        except ccxt.ExchangeError as balance_err:
             # Fallback if specific account type failed
             lg.warning(f"{NEON_YELLOW}Exchange error fetching balance (Type: {account_type_to_test}): {balance_err}. Trying default fetch...{RESET}")
             try:
                  balance = safe_api_call(exchange.fetch_balance, lg)
                  if balance:
                       quote_curr = config.get("quote_currency", "USDT")
                       available_quote = balance.get(quote_curr, {}).get('free', 'N/A')
                       if available_quote == 'N/A' and quote_curr in balance.get('free', {}):
                           available_quote = balance['free'][quote_curr]
                       lg.info(f"{NEON_GREEN}Successfully fetched balance using default parameters.{RESET} (Example: {quote_curr} available: {available_quote})")
                  else:
                       lg.warning(f"{NEON_YELLOW}Default balance fetch also returned no data.{RESET}")
             except Exception as fallback_err:
                  lg.warning(f"{NEON_YELLOW}Default balance fetch also failed: {fallback_err}. Check API permissions/account type/network.{RESET}")
        except Exception as balance_err: # Catches errors from safe_api_call
             lg.warning(f"{NEON_YELLOW}Could not perform initial balance fetch after retries or due to error: {balance_err}. Proceeding cautiously.{RESET}")


        # --- Load Markets (Crucial for market info, precision, etc.) ---
        lg.info(f"Loading markets for {exchange.id}...")
        try:
             safe_api_call(exchange.load_markets, lg, reload=True) # Force reload
             lg.info(f"Markets loaded successfully for {exchange.id}.")
        except Exception as market_err:
             lg.error(f"{NEON_RED}Failed to load markets after retries: {market_err}. Cannot operate without market data. Exiting.{RESET}")
             return None # Fatal error if markets cannot be loaded

        lg.info(f"CCXT exchange initialized ({exchange.id}). Sandbox: {config.get('use_sandbox')}")
        return exchange

    except ccxt.AuthenticationError as e: # Catch auth errors during class instantiation
        lg.error(f"{NEON_RED}CCXT Authentication Error during initialization: {e}{RESET}")
        lg.error(f"{NEON_RED}>> Check API Key/Secret format and validity in your .env file.{RESET}")
    except ccxt.ExchangeError as e:
        lg.error(f"{NEON_RED}CCXT Exchange Error initializing: {e}{RESET}")
    except ccxt.NetworkError as e:
        lg.error(f"{NEON_RED}CCXT Network Error initializing: {e}{RESET}")
    except Exception as e:
        lg.error(f"{NEON_RED}Failed to initialize CCXT exchange: {e}{RESET}", exc_info=True)

    return None

# --- API Call Wrapper with Retries ---
def safe_api_call(func, logger: logging.Logger, *args, **kwargs):
    """Wraps an API call with retry logic for network/rate limit/specific exchange errors."""
    lg = logger
    attempts = 0
    last_exception = None
    while attempts <= MAX_API_RETRIES:
        try:
            result = func(*args, **kwargs)
            # Optional: Add specific success logging here if needed
            # lg.debug(f"API call {func.__name__} successful.")
            return result # Success
        except (ccxt.NetworkError, ccxt.RequestTimeout, requests.exceptions.ConnectionError, requests.exceptions.Timeout, ccxt.ExchangeNotAvailable, ccxt.DDoSProtection) as e:
            last_exception = e
            wait_time = RETRY_DELAY_SECONDS * (1.5 ** attempts) # Exponential backoff
            lg.warning(f"{NEON_YELLOW}Retryable network/availability error in {func.__name__}: {type(e).__name__}. Waiting {wait_time:.1f}s (Attempt {attempts+1}/{MAX_API_RETRIES}). Error: {e}{RESET}")
            time.sleep(wait_time)
        except ccxt.RateLimitExceeded as e:
            last_exception = e
            # Extract wait time from headers if possible (specific to exchange/ccxt impl.)
            wait_time_header = getattr(e, 'retry_after', None) # Check if ccxt provides this
            wait_time = RETRY_DELAY_SECONDS * (2 ** attempts) # Stronger backoff for rate limits
            if wait_time_header:
                try: wait_time = max(wait_time, float(wait_time_header) + 0.5) # Add buffer
                except: pass # Ignore if header value is invalid
            lg.warning(f"{NEON_YELLOW}Rate limit exceeded in {func.__name__}. Waiting {wait_time:.1f}s (Attempt {attempts+1}/{MAX_API_RETRIES}). Error: {e}{RESET}")
            time.sleep(wait_time)
        except ccxt.AuthenticationError as e:
             lg.error(f"{NEON_RED}Authentication Error in {func.__name__}: {e}. Aborting call.{RESET}")
             raise e # Don't retry auth errors, re-raise immediately
        except ccxt.ExchangeError as e:
            last_exception = e
            # Decide if specific exchange errors are retryable
            bybit_retry_codes = [
                10001, # Internal server error
                10006, # Request frequent, please try again later (Generic Rate Limit)
                # Add other Bybit V5 codes known to be potentially transient
                # e.g., some margin errors if balance update is slow? (Requires testing)
            ]
            exchange_code = getattr(e, 'code', None)
            err_str = str(e).lower()
            # Check if code is retryable OR message suggests temporary issue
            is_retryable_exchange_err = exchange_code in bybit_retry_codes or \
                                        "internal server error" in err_str or \
                                        "request validation failed" in err_str # Example message check

            if is_retryable_exchange_err:
                 wait_time = RETRY_DELAY_SECONDS * (1.5 ** attempts)
                 lg.warning(f"{NEON_YELLOW}Potentially retryable exchange error in {func.__name__}: {e} (Code: {exchange_code}). Waiting {wait_time:.1f}s (Attempt {attempts+1}/{MAX_API_RETRIES})...{RESET}")
                 time.sleep(wait_time)
            else:
                 # Non-retryable ExchangeError (e.g., InvalidOrder, InsufficientFunds)
                 lg.error(f"{NEON_RED}Non-retryable Exchange Error in {func.__name__}: {e} (Code: {exchange_code}){RESET}")
                 raise e # Re-raise
        except Exception as e:
            # Catch any other unexpected error
            last_exception = e
            lg.error(f"{NEON_RED}Unexpected error in {func.__name__}: {e}{RESET}", exc_info=True)
            raise e # Re-raise unexpected errors immediately (or decide based on type)

        attempts += 1

    # If loop completes, max retries were exceeded
    lg.error(f"{NEON_RED}Max retries ({MAX_API_RETRIES}) exceeded for {func.__name__}.{RESET}")
    # Raise the *last* exception encountered to provide context
    if last_exception:
        raise last_exception
    else:
        # Should not happen if loop was entered, but as a safeguard
        raise ccxt.RequestTimeout(f"Max retries exceeded for {func.__name__} (no specific exception captured)")


# --- CCXT Data Fetching (Using safe_api_call) ---
def fetch_current_price_ccxt(exchange: ccxt.Exchange, symbol: str, logger: logging.Logger) -> Optional[Decimal]:
    """Fetch the current price of a trading symbol using CCXT ticker with fallbacks and retries."""
    lg = logger
    try:
        ticker = safe_api_call(exchange.fetch_ticker, lg, symbol)
        if not ticker:
            # Error already logged by safe_api_call
            return None

        lg.debug(f"Ticker data for {symbol}: {ticker}")
        price = None
        # Prioritize 'last', then mid-price ('average' if available), then ask/bid
        last_price = ticker.get('last')
        bid_price = ticker.get('bid')
        ask_price = ticker.get('ask')
        avg_price = ticker.get('average') # Some exchanges provide volume-weighted avg or simple mid

        # Robust Decimal conversion helper
        def to_decimal(value) -> Optional[Decimal]:
            if value is None: return None
            try:
                d = Decimal(str(value))
                # Ensure the price is finite and positive
                return d if d.is_finite() and d > 0 else None
            except (InvalidOperation, ValueError, TypeError):
                lg.warning(f"Invalid price format encountered: {value}")
                return None

        p_last = to_decimal(last_price)
        p_bid = to_decimal(bid_price)
        p_ask = to_decimal(ask_price)
        p_avg = to_decimal(avg_price)

        # Determine price with priority
        if p_last:
            price = p_last; lg.debug(f"Using 'last' price: {price}")
        elif p_avg: # Use 'average' if last is missing but average exists
            price = p_avg; lg.debug(f"Using 'average' price: {price}")
        elif p_bid and p_ask: # Use bid/ask midpoint if others missing
            price = (p_bid + p_ask) / 2; lg.debug(f"Using bid/ask midpoint: {price}")
        elif p_ask: # Fallback to ask if only ask is valid
            price = p_ask; lg.warning(f"Using 'ask' price fallback (bid invalid/missing): {price}")
        elif p_bid: # Fallback to bid if only bid is valid
            price = p_bid; lg.warning(f"Using 'bid' price fallback (ask invalid/missing): {price}")

        # Final validation
        if price is not None and price.is_finite() and price > 0:
            return price
        else:
            lg.error(f"{NEON_RED}Failed to extract a valid price from ticker data for {symbol}. Ticker: {ticker}{RESET}")
            return None

    except Exception as e:
        # Catch errors raised by safe_api_call or during parsing
        lg.error(f"{NEON_RED}Error fetching current price for {symbol}: {e}{RESET}", exc_info=False) # Keep log concise
        return None

def fetch_klines_ccxt(exchange: ccxt.Exchange, symbol: str, timeframe: str, limit: int = 250, logger: logging.Logger = None) -> pd.DataFrame:
    """Fetch OHLCV kline data using CCXT with retries and robust validation."""
    lg = logger or logging.getLogger(__name__)
    if not exchange.has['fetchOHLCV']:
        lg.error(f"Exchange {exchange.id} does not support fetchOHLCV.")
        return pd.DataFrame()

    try:
        # Use safe_api_call to handle retries
        ohlcv = safe_api_call(exchange.fetch_ohlcv, lg, symbol, timeframe=timeframe, limit=limit)

        if ohlcv is None or not isinstance(ohlcv, list) or len(ohlcv) == 0:
            # Error logged by safe_api_call if failed after retries
            if ohlcv is not None: # Log only if it returned empty list/None without raising error
                lg.warning(f"{NEON_YELLOW}No valid kline data returned for {symbol} {timeframe}.{RESET}")
            return pd.DataFrame()

        # Process the data into a pandas DataFrame
        df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])

        if df.empty:
            lg.warning(f"Kline data DataFrame is empty for {symbol} {timeframe}.")
            return df

        # Convert timestamp to datetime objects (UTC), coerce errors
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms', errors='coerce', utc=True)
        df.dropna(subset=['timestamp'], inplace=True)
        df.set_index('timestamp', inplace=True)

        # Convert price/volume columns to numeric Decimal, handling potential empty strings or invalid formats
        for col in ['open', 'high', 'low', 'close', 'volume']:
             try:
                  # Apply robust conversion to Decimal, handle empty strings/None explicitly
                  df[col] = df[col].apply(lambda x: Decimal(str(x)) if pd.notna(x) and str(x).strip() != '' else Decimal('NaN'))
             except (TypeError, ValueError, InvalidOperation) as conv_err:
                  lg.warning(f"Could not convert column '{col}' to Decimal, attempting numeric fallback: {conv_err}")
                  df[col] = pd.to_numeric(df[col], errors='coerce') # Fallback to float/NaN

        # Data Cleaning: Drop rows with NaN in essential price columns or non-positive/non-finite close price
        initial_len = len(df)
        close_col = df['close'] # Reference the column for checks
        df.dropna(subset=['open', 'high', 'low', 'close'], inplace=True)

        # Filter out rows with non-positive or non-finite close prices
        if not df.empty:
            if isinstance(close_col.iloc[0], Decimal):
                # Use Decimal methods for filtering
                df = df[close_col.apply(lambda x: x.is_finite() and x > 0)]
            elif pd.api.types.is_numeric_dtype(close_col.dtype): # Check if float/int
                 # Use numpy methods for filtering float columns
                 df = df[np.isfinite(close_col) & (close_col > 0)]

        rows_dropped = initial_len - len(df)
        if rows_dropped > 0:
            lg.debug(f"Dropped {rows_dropped} rows with NaN/invalid price data for {symbol}.")

        if df.empty:
            lg.warning(f"Kline data for {symbol} {timeframe} empty after cleaning.")
            return pd.DataFrame()

        # Sort by timestamp index and remove duplicates (keeping the last occurrence)
        df.sort_index(inplace=True)
        df = df[~df.index.duplicated(keep='last')]

        lg.info(f"Successfully fetched and processed {len(df)} klines for {symbol} {timeframe}")
        return df

    except Exception as e:
        # Catch errors from safe_api_call or during processing
        lg.error(f"{NEON_RED}Error fetching/processing klines for {symbol}: {e}{RESET}", exc_info=True)
        return pd.DataFrame()


def fetch_orderbook_ccxt(exchange: ccxt.Exchange, symbol: str, limit: int, logger: logging.Logger) -> Optional[Dict]:
    """Fetch orderbook data using ccxt with retries and validation."""
    lg = logger
    if not exchange.has['fetchOrderBook']:
        lg.error(f"Exchange {exchange.id} does not support fetchOrderBook.")
        return None

    try:
        orderbook = safe_api_call(exchange.fetch_order_book, lg, symbol, limit=limit)

        if not orderbook: # Error already logged by safe_api_call if it failed
            return None
        # Validate structure
        if not isinstance(orderbook, dict) or 'bids' not in orderbook or 'asks' not in orderbook or \
           not isinstance(orderbook['bids'], list) or not isinstance(orderbook['asks'], list):
            lg.warning(f"Invalid orderbook structure received for {symbol}. Data: {orderbook}")
            return None

        if not orderbook['bids'] and not orderbook['asks']:
            lg.warning(f"Orderbook received but both bids and asks lists are empty for {symbol}.")
            # Return the empty but valid book
            return orderbook

        # Basic validation of bid/ask entry format (price, size structure)
        valid = True
        for side in ['bids', 'asks']:
             if orderbook[side]: # Check first entry if list is not empty
                  entry = orderbook[side][0]
                  if not (isinstance(entry, list) and len(entry) == 2):
                       lg.warning(f"Invalid {side[:-1]} entry format in orderbook: {entry}")
                       valid = False; break
                  try: # Check if price and size are numeric (allow float conversion)
                       _ = float(entry[0]); _ = float(entry[1])
                  except (ValueError, TypeError):
                       lg.warning(f"Non-numeric data in {side[:-1]} entry: {entry}")
                       valid = False; break
        if not valid:
             lg.error("Orderbook data format validation failed.")
             return None

        lg.debug(f"Successfully fetched orderbook for {symbol} ({len(orderbook['bids'])} bids, {len(orderbook['asks'])} asks).")
        return orderbook

    except Exception as e:
        # Catch errors raised by safe_api_call or other validation issues
        lg.error(f"{NEON_RED}Error fetching order book for {symbol}: {e}{RESET}", exc_info=False)
        return None

# --- Trading Analyzer Class ---
class TradingAnalyzer:
    """Analyzes trading data using pandas_ta and generates weighted signals."""

    def __init__(
        self,
        df: pd.DataFrame,
        logger: logging.Logger,
        config: Dict[str, Any],
        market_info: Dict[str, Any],
    ) -> None:
        """
        Initializes the TradingAnalyzer.

        Args:
            df: Pandas DataFrame with OHLCV data (expects Decimal values), indexed by timestamp.
            logger: Logger instance for logging messages.
            config: Dictionary containing bot configuration.
            market_info: Dictionary containing market details (precision, limits, etc.).
        """
        self.df = df # Expects OHLCV columns with Decimal type from fetch_klines
        self.logger = logger
        self.config = config
        self.market_info = market_info
        self.symbol = market_info.get('symbol', 'UNKNOWN_SYMBOL')
        self.interval = config.get("interval", "5")
        self.ccxt_interval = CCXT_INTERVAL_MAP.get(self.interval)
        if not self.ccxt_interval:
            self.logger.error(f"Invalid interval '{self.interval}' in config for {self.symbol}.")
            # Bot might fail later if this is not valid

        # Stores latest indicator values (Decimal for prices/ATR, float for others)
        self.indicator_values: Dict[str, Union[Decimal, float, Any]] = {}
        self.signals: Dict[str, int] = {"BUY": 0, "SELL": 0, "HOLD": 1} # Default HOLD
        self.active_weight_set_name = config.get("active_weight_set", "default")
        self.weights = config.get("weight_sets", {}).get(self.active_weight_set_name, {})
        self.fib_levels_data: Dict[str, Decimal] = {} # Stores calculated fib levels
        self.ta_column_names: Dict[str, Optional[str]] = {} # Maps internal name to actual DataFrame column name

        if not self.weights:
            logger.warning(f"{NEON_YELLOW}Active weight set '{self.active_weight_set_name}' not found or empty for {self.symbol}. Scoring will be zero.{RESET}")
            self.weights = {} # Use empty dict to prevent errors

        # Perform initial calculations only if DataFrame is valid
        if not self.df.empty:
             self._calculate_all_indicators()
             self._update_latest_indicator_values() # Run AFTER indicator calculation
             self.calculate_fibonacci_levels()
        else:
             self.logger.warning("TradingAnalyzer initialized with empty DataFrame. No calculations performed.")


    def _get_ta_col_name(self, base_name: str, result_df: pd.DataFrame) -> Optional[str]:
        """Helper to find the actual column name generated by pandas_ta."""
        # Define expected patterns, potentially using f-strings for dynamic parts
        expected_patterns = {
            "ATR": [f"ATRr_{self.config.get('atr_period', DEFAULT_ATR_PERIOD)}"],
            "EMA_Short": [f"EMA_{self.config.get('ema_short_period', DEFAULT_EMA_SHORT_PERIOD)}"],
            "EMA_Long": [f"EMA_{self.config.get('ema_long_period', DEFAULT_EMA_LONG_PERIOD)}"],
            "Momentum": [f"MOM_{self.config.get('momentum_period', DEFAULT_MOMENTUM_PERIOD)}"],
            # CCI often includes the constant (e.g., 100.0) which pandas_ta adds
            "CCI": [f"CCI_{self.config.get('cci_window', DEFAULT_CCI_WINDOW)}"],
            "Williams_R": [f"WILLR_{self.config.get('williams_r_window', DEFAULT_WILLIAMS_R_WINDOW)}"],
            "MFI": [f"MFI_{self.config.get('mfi_window', DEFAULT_MFI_WINDOW)}"],
            "VWAP": ["VWAP_D"], # Default pandas_ta VWAP often daily anchored
            "PSAR_long": [f"PSARl_{self.config.get('psar_af', DEFAULT_PSAR_AF)}_{self.config.get('psar_max_af', DEFAULT_PSAR_MAX_AF)}"],
            "PSAR_short": [f"PSARs_{self.config.get('psar_af', DEFAULT_PSAR_AF)}_{self.config.get('psar_max_af', DEFAULT_PSAR_MAX_AF)}"],
            "SMA10": [f"SMA_{self.config.get('sma_10_window', DEFAULT_SMA_10_WINDOW)}"],
            # StochRSI names can be complex, include core parameters
            "StochRSI_K": [f"STOCHRSIk_{self.config.get('stoch_rsi_window', DEFAULT_STOCH_RSI_WINDOW)}_{self.config.get('stoch_rsi_rsi_window', DEFAULT_STOCH_WINDOW)}_{self.config.get('stoch_rsi_k', DEFAULT_K_WINDOW)}"],
            "StochRSI_D": [f"STOCHRSId_{self.config.get('stoch_rsi_window', DEFAULT_STOCH_RSI_WINDOW)}_{self.config.get('stoch_rsi_rsi_window', DEFAULT_STOCH_WINDOW)}_{self.config.get('stoch_rsi_k', DEFAULT_K_WINDOW)}_{self.config.get('stoch_rsi_d', DEFAULT_D_WINDOW)}"],
            "RSI": [f"RSI_{self.config.get('rsi_period', DEFAULT_RSI_WINDOW)}"],
            # BBands names include period and std dev (formatted to 1 decimal place by default)
            "BB_Lower": [f"BBL_{self.config.get('bollinger_bands_period', DEFAULT_BOLLINGER_BANDS_PERIOD)}_{float(self.config.get('bollinger_bands_std_dev', DEFAULT_BOLLINGER_BANDS_STD_DEV)):.1f}"],
            "BB_Middle": [f"BBM_{self.config.get('bollinger_bands_period', DEFAULT_BOLLINGER_BANDS_PERIOD)}_{float(self.config.get('bollinger_bands_std_dev', DEFAULT_BOLLINGER_BANDS_STD_DEV)):.1f}"],
            "BB_Upper": [f"BBU_{self.config.get('bollinger_bands_period', DEFAULT_BOLLINGER_BANDS_PERIOD)}_{float(self.config.get('bollinger_bands_std_dev', DEFAULT_BOLLINGER_BANDS_STD_DEV)):.1f}"],
            # Custom name used for Volume MA
            "Volume_MA": [f"VOL_SMA_{self.config.get('volume_ma_period', DEFAULT_VOLUME_MA_PERIOD)}"]
        }

        patterns = expected_patterns.get(base_name, [])
        df_cols = result_df.columns.tolist()

        # Exact match or startswith preferred
        for col in df_cols:
            for pattern in patterns:
                # Use startswith for flexibility (e.g., CCI_20_100.0 matches CCI_20)
                if col.startswith(pattern):
                    self.logger.debug(f"Mapped '{base_name}' to column '{col}'")
                    return col

        # Fallback: Simple case-insensitive substring search
        base_lower = base_name.lower()
        simple_base = base_lower.split('_')[0] # e.g., "ema_short" -> "ema"
        for col in df_cols:
            col_lower = col.lower()
            # Check full base name first, then simpler version
            if base_lower in col_lower:
                 self.logger.debug(f"Mapped '{base_name}' to '{col}' via substring search ('{base_lower}').")
                 return col
            # Avoid overly broad matches with simple base (e.g., 'r' matching 'atr')
            # Ensure simple_base is reasonably specific
            elif len(simple_base) > 2 and simple_base in col_lower:
                 self.logger.debug(f"Mapped '{base_name}' to '{col}' via substring search ('{simple_base}').")
                 return col

        self.logger.warning(f"Could not find column name for indicator '{base_name}' in DataFrame columns: {df_cols}")
        return None

    def _calculate_all_indicators(self):
        """Calculates all enabled indicators using pandas_ta."""
        if self.df.empty:
            self.logger.warning(f"DataFrame is empty, cannot calculate indicators for {self.symbol}.")
            return

        # Determine minimum required data length based on enabled & weighted indicators
        required_periods = []
        indicators_config = self.config.get("indicators", {})
        active_weights = self.weights # Use stored weights

        # Helper to add requirement if indicator is enabled AND weighted
        def add_req(key, config_key, default_period):
            if indicators_config.get(key, False) and float(active_weights.get(key, 0)) != 0:
                required_periods.append(self.config.get(config_key, default_period))

        add_req("atr", "atr_period", DEFAULT_ATR_PERIOD) # ATR always calculated if possible
        add_req("momentum", "momentum_period", DEFAULT_MOMENTUM_PERIOD)
        add_req("cci", "cci_window", DEFAULT_CCI_WINDOW)
        add_req("wr", "williams_r_window", DEFAULT_WILLIAMS_R_WINDOW)
        add_req("mfi", "mfi_window", DEFAULT_MFI_WINDOW)
        add_req("sma_10", "sma_10_window", DEFAULT_SMA_10_WINDOW)
        add_req("rsi", "rsi_period", DEFAULT_RSI_WINDOW)
        add_req("bollinger_bands", "bollinger_bands_period", DEFAULT_BOLLINGER_BANDS_PERIOD)
        add_req("volume_confirmation", "volume_ma_period", DEFAULT_VOLUME_MA_PERIOD)
        required_periods.append(self.config.get("fibonacci_window", DEFAULT_FIB_WINDOW)) # For Fib levels

        if indicators_config.get("ema_alignment", False) and float(active_weights.get("ema_alignment", 0)) != 0:
             required_periods.append(self.config.get("ema_short_period", DEFAULT_EMA_SHORT_PERIOD))
             required_periods.append(self.config.get("ema_long_period", DEFAULT_EMA_LONG_PERIOD))
        if indicators_config.get("stoch_rsi", False) and float(active_weights.get("stoch_rsi", 0)) != 0:
            required_periods.append(self.config.get("stoch_rsi_window", DEFAULT_STOCH_RSI_WINDOW))
            required_periods.append(self.config.get("stoch_rsi_rsi_window", DEFAULT_STOCH_WINDOW))

        min_required_data = max(required_periods) + 30 if required_periods else 50 # Add buffer

        if len(self.df) < min_required_data:
             self.logger.warning(f"{NEON_YELLOW}Insufficient data ({len(self.df)} points) for {self.symbol} to calculate indicators reliably (min recommended: {min_required_data}). Results may contain NaNs.{RESET}")

        try:
            df_calc = self.df.copy()
            # --- Convert Decimal columns to float for pandas_ta ---
            # Store original types to potentially convert back later if needed
            original_types = {}
            for col in ['open', 'high', 'low', 'close', 'volume']:
                 if col in df_calc.columns:
                     # Check first non-NaN value's type
                     first_valid_idx = df_calc[col].first_valid_index()
                     if first_valid_idx is not None:
                          original_types[col] = type(df_calc.loc[first_valid_idx, col])
                          if original_types[col] == Decimal:
                               self.logger.debug(f"Converting Decimal column '{col}' to float for TA calculation.")
                               # Apply conversion robustly, handle non-finite Decimals
                               df_calc[col] = df_calc[col].apply(lambda x: float(x) if isinstance(x, Decimal) and x.is_finite() else np.nan)
                     # If column exists but is all NaN, it's fine
                     elif not df_calc[col].isnull().all(): # If not all NaN, but first is NaN, try converting anyway
                          if isinstance(df_calc[col].iloc[0], Decimal): # Check type even if NaN initially
                               self.logger.debug(f"Converting Decimal column '{col}' (starting with NaN) to float.")
                               df_calc[col] = df_calc[col].apply(lambda x: float(x) if isinstance(x, Decimal) and x.is_finite() else np.nan)

            # --- Calculate Indicators using pandas_ta ---
            # Always calculate ATR
            atr_period = self.config.get("atr_period", DEFAULT_ATR_PERIOD)
            df_calc.ta.atr(length=atr_period, append=True)
            self.ta_column_names["ATR"] = self._get_ta_col_name("ATR", df_calc)

            # Calculate others based on config and weight
            key_map = { # Map internal keys to config keys and defaults if needed
                "momentum": ("momentum_period", DEFAULT_MOMENTUM_PERIOD),
                "cci": ("cci_window", DEFAULT_CCI_WINDOW),
                "wr": ("williams_r_window", DEFAULT_WILLIAMS_R_WINDOW),
                "mfi": ("mfi_window", DEFAULT_MFI_WINDOW),
                "sma_10": ("sma_10_window", DEFAULT_SMA_10_WINDOW),
                "rsi": ("rsi_period", DEFAULT_RSI_WINDOW),
            }

            for key, enabled in indicators_config.items():
                if key == "atr": continue # Already done
                if enabled and float(active_weights.get(key, 0)) != 0:
                    self.logger.debug(f"Calculating indicator: {key}")
                    try:
                        if key == "ema_alignment":
                            ema_short = self.config.get("ema_short_period", DEFAULT_EMA_SHORT_PERIOD)
                            ema_long = self.config.get("ema_long_period", DEFAULT_EMA_LONG_PERIOD)
                            df_calc.ta.ema(length=ema_short, append=True)
                            self.ta_column_names["EMA_Short"] = self._get_ta_col_name("EMA_Short", df_calc)
                            df_calc.ta.ema(length=ema_long, append=True)
                            self.ta_column_names["EMA_Long"] = self._get_ta_col_name("EMA_Long", df_calc)
                        elif key == "psar":
                            psar_af = self.config.get("psar_af", DEFAULT_PSAR_AF)
                            psar_max_af = self.config.get("psar_max_af", DEFAULT_PSAR_MAX_AF)
                            psar_result = df_calc.ta.psar(af=psar_af, max_af=psar_max_af)
                            if psar_result is not None and not psar_result.empty:
                                df_calc = pd.concat([df_calc, psar_result], axis=1)
                                self.ta_column_names["PSAR_long"] = self._get_ta_col_name("PSAR_long", df_calc)
                                self.ta_column_names["PSAR_short"] = self._get_ta_col_name("PSAR_short", df_calc)
                        elif key == "stoch_rsi":
                            st_len = self.config.get("stoch_rsi_window", DEFAULT_STOCH_RSI_WINDOW)
                            st_rsi_len = self.config.get("stoch_rsi_rsi_window", DEFAULT_STOCH_WINDOW)
                            st_k = self.config.get("stoch_rsi_k", DEFAULT_K_WINDOW)
                            st_d = self.config.get("stoch_rsi_d", DEFAULT_D_WINDOW)
                            st_result = df_calc.ta.stochrsi(length=st_len, rsi_length=st_rsi_len, k=st_k, d=st_d)
                            if st_result is not None and not st_result.empty:
                                df_calc = pd.concat([df_calc, st_result], axis=1)
                                self.ta_column_names["StochRSI_K"] = self._get_ta_col_name("StochRSI_K", df_calc)
                                self.ta_column_names["StochRSI_D"] = self._get_ta_col_name("StochRSI_D", df_calc)
                        elif key == "bollinger_bands":
                            bb_p = self.config.get("bollinger_bands_period", DEFAULT_BOLLINGER_BANDS_PERIOD)
                            bb_std = float(self.config.get("bollinger_bands_std_dev", DEFAULT_BOLLINGER_BANDS_STD_DEV))
                            bb_result = df_calc.ta.bbands(length=bb_p, std=bb_std)
                            if bb_result is not None and not bb_result.empty:
                                df_calc = pd.concat([df_calc, bb_result], axis=1)
                                self.ta_column_names["BB_Lower"] = self._get_ta_col_name("BB_Lower", df_calc)
                                self.ta_column_names["BB_Middle"] = self._get_ta_col_name("BB_Middle", df_calc)
                                self.ta_column_names["BB_Upper"] = self._get_ta_col_name("BB_Upper", df_calc)
                        elif key == "volume_confirmation":
                            vol_ma_p = self.config.get("volume_ma_period", DEFAULT_VOLUME_MA_PERIOD)
                            vol_ma_col = f"VOL_SMA_{vol_ma_p}"
                            # Ensure volume is float for SMA calculation
                            vol_series = df_calc['volume'].astype(float) # Already converted above if needed
                            df_calc[vol_ma_col] = ta.sma(vol_series.fillna(0), length=vol_ma_p)
                            self.ta_column_names["Volume_MA"] = vol_ma_col
                        elif key == "vwap":
                             df_calc.ta.vwap(append=True)
                             self.ta_column_names["VWAP"] = self._get_ta_col_name("VWAP", df_calc)
                        elif key in key_map: # General case using key_map
                            config_k, default_p = key_map[key]
                            period = self.config.get(config_k, default_p)
                            method = getattr(df_calc.ta, key, None)
                            if method and callable(method):
                                method(length=period, append=True)
                                # Map internal key to pandas_ta base name for column lookup
                                ta_base_map = {"cci": "CCI", "wr": "Williams_R", "mfi": "MFI", "sma_10": "SMA10", "rsi": "RSI", "momentum": "Momentum"}
                                ta_base_name = ta_base_map.get(key, key.upper()) # Simple mapping
                                self.ta_column_names[ta_base_name] = self._get_ta_col_name(ta_base_name, df_calc)
                            else:
                                self.logger.warning(f"Pandas TA method '{key}' not found or not callable.")

                    except Exception as calc_err:
                        self.logger.error(f"Error calculating indicator '{key}': {calc_err}", exc_info=True)

            # --- Convert ATR column back to Decimal ---
            # pandas_ta outputs float, convert ATR back for precise calculations
            atr_col = self.ta_column_names.get("ATR")
            if atr_col and atr_col in df_calc.columns:
                 try:
                     # Convert float column back to Decimal, handling potential NaNs/infs
                     df_calc[atr_col] = df_calc[atr_col].apply(lambda x: Decimal(str(x)) if pd.notna(x) and np.isfinite(x) else Decimal('NaN'))
                     self.logger.debug(f"Converted calculated ATR column '{atr_col}' back to Decimal.")
                 except (ValueError, TypeError, InvalidOperation) as conv_err:
                      self.logger.error(f"Failed to convert ATR column '{atr_col}' back to Decimal: {conv_err}")

            # Update the instance's DataFrame
            self.df = df_calc
            self.logger.debug(f"Finished indicator calculations. Final DF columns: {self.df.columns.tolist()}")

        except Exception as e:
            self.logger.error(f"{NEON_RED}Error during indicator calculation setup or execution: {e}{RESET}", exc_info=True)


    def _update_latest_indicator_values(self):
        """Updates indicator_values dict with latest values, handling types."""
        # Define keys expected based on calculation attempts + base OHLCV
        expected_keys = list(self.ta_column_names.keys()) + ["Open", "High", "Low", "Close", "Volume"]
        default_values = {k: np.nan for k in expected_keys} # Initialize with NaN

        if self.df.empty:
            self.logger.warning(f"Cannot update latest values: DataFrame empty for {self.symbol}.")
            self.indicator_values = default_values
            return
        try:
            # Use the last valid index in case of missing data points
            last_valid_index = self.df.last_valid_index()
            if last_valid_index is None: raise IndexError("No valid index found.")
            latest = self.df.loc[last_valid_index]
        except (IndexError, KeyError):
            self.logger.error(f"Error accessing latest valid row/index for {self.symbol}.")
            self.indicator_values = default_values
            return

        if latest.isnull().all():
            self.logger.warning(f"Last valid row contains all NaNs for {self.symbol}. Cannot update values.")
            self.indicator_values = default_values
            return

        updated_values = {}
        # --- Process TA indicators ---
        for key, col_name in self.ta_column_names.items():
            if col_name and col_name in latest.index:
                value = latest[col_name]
                # Ensure value is finite number (not NaN, not inf)
                if pd.notna(value) and np.isfinite(value):
                    try:
                        if key == "ATR": # ATR should be Decimal
                            updated_values[key] = value if isinstance(value, Decimal) else Decimal(str(value))
                        else: # Others as float
                            updated_values[key] = float(value)
                    except (ValueError, TypeError, InvalidOperation) as conv_err:
                        self.logger.warning(f"Could not convert TA value {key} ('{col_name}': {value}): {conv_err}. Storing NaN.")
                        updated_values[key] = np.nan
                else: updated_values[key] = np.nan # Store NaN if value is NaN or inf
            else:
                 # Log only if calculation was attempted (key exists in ta_column_names)
                 if key in self.ta_column_names:
                     self.logger.debug(f"Indicator column '{col_name}' for '{key}' not found in latest data. Storing NaN.")
                 updated_values[key] = np.nan

        # --- Process Base OHLCV (should be Decimal from fetch) ---
        for base_col in ['open', 'high', 'low', 'close', 'volume']:
            key_name = base_col.capitalize()
            value = latest.get(base_col)
            if pd.notna(value) and isinstance(value, Decimal) and value.is_finite():
                 updated_values[key_name] = value
            elif pd.notna(value): # If not Decimal or not finite
                 self.logger.warning(f"Base value '{base_col}' ({value}) is not a finite Decimal. Storing NaN.")
                 updated_values[key_name] = np.nan
            else: # Value is NaN
                 updated_values[key_name] = np.nan

        self.indicator_values = updated_values

        # --- Log Summary (formatted) ---
        log_vals = {}
        price_prec = self.get_price_precision()
        for k, v in self.indicator_values.items():
            # Log only finite numeric values
            if pd.notna(v) and isinstance(v, (Decimal, float, int)) and np.isfinite(v):
                if isinstance(v, Decimal):
                    prec = price_prec if k in ['Open', 'High', 'Low', 'Close', 'ATR'] else 8
                    log_vals[k] = f"{v:.{prec}f}"
                elif isinstance(v, float): log_vals[k] = f"{v:.5f}"
                else: log_vals[k] = str(v)
            # else: log_vals[k] = "NaN" # Optionally log NaNs

        self.logger.debug(f"Latest values updated ({self.symbol}): {log_vals}")


    def calculate_fibonacci_levels(self, window: Optional[int] = None) -> Dict[str, Decimal]:
        """Calculates Fibonacci levels using Decimal precision."""
        window = window or self.config.get("fibonacci_window", DEFAULT_FIB_WINDOW)
        if len(self.df) < window:
            self.logger.debug(f"Not enough data ({len(self.df)}) for Fibonacci ({window}) on {self.symbol}.")
            self.fib_levels_data = {}; return {}

        df_slice = self.df.tail(window)
        try:
            # Ensure 'high'/'low' are numeric (handle Decimal or float)
            high_series = pd.to_numeric(df_slice["high"], errors='coerce')
            low_series = pd.to_numeric(df_slice["low"], errors='coerce')
            high_price_raw = high_series.dropna().max()
            low_price_raw = low_series.dropna().min()

            if pd.isna(high_price_raw) or pd.isna(low_price_raw):
                self.logger.warning(f"Could not find valid high/low for Fibonacci (Window: {window}).")
                self.fib_levels_data = {}; return {}

            high = Decimal(str(high_price_raw))
            low = Decimal(str(low_price_raw))
            diff = high - low

            levels = {}
            price_precision = self.get_price_precision()
            rounding_factor = Decimal('1e-' + str(price_precision))

            if diff > 0:
                for level_pct in FIB_LEVELS:
                    level_name = f"Fib_{level_pct * 100:.1f}%"
                    # Level price = High - (Range * Percentage)
                    level_price = high - (diff * Decimal(str(level_pct)))
                    # Quantize down from high (conservative support)
                    levels[level_name] = level_price.quantize(rounding_factor, rounding=ROUND_DOWN)
            else: # Handle zero range
                self.logger.debug(f"Fibonacci range is zero (High=Low={high}). Setting all levels to this price.")
                level_price_quantized = high.quantize(rounding_factor, rounding=ROUND_DOWN)
                for level_pct in FIB_LEVELS:
                    levels[f"Fib_{level_pct * 100:.1f}%"] = level_price_quantized

            self.fib_levels_data = levels
            log_levels = {k: str(v) for k, v in levels.items()}
            self.logger.debug(f"Calculated Fibonacci levels (Window: {window}): {log_levels}")
            return levels

        except KeyError as e:
            self.logger.error(f"{NEON_RED}Fibonacci error: Missing column '{e}'.{RESET}")
            self.fib_levels_data = {}; return {}
        except (ValueError, TypeError, InvalidOperation) as e:
             self.logger.error(f"{NEON_RED}Fibonacci error: Invalid data type for high/low. {e}{RESET}")
             self.fib_levels_data = {}; return {}
        except Exception as e:
            self.logger.error(f"{NEON_RED}Unexpected Fibonacci calculation error: {e}{RESET}", exc_info=True)
            self.fib_levels_data = {}; return {}

    def get_price_precision(self) -> int:
        """Determines price precision (decimal places) from market info."""
        try:
            # 1. Check precision.price (most reliable)
            precision_info = self.market_info.get('precision', {})
            price_precision_val = precision_info.get('price')
            if price_precision_val is not None:
                if isinstance(price_precision_val, int) and price_precision_val >= 0:
                    return price_precision_val
                try: # Assume float/str represents tick size
                    tick_size = Decimal(str(price_precision_val))
                    if tick_size.is_finite() and tick_size > 0:
                        return abs(tick_size.normalize().as_tuple().exponent)
                except (TypeError, ValueError, InvalidOperation) as e:
                     self.logger.debug(f"Could not parse precision.price '{price_precision_val}' as tick size: {e}")

            # 2. Fallback: Infer from limits.price.min (less reliable)
            min_price_val = self.market_info.get('limits', {}).get('price', {}).get('min')
            if min_price_val is not None:
                try:
                    min_price_tick = Decimal(str(min_price_val))
                    if min_price_tick.is_finite() and 0 < min_price_tick < Decimal('0.1'): # Heuristic
                        return abs(min_price_tick.normalize().as_tuple().exponent)
                except (TypeError, ValueError, InvalidOperation) as e:
                    self.logger.debug(f"Could not parse limits.price.min '{min_price_val}' for precision: {e}")

            # 3. Fallback: Infer from last close price (least reliable)
            last_close = self.indicator_values.get("Close")
            if isinstance(last_close, Decimal) and last_close.is_finite() and last_close > 0:
                try:
                    precision = abs(last_close.normalize().as_tuple().exponent)
                    if 0 <= precision < 10: return precision # Sanity check
                except Exception: pass

        except Exception as e:
            self.logger.warning(f"Error determining price precision for {self.symbol}: {e}. Falling back.")

        default_precision = 4
        self.logger.warning(f"Could not determine price precision for {self.symbol}. Using default: {default_precision}.")
        return default_precision

    def get_min_tick_size(self) -> Decimal:
        """Gets the minimum price increment (tick size) from market info."""
        try:
            # 1. Try precision.price
            precision_info = self.market_info.get('precision', {})
            price_precision_val = precision_info.get('price')
            if price_precision_val is not None:
                if isinstance(price_precision_val, (float, str, int)):
                     try:
                          if isinstance(price_precision_val, int): # Decimal places
                               if price_precision_val >= 0:
                                    tick = Decimal('1e-' + str(price_precision_val))
                                    if tick.is_finite() and tick > 0: return tick
                          else: # float or str -> Assume it IS the tick size
                               tick = Decimal(str(price_precision_val))
                               if tick.is_finite() and tick > 0: return tick
                     except (TypeError, ValueError, InvalidOperation) as e:
                          self.logger.debug(f"Could not parse precision.price '{price_precision_val}' as tick size: {e}")

            # 2. Fallback: Try limits.price.min
            min_price_val = self.market_info.get('limits', {}).get('price', {}).get('min')
            if min_price_val is not None:
                try:
                    min_tick = Decimal(str(min_price_val))
                    if min_tick.is_finite() and 0 < min_tick < Decimal('0.1'): # Heuristic check
                        return min_tick
                except (TypeError, ValueError, InvalidOperation) as e:
                     self.logger.debug(f"Could not parse limits.price.min '{min_price_val}' for tick size: {e}")

        except Exception as e:
            self.logger.warning(f"Could not determine min tick size for {self.symbol} from market info: {e}.")

        # --- Final Fallback: Calculate from derived decimal places ---
        price_precision_places = self.get_price_precision()
        fallback_tick = Decimal('1e-' + str(price_precision_places))
        self.logger.debug(f"Using fallback tick size based on derived precision ({price_precision_places}): {fallback_tick}")
        return fallback_tick

    def get_amount_precision_places(self) -> int:
        """Determines amount precision (decimal places) from market info."""
        try:
            precision_info = self.market_info.get('precision', {})
            amount_precision_val = precision_info.get('amount')
            if amount_precision_val is not None:
                if isinstance(amount_precision_val, int) and amount_precision_val >= 0:
                    return amount_precision_val
                try: # Assume step size
                    step_size = Decimal(str(amount_precision_val))
                    if step_size.is_finite() and step_size > 0:
                        return abs(step_size.normalize().as_tuple().exponent)
                except (TypeError, ValueError, InvalidOperation): pass

            min_amount_val = self.market_info.get('limits', {}).get('amount', {}).get('min')
            if min_amount_val is not None:
                try:
                    min_amount_step = Decimal(str(min_amount_val))
                    if min_amount_step.is_finite() and 0 < min_amount_step <= Decimal('1'):
                       if min_amount_step < 1: # Looks like step size
                           return abs(min_amount_step.normalize().as_tuple().exponent)
                       elif min_amount_step >= 1 and '.' not in str(min_amount_val): return 0 # Integer min amount likely 0 precision
                except (TypeError, ValueError, InvalidOperation): pass

        except Exception as e:
            self.logger.warning(f"Error determining amount precision for {self.symbol}: {e}.")

        default_precision = 8
        self.logger.warning(f"Could not determine amount precision for {self.symbol}. Using default: {default_precision}.")
        return default_precision

    def get_min_amount_step(self) -> Decimal:
        """Gets the minimum amount increment (step size) from market info."""
        try:
            precision_info = self.market_info.get('precision', {})
            amount_precision_val = precision_info.get('amount')
            if amount_precision_val is not None:
                if isinstance(amount_precision_val, (float, str, int)):
                     try:
                          if isinstance(amount_precision_val, int): # Decimal places
                               if amount_precision_val >= 0:
                                    step = Decimal('1e-' + str(amount_precision_val))
                                    if step.is_finite() and step > 0: return step
                          else: # Float/Str = step size itself
                               step = Decimal(str(amount_precision_val))
                               if step.is_finite() and step > 0: return step
                     except (TypeError, ValueError, InvalidOperation): pass

            min_amount_val = self.market_info.get('limits', {}).get('amount', {}).get('min')
            if min_amount_val is not None:
                try:
                    min_step = Decimal(str(min_amount_val))
                    # Assume min limit IS the step size if it's positive and finite
                    if min_step.is_finite() and min_step > 0: return min_step
                except (TypeError, ValueError, InvalidOperation): pass

        except Exception as e:
            self.logger.warning(f"Could not determine min amount step for {self.symbol}: {e}.")

        amount_precision_places = self.get_amount_precision_places()
        fallback_step = Decimal('1e-' + str(amount_precision_places))
        self.logger.debug(f"Using fallback amount step based on derived precision ({amount_precision_places}): {fallback_step}")
        return fallback_step


    def get_nearest_fibonacci_levels(self, current_price: Decimal, num_levels: int = 5) -> List[Tuple[str, Decimal]]:
        """Finds the N nearest Fibonacci levels to the current price."""
        if not self.fib_levels_data:
            self.logger.debug(f"Fibonacci levels not calculated for {self.symbol}.")
            return []
        if not isinstance(current_price, Decimal) or not current_price.is_finite() or current_price <= 0:
            self.logger.warning(f"Invalid current price ({current_price}) for Fibonacci comparison on {self.symbol}.")
            return []

        try:
            level_distances = []
            for name, level_price in self.fib_levels_data.items():
                if isinstance(level_price, Decimal) and level_price.is_finite() and level_price > 0:
                    distance = abs(current_price - level_price)
                    level_distances.append({'name': name, 'level': level_price, 'distance': distance})
                else:
                    self.logger.warning(f"Invalid Fib level value encountered: {name}={level_price}. Skipping.")

            level_distances.sort(key=lambda x: x['distance'])
            return [(item['name'], item['level']) for item in level_distances[:num_levels]]

        except Exception as e:
            self.logger.error(f"{NEON_RED}Error finding nearest Fibonacci levels for {self.symbol}: {e}{RESET}", exc_info=True)
            return []

    def calculate_ema_alignment_score(self) -> float:
        """Calculates EMA alignment score."""
        ema_s = self.indicator_values.get("EMA_Short") # Float
        ema_l = self.indicator_values.get("EMA_Long") # Float
        close_dec = self.indicator_values.get("Close") # Decimal

        if not (isinstance(ema_s, (float, int)) and np.isfinite(ema_s) and
                isinstance(ema_l, (float, int)) and np.isfinite(ema_l) and
                isinstance(close_dec, Decimal) and close_dec.is_finite()):
            self.logger.debug("EMA alignment check skipped: Missing or non-finite values.")
            return np.nan

        price_f = float(close_dec)
        if price_f > ema_s > ema_l: return 1.0 # Strong Bullish
        elif price_f < ema_s < ema_l: return -1.0 # Strong Bearish
        else: return 0.0 # Mixed / Crossing

    def generate_trading_signal(self, current_price: Decimal, orderbook_data: Optional[Dict]) -> str:
        """Generates final trading signal (BUY/SELL/HOLD) based on weighted score."""
        self.signals = {"BUY": 0, "SELL": 0, "HOLD": 1} # Default HOLD
        final_score = Decimal("0.0")
        total_weight = Decimal("0.0")
        active_count, nan_count = 0, 0
        debug_scores = {}

        # --- Basic Validation ---
        if not self.indicator_values:
            self.logger.warning("Signal Gen: Indicator values empty."); return "HOLD"
        core_ok = any(
            pd.notna(v) and np.isfinite(v)
            for k, v in self.indicator_values.items()
            if k not in ['Open', 'High', 'Low', 'Close', 'Volume'] and float(self.weights.get(k, 0)) != 0
        )
        if not core_ok:
            self.logger.warning("Signal Gen: All weighted core indicators NaN/invalid."); return "HOLD"
        if not isinstance(current_price, Decimal) or not current_price.is_finite() or current_price <= 0:
            self.logger.warning(f"Signal Gen: Invalid current price ({current_price})."); return "HOLD"
        if not self.weights:
            self.logger.error("Signal Gen: Active weight set missing/empty."); return "HOLD"

        # --- Iterate through indicators ---
        for indicator_key, enabled in self.config.get("indicators", {}).items():
            if not enabled: continue
            weight_str = self.weights.get(indicator_key)
            if weight_str is None: continue # No weight defined

            try:
                weight = Decimal(str(weight_str))
                if not weight.is_finite(): raise ValueError("Weight not finite")
                if weight == 0: continue # Skip zero weight
            except (ValueError, TypeError, InvalidOperation):
                self.logger.warning(f"Invalid weight '{weight_str}' for '{indicator_key}'. Skipping."); continue

            check_method_name = f"_check_{indicator_key}"
            score_float = np.nan
            if hasattr(self, check_method_name) and callable(getattr(self, check_method_name)):
                try:
                    method = getattr(self, check_method_name)
                    if indicator_key == "orderbook":
                        if orderbook_data: score_float = method(orderbook_data, current_price)
                        elif weight != 0: self.logger.debug("Orderbook check skipped: No data.")
                    else: score_float = method()
                except Exception as e:
                    self.logger.error(f"Error executing check {check_method_name}: {e}", exc_info=True)
            elif weight != 0:
                self.logger.warning(f"Check method '{check_method_name}' not found for weighted indicator '{indicator_key}'.")

            # Store score for debugging
            debug_scores[indicator_key] = f"{score_float:.3f}" if pd.notna(score_float) and np.isfinite(score_float) else str(score_float)

            # Aggregate score if valid
            if pd.notna(score_float) and np.isfinite(score_float):
                try:
                    score_dec = Decimal(str(score_float))
                    clamped_score = max(Decimal("-1.0"), min(Decimal("1.0"), score_dec))
                    final_score += clamped_score * weight
                    total_weight += weight
                    active_count += 1
                except (ValueError, TypeError, InvalidOperation) as calc_err:
                    self.logger.error(f"Error processing score for {indicator_key}: {calc_err}"); nan_count += 1
            else:
                nan_count += 1

        # --- Determine Final Signal ---
        final_signal = "HOLD"
        if total_weight == 0:
            self.logger.warning(f"No indicators contributed valid scores/weights ({self.symbol}). Defaulting to HOLD.")
        else:
            try:
                threshold_str = self.config.get("signal_score_threshold", "1.5")
                threshold = Decimal(str(threshold_str))
                if not threshold.is_finite() or threshold <= 0: raise ValueError("Threshold non-positive/finite")
            except (ValueError, TypeError, InvalidOperation):
                self.logger.warning(f"Invalid signal_score_threshold '{threshold_str}'. Using default 1.5.")
                threshold = Decimal("1.5")

            if final_score >= threshold: final_signal = "BUY"
            elif final_score <= -threshold: final_signal = "SELL"

        # --- Log Summary ---
        price_prec = self.get_price_precision()
        sig_color = NEON_GREEN if final_signal == "BUY" else NEON_RED if final_signal == "SELL" else NEON_YELLOW
        log_msg = (
            f"Signal Summary ({self.symbol} @ {current_price:.{price_prec}f}): "
            f"Set='{self.active_weight_set_name}', Ind=[Act:{active_count}, NaN:{nan_count}], "
            f"Weight={total_weight:.2f}, Score={final_score:.4f} (Thr: +/-{threshold:.2f}) "
            f"==> {sig_color}{final_signal}{RESET}"
        )
        self.logger.info(log_msg)
        self.logger.debug(f"  Indicator Scores ({self.symbol}): {debug_scores}")

        # Update internal signal state
        if final_signal == "BUY": self.signals = {"BUY": 1, "SELL": 0, "HOLD": 0}
        elif final_signal == "SELL": self.signals = {"BUY": 0, "SELL": 1, "HOLD": 0}
        else: self.signals = {"BUY": 0, "SELL": 0, "HOLD": 1}
        return final_signal

    # --- Indicator Check Methods (return float score -1.0 to 1.0 or np.nan) ---
    # Ensure methods handle potential NaN/inf values from self.indicator_values
    def _check_ema_alignment(self) -> float:
        return self.calculate_ema_alignment_score()

    def _check_momentum(self) -> float:
        momentum = self.indicator_values.get("Momentum")
        if not isinstance(momentum, (float, int)) or not np.isfinite(momentum): return np.nan
        threshold = 0.1 # Example threshold, adjust based on expected MOM range
        if threshold == 0: return 0.0
        score = momentum / threshold
        return max(-1.0, min(1.0, score)) # Clamp

    def _check_volume_confirmation(self) -> float:
        current_volume = self.indicator_values.get("Volume") # Decimal
        volume_ma = self.indicator_values.get("Volume_MA") # Float
        multiplier = float(self.config.get("volume_confirmation_multiplier", 1.5))
        if not (isinstance(current_volume, Decimal) and current_volume.is_finite() and
                isinstance(volume_ma, (float, int)) and np.isfinite(volume_ma) and volume_ma > 0 and multiplier > 0):
            return np.nan
        try:
            volume_ma_dec = Decimal(str(volume_ma)); multiplier_dec = Decimal(str(multiplier))
            if current_volume > volume_ma_dec * multiplier_dec: return 0.7 # High volume
            elif current_volume < volume_ma_dec / multiplier_dec: return -0.4 # Low volume
            else: return 0.0 # Neutral
        except (ValueError, TypeError, InvalidOperation): return np.nan

    def _check_stoch_rsi(self) -> float:
        k = self.indicator_values.get("StochRSI_K")
        d = self.indicator_values.get("StochRSI_D")
        if not (isinstance(k, (float, int)) and np.isfinite(k) and
                isinstance(d, (float, int)) and np.isfinite(d)): return np.nan
        oversold = float(self.config.get("stoch_rsi_oversold_threshold", 25))
        overbought = float(self.config.get("stoch_rsi_overbought_threshold", 75))
        score = 0.0
        if k < oversold and d < oversold: score = 1.0
        elif k > overbought and d > overbought: score = -1.0
        diff = k - d
        if abs(diff) > 5: score = max(score, 0.6) if diff > 0 else min(score, -0.6) # Stronger cross signal
        elif k > d: score = max(score, 0.2) # Mild bullish
        elif k < d: score = min(score, -0.2) # Mild bearish
        if 40 < k < 60: score *= 0.5 # Dampen in neutral zone
        return score

    def _check_rsi(self) -> float:
        rsi = self.indicator_values.get("RSI")
        if not isinstance(rsi, (float, int)) or not np.isfinite(rsi): return np.nan
        if rsi <= 30: return 1.0;   elif rsi >= 70: return -1.0
        if rsi < 40: return 0.5;    elif rsi > 60: return -0.5
        if 40 <= rsi <= 60: return (rsi - 50) / 50.0 # Scale -0.2 to +0.2
        return 0.0

    def _check_cci(self) -> float:
        cci = self.indicator_values.get("CCI")
        if not isinstance(cci, (float, int)) or not np.isfinite(cci): return np.nan
        if cci <= -150: return 1.0; elif cci >= 150: return -1.0
        if cci < -80: return 0.6;   elif cci > 80: return -0.6
        if cci > 0: return -0.1;    elif cci < 0: return 0.1
        return 0.0

    def _check_wr(self) -> float:
        wr = self.indicator_values.get("Williams_R")
        if not isinstance(wr, (float, int)) or not np.isfinite(wr): return np.nan
        if wr <= -80: return 1.0;   elif wr >= -20: return -1.0
        if wr < -50: return 0.4;    elif wr > -50: return -0.4
        return 0.0

    def _check_psar(self) -> float:
        psar_l = self.indicator_values.get("PSAR_long"); psar_s = self.indicator_values.get("PSAR_short")
        l_act = pd.notna(psar_l) and np.isfinite(psar_l)
        s_act = pd.notna(psar_s) and np.isfinite(psar_s)
        if l_act and not s_act: return 1.0 # Long trend
        elif s_act and not l_act: return -1.0 # Short trend
        elif not l_act and not s_act: return np.nan # Indeterminate
        else: self.logger.warning(f"PSAR unusual: L={psar_l}, S={psar_s}"); return 0.0 # Both active? Error.

    def _check_sma_10(self) -> float:
        sma = self.indicator_values.get("SMA10"); close = self.indicator_values.get("Close")
        if not (isinstance(sma, (float, int)) and np.isfinite(sma) and
                isinstance(close, Decimal) and close.is_finite()): return np.nan
        try: sma_dec = Decimal(str(sma))
        except (ValueError, TypeError, InvalidOperation): return np.nan
        if close > sma_dec: return 0.6
        elif close < sma_dec: return -0.6
        else: return 0.0

    def _check_vwap(self) -> float:
        vwap = self.indicator_values.get("VWAP"); close = self.indicator_values.get("Close")
        if not (isinstance(vwap, (float, int)) and np.isfinite(vwap) and
                isinstance(close, Decimal) and close.is_finite()): return np.nan
        try: vwap_dec = Decimal(str(vwap))
        except (ValueError, TypeError, InvalidOperation): return np.nan
        if close > vwap_dec: return 0.7
        elif close < vwap_dec: return -0.7
        else: return 0.0

    def _check_mfi(self) -> float:
        mfi = self.indicator_values.get("MFI")
        if not isinstance(mfi, (float, int)) or not np.isfinite(mfi): return np.nan
        if mfi <= 20: return 1.0;   elif mfi >= 80: return -1.0
        if mfi < 40: return 0.4;    elif mfi > 60: return -0.4
        return 0.0

    def _check_bollinger_bands(self) -> float:
        bbl=self.indicator_values.get("BB_Lower"); bbm=self.indicator_values.get("BB_Middle"); bbu=self.indicator_values.get("BB_Upper")
        close = self.indicator_values.get("Close")
        if not (isinstance(bbl, (float, int)) and np.isfinite(bbl) and
                isinstance(bbm, (float, int)) and np.isfinite(bbm) and
                isinstance(bbu, (float, int)) and np.isfinite(bbu) and
                isinstance(close, Decimal) and close.is_finite()): return np.nan
        try:
            bbl_d, bbm_d, bbu_d = Decimal(str(bbl)), Decimal(str(bbm)), Decimal(str(bbu))
            if bbu_d <= bbl_d: return 0.0 # Avoid division by zero if bands collapse/invalid
        except (ValueError, TypeError, InvalidOperation): return np.nan

        if close <= bbl_d: return 1.0 # Touch/Below Lower -> Buy Signal
        if close >= bbu_d: return -1.0 # Touch/Above Upper -> Sell Signal

        # Scale score based on position between middle and outer bands
        if close > bbm_d: # Above middle
             dist_from_mid = close - bbm_d
             upper_range = bbu_d - bbm_d
             # Score decreases from 0.5 (at mid) to 0.0 (at upper band)
             score = 0.5 * float(1 - (dist_from_mid / upper_range if upper_range > 0 else 0))
             return max(0.0, min(score, 0.5)) # Clamp [0.0, 0.5]
        else: # Below middle
             dist_from_mid = bbm_d - close
             lower_range = bbm_d - bbl_d
             # Score increases from -0.5 (at mid) to 0.0 (at lower band)
             score = -0.5 * float(1 - (dist_from_mid / lower_range if lower_range > 0 else 0))
             return max(-0.5, min(score, 0.0)) # Clamp [-0.5, 0.0]

    def _check_orderbook(self, orderbook_data: Optional[Dict], current_price: Decimal) -> float:
        if not orderbook_data or not orderbook_data.get('bids') or not orderbook_data.get('asks'):
            self.logger.debug("Orderbook check skipped: No data or missing bids/asks.")
            return np.nan
        try:
            bids = orderbook_data['bids']; asks = orderbook_data['asks']
            levels = min(len(bids), len(asks), 10) # Use top 10 levels
            if levels == 0: return 0.0 # Neutral if no common levels

            bid_v = sum(Decimal(str(b[1])) for b in bids[:levels] if len(b)==2)
            ask_v = sum(Decimal(str(a[1])) for a in asks[:levels] if len(a)==2)
            total_v = bid_v + ask_v
            if total_v == 0: return 0.0 # Avoid division by zero

            obi = (bid_v - ask_v) / total_v # Order Book Imbalance ratio
            score = float(max(Decimal("-1.0"), min(Decimal("1.0"), obi))) # Clamp and convert

            self.logger.debug(f"OB Check: Lvl={levels}, BidV={bid_v:.4f}, AskV={ask_v:.4f}, OBI={obi:.4f} -> Score={score:.4f}")
            return score
        except (IndexError, ValueError, TypeError, InvalidOperation) as e:
             self.logger.warning(f"Orderbook analysis failed: {e}", exc_info=True); return np.nan

    def calculate_entry_tp_sl(
        self, entry_price_estimate: Decimal, signal: str
    ) -> Tuple[Optional[Decimal], Optional[Decimal], Optional[Decimal]]:
        """Calculates potential TP and initial SL based on entry estimate, signal, and ATR."""
        if signal not in ["BUY", "SELL"]: return entry_price_estimate, None, None
        atr = self.indicator_values.get("ATR") # Decimal
        if not isinstance(atr, Decimal) or not atr.is_finite() or atr <= 0:
            self.logger.warning(f"Calc TP/SL Fail ({signal}): Invalid ATR ({atr})."); return entry_price_estimate, None, None
        if not isinstance(entry_price_estimate, Decimal) or not entry_price_estimate.is_finite() or entry_price_estimate <= 0:
            self.logger.warning(f"Calc TP/SL Fail ({signal}): Invalid entry estimate ({entry_price_estimate})."); return entry_price_estimate, None, None

        try:
            tp_mult = Decimal(str(self.config.get("take_profit_multiple", "1.0")))
            sl_mult = Decimal(str(self.config.get("stop_loss_multiple", "1.5")))
            prec = self.get_price_precision()
            rnd = Decimal('1e-' + str(prec))
            tick = self.get_min_tick_size()

            tp_off = atr * tp_mult; sl_off = atr * sl_mult
            tp_raw, sl_raw = None, None

            if signal == "BUY": tp_raw, sl_raw = entry_price_estimate + tp_off, entry_price_estimate - sl_off
            else: tp_raw, sl_raw = entry_price_estimate - tp_off, entry_price_estimate + sl_off

            # Quantize TP/SL using market precision
            # Round TP towards neutral (less profit), SL away from neutral (more room)
            tp_q = tp_raw.quantize(rnd, rounding=ROUND_DOWN if signal=="BUY" else ROUND_UP) if tp_raw else None
            sl_q = sl_raw.quantize(rnd, rounding=ROUND_DOWN if signal=="BUY" else ROUND_UP) if sl_raw else None

            # --- Validation & Adjustment ---
            final_tp, final_sl = tp_q, sl_q
            # Ensure SL is strictly beyond entry by at least one tick
            if final_sl:
                if signal == "BUY" and final_sl >= entry_price_estimate:
                    final_sl = (entry_price_estimate - tick).quantize(rnd, rounding=ROUND_DOWN)
                    self.logger.debug(f"Adjusted BUY SL below entry: {tp_q} -> {final_sl}")
                elif signal == "SELL" and final_sl <= entry_price_estimate:
                    final_sl = (entry_price_estimate + tick).quantize(rnd, rounding=ROUND_UP)
                    self.logger.debug(f"Adjusted SELL SL above entry: {tp_q} -> {final_sl}")

            # Ensure TP offers profit (strictly beyond entry)
            if final_tp:
                 if signal == "BUY" and final_tp <= entry_price_estimate:
                      self.logger.warning(f"BUY TP {final_tp} <= Entry {entry_price_estimate}. Nullifying TP."); final_tp = None
                 elif signal == "SELL" and final_tp >= entry_price_estimate:
                      self.logger.warning(f"SELL TP {final_tp} >= Entry {entry_price_estimate}. Nullifying TP."); final_tp = None

            # Ensure SL/TP are positive
            if final_sl and final_sl <= 0: self.logger.error(f"SL calc non-positive ({final_sl}). Nullifying SL."); final_sl = None
            if final_tp and final_tp <= 0: self.logger.warning(f"TP calc non-positive ({final_tp}). Nullifying TP."); final_tp = None

            tp_str = f"{final_tp:.{prec}f}" if final_tp else "None"; sl_str = f"{final_sl:.{prec}f}" if final_sl else "None"
            self.logger.debug(f"Calc TP/SL ({signal}): Entry={entry_price_estimate:.{prec}f}, ATR={atr:.{prec+2}f}, TP={tp_str}, SL={sl_str}")
            return entry_price_estimate, final_tp, final_sl
        except Exception as e:
            self.logger.error(f"Unexpected error calculating TP/SL: {e}", exc_info=True)
            return entry_price_estimate, None, None

# --- Trading Logic Helper Functions ---
# (fetch_balance, get_market_info, calculate_position_size, get_open_position,
# set_leverage_ccxt, place_trade, _set_position_protection, set_trailing_stop_loss
# remain largely unchanged from the input, assuming they are functional and robust
# as implemented in the provided `sx.py`.)

# --- Main Analysis and Trading Loop ---
def analyze_and_trade_symbol(exchange: ccxt.Exchange, symbol: str, config: Dict[str, Any], logger: logging.Logger) -> None:
    """Performs one cycle of analysis and trading logic for a single symbol."""
    lg = logger
    lg.info(f"---== Analyzing {symbol} ({config['interval']}) Cycle Start ==---")
    cycle_start_time = time.monotonic()

    try:
        # --- Get Market Info (Critical) ---
        market_info = get_market_info(exchange, symbol, lg)
        if not market_info: raise ValueError(f"Fatal: Failed to get market info for {symbol}.")

        # --- Fetch Data ---
        ccxt_interval = CCXT_INTERVAL_MAP.get(config["interval"])
        if not ccxt_interval: raise ValueError(f"Invalid interval '{config['interval']}'.")
        klines_df = fetch_klines_ccxt(exchange, symbol, ccxt_interval, limit=500, logger=lg)
        if klines_df.empty or len(klines_df) < 50: raise ValueError(f"Insufficient kline data ({len(klines_df)}).")

        current_price = fetch_current_price_ccxt(exchange, symbol, lg)
        if current_price is None: # Fallback to last close
             lg.warning("Using last close from klines as current price.")
             try:
                 last_close = klines_df['close'].iloc[-1] # Assumes klines_df uses Decimal
                 if not isinstance(last_close, Decimal) or not last_close.is_finite():
                     raise ValueError("Last close is not a valid Decimal.")
                 current_price = last_close
                 if current_price <= 0: raise ValueError("Last close price non-positive.")
             except (IndexError, KeyError, ValueError, TypeError, InvalidOperation) as e:
                 raise ValueError(f"Failed to get valid last close price: {e}")

        # Fetch order book if needed for scoring
        orderbook_data = None
        active_weights = config.get("weight_sets", {}).get(config.get("active_weight_set", "default"), {})
        if config.get("indicators",{}).get("orderbook", False) and float(active_weights.get("orderbook", 0)) != 0:
            orderbook_data = fetch_orderbook_ccxt(exchange, symbol, config["orderbook_limit"], lg)
            if not orderbook_data: lg.warning(f"Failed orderbook fetch for {symbol}. Proceeding without.")

        # --- Analyze Data & Generate Signal ---
        analyzer = TradingAnalyzer(klines_df.copy(), lg, config, market_info)
        if not analyzer.indicator_values: raise ValueError("Indicator calculation failed.")
        signal = analyzer.generate_trading_signal(current_price, orderbook_data)

        # --- Calculate Potential TP/SL & Log Summary ---
        _, tp_calc, sl_calc = analyzer.calculate_entry_tp_sl(current_price, signal)
        price_prec = analyzer.get_price_precision(); current_atr = analyzer.indicator_values.get("ATR")
        lg.info(f"Current Price: {current_price:.{price_prec}f}")
        lg.info(f"ATR: {current_atr:.{price_prec+2}f}" if isinstance(current_atr, Decimal) else 'ATR: N/A')
        lg.info(f"Calc Initial SL (sizing): {sl_calc or 'N/A'}, TP (target): {tp_calc or 'N/A'}")
        lg.info(f"Mgmt: TSL={'On' if config['enable_trailing_stop'] else 'Off'}, BE={'On' if config['enable_break_even'] else 'Off'}, TimeExit={config.get('time_based_exit_minutes') or 'Off'}")

        # --- Trading Execution Logic ---
        if not config.get("enable_trading"):
            lg.debug("Trading disabled. Cycle complete."); return

        open_position = get_open_position(exchange, symbol, lg)

        # --- Scenario 1: No Open Position ---
        if open_position is None:
            if signal in ["BUY", "SELL"]:
                lg.info(f"*** {signal} Signal & No Position: Initiating Trade Sequence ***")
                balance = fetch_balance(exchange, config["quote_currency"], lg)
                if balance is None or balance <= 0: raise ValueError("Balance fetch failed or zero/negative.")
                if sl_calc is None: raise ValueError("Initial SL calculation failed (required for sizing).")

                if market_info.get('is_contract') and int(config.get("leverage", 0)) > 0:
                    if not set_leverage_ccxt(exchange, symbol, int(config["leverage"]), market_info, lg):
                        raise ValueError("Failed to set leverage.")

                pos_size = calculate_position_size(balance, config["risk_per_trade"], sl_calc, current_price, market_info, exchange, lg)
                if pos_size is None or pos_size <= 0: raise ValueError(f"Position size calculation failed ({pos_size}).")

                # --- Place Order (Market or Limit) ---
                entry_type = config.get("entry_order_type", "market"); limit_px = None
                if entry_type == "limit":
                     try:
                         offset = Decimal(str(config[f"limit_order_offset_{signal.lower()}"]))
                         rnd_f = Decimal(f'1e-{price_prec}')
                         raw_px = current_price * (1 - offset if signal=='BUY' else 1 + offset)
                         limit_px = raw_px.quantize(rnd_f, rounding=ROUND_DOWN if signal=='BUY' else ROUND_UP)
                         if limit_px <= 0: raise ValueError("Limit price non-positive")
                         lg.info(f"Calc Limit Entry for {signal}: {limit_px}")
                     except (KeyError, ValueError, InvalidOperation) as e:
                          lg.error(f"Limit price calc failed ({e}). Switching to Market."); entry_type="market"; limit_px=None

                trade_order = place_trade(exchange, symbol, signal, pos_size, market_info, lg, entry_type, limit_px)

                # --- Post-Order Handling ---
                if trade_order and trade_order.get('id'):
                    order_id, status = trade_order['id'], trade_order.get('status')
                    # If filled immediately (market or fast limit)
                    if status == 'closed' or entry_type == 'market':
                        delay = config["position_confirm_delay_seconds"] if entry_type=='market' else 2
                        lg.info(f"Order {order_id} placed/filled. Waiting {delay}s for confirmation...")
                        time.sleep(delay)
                        confirmed_pos = get_open_position(exchange, symbol, lg)
                        if confirmed_pos:
                            lg.info(f"{NEON_GREEN}Position Confirmed!{RESET}")
                            # --- Set Protection ---
                            try:
                                entry_act = confirmed_pos.get('entryPriceDecimal') or current_price # Use actual or estimate
                                lg.info(f"Actual Entry ~ {entry_act:.{price_prec}f}")
                                _, tp_final, sl_final = analyzer.calculate_entry_tp_sl(entry_act, signal) # Recalculate based on actual entry
                                protection_ok = False
                                if config["enable_trailing_stop"]:
                                     lg.info(f"Setting TSL (TP target: {tp_final})...")
                                     protection_ok = set_trailing_stop_loss(exchange, symbol, market_info, confirmed_pos, config, lg, tp_final)
                                elif sl_final or tp_final: # Use fixed if TSL disabled AND calc valid
                                     lg.info(f"Setting Fixed SL ({sl_final}) / TP ({tp_final})...")
                                     protection_ok = _set_position_protection(exchange, symbol, market_info, confirmed_pos, lg, sl_final, tp_final)
                                else: lg.warning("No valid protection calculated (TSL disabled or calc failed).")

                                if protection_ok: lg.info(f"{NEON_GREEN}=== TRADE ENTRY & PROTECTION COMPLETE ({symbol} {signal}) ===")
                                else: lg.error(f"{NEON_RED}=== TRADE PLACED BUT PROTECTION FAILED ({symbol} {signal}) ===\n{NEON_YELLOW}>>> MANUAL MONITORING REQUIRED! <<<")
                            except Exception as post_err:
                                 lg.error(f"Error setting protection: {post_err}", exc_info=True); lg.warning(f"{NEON_YELLOW}Position open, manual check needed!{RESET}")
                        else: lg.error(f"{NEON_RED}Order {order_id} placed/filled BUT POSITION NOT CONFIRMED! Manual check!{RESET}")
                    # If limit order is open
                    elif status == 'open' and entry_type == 'limit':
                         lg.info(f"Limit order {order_id} OPEN. Will check status next cycle.")
                         # TODO: Optionally add logic to track open orders and cancel if stale
                    else: # Order failed or other status
                         lg.error(f"Order {order_id} status: {status}. Trade did not open as expected.")
                else: # place_trade failed
                     lg.error(f"{NEON_RED}=== TRADE EXECUTION FAILED. Order placement error. ===")
            else: lg.info("Signal HOLD, no position. No action.")

        # --- Scenario 2: Existing Open Position ---
        else:
            pos_side = open_position['side']; pos_size = open_position['contractsDecimal']
            entry_price = open_position['entryPriceDecimal']; pos_ts_ms = open_position['timestamp_ms']
            lg.info(f"Managing existing {pos_side.upper()} position. Size: {pos_size}, Entry: {entry_price}")

            # --- Check for Exit Signal (Opposite Direction) ---
            if (pos_side == 'long' and signal == "SELL") or (pos_side == 'short' and signal == "BUY"):
                lg.warning(f"{NEON_YELLOW}*** EXIT Signal ({signal}) opposes {pos_side} position. Closing... ***{RESET}")
                try:
                    close_sig = "SELL" if pos_side == 'long' else "BUY"
                    size_close = abs(pos_size)
                    if size_close <= 0: raise ValueError("Position size is zero/negative.")
                    lg.info(f"==> Placing {close_sig} MARKET order (reduceOnly=True) | Size: {size_close} <==")
                    close_order = place_trade(exchange, symbol, close_sig, size_close, market_info, lg, 'market', reduce_only=True)
                    if close_order: lg.info(f"{NEON_GREEN}Close order placed successfully. ID: {close_order.get('id','?')}{RESET}")
                    else: lg.error(f"{NEON_RED}Failed placing CLOSE order! Manual check!{RESET}")
                except Exception as close_err:
                    lg.error(f"Error closing position: {close_err}", exc_info=True); lg.warning(f"{NEON_YELLOW}Manual close may be needed!{RESET}")
                return # Exit cycle after close attempt

            # --- Check for Time-Based Exit ---
            time_exit = config.get("time_based_exit_minutes")
            if isinstance(time_exit, (int, float)) and time_exit > 0 and pos_ts_ms:
                 try:
                      elapsed_mins = (time.time() * 1000 - pos_ts_ms) / 60000
                      lg.debug(f"Time Exit Check: Elapsed={elapsed_mins:.2f}m, Limit={time_exit}m")
                      if elapsed_mins >= time_exit:
                           lg.warning(f"{NEON_YELLOW}*** TIME-BASED EXIT ({elapsed_mins:.1f} >= {time_exit}m). Closing... ***{RESET}")
                           # Execute Close Logic (identical to signal-based exit)
                           close_sig = "SELL" if pos_side == 'long' else "BUY"
                           size_close = abs(pos_size)
                           if size_close <= 0: raise ValueError("Position size is zero/negative.")
                           close_order = place_trade(exchange, symbol, close_sig, size_close, market_info, lg, 'market', reduce_only=True)
                           if close_order: lg.info(f"{NEON_GREEN}Time-based CLOSE order placed. ID: {close_order.get('id','?')}{RESET}")
                           else: lg.error(f"{NEON_RED}Failed time-based CLOSE order! Manual check!{RESET}")
                           return # Exit cycle
                 except Exception as time_err: lg.error(f"Error in time exit check: {time_err}")

            # --- Position Management (Break-Even) ---
            # Check if TSL is already active on the exchange
            is_tsl_active = open_position.get('trailingStopLossValueDecimal') is not None
            if config["enable_break_even"] and not is_tsl_active:
                 lg.debug("Checking Break-Even conditions...")
                 try:
                     if entry_price is None or entry_price <= 0: raise ValueError("Invalid entry price for BE")
                     if not isinstance(current_atr, Decimal) or not current_atr.is_finite() or current_atr <= 0: raise ValueError("Invalid ATR for BE")

                     be_trig_atr = Decimal(str(config["break_even_trigger_atr_multiple"]))
                     be_off_ticks = int(config["break_even_offset_ticks"])
                     min_tick = analyzer.get_min_tick_size()

                     price_diff = current_price - entry_price if pos_side == 'long' else entry_price - current_price
                     profit_atr = price_diff / current_atr if current_atr > 0 else Decimal(0)
                     lg.debug(f"BE Check: ProfitATRs={profit_atr:.2f}, TargetATRs={be_trig_atr}")

                     if profit_atr >= be_trig_atr:
                          tick_off = min_tick * be_off_ticks
                          be_sl = (entry_price + tick_off).quantize(min_tick, ROUND_UP) if pos_side=='long' else \
                                  (entry_price - tick_off).quantize(min_tick, ROUND_DOWN)
                          if be_sl <= 0: raise ValueError(f"Calculated BE SL non-positive ({be_sl})")

                          curr_sl = open_position.get('stopLossPriceDecimal')
                          update_needed = False
                          if curr_sl is None: update_needed = True; lg.info("BE triggered: No current SL.")
                          elif pos_side=='long' and be_sl > curr_sl: update_needed = True; lg.info(f"BE triggered: Target {be_sl} > Current {curr_sl}.")
                          elif pos_side=='short' and be_sl < curr_sl: update_needed = True; lg.info(f"BE triggered: Target {be_sl} < Current {curr_sl}.")
                          else: lg.debug(f"BE triggered but current SL {curr_sl} already adequate.")

                          if update_needed:
                               lg.warning(f"{NEON_PURPLE}*** Moving SL to Break-Even ({symbol} @ {be_sl}) ***{RESET}")
                               curr_tp = open_position.get('takeProfitPriceDecimal') # Preserve existing TP
                               success = _set_position_protection(exchange, symbol, market_info, open_position, lg, be_sl, curr_tp)
                               if success: lg.info(f"{NEON_GREEN}Break-Even SL updated.{RESET}")
                               else: lg.error(f"{NEON_RED}Failed updating Break-Even SL.{RESET}")
                     else: lg.debug("BE Profit target not reached.")
                 except ValueError as ve: lg.warning(f"BE Check skipped: {ve}")
                 except Exception as be_err: lg.error(f"Error during BE check: {be_err}", exc_info=True)
            elif is_tsl_active: lg.debug("BE check skipped: TSL active.")
            else: lg.debug("BE check skipped: Disabled in config.")

            # Placeholder for other potential management logic
            # lg.debug("End of position management checks.")

    # --- Error Handling for the entire cycle ---
    except ValueError as data_err: # Catch data/config related errors
        lg.error(f"{NEON_RED}Data/Config Error ({symbol}): {data_err}. Skipping cycle.{RESET}")
    except ccxt.AuthenticationError as auth_err: # Catch critical auth errors
         lg.critical(f"{NEON_RED}CRITICAL: Authentication Failed: {auth_err}. Stopping bot.{RESET}")
         raise SystemExit("Authentication Failed") # Stop the bot
    except (ccxt.NetworkError, ccxt.RequestTimeout, ccxt.ExchangeNotAvailable, ccxt.DDoSProtection) as net_err:
         lg.error(f"{NEON_RED}Network/Exchange Availability Error ({symbol}): {net_err}. Skipping cycle.{RESET}")
    except Exception as cycle_err: # Catch unexpected errors
        lg.error(f"{NEON_RED}Unexpected Cycle Error ({symbol}): {cycle_err}{RESET}", exc_info=True)
        # Decide behavior: continue or stop? For now, just log and continue.

    finally:
        # --- Cycle End Logging ---
        cycle_end_time = time.monotonic()
        lg.debug(f"---== Analysis Cycle End ({symbol}, {cycle_end_time - cycle_start_time:.2f}s) ==---")


def main() -> None:
    """Main function to initialize the bot and run the analysis loop."""
    global CONFIG, QUOTE_CURRENCY # Allow modification of globals

    # Setup initial logger
    init_logger = setup_logger("ScalpXRX_Init", level=logging.INFO)
    start_time_str = datetime.now(TIMEZONE).strftime('%Y-%m-%d %H:%M:%S %Z')
    init_logger.info(f"--- Starting ScalpXRX Bot ({start_time_str}) ---")

    try:
        CONFIG = load_config(CONFIG_FILE)
        QUOTE_CURRENCY = CONFIG.get("quote_currency", "USDT")
        TARGET_SYMBOL = CONFIG.get("symbol")

        if not TARGET_SYMBOL:
            init_logger.critical("CRITICAL: 'symbol' not defined in config.json. Exiting.")
            return

        # Setup logger specific to the target symbol for the main loop
        safe_symbol_name = TARGET_SYMBOL.replace('/', '_').replace(':', '-')
        symbol_logger_name = f"ScalpXRX_{safe_symbol_name}"
        main_logger = setup_logger(symbol_logger_name, level=logging.INFO) # Use INFO for console by default
        main_logger.info(f"Logging initialized for symbol: {TARGET_SYMBOL}")
        main_logger.info(f"Config loaded. Quote: {QUOTE_CURRENCY}, Interval: {CONFIG['interval']}")
        try: ta_version = ta.version
        except: ta_version = "N/A"
        main_logger.info(f"Versions: CCXT={ccxt.__version__}, Pandas={pd.__version__}, PandasTA={ta_version}")


        # --- Trading Enabled Warning ---
        if CONFIG.get("enable_trading"):
            main_logger.warning(f"{NEON_YELLOW}!!! LIVE TRADING IS ENABLED !!!{RESET}")
            env_type = "SANDBOX (Testnet)" if CONFIG.get("use_sandbox") else f"{NEON_RED}!!! REAL MONEY !!!"
            main_logger.warning(f"Environment: {env_type}{RESET}")
            risk_pct = CONFIG.get('risk_per_trade', 0) * 100
            lev = CONFIG.get('leverage', 1)
            main_logger.warning(f"Settings: Risk/Trade={risk_pct:.2f}%, Leverage={lev}x")
            for i in range(3, 0, -1):
                main_logger.warning(f"Starting in {i}...")
                time.sleep(1)
        else:
            main_logger.info("Trading is disabled in config. Running in analysis-only mode.")

        # --- Initialize Exchange ---
        exchange = initialize_exchange(CONFIG, main_logger)
        if not exchange:
            main_logger.critical("Failed to initialize exchange. Exiting.")
            return

        # --- Main Loop ---
        main_logger.info(f"Starting main analysis loop for {TARGET_SYMBOL}...")
        loop_interval = max(1, CONFIG.get("loop_delay_seconds", LOOP_DELAY_SECONDS)) # Ensure positive delay
        while True:
            try:
                analyze_and_trade_symbol(exchange, TARGET_SYMBOL, CONFIG, main_logger)
            except SystemExit as e: # Catch SystemExit for clean shutdown
                 main_logger.critical(f"SystemExit triggered: {e}. Shutting down.")
                 break
            except KeyboardInterrupt: # Allow Ctrl+C to break loop
                 main_logger.info("KeyboardInterrupt detected in loop. Shutting down.")
                 break
            except Exception as loop_err:
                # Catch unexpected errors from analyze_and_trade_symbol if they weren't caught internally
                main_logger.error(f"{NEON_RED}Error in main loop iteration: {loop_err}{RESET}", exc_info=True)
                # Decide whether to continue or stop based on the error type?
                # For now, log and continue, but could add logic to stop on critical errors.

            # Delay before next cycle
            main_logger.debug(f"Waiting {loop_interval} seconds before next cycle...")
            time.sleep(loop_interval)

    except KeyboardInterrupt:
        init_logger.info("KeyboardInterrupt received during startup/shutdown. Shutting down...")
    except Exception as startup_err:
        init_logger.critical(f"Critical error during startup: {startup_err}", exc_info=True)
    finally:
        end_time_str = datetime.now(TIMEZONE).strftime('%Y-%m-%d %H:%M:%S %Z')
        init_logger.info(f"--- ScalpXRX Bot Shutdown ({end_time_str}) ---")
        logging.shutdown() # Ensure all logs are flushed


if __name__ == "__main__":
    main()

```python
# scalpxrx.py
# Enhanced and Upgraded Scalping Bot Framework
# Derived from xrscalper.py, focusing on robust execution, error handling,
# advanced position management (BE, TSL), and Bybit V5 compatibility.

import hashlib
import hmac
import json
import logging
import math
import os
import time
from datetime import datetime, timedelta, timezone
from decimal import ROUND_DOWN, ROUND_UP, Decimal, InvalidOperation, getcontext
from logging.handlers import RotatingFileHandler
from typing import Any, Dict, List, Optional, Tuple, Union

import ccxt
import numpy as np
import pandas as pd
import pandas_ta as ta  # Import pandas_ta
import requests
from colorama import Fore, Style, init
from dotenv import load_dotenv
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from zoneinfo import ZoneInfo

# Initialize colorama and set Decimal precision
getcontext().prec = 36  # Increased precision for complex calculations
init(autoreset=True)
load_dotenv()

# Neon Color Scheme
NEON_GREEN = Fore.LIGHTGREEN_EX
NEON_BLUE = Fore.CYAN
NEON_PURPLE = Fore.MAGENTA
NEON_YELLOW = Fore.YELLOW
NEON_RED = Fore.LIGHTRED_EX
NEON_CYAN = Fore.CYAN
RESET = Style.RESET_ALL

# --- Constants ---
API_KEY = os.getenv("BYBIT_API_KEY")
API_SECRET = os.getenv("BYBIT_API_SECRET")
if not API_KEY or not API_SECRET:
    raise ValueError("BYBIT_API_KEY and BYBIT_API_SECRET must be set in .env")

CONFIG_FILE = "config.json"
LOG_DIRECTORY = "bot_logs"
# Timezone for logging and display
TIMEZONE = ZoneInfo("America/Chicago")  # Adjust as needed
MAX_API_RETRIES = 5  # Max retries for recoverable API errors
RETRY_DELAY_SECONDS = 7  # Increased delay between retries
VALID_INTERVALS = ["1", "3", "5", "15", "30", "60", "120", "240", "D", "W", "M"]
CCXT_INTERVAL_MAP = { # Map our intervals to ccxt's expected format
    "1": "1m", "3": "3m", "5": "5m", "15": "15m", "30": "30m",
    "60": "1h", "120": "2h", "240": "4h", "D": "1d", "W": "1w", "M": "1M"
}
RETRY_ERROR_CODES = [429, 500, 502, 503, 504] # HTTP status codes considered retryable
# Default indicator periods (can be overridden by config.json)
DEFAULT_ATR_PERIOD = 14
DEFAULT_CCI_WINDOW = 20
DEFAULT_WILLIAMS_R_WINDOW = 14
DEFAULT_MFI_WINDOW = 14
DEFAULT_STOCH_RSI_WINDOW = 14
DEFAULT_STOCH_WINDOW = 12
DEFAULT_K_WINDOW = 3
DEFAULT_D_WINDOW = 3
DEFAULT_RSI_WINDOW = 14
DEFAULT_BOLLINGER_BANDS_PERIOD = 20
DEFAULT_BOLLINGER_BANDS_STD_DEV = 2.0
DEFAULT_SMA_10_WINDOW = 10
DEFAULT_EMA_SHORT_PERIOD = 9
DEFAULT_EMA_LONG_PERIOD = 21
DEFAULT_MOMENTUM_PERIOD = 7
DEFAULT_VOLUME_MA_PERIOD = 15
DEFAULT_FIB_WINDOW = 50
DEFAULT_PSAR_AF = 0.02
DEFAULT_PSAR_MAX_AF = 0.2

FIB_LEVELS = [0.0, 0.236, 0.382, 0.5, 0.618, 0.786, 1.0] # Standard Fibonacci levels
LOOP_DELAY_SECONDS = 10 # Time between the end of one cycle and the start of the next
POSITION_CONFIRM_DELAY_SECONDS = 10 # Increased wait time after placing order before confirming position
# QUOTE_CURRENCY dynamically loaded from config

os.makedirs(LOG_DIRECTORY, exist_ok=True)

class SensitiveFormatter(logging.Formatter):
    """Formatter to redact sensitive information (API keys) from logs."""
    def format(self, record: logging.LogRecord) -> str:
        msg = super().format(record)
        if API_KEY:
            msg = msg.replace(API_KEY, "***API_KEY***")
        if API_SECRET:
            msg = msg.replace(API_SECRET, "***API_SECRET***")
        return msg

def load_config(filepath: str) -> Dict[str, Any]:
    """
    Load configuration from JSON file, creating default if not found,
    and ensuring all default keys are present with validation.
    """
    # Define the default configuration structure and values
    default_config = {
        # Trading pair and timeframe
        "symbol": "BTC/USDT:USDT", # Bybit linear perpetual example
        "interval": "5", # Default timeframe (e.g., "5" for 5 minutes)

        # API and Bot Behavior
        "retry_delay": RETRY_DELAY_SECONDS, # Delay between API retries
        "enable_trading": False, # Safety Feature: Must be explicitly set to true to trade
        "use_sandbox": True, # Safety Feature: Use testnet by default
        "max_concurrent_positions": 1, # Max open positions for this symbol instance
        "quote_currency": "USDT", # Quote currency for balance checks and sizing
        "position_confirm_delay_seconds": POSITION_CONFIRM_DELAY_SECONDS, # Delay after order before confirming position
        "loop_delay_seconds": LOOP_DELAY_SECONDS, # Delay between main loop cycles

        # Risk Management
        "risk_per_trade": 0.01, # Fraction of balance to risk (e.g., 0.01 = 1%)
        "leverage": 20, # Desired leverage (Ensure supported by exchange/market)
        "stop_loss_multiple": 1.8, # ATR multiple for initial SL (used for sizing/initial fixed SL)
        "take_profit_multiple": 0.7, # ATR multiple for initial TP

        # Order Execution
        "entry_order_type": "market", # "market" or "limit"
        "limit_order_offset_buy": 0.0005, # % offset from price for BUY limit (0.0005 = 0.05%)
        "limit_order_offset_sell": 0.0005, # % offset from price for SELL limit

        # Advanced Position Management
        "enable_trailing_stop": True, # Use exchange-native Trailing Stop Loss
        "trailing_stop_callback_rate": 0.005, # Trail distance % (e.g., 0.005 = 0.5%)
        "trailing_stop_activation_percentage": 0.003, # % profit move from entry to activate TSL
        "enable_break_even": True, # Enable moving SL to break-even point
        "break_even_trigger_atr_multiple": 1.0, # Move SL when profit >= X * ATR
        "break_even_offset_ticks": 2, # Place BE SL X ticks beyond entry price
        "time_based_exit_minutes": None, # Optional: Exit after X minutes (e.g., 60)

        # Indicator Periods & Parameters
        "atr_period": DEFAULT_ATR_PERIOD,
        "ema_short_period": DEFAULT_EMA_SHORT_PERIOD,
        "ema_long_period": DEFAULT_EMA_LONG_PERIOD,
        "rsi_period": DEFAULT_RSI_WINDOW,
        "bollinger_bands_period": DEFAULT_BOLLINGER_BANDS_PERIOD,
        "bollinger_bands_std_dev": DEFAULT_BOLLINGER_BANDS_STD_DEV,
        "cci_window": DEFAULT_CCI_WINDOW,
        "williams_r_window": DEFAULT_WILLIAMS_R_WINDOW,
        "mfi_window": DEFAULT_MFI_WINDOW,
        "stoch_rsi_window": DEFAULT_STOCH_RSI_WINDOW, # StochRSI main window
        "stoch_rsi_rsi_window": DEFAULT_STOCH_WINDOW, # Underlying RSI window for StochRSI
        "stoch_rsi_k": DEFAULT_K_WINDOW, # StochRSI K period
        "stoch_rsi_d": DEFAULT_D_WINDOW, # StochRSI D period
        "psar_af": DEFAULT_PSAR_AF, # PSAR Acceleration Factor
        "psar_max_af": DEFAULT_PSAR_MAX_AF, # PSAR Max Acceleration Factor
        "sma_10_window": DEFAULT_SMA_10_WINDOW,
        "momentum_period": DEFAULT_MOMENTUM_PERIOD,
        "volume_ma_period": DEFAULT_VOLUME_MA_PERIOD,
        "fibonacci_window": DEFAULT_FIB_WINDOW,

        # Indicator Calculation & Scoring Control
        "orderbook_limit": 25, # Depth of order book levels to fetch/analyze
        "signal_score_threshold": 1.5, # Score needed to trigger BUY/SELL signal
        "stoch_rsi_oversold_threshold": 25, # Threshold for StochRSI oversold score
        "stoch_rsi_overbought_threshold": 75, # Threshold for StochRSI overbought score
        "volume_confirmation_multiplier": 1.5, # Volume > Multiplier * VolMA for confirmation
        "scalping_signal_threshold": 2.5, # Alternative threshold for specific weight sets (if needed)
        "indicators": { # Toggle calculation and scoring contribution
            "ema_alignment": True, "momentum": True, "volume_confirmation": True,
            "stoch_rsi": True, "rsi": True, "bollinger_bands": True, "vwap": True,
            "cci": True, "wr": True, "psar": True, "sma_10": True, "mfi": True,
            "orderbook": True,
        },
        "weight_sets": { # Define scoring weights for different strategies
            "scalping": { # Example: Faster, momentum-focused
                "ema_alignment": 0.2, "momentum": 0.3, "volume_confirmation": 0.2,
                "stoch_rsi": 0.6, "rsi": 0.2, "bollinger_bands": 0.3, "vwap": 0.4,
                "cci": 0.3, "wr": 0.3, "psar": 0.2, "sma_10": 0.1, "mfi": 0.2, "orderbook": 0.15,
            },
            "default": { # Example: Balanced
                "ema_alignment": 0.3, "momentum": 0.2, "volume_confirmation": 0.1,
                "stoch_rsi": 0.4, "rsi": 0.3, "bollinger_bands": 0.2, "vwap": 0.3,
                "cci": 0.2, "wr": 0.2, "psar": 0.3, "sma_10": 0.1, "mfi": 0.2, "orderbook": 0.1,
            }
        },
        "active_weight_set": "default" # Select the active weight set
    }

    config = default_config.copy()
    if os.path.exists(filepath):
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                loaded_config = json.load(f)
            # Merge loaded config with defaults, ensuring all keys exist
            config = _merge_configs(loaded_config, default_config)
            print(f"{NEON_GREEN}Loaded configuration from {filepath}{RESET}")
        except (json.JSONDecodeError, IOError) as e:
            print(f"{NEON_RED}Error loading config file {filepath}: {e}. Using default config.{RESET}")
            # Attempt to recreate default file if loading failed
            try:
                with open(filepath, "w", encoding="utf-8") as f_write:
                    json.dump(default_config, f_write, indent=4)
                print(f"{NEON_YELLOW}Recreated default config file: {filepath}{RESET}")
            except IOError as e_create:
                print(f"{NEON_RED}Error recreating default config file: {e_create}{RESET}")
            config = default_config # Use in-memory default
    else:
        # Config file doesn't exist, create it with defaults
        print(f"{NEON_YELLOW}Config file not found. Creating default config at {filepath}{RESET}")
        try:
            with open(filepath, "w", encoding="utf-8") as f:
                json.dump(default_config, f, indent=4)
            config = default_config
        except IOError as e:
            print(f"{NEON_RED}Error creating default config file {filepath}: {e}{RESET}")
            # Continue with in-memory default config if creation fails

    # --- Validation Section ---
    updated = False # Flag to track if config needs saving back

    # Validate symbol
    if not config.get("symbol") or not isinstance(config.get("symbol"), str):
         print(f"{NEON_RED}CRITICAL: 'symbol' is missing, empty, or invalid in config. Resetting to default: '{default_config['symbol']}'{RESET}")
         config["symbol"] = default_config["symbol"]
         updated = True

    # Validate interval
    if config.get("interval") not in VALID_INTERVALS:
        print(f"{NEON_RED}Invalid interval '{config.get('interval')}' in config. Resetting to default '{default_config['interval']}'. Valid: {VALID_INTERVALS}{RESET}")
        config["interval"] = default_config["interval"]
        updated = True

    # Validate entry order type
    if config.get("entry_order_type") not in ["market", "limit"]:
        print(f"{NEON_RED}Invalid entry_order_type '{config.get('entry_order_type')}' in config. Resetting to 'market'.{RESET}")
        config["entry_order_type"] = "market"
        updated = True

    # Validate active weight set exists
    if config.get("active_weight_set") not in config.get("weight_sets", {}):
         print(f"{NEON_RED}Active weight set '{config.get('active_weight_set')}' not found in 'weight_sets'. Resetting to 'default'.{RESET}")
         config["active_weight_set"] = "default" # Ensure 'default' exists in defaults
         updated = True

    # Validate numeric parameters (ranges and types)
    numeric_params = {
        # key: (min_val, max_val, allow_min_equal, allow_max_equal, is_integer)
        "risk_per_trade": (0, 1, False, False, False),
        "leverage": (1, 1000, True, True, True), # Adjust max leverage realistically
        "stop_loss_multiple": (0, float('inf'), False, True, False),
        "take_profit_multiple": (0, float('inf'), False, True, False),
        "trailing_stop_callback_rate": (0, 1, False, False, False),
        "trailing_stop_activation_percentage": (0, 1, True, False, False), # Allow 0%
        "break_even_trigger_atr_multiple": (0, float('inf'), False, True, False),
        "break_even_offset_ticks": (0, 100, True, True, True),
        "signal_score_threshold": (0, float('inf'), False, True, False),
        "atr_period": (1, 1000, True, True, True),
        "ema_short_period": (1, 1000, True, True, True),
        "ema_long_period": (1, 1000, True, True, True),
        "rsi_period": (1, 1000, True, True, True),
        "bollinger_bands_period": (1, 1000, True, True, True),
        "bollinger_bands_std_dev": (0, 10, False, True, False),
        "cci_window": (1, 1000, True, True, True),
        "williams_r_window": (1, 1000, True, True, True),
        "mfi_window": (1, 1000, True, True, True),
        "stoch_rsi_window": (1, 1000, True, True, True),
        "stoch_rsi_rsi_window": (1, 1000, True, True, True),
        "stoch_rsi_k": (1, 1000, True, True, True),
        "stoch_rsi_d": (1, 1000, True, True, True),
        "psar_af": (0, 1, False, False, False),
        "psar_max_af": (0, 1, False, False, False),
        "sma_10_window": (1, 1000, True, True, True),
        "momentum_period": (1, 1000, True, True, True),
        "volume_ma_period": (1, 1000, True, True, True),
        "fibonacci_window": (2, 1000, True, True, True), # Need at least 2 points
        "orderbook_limit": (1, 100, True, True, True),
        "position_confirm_delay_seconds": (0, 60, True, True, False),
        "loop_delay_seconds": (1, 300, True, True, False),
        "stoch_rsi_oversold_threshold": (0, 100, True, False, False),
        "stoch_rsi_overbought_threshold": (0, 100, False, True, False),
        "volume_confirmation_multiplier": (0, float('inf'), False, True, False),
        "limit_order_offset_buy": (0, 0.1, True, False, False), # 10% offset max?
        "limit_order_offset_sell": (0, 0.1, True, False, False),
    }
    for key, (min_val, max_val, allow_min, allow_max, is_integer) in numeric_params.items():
        try:
            value_str = str(config[key]) # Convert potential int/float to str first
            value = Decimal(value_str) if not is_integer else int(Decimal(value_str))

            # Check bounds
            lower_bound_ok = value >= min_val if allow_min else value > min_val
            upper_bound_ok = value <= max_val if allow_max else value < max_val

            if not (lower_bound_ok and upper_bound_ok):
                raise ValueError(f"Value {value} out of range "
                                 f"({min_val} {'<=' if allow_min else '<'} x {'<=' if allow_max else '<'} {max_val})")

            # Store the validated value (could be int or float/Decimal)
            config[key] = int(value) if is_integer else float(value) # Store float for simplicity unless int needed

        except (ValueError, TypeError, KeyError, InvalidOperation) as e:
            print(f"{NEON_RED}Invalid value for '{key}' ({config.get(key)}): {e}. Resetting to default '{default_config[key]}'.{RESET}")
            config[key] = default_config[key]
            updated = True

    # Specific validation for time_based_exit_minutes (allow None or positive number)
    time_exit = config.get("time_based_exit_minutes")
    if time_exit is not None:
        try:
            time_exit_val = float(time_exit)
            if time_exit_val <= 0: raise ValueError("Must be positive if set")
            config["time_based_exit_minutes"] = time_exit_val # Store as float
        except (ValueError, TypeError) as e:
             print(f"{NEON_RED}Invalid value for 'time_based_exit_minutes' ({time_exit}): {e}. Resetting to default (None).{RESET}")
             config["time_based_exit_minutes"] = None
             updated = True

    # If config was updated due to invalid values, save it back
    if updated:
        try:
            with open(filepath, "w", encoding="utf-8") as f_write:
                # Use ensure_ascii=False for better readability if non-ASCII chars exist
                json.dump(config, f_write, indent=4, ensure_ascii=False)
            print(f"{NEON_YELLOW}Updated config file {filepath} with corrected/default values.{RESET}")
        except IOError as e:
            print(f"{NEON_RED}Error writing updated config file {filepath}: {e}{RESET}")

    return config

def _merge_configs(loaded_config: Dict, default_config: Dict) -> Dict:
    """
    Recursively merges the loaded configuration with default values.
    Ensures all keys from the default config exist in the final config.
    Prioritizes values from the loaded config.
    """
    merged = default_config.copy()
    for key, value in loaded_config.items():
        # If key exists in both and both values are dicts, recurse
        if isinstance(value, dict) and isinstance(merged.get(key), dict):
            merged[key] = _merge_configs(value, merged[key])
        else:
            # Otherwise, overwrite default with loaded value
            merged[key] = value
    return merged

def setup_logger(name: str, level: int = logging.INFO) -> logging.Logger:
    """Sets up a logger with rotating file and colored console handlers."""
    logger = logging.getLogger(name)
    # Prevent adding multiple handlers if logger is reused
    if logger.hasHandlers():
        for handler in logger.handlers[:]:
            try: handler.close()
            except: pass # Ignore errors closing handlers
            logger.removeHandler(handler)

    logger.setLevel(logging.DEBUG) # Capture all levels at the logger level

    # File Handler (Rotating)
    log_filename = os.path.join(LOG_DIRECTORY, f"{name}.log")
    try:
        file_handler = RotatingFileHandler(
            log_filename, maxBytes=10 * 1024 * 1024, backupCount=5, encoding='utf-8'
        )
        file_formatter = SensitiveFormatter(
            "%(asctime)s.%(msecs)03d %(levelname)-8s [%(name)s:%(lineno)d] %(message)s",
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        file_handler.setFormatter(file_formatter)
        file_handler.setLevel(logging.DEBUG) # Log DEBUG and above to file
        logger.addHandler(file_handler)
    except Exception as e:
        print(f"Error setting up file logger {log_filename}: {e}")

    # Console Handler (Colored)
    stream_handler = logging.StreamHandler()
    stream_formatter = SensitiveFormatter(
        f"{NEON_BLUE}%(asctime)s{RESET} - {NEON_YELLOW}%(levelname)-8s{RESET} - {NEON_PURPLE}[%(name)s]{RESET} - %(message)s",
        datefmt='%Y-%m-%d %H:%M:%S %Z' # Include Timezone abbreviation
    )
    # Use UTC internally for consistency, display local time in logs via formatter
    stream_formatter.converter = time.gmtime # Log record times in UTC
    # Set the formatter's timezone for display purposes (using datefmt %Z)
    # Ensure the TIMEZONE object is used correctly by the formatter
    logging.Formatter.converter = lambda *args: datetime.now(TIMEZONE).timetuple()

    stream_handler.setFormatter(stream_formatter)
    stream_handler.setLevel(level) # Set console level (e.g., INFO)
    logger.addHandler(stream_handler)

    logger.propagate = False # Prevent duplicate logs in root logger
    return logger

# --- CCXT Exchange Setup ---
def initialize_exchange(config: Dict[str, Any], logger: logging.Logger) -> Optional[ccxt.Exchange]:
    """Initializes the CCXT Bybit exchange object with enhanced error handling."""
    lg = logger
    try:
        exchange_options = {
            'apiKey': API_KEY,
            'secret': API_SECRET,
            'enableRateLimit': True, # Use CCXT's built-in rate limiter
            'rateLimit': 150, # Adjust based on Bybit V5 limits (e.g., 100ms for 10/s might be safer)
            'options': {
                'defaultType': 'linear', # Essential for Bybit V5 USDT perpetuals
                'adjustForTimeDifference': True, # Helps with timestamp sync issues
                # Increased timeouts
                'fetchTickerTimeout': 15000, 'fetchBalanceTimeout': 20000,
                'createOrderTimeout': 25000, 'cancelOrderTimeout': 20000,
                'fetchPositionsTimeout': 20000, 'fetchOHLCVTimeout': 20000,
                # Add user agent for potential identification
                'user-agent': 'ScalpXRX Bot v1.0',
                # Consider Bybit V5 specific options if needed
                # 'recvWindow': 10000 # Example: Increase if timestamp errors persist
            }
        }

        # Default to Bybit, could be made configurable
        exchange_id = "bybit"
        exchange_class = getattr(ccxt, exchange_id)
        exchange = exchange_class(exchange_options)

        # --- Sandbox Mode Setup ---
        if config.get('use_sandbox'):
            lg.warning(f"{NEON_YELLOW}USING SANDBOX MODE (Testnet){RESET}")
            try:
                exchange.set_sandbox_mode(True)
                lg.info(f"Sandbox mode explicitly enabled for {exchange.id}.")
            except AttributeError:
                lg.warning(f"{exchange.id} does not support set_sandbox_mode via ccxt. Ensuring API keys are for Testnet.")
                # Manually set Bybit testnet URL if needed
                if exchange.id == 'bybit':
                    exchange.urls['api'] = 'https://api-testnet.bybit.com'
                    lg.info("Manually set Bybit API URL to Testnet.")
            except Exception as e:
                lg.error(f"Error enabling sandbox mode: {e}")
        else:
            lg.info(f"{NEON_GREEN}Using LIVE (Real Money) Environment.{RESET}")


        lg.info(f"Initializing {exchange.id}...")
        # --- Initial Connection & Permissions Test (Fetch Balance) ---
        account_type_to_test = 'CONTRACT' # Prioritize CONTRACT for V5 derivatives
        lg.info(f"Attempting initial balance fetch (Account Type: {account_type_to_test})...")
        try:
            params = {'type': account_type_to_test} if exchange.id == 'bybit' else {}
            # Use safe_api_call for robustness
            balance = safe_api_call(exchange.fetch_balance, lg, params=params)

            if balance:
                quote_curr = config.get("quote_currency", "USDT")
                # Handle potential differences in balance structure more robustly
                available_quote_val = None
                if quote_curr in balance:
                    available_quote_val = balance[quote_curr].get('free')
                if available_quote_val is None and 'free' in balance and quote_curr in balance['free']:
                    available_quote_val = balance['free'][quote_curr]
                # Add check for Bybit V5 structure if needed (though fetch_balance often standardizes)

                available_quote_str = str(available_quote_val) if available_quote_val is not None else 'N/A'
                lg.info(f"{NEON_GREEN}Successfully connected and fetched initial balance.{RESET} (Example: {quote_curr} available: {available_quote_str})")
            else:
                 lg.warning(f"{NEON_YELLOW}Initial balance fetch (Type: {account_type_to_test}) returned no data. Check connection/permissions.{RESET}")

        except ccxt.AuthenticationError as auth_err:
             lg.error(f"{NEON_RED}Authentication Error during initial balance fetch: {auth_err}{RESET}")
             lg.error(f"{NEON_RED}>> Ensure API keys (in .env) are correct, have permissions (Read, Trade), match environment (Real/Testnet), and IP whitelist is correct.{RESET}")
             return None # Fatal error
        except ccxt.ExchangeError as balance_err:
             # Fallback if specific account type failed
             lg.warning(f"{NEON_YELLOW}Exchange error fetching balance (Type: {account_type_to_test}): {balance_err}. Trying default fetch...{RESET}")
             try:
                  balance = safe_api_call(exchange.fetch_balance, lg)
                  if balance:
                       quote_curr = config.get("quote_currency", "USDT")
                       available_quote_val = None
                       if quote_curr in balance:
                           available_quote_val = balance[quote_curr].get('free')
                       if available_quote_val is None and 'free' in balance and quote_curr in balance['free']:
                           available_quote_val = balance['free'][quote_curr]
                       available_quote_str = str(available_quote_val) if available_quote_val is not None else 'N/A'
                       lg.info(f"{NEON_GREEN}Successfully fetched balance using default parameters.{RESET} (Example: {quote_curr} available: {available_quote_str})")
                  else:
                       lg.warning(f"{NEON_YELLOW}Default balance fetch also returned no data.{RESET}")
             except Exception as fallback_err:
                  lg.warning(f"{NEON_YELLOW}Default balance fetch also failed: {fallback_err}. Check API permissions/account type/network.{RESET}")
        except Exception as balance_err: # Catches errors from safe_api_call
             lg.warning(f"{NEON_YELLOW}Could not perform initial balance fetch after retries or due to error: {balance_err}. Proceeding cautiously.{RESET}")


        # --- Load Markets (Crucial for market info, precision, etc.) ---
        lg.info(f"Loading markets for {exchange.id}...")
        try:
             safe_api_call(exchange.load_markets, lg, reload=True) # Force reload
             lg.info(f"Markets loaded successfully for {exchange.id}.")
        except Exception as market_err:
             lg.error(f"{NEON_RED}Failed to load markets after retries: {market_err}. Cannot operate without market data. Exiting.{RESET}")
             return None # Fatal error if markets cannot be loaded

        lg.info(f"CCXT exchange initialized ({exchange.id}). Sandbox: {config.get('use_sandbox')}")
        return exchange

    except ccxt.AuthenticationError as e: # Catch auth errors during class instantiation
        lg.error(f"{NEON_RED}CCXT Authentication Error during initialization: {e}{RESET}")
        lg.error(f"{NEON_RED}>> Check API Key/Secret format and validity in your .env file.{RESET}")
    except ccxt.ExchangeError as e:
        lg.error(f"{NEON_RED}CCXT Exchange Error initializing: {e}{RESET}")
    except ccxt.NetworkError as e:
        lg.error(f"{NEON_RED}CCXT Network Error initializing: {e}{RESET}")
    except Exception as e:
        lg.error(f"{NEON_RED}Failed to initialize CCXT exchange: {e}{RESET}", exc_info=True)

    return None

# --- API Call Wrapper with Retries ---
def safe_api_call(func, logger: logging.Logger, *args, **kwargs):
    """Wraps an API call with retry logic for network/rate limit/specific exchange errors."""
    lg = logger
    attempts = 0
    last_exception = None
    while attempts <= MAX_API_RETRIES:
        try:
            result = func(*args, **kwargs)
            # lg.debug(f"API call {func.__name__} successful.") # Optional success log
            return result # Success
        except (ccxt.NetworkError, ccxt.RequestTimeout, requests.exceptions.ConnectionError, requests.exceptions.Timeout, ccxt.ExchangeNotAvailable, ccxt.DDoSProtection) as e:
            last_exception = e
            wait_time = RETRY_DELAY_SECONDS * (1.5 ** attempts) # Exponential backoff
            lg.warning(f"{NEON_YELLOW}Retryable network/availability error in {func.__name__}: {type(e).__name__}. Waiting {wait_time:.1f}s (Attempt {attempts+1}/{MAX_API_RETRIES}). Error: {e}{RESET}")
            time.sleep(wait_time)
        except ccxt.RateLimitExceeded as e:
            last_exception = e
            wait_time_header = getattr(e, 'retry_after', None)
            wait_time = RETRY_DELAY_SECONDS * (2 ** attempts) # Stronger backoff
            if wait_time_header:
                try: wait_time = max(wait_time, float(wait_time_header) + 0.5) # Add buffer
                except: pass # Ignore invalid header
            lg.warning(f"{NEON_YELLOW}Rate limit exceeded in {func.__name__}. Waiting {wait_time:.1f}s (Attempt {attempts+1}/{MAX_API_RETRIES}). Error: {e}{RESET}")
            time.sleep(wait_time)
        except ccxt.AuthenticationError as e:
             lg.error(f"{NEON_RED}Authentication Error in {func.__name__}: {e}. Aborting call.{RESET}")
             raise e # Don't retry, re-raise immediately
        except ccxt.ExchangeError as e:
            last_exception = e
            bybit_retry_codes = [
                10001, # Internal server error
                10006, # Request frequent
                # Add other transient error codes based on Bybit docs/experience
            ]
            exchange_code = getattr(e, 'code', None)
            err_str = str(e).lower()
            is_retryable_exchange_err = exchange_code in bybit_retry_codes or \
                                        "internal server error" in err_str or \
                                        "request validation failed" in err_str # Check message too

            if is_retryable_exchange_err:
                 wait_time = RETRY_DELAY_SECONDS * (1.5 ** attempts)
                 lg.warning(f"{NEON_YELLOW}Potentially retryable exchange error in {func.__name__}: {e} (Code: {exchange_code}). Waiting {wait_time:.1f}s (Attempt {attempts+1}/{MAX_API_RETRIES})...{RESET}")
                 time.sleep(wait_time)
            else:
                 lg.error(f"{NEON_RED}Non-retryable Exchange Error in {func.__name__}: {e} (Code: {exchange_code}){RESET}")
                 raise e # Re-raise non-retryable ones
        except Exception as e:
            last_exception = e
            lg.error(f"{NEON_RED}Unexpected error in {func.__name__}: {e}{RESET}", exc_info=True)
            raise e # Re-raise unexpected errors immediately

        attempts += 1

    # If loop completes, max retries exceeded
    lg.error(f"{NEON_RED}Max retries ({MAX_API_RETRIES}) exceeded for {func.__name__}.{RESET}")
    if last_exception:
        raise last_exception # Raise the last known exception
    else:
        # Fallback if no exception was captured (shouldn't normally happen)
        raise ccxt.RequestTimeout(f"Max retries exceeded for {func.__name__} (no specific exception captured)")


# --- CCXT Data Fetching (Using safe_api_call) ---
def fetch_current_price_ccxt(exchange: ccxt.Exchange, symbol: str, logger: logging.Logger) -> Optional[Decimal]:
    """Fetch the current price of a trading symbol using CCXT ticker with fallbacks and retries."""
    lg = logger
    try:
        ticker = safe_api_call(exchange.fetch_ticker, lg, symbol)
        if not ticker:
            return None # Error logged by safe_api_call

        lg.debug(f"Ticker data for {symbol}: {ticker}")
        price = None
        # Prioritize 'last', then 'average', then mid-price, then ask/bid
        last_price = ticker.get('last')
        bid_price = ticker.get('bid')
        ask_price = ticker.get('ask')
        avg_price = ticker.get('average')

        # Robust Decimal conversion helper
        def to_decimal(value) -> Optional[Decimal]:
            if value is None: return None
            try:
                d = Decimal(str(value))
                return d if d.is_finite() and d > 0 else None
            except (InvalidOperation, ValueError, TypeError):
                lg.warning(f"Invalid price format encountered: {value}")
                return None

        p_last = to_decimal(last_price)
        p_bid = to_decimal(bid_price)
        p_ask = to_decimal(ask_price)
        p_avg = to_decimal(avg_price)

        # Determine price with priority
        if p_last:
            price = p_last; lg.debug(f"Using 'last' price: {price}")
        elif p_avg:
            price = p_avg; lg.debug(f"Using 'average' price: {price}")
        elif p_bid and p_ask:
            price = (p_bid + p_ask) / 2; lg.debug(f"Using bid/ask midpoint: {price}")
        elif p_ask:
            price = p_ask; lg.warning(f"Using 'ask' price fallback (bid invalid/missing): {price}")
        elif p_bid:
            price = p_bid; lg.warning(f"Using 'bid' price fallback (ask invalid/missing): {price}")

        # Final validation
        if price is not None and price.is_finite() and price > 0:
            return price
        else:
            lg.error(f"{NEON_RED}Failed to extract a valid price from ticker data for {symbol}. Ticker: {ticker}{RESET}")
            return None

    except Exception as e:
        lg.error(f"{NEON_RED}Error fetching current price for {symbol}: {e}{RESET}", exc_info=False)
        return None

def fetch_klines_ccxt(exchange: ccxt.Exchange, symbol: str, timeframe: str, limit: int = 250, logger: logging.Logger = None) -> pd.DataFrame:
    """Fetch OHLCV kline data using CCXT with retries and robust validation."""
    lg = logger or logging.getLogger(__name__)
    if not exchange.has['fetchOHLCV']:
        lg.error(f"Exchange {exchange.id} does not support fetchOHLCV.")
        return pd.DataFrame()

    try:
        ohlcv = safe_api_call(exchange.fetch_ohlcv, lg, symbol, timeframe=timeframe, limit=limit)

        if ohlcv is None or not isinstance(ohlcv, list) or len(ohlcv) == 0:
            if ohlcv is not None:
                lg.warning(f"{NEON_YELLOW}No valid kline data returned for {symbol} {timeframe}.{RESET}")
            return pd.DataFrame()

        df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])

        if df.empty:
            lg.warning(f"Kline data DataFrame is empty for {symbol} {timeframe}.")
            return df

        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms', errors='coerce', utc=True)
        df.dropna(subset=['timestamp'], inplace=True)
        df.set_index('timestamp', inplace=True)

        # Convert price/volume columns to numeric Decimal
        for col in ['open', 'high', 'low', 'close', 'volume']:
             try:
                  df[col] = df[col].apply(lambda x: Decimal(str(x)) if pd.notna(x) and str(x).strip() != '' else Decimal('NaN'))
             except (TypeError, ValueError, InvalidOperation) as conv_err:
                  lg.warning(f"Could not convert column '{col}' to Decimal, attempting numeric fallback: {conv_err}")
                  df[col] = pd.to_numeric(df[col], errors='coerce')

        # Data Cleaning
        initial_len = len(df)
        close_col = df['close']
        df.dropna(subset=['open', 'high', 'low', 'close'], inplace=True)

        if not df.empty:
            if isinstance(close_col.iloc[0], Decimal):
                df = df[close_col.apply(lambda x: x.is_finite() and x > 0)]
            elif pd.api.types.is_numeric_dtype(close_col.dtype):
                df = df[np.isfinite(close_col) & (close_col > 0)]

        rows_dropped = initial_len - len(df)
        if rows_dropped > 0:
            lg.debug(f"Dropped {rows_dropped} rows with NaN/invalid price data for {symbol}.")

        if df.empty:
            lg.warning(f"Kline data for {symbol} {timeframe} empty after cleaning.")
            return pd.DataFrame()

        df.sort_index(inplace=True)
        df = df[~df.index.duplicated(keep='last')]

        lg.info(f"Successfully fetched and processed {len(df)} klines for {symbol} {timeframe}")
        return df

    except Exception as e:
        lg.error(f"{NEON_RED}Error fetching/processing klines for {symbol}: {e}{RESET}", exc_info=True)
        return pd.DataFrame()


def fetch_orderbook_ccxt(exchange: ccxt.Exchange, symbol: str, limit: int, logger: logging.Logger) -> Optional[Dict]:
    """Fetch orderbook data using ccxt with retries and validation."""
    lg = logger
    if not exchange.has['fetchOrderBook']:
        lg.error(f"Exchange {exchange.id} does not support fetchOrderBook.")
        return None

    try:
        orderbook = safe_api_call(exchange.fetch_order_book, lg, symbol, limit=limit)

        if not orderbook:
            return None
        if not isinstance(orderbook, dict) or 'bids' not in orderbook or 'asks' not in orderbook or \
           not isinstance(orderbook['bids'], list) or not isinstance(orderbook['asks'], list):
            lg.warning(f"Invalid orderbook structure received for {symbol}. Data: {orderbook}")
            return None

        if not orderbook['bids'] and not orderbook['asks']:
            lg.warning(f"Orderbook received but both bids and asks lists are empty for {symbol}.")
            return orderbook # Return empty but valid book

        # Basic validation of entry format
        valid = True
        for side in ['bids', 'asks']:
             if orderbook[side]:
                  entry = orderbook[side][0]
                  if not (isinstance(entry, list) and len(entry) == 2):
                       lg.warning(f"Invalid {side[:-1]} entry format: {entry}"); valid = False; break
                  try: # Check numeric format
                       _ = float(entry[0]); _ = float(entry[1])
                  except (ValueError, TypeError):
                       lg.warning(f"Non-numeric data in {side[:-1]} entry: {entry}"); valid = False; break
        if not valid:
             lg.error("Orderbook data format validation failed."); return None

        lg.debug(f"Successfully fetched orderbook for {symbol} ({len(orderbook['bids'])} bids, {len(orderbook['asks'])} asks).")
        return orderbook

    except Exception as e:
        lg.error(f"{NEON_RED}Error fetching order book for {symbol}: {e}{RESET}", exc_info=False)
        return None

# --- Trading Analyzer Class (Enhancements Incorporated) ---
# Assuming TradingAnalyzer class definition is identical to the input sx.py
# with the enhancements already discussed (robust TA conversion, precision handling, etc.)
# (Class definition omitted here for brevity, assuming it's the enhanced version from sx.py)
# ... [TradingAnalyzer class definition from sx.py goes here] ...

# --- Trading Logic Helper Functions (Enhancements Incorporated) ---
# Assuming these functions are identical to the input sx.py
# with the enhancements already discussed (robust parsing, validation, error handling)
# (Function definitions omitted here for brevity, assuming they are the enhanced versions from sx.py)
# ... [fetch_balance function definition from sx.py goes here] ...
# ... [get_market_info function definition from sx.py goes here] ...
# ... [calculate_position_size function definition from sx.py goes here] ...
# ... [get_open_position function definition from sx.py goes here] ...
# ... [set_leverage_ccxt function definition from sx.py goes here] ...
# ... [place_trade function definition from sx.py goes here] ...
# ... [_set_position_protection function definition from sx.py goes here] ...
# ... [set_trailing_stop_loss function definition from sx.py goes here] ...

# --- Main Analysis and Trading Loop (Enhancements Incorporated) ---
def analyze_and_trade_symbol(exchange: ccxt.Exchange, symbol: str, config: Dict[str, Any], logger: logging.Logger) -> None:
    """Performs one cycle of analysis and trading logic for a single symbol."""
    lg = logger
    lg.info(f"---== Analyzing {symbol} ({config['interval']}) Cycle Start ==---")
    cycle_start_time = time.monotonic()

    try:
        # --- Get Market Info (Critical) ---
        market_info = get_market_info(exchange, symbol, lg)
        if not market_info: raise ValueError(f"Fatal: Failed to get market info for {symbol}.")

        # --- Fetch Data ---
        ccxt_interval = CCXT_INTERVAL_MAP.get(config["interval"])
        if not ccxt_interval: raise ValueError(f"Invalid interval '{config['interval']}'.")
        klines_df = fetch_klines_ccxt(exchange, symbol, ccxt_interval, limit=500, logger=lg)
        if klines_df.empty or len(klines_df) < 50: raise ValueError(f"Insufficient kline data ({len(klines_df)}).")

        current_price = fetch_current_price_ccxt(exchange, symbol, lg)
        if current_price is None: # Fallback to last close
             lg.warning("Using last close from klines as current price.")
             try:
                 last_close = klines_df['close'].iloc[-1] # Assumes klines_df uses Decimal
                 if not isinstance(last_close, Decimal) or not last_close.is_finite():
                     raise ValueError("Last close is not a valid Decimal.")
                 current_price = last_close
                 if current_price <= 0: raise ValueError("Last close price non-positive.")
             except (IndexError, KeyError, ValueError, TypeError, InvalidOperation) as e:
                 raise ValueError(f"Failed to get valid last close price: {e}")

        # Fetch order book if needed for scoring
        orderbook_data = None
        active_weights = config.get("weight_sets", {}).get(config.get("active_weight_set", "default"), {})
        if config.get("indicators",{}).get("orderbook", False) and float(active_weights.get("orderbook", 0)) != 0:
            orderbook_data = fetch_orderbook_ccxt(exchange, symbol, config["orderbook_limit"], lg)
            if not orderbook_data: lg.warning(f"Failed orderbook fetch for {symbol}. Proceeding without.")

        # --- Analyze Data & Generate Signal ---
        analyzer = TradingAnalyzer(klines_df.copy(), lg, config, market_info)
        if not analyzer.indicator_values: raise ValueError("Indicator calculation failed.")
        signal = analyzer.generate_trading_signal(current_price, orderbook_data)

        # --- Calculate Potential TP/SL & Log Summary ---
        _, tp_calc, sl_calc = analyzer.calculate_entry_tp_sl(current_price, signal)
        price_prec = analyzer.get_price_precision(); current_atr = analyzer.indicator_values.get("ATR")
        lg.info(f"Current Price: {current_price:.{price_prec}f}")
        lg.info(f"ATR: {current_atr:.{price_prec+2}f}" if isinstance(current_atr, Decimal) else 'ATR: N/A')
        lg.info(f"Calc Initial SL (sizing): {sl_calc or 'N/A'}, TP (target): {tp_calc or 'N/A'}")
        lg.info(f"Mgmt: TSL={'On' if config['enable_trailing_stop'] else 'Off'}, BE={'On' if config['enable_break_even'] else 'Off'}, TimeExit={config.get('time_based_exit_minutes') or 'Off'}")

        # --- Trading Execution Logic ---
        if not config.get("enable_trading"):
            lg.debug("Trading disabled. Cycle complete."); return

        open_position = get_open_position(exchange, symbol, lg)

        # --- Scenario 1: No Open Position ---
        if open_position is None:
            if signal in ["BUY", "SELL"]:
                lg.info(f"*** {signal} Signal & No Position: Initiating Trade Sequence ***")
                balance = fetch_balance(exchange, config["quote_currency"], lg)
                if balance is None or balance <= 0: raise ValueError("Balance fetch failed or zero/negative.")
                if sl_calc is None: raise ValueError("Initial SL calculation failed (required for sizing).")

                if market_info.get('is_contract') and int(config.get("leverage", 0)) > 0:
                    if not set_leverage_ccxt(exchange, symbol, int(config["leverage"]), market_info, lg):
                        raise ValueError("Failed to set leverage.")

                pos_size = calculate_position_size(balance, config["risk_per_trade"], sl_calc, current_price, market_info, exchange, lg)
                if pos_size is None or pos_size <= 0: raise ValueError(f"Position size calculation failed ({pos_size}).")

                # --- Place Order (Market or Limit) ---
                entry_type = config.get("entry_order_type", "market"); limit_px = None
                if entry_type == "limit":
                     try:
                         offset = Decimal(str(config[f"limit_order_offset_{signal.lower()}"]))
                         rnd_f = Decimal(f'1e-{price_prec}')
                         raw_px = current_price * (1 - offset if signal=='BUY' else 1 + offset)
                         limit_px = raw_px.quantize(rnd_f, rounding=ROUND_DOWN if signal=='BUY' else ROUND_UP)
                         if limit_px <= 0: raise ValueError("Limit price non-positive")
                         lg.info(f"Calc Limit Entry for {signal}: {limit_px}")
                     except (KeyError, ValueError, InvalidOperation) as e:
                          lg.error(f"Limit price calc failed ({e}). Switching to Market."); entry_type="market"; limit_px=None

                trade_order = place_trade(exchange, symbol, signal, pos_size, market_info, lg, entry_type, limit_px)

                # --- Post-Order Handling ---
                if trade_order and trade_order.get('id'):
                    order_id, status = trade_order['id'], trade_order.get('status')
                    # If filled immediately (market or fast limit)
                    if status == 'closed' or entry_type == 'market':
                        delay = config.get("position_confirm_delay_seconds", POSITION_CONFIRM_DELAY_SECONDS)
                        lg.info(f"Order {order_id} placed/filled. Waiting {delay}s for confirmation...")
                        time.sleep(delay)
                        confirmed_pos = get_open_position(exchange, symbol, lg)
                        if confirmed_pos:
                            lg.info(f"{NEON_GREEN}Position Confirmed!{RESET}")
                            # --- Set Protection ---
                            try:
                                entry_act = confirmed_pos.get('entryPriceDecimal') or current_price # Use actual or estimate
                                lg.info(f"Actual Entry ~ {entry_act:.{price_prec}f}")
                                _, tp_final, sl_final = analyzer.calculate_entry_tp_sl(entry_act, signal) # Recalculate based on actual entry
                                protection_ok = False
                                if config["enable_trailing_stop"]:
                                     lg.info(f"Setting TSL (TP target: {tp_final})...")
                                     protection_ok = set_trailing_stop_loss(exchange, symbol, market_info, confirmed_pos, config, lg, tp_final)
                                elif sl_final or tp_final: # Use fixed if TSL disabled AND calc valid
                                     lg.info(f"Setting Fixed SL ({sl_final}) / TP ({tp_final})...")
                                     protection_ok = _set_position_protection(exchange, symbol, market_info, confirmed_pos, lg, sl_final, tp_final)
                                else: lg.warning("No valid protection calculated (TSL disabled or calc failed).")

                                if protection_ok: lg.info(f"{NEON_GREEN}=== TRADE ENTRY & PROTECTION COMPLETE ({symbol} {signal}) ===")
                                else: lg.error(f"{NEON_RED}=== TRADE PLACED BUT PROTECTION FAILED ({symbol} {signal}) ===\n{NEON_YELLOW}>>> MANUAL MONITORING REQUIRED! <<<")
                            except Exception as post_err:
                                 lg.error(f"Error setting protection: {post_err}", exc_info=True); lg.warning(f"{NEON_YELLOW}Position open, manual check needed!{RESET}")
                        else: lg.error(f"{NEON_RED}Order {order_id} placed/filled BUT POSITION NOT CONFIRMED! Manual check!{RESET}")
                    # If limit order is open
                    elif status == 'open' and entry_type == 'limit':
                         lg.info(f"Limit order {order_id} OPEN. Will check status next cycle.")
                         # TODO: Optionally add logic to track open orders and cancel if stale
                    else: # Order failed or other status
                         lg.error(f"Order {order_id} status: {status}. Trade did not open as expected.")
                else: # place_trade failed
                     lg.error(f"{NEON_RED}=== TRADE EXECUTION FAILED. Order placement error. ===")
            else: lg.info("Signal HOLD, no position. No action.")

        # --- Scenario 2: Existing Open Position ---
        else:
            pos_side = open_position['side']; pos_size = open_position['contractsDecimal']
            entry_price = open_position['entryPriceDecimal']; pos_ts_ms = open_position['timestamp_ms']
            lg.info(f"Managing existing {pos_side.upper()} position. Size: {pos_size}, Entry: {entry_price}")

            # --- Check for Exit Signal (Opposite Direction) ---
            if (pos_side == 'long' and signal == "SELL") or (pos_side == 'short' and signal == "BUY"):
                lg.warning(f"{NEON_YELLOW}*** EXIT Signal ({signal}) opposes {pos_side} position. Closing... ***{RESET}")
                try:
                    close_sig = "SELL" if pos_side == 'long' else "BUY"
                    size_close = abs(pos_size)
                    if size_close <= 0: raise ValueError("Position size is zero/negative.")
                    lg.info(f"==> Placing {close_sig} MARKET order (reduceOnly=True) | Size: {size_close} <==")
                    close_order = place_trade(exchange, symbol, close_sig, size_close, market_info, lg, 'market', reduce_only=True)
                    if close_order: lg.info(f"{NEON_GREEN}Close order placed successfully. ID: {close_order.get('id','?')}{RESET}")
                    else: lg.error(f"{NEON_RED}Failed placing CLOSE order! Manual check!{RESET}")
                except Exception as close_err:
                    lg.error(f"Error closing position: {close_err}", exc_info=True); lg.warning(f"{NEON_YELLOW}Manual close may be needed!{RESET}")
                return # Exit cycle after close attempt

            # --- Check for Time-Based Exit ---
            time_exit = config.get("time_based_exit_minutes")
            if isinstance(time_exit, (int, float)) and time_exit > 0 and pos_ts_ms:
                 try:
                      elapsed_mins = (time.time() * 1000 - pos_ts_ms) / 60000
                      lg.debug(f"Time Exit Check: Elapsed={elapsed_mins:.2f}m, Limit={time_exit}m")
                      if elapsed_mins >= time_exit:
                           lg.warning(f"{NEON_YELLOW}*** TIME-BASED EXIT ({elapsed_mins:.1f} >= {time_exit}m). Closing... ***{RESET}")
                           # Execute Close Logic (identical to signal-based exit)
                           close_sig = "SELL" if pos_side == 'long' else "BUY"
                           size_close = abs(pos_size)
                           if size_close <= 0: raise ValueError("Position size is zero/negative.")
                           close_order = place_trade(exchange, symbol, close_sig, size_close, market_info, lg, 'market', reduce_only=True)
                           if close_order: lg.info(f"{NEON_GREEN}Time-based CLOSE order placed. ID: {close_order.get('id','?')}{RESET}")
                           else: lg.error(f"{NEON_RED}Failed time-based CLOSE order! Manual check!{RESET}")
                           return # Exit cycle
                 except Exception as time_err: lg.error(f"Error in time exit check: {time_err}")

            # --- Position Management (Break-Even) ---
            # Check if TSL is already active on the exchange
            is_tsl_active = open_position.get('trailingStopLossValueDecimal') is not None
            if config["enable_break_even"] and not is_tsl_active:
                 lg.debug("Checking Break-Even conditions...")
                 try:
                     if entry_price is None or not entry_price.is_finite() or entry_price <= 0: raise ValueError("Invalid entry price for BE")
                     if not isinstance(current_atr, Decimal) or not current_atr.is_finite() or current_atr <= 0: raise ValueError("Invalid ATR for BE")

                     be_trig_atr = Decimal(str(config["break_even_trigger_atr_multiple"]))
                     be_off_ticks = int(config["break_even_offset_ticks"])
                     min_tick = analyzer.get_min_tick_size()

                     price_diff = current_price - entry_price if pos_side == 'long' else entry_price - current_price
                     profit_atr = price_diff / current_atr if current_atr > 0 else Decimal(0)
                     lg.debug(f"BE Check: ProfitATRs={profit_atr:.2f}, TargetATRs={be_trig_atr}")

                     if profit_atr >= be_trig_atr:
                          tick_offset = min_tick * be_off_ticks
                          be_sl = (entry_price + tick_offset).quantize(min_tick, rounding=ROUND_UP) if pos_side=='long' else \
                                  (entry_price - tick_offset).quantize(min_tick, rounding=ROUND_DOWN)
                          if not be_sl.is_finite() or be_sl <= 0: raise ValueError(f"Calculated BE SL non-positive/finite ({be_sl})")

                          curr_sl = open_position.get('stopLossPriceDecimal')
                          update_needed = False
                          if curr_sl is None: update_needed = True; lg.info("BE triggered: No current SL.")
                          elif pos_side=='long' and be_sl > curr_sl: update_needed = True; lg.info(f"BE triggered: Target {be_sl} > Current {curr_sl}.")
                          elif pos_side=='short' and be_sl < curr_sl: update_needed = True; lg.info(f"BE triggered: Target {be_sl} < Current {curr_sl}.")
                          else: lg.debug(f"BE triggered but current SL {curr_sl} already adequate.")

                          if update_needed:
                               lg.warning(f"{NEON_PURPLE}*** Moving SL to Break-Even ({symbol} @ {be_sl}) ***{RESET}")
                               curr_tp = open_position.get('takeProfitPriceDecimal') # Preserve existing TP
                               success = _set_position_protection(exchange, symbol, market_info, open_position, lg, be_sl, curr_tp)
                               if success: lg.info(f"{NEON_GREEN}Break-Even SL updated.{RESET}")
                               else: lg.error(f"{NEON_RED}Failed updating Break-Even SL.{RESET}")
                     else: lg.debug("BE Profit target not reached.")
                 except ValueError as ve: lg.warning(f"BE Check skipped: {ve}")
                 except Exception as be_err: lg.error(f"Error during BE check: {be_err}", exc_info=True)
            elif is_tsl_active: lg.debug("BE check skipped: TSL active.")
            else: lg.debug("BE check skipped: Disabled in config.")

            # Placeholder for other potential management logic (e.g., TSL adjustments)
            # lg.debug("End of position management checks.")

    # --- Error Handling for the entire cycle ---
    except ValueError as data_err: # Catch data/config related errors
        lg.error(f"{NEON_RED}Data/Config Error ({symbol}): {data_err}. Skipping cycle.{RESET}")
    except ccxt.AuthenticationError as auth_err: # Catch critical auth errors
         lg.critical(f"{NEON_RED}CRITICAL: Authentication Failed: {auth_err}. Stopping bot.{RESET}")
         raise SystemExit("Authentication Failed") # Stop the bot
    except (ccxt.NetworkError, ccxt.RequestTimeout, ccxt.ExchangeNotAvailable, ccxt.DDoSProtection) as net_err:
         lg.error(f"{NEON_RED}Network/Exchange Availability Error ({symbol}): {net_err}. Skipping cycle.{RESET}")
    except Exception as cycle_err: # Catch unexpected errors
        lg.error(f"{NEON_RED}Unexpected Cycle Error ({symbol}): {cycle_err}{RESET}", exc_info=True)
        # Decide behavior: continue or stop? For now, just log and continue.

    finally:
        # --- Cycle End Logging ---
        cycle_end_time = time.monotonic()
        lg.debug(f"---== Analysis Cycle End ({symbol}, {cycle_end_time - cycle_start_time:.2f}s) ==---")


def main() -> None:
    """Main function to initialize the bot and run the analysis loop."""
    global CONFIG, QUOTE_CURRENCY # Allow modification of globals

    # Setup initial logger
    init_logger = setup_logger("ScalpXRX_Init", level=logging.INFO)
    start_time_str = datetime.now(TIMEZONE).strftime('%Y-%m-%d %H:%M:%S %Z')
    init_logger.info(f"--- Starting ScalpXRX Bot ({start_time_str}) ---")

    try:
        CONFIG = load_config(CONFIG_FILE)
        QUOTE_CURRENCY = CONFIG.get("quote_currency", "USDT")
        TARGET_SYMBOL = CONFIG.get("symbol")

        if not TARGET_SYMBOL:
            init_logger.critical("CRITICAL: 'symbol' not defined in config.json. Exiting.")
            return

        # Setup logger specific to the target symbol for the main loop
        safe_symbol_name = TARGET_SYMBOL.replace('/', '_').replace(':', '-')
        symbol_logger_name = f"ScalpXRX_{safe_symbol_name}"
        main_logger = setup_logger(symbol_logger_name, level=logging.INFO) # Use INFO for console by default
        main_logger.info(f"Logging initialized for symbol: {TARGET_SYMBOL}")
        main_logger.info(f"Config loaded. Quote: {QUOTE_CURRENCY}, Interval: {CONFIG['interval']}")
        try: ta_version = ta.version
        except AttributeError: ta_version = "N/A" # Handle if version attribute is missing
        main_logger.info(f"Versions: CCXT={ccxt.__version__}, Pandas={pd.__version__}, PandasTA={ta_version}")


        # --- Trading Enabled Warning ---
        if CONFIG.get("enable_trading"):
            main_logger.warning(f"{NEON_YELLOW}!!! LIVE TRADING IS ENABLED !!!{RESET}")
            env_type = "SANDBOX (Testnet)" if CONFIG.get("use_sandbox") else f"{NEON_RED}!!! REAL MONEY !!!"
            main_logger.warning(f"Environment: {env_type}{RESET}")
            risk_pct = CONFIG.get('risk_per_trade', 0) * 100
            lev = CONFIG.get('leverage', 1)
            main_logger.warning(f"Settings: Risk/Trade={risk_pct:.2f}%, Leverage={lev}x")
            for i in range(3, 0, -1):
                main_logger.warning(f"Starting in {i}...")
                time.sleep(1)
        else:
            main_logger.info("Trading is disabled in config. Running in analysis-only mode.")

        # --- Initialize Exchange ---
        exchange = initialize_exchange(CONFIG, main_logger)
        if not exchange:
            main_logger.critical("Failed to initialize exchange. Exiting.")
            return

        # --- Main Loop ---
        main_logger.info(f"Starting main analysis loop for {TARGET_SYMBOL}...")
        loop_interval = max(1, CONFIG.get("loop_delay_seconds", LOOP_DELAY_SECONDS)) # Ensure positive delay
        while True:
            try:
                analyze_and_trade_symbol(exchange, TARGET_SYMBOL, CONFIG, main_logger)
            except SystemExit as e: # Catch SystemExit for clean shutdown
                 main_logger.critical(f"SystemExit triggered: {e}. Shutting down.")
                 break
            except KeyboardInterrupt: # Allow Ctrl+C to break loop
                 main_logger.info("KeyboardInterrupt detected in loop. Shutting down.")
                 break
            except Exception as loop_err:
                # Catch unexpected errors from analyze_and_trade_symbol if they weren't caught internally
                main_logger.error(f"{NEON_RED}Error in main loop iteration: {loop_err}{RESET}", exc_info=True)
                # Decide whether to continue or stop based on the error type?
                # For now, log and continue, but could add logic to stop on critical errors.

            # Delay before next cycle
            main_logger.debug(f"Waiting {loop_interval} seconds before next cycle...")
            time.sleep(loop_interval)

    except KeyboardInterrupt:
        init_logger.info("KeyboardInterrupt received during startup/shutdown. Shutting down...")
    except Exception as startup_err:
        init_logger.critical(f"Critical error during startup: {startup_err}", exc_info=True)
    finally:
        end_time_str = datetime.now(TIMEZONE).strftime('%Y-%m-%d %H:%M:%S %Z')
        init_logger.info(f"--- ScalpXRX Bot Shutdown ({end_time_str}) ---")
        logging.shutdown() # Ensure all logs are flushed


if __name__ == "__main__":
    main()
```

        # --- Cycle End Logging ---
        cycle_end_time = time.monotonic()
        lg.debug(f"---== Analysis Cycle End ({symbol}, {cycle_end_time - cycle_start_time:.2f}s) ==---")


def main() -> None:
    """Main function to initialize the bot and run the analysis loop."""
    global CONFIG, QUOTE_CURRENCY # Allow modification of globals

    # Setup initial logger
    init_logger = setup_logger("ScalpXRX_Init")
    init_logger.info(f"--- Starting ScalpXRX Bot ({datetime.now(TIMEZONE).strftime('%Y-%m-%d %H:%M:%S %Z')}) ---")

    CONFIG = load_config(CONFIG_FILE)
    QUOTE_CURRENCY = CONFIG.get("quote_currency", "USDT")
    TARGET_SYMBOL = CONFIG.get("symbol")
    if not TARGET_SYMBOL:
         init_logger.critical("CRITICAL: 'symbol' not defined in config.json. Exiting.")
         return

    # Setup logger specific to the target symbol for the main loop
    symbol_logger_name = f"ScalpXRX_{TARGET_SYMBOL.replace('/', '_').replace(':', '-')}"
    main_logger = setup_logger(symbol_logger_name)
    main_logger.info(f"Logging initialized for symbol: {TARGET_SYMBOL}")
    main_logger.info(f"Config loaded. Quote: {QUOTE_CURRENCY}, Interval: {CONFIG['interval']}")
```python
# sxs.py
# Enhanced and Upgraded Scalping Bot Framework
# Derived from xrscalper.py, focusing on robust execution, error handling,
# advanced position management (BE, TSL), and Bybit V5 compatibility.

import hashlib
import hmac
import json
import logging
import math
import os
import time
from datetime import datetime, timedelta, timezone
from decimal import ROUND_DOWN, ROUND_UP, Decimal, InvalidOperation, getcontext
from logging.handlers import RotatingFileHandler
from typing import Any, Dict, List, Optional, Tuple, Union

import ccxt
import numpy as np
import pandas as pd
import pandas_ta as ta  # Import pandas_ta
import requests
from colorama import Fore, Style, init
from dotenv import load_dotenv
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from zoneinfo import ZoneInfo

# Initialize colorama and set Decimal precision
getcontext().prec = 36  # Increased precision for complex calculations
init(autoreset=True)
load_dotenv()

# Neon Color Scheme
NEON_GREEN = Fore.LIGHTGREEN_EX
NEON_BLUE = Fore.CYAN
NEON_PURPLE = Fore.MAGENTA
NEON_YELLOW = Fore.YELLOW
NEON_RED = Fore.LIGHTRED_EX
NEON_CYAN = Fore.CYAN
RESET = Style.RESET_ALL

# --- Constants ---
API_KEY = os.getenv("BYBIT_API_KEY")
API_SECRET = os.getenv("BYBIT_API_SECRET")
if not API_KEY or not API_SECRET:
    raise ValueError("BYBIT_API_KEY and BYBIT_API_SECRET must be set in .env")

CONFIG_FILE = "config.json"
LOG_DIRECTORY = "bot_logs"
# Timezone for logging and display
TIMEZONE = ZoneInfo("America/Chicago")  # Adjust as needed (e.g., "Europe/London", "Asia/Tokyo", "UTC")
MAX_API_RETRIES = 5  # Max retries for recoverable API errors
RETRY_DELAY_SECONDS = 7  # Increased delay between retries
VALID_INTERVALS = ["1", "3", "5", "15", "30", "60", "120", "240", "D", "W", "M"]
CCXT_INTERVAL_MAP = { # Map our intervals to ccxt's expected format
    "1": "1m", "3": "3m", "5": "5m", "15": "15m", "30": "30m",
    "60": "1h", "120": "2h", "240": "4h", "D": "1d", "W": "1w", "M": "1M"
}
# HTTP status codes considered retryable (can be expanded)
RETRY_HTTP_CODES = [429, 500, 502, 503, 504]
# Bybit V5 specific error codes considered potentially retryable (transient issues)
# Check Bybit V5 API documentation for the most accurate list
BYBIT_V5_RETRY_CODES = [
    10001, # Internal server error
    10002, # Service Unavailable / Server Overloaded
    10006, # Request frequent, please try again later (Rate Limiting)
    10016, # Service unavailable / System maintenance
    130150, # Order placement failed due to system upgrade (transient)
    # Add others based on experience/docs, e.g., specific transient connection errors
]
# Default indicator periods (can be overridden by config.json)
DEFAULT_ATR_PERIOD = 14
DEFAULT_CCI_WINDOW = 20
DEFAULT_WILLIAMS_R_WINDOW = 14
DEFAULT_MFI_WINDOW = 14
DEFAULT_STOCH_RSI_WINDOW = 14
DEFAULT_STOCH_WINDOW = 12 # Underlying RSI window for StochRSI
DEFAULT_K_WINDOW = 3 # StochRSI K
DEFAULT_D_WINDOW = 3 # StochRSI D
DEFAULT_RSI_WINDOW = 14
DEFAULT_BOLLINGER_BANDS_PERIOD = 20
DEFAULT_BOLLINGER_BANDS_STD_DEV = 2.0
DEFAULT_SMA_10_WINDOW = 10
DEFAULT_EMA_SHORT_PERIOD = 9
DEFAULT_EMA_LONG_PERIOD = 21
DEFAULT_MOMENTUM_PERIOD = 7
DEFAULT_VOLUME_MA_PERIOD = 15
DEFAULT_FIB_WINDOW = 50
DEFAULT_PSAR_AF = 0.02
DEFAULT_PSAR_MAX_AF = 0.2

FIB_LEVELS = [0.0, 0.236, 0.382, 0.5, 0.618, 0.786, 1.0] # Standard Fibonacci levels
LOOP_DELAY_SECONDS = 10 # Time between the end of one cycle and the start of the next
POSITION_CONFIRM_DELAY_SECONDS = 12 # Increased wait time after placing order before confirming position
# QUOTE_CURRENCY dynamically loaded from config

os.makedirs(LOG_DIRECTORY, exist_ok=True)

# --- Global Config Variable ---
# Loaded in main() and potentially used by helper functions if needed,
# though passing explicitly is preferred.
config: Dict[str, Any] = {}
QUOTE_CURRENCY: str = "USDT" # Default, overridden by config

class SensitiveFormatter(logging.Formatter):
    """Formatter to redact sensitive information (API keys) from logs."""
    def format(self, record: logging.LogRecord) -> str:
        msg = super().format(record)
        if API_KEY:
            msg = msg.replace(API_KEY, "***API_KEY***")
        if API_SECRET:
            msg = msg.replace(API_SECRET, "***API_SECRET***")
        return msg

def load_config(filepath: str) -> Dict[str, Any]:
    """
    Load configuration from JSON file, creating default if not found,
    and ensuring all default keys are present with validation.
    """
    # Define the default configuration structure and values
    default_config = {
        # Trading pair and timeframe
        "symbol": "BTC/USDT:USDT", # Bybit linear perpetual example
        "interval": "5", # Default timeframe (e.g., "5" for 5 minutes)

        # API and Bot Behavior
        "retry_delay": RETRY_DELAY_SECONDS, # Delay between API retries
        "enable_trading": False, # Safety Feature: Must be explicitly set to true to trade
        "use_sandbox": True, # Safety Feature: Use testnet by default
        "max_concurrent_positions": 1, # Max open positions for this symbol instance (can be strategy-specific)
        "quote_currency": "USDT", # Quote currency for balance checks and sizing
        "position_confirm_delay_seconds": POSITION_CONFIRM_DELAY_SECONDS, # Delay after order before confirming position
        "loop_delay_seconds": LOOP_DELAY_SECONDS, # Delay between main loop cycles

        # Risk Management
        "risk_per_trade": 0.01, # Fraction of balance to risk (e.g., 0.01 = 1%)
        "leverage": 20, # Desired leverage (Ensure supported by exchange/market)
        "stop_loss_multiple": 1.8, # ATR multiple for initial SL (used for sizing/initial fixed SL)
        "take_profit_multiple": 0.7, # ATR multiple for initial TP

        # Order Execution
        "entry_order_type": "market", # "market" or "limit"
        "limit_order_offset_buy": 0.0005, # % offset from price for BUY limit (0.0005 = 0.05%)
        "limit_order_offset_sell": 0.0005, # % offset from price for SELL limit

        # Advanced Position Management
        "enable_trailing_stop": True, # Use exchange-native Trailing Stop Loss
        "trailing_stop_callback_rate": 0.005, # Trail distance % (e.g., 0.005 = 0.5% from peak/valley)
        "trailing_stop_activation_percentage": 0.003, # % profit move from entry to activate TSL
        "enable_break_even": True, # Enable moving SL to break-even point
        "break_even_trigger_atr_multiple": 1.0, # Move SL when profit >= X * ATR
        "break_even_offset_ticks": 2, # Place BE SL X ticks beyond entry price
        "time_based_exit_minutes": None, # Optional: Exit after X minutes (e.g., 60)

        # Indicator Periods & Parameters
        "atr_period": DEFAULT_ATR_PERIOD,
        "ema_short_period": DEFAULT_EMA_SHORT_PERIOD,
        "ema_long_period": DEFAULT_EMA_LONG_PERIOD,
        "rsi_period": DEFAULT_RSI_WINDOW,
        "bollinger_bands_period": DEFAULT_BOLLINGER_BANDS_PERIOD,
        "bollinger_bands_std_dev": DEFAULT_BOLLINGER_BANDS_STD_DEV,
        "cci_window": DEFAULT_CCI_WINDOW,
        "williams_r_window": DEFAULT_WILLIAMS_R_WINDOW,
        "mfi_window": DEFAULT_MFI_WINDOW,
        "stoch_rsi_window": DEFAULT_STOCH_RSI_WINDOW, # StochRSI main window
        "stoch_rsi_rsi_window": DEFAULT_STOCH_WINDOW, # Underlying RSI window for StochRSI
        "stoch_rsi_k": DEFAULT_K_WINDOW, # StochRSI K period
        "stoch_rsi_d": DEFAULT_D_WINDOW, # StochRSI D period
        "psar_af": DEFAULT_PSAR_AF, # PSAR Acceleration Factor
        "psar_max_af": DEFAULT_PSAR_MAX_AF, # PSAR Max Acceleration Factor
        "sma_10_window": DEFAULT_SMA_10_WINDOW,
        "momentum_period": DEFAULT_MOMENTUM_PERIOD,
        "volume_ma_period": DEFAULT_VOLUME_MA_PERIOD,
        "fibonacci_window": DEFAULT_FIB_WINDOW,

        # Indicator Calculation & Scoring Control
        "orderbook_limit": 25, # Depth of order book levels to fetch/analyze
        "signal_score_threshold": 1.5, # Score needed to trigger BUY/SELL signal
        "stoch_rsi_oversold_threshold": 25, # Threshold for StochRSI oversold score
        "stoch_rsi_overbought_threshold": 75, # Threshold for StochRSI overbought score
        "volume_confirmation_multiplier": 1.5, # Volume > Multiplier * VolMA for confirmation
        "indicators": { # Toggle calculation and scoring contribution
            "ema_alignment": True, "momentum": True, "volume_confirmation": True,
            "stoch_rsi": True, "rsi": True, "bollinger_bands": True, "vwap": True,
            "cci": True, "wr": True, "psar": True, "sma_10": True, "mfi": True,
            "orderbook": True, "atr": True, # ATR is often needed for SL/TP/sizing
        },
        "weight_sets": { # Define scoring weights for different strategies
            "scalping": { # Example: Faster, momentum-focused
                "ema_alignment": 0.2, "momentum": 0.3, "volume_confirmation": 0.2,
                "stoch_rsi": 0.6, "rsi": 0.2, "bollinger_bands": 0.3, "vwap": 0.4,
                "cci": 0.3, "wr": 0.3, "psar": 0.2, "sma_10": 0.1, "mfi": 0.2, "orderbook": 0.15,
                "atr": 0.0, # ATR value itself not usually scored, but used elsewhere
            },
            "default": { # Example: Balanced
                "ema_alignment": 0.3, "momentum": 0.2, "volume_confirmation": 0.1,
                "stoch_rsi": 0.4, "rsi": 0.3, "bollinger_bands": 0.2, "vwap": 0.3,
                "cci": 0.2, "wr": 0.2, "psar": 0.3, "sma_10": 0.1, "mfi": 0.2, "orderbook": 0.1,
                "atr": 0.0,
            }
        },
        "active_weight_set": "default" # Select the active weight set
    }

    merged_config = default_config.copy()
    if os.path.exists(filepath):
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                loaded_config = json.load(f)
            # Merge loaded config with defaults, ensuring all keys exist
            merged_config = _merge_configs(loaded_config, default_config)
            print(f"{NEON_GREEN}Loaded configuration from {filepath}{RESET}")
        except (json.JSONDecodeError, IOError) as e:
            print(f"{NEON_RED}Error loading config file {filepath}: {e}. Using default config.{RESET}")
            merged_config = default_config # Use in-memory default
            # Attempt to recreate default file if loading failed
            try:
                with open(filepath, "w", encoding="utf-8") as f_write:
                    json.dump(default_config, f_write, indent=4, ensure_ascii=False)
                print(f"{NEON_YELLOW}Recreated default config file: {filepath}{RESET}")
            except IOError as e_create:
                print(f"{NEON_RED}Error recreating default config file: {e_create}{RESET}")
    else:
        # Config file doesn't exist, create it with defaults
        print(f"{NEON_YELLOW}Config file not found. Creating default config at {filepath}{RESET}")
        try:
            with open(filepath, "w", encoding="utf-8") as f:
                json.dump(default_config, f, indent=4, ensure_ascii=False)
            merged_config = default_config
        except IOError as e:
            print(f"{NEON_RED}Error creating default config file {filepath}: {e}{RESET}")
            # Continue with in-memory default config if creation fails

    # --- Validation Section ---
    final_config = merged_config.copy() # Work on a copy for validation
    updated = False # Flag to track if config needs saving back

    # Validate symbol
    if not final_config.get("symbol") or not isinstance(final_config.get("symbol"), str) or "/" not in final_config["symbol"]:
         print(f"{NEON_RED}CRITICAL: 'symbol' ('{final_config.get('symbol')}') is missing, empty, or invalid format (e.g., BTC/USDT or BTC/USDT:USDT) in config. Resetting to default: '{default_config['symbol']}'{RESET}")
         final_config["symbol"] = default_config["symbol"]
         updated = True

    # Validate interval
    if str(final_config.get("interval")) not in VALID_INTERVALS:
        print(f"{NEON_RED}Invalid interval '{final_config.get('interval')}' in config. Resetting to default '{default_config['interval']}'. Valid: {VALID_INTERVALS}{RESET}")
        final_config["interval"] = default_config["interval"]
        updated = True

    # Validate entry order type
    if final_config.get("entry_order_type") not in ["market", "limit"]:
        print(f"{NEON_RED}Invalid entry_order_type '{final_config.get('entry_order_type')}' in config. Resetting to 'market'.{RESET}")
        final_config["entry_order_type"] = "market"
        updated = True

    # Validate active weight set exists
    if final_config.get("active_weight_set") not in final_config.get("weight_sets", {}):
         print(f"{NEON_RED}Active weight set '{final_config.get('active_weight_set')}' not found in 'weight_sets'. Resetting to 'default'.{RESET}")
         final_config["active_weight_set"] = "default" # Ensure 'default' exists in defaults
         updated = True

    # Validate numeric parameters (ranges and types)
    numeric_params = {
        # key: (min_val, max_val, allow_min_equal, allow_max_equal, is_integer, allow_none=False)
        "risk_per_trade": (0, 1, False, False, False),
        "leverage": (1, 1000, True, True, True), # Adjust max leverage realistically
        "stop_loss_multiple": (0, float('inf'), False, True, False),
        "take_profit_multiple": (0, float('inf'), False, True, False),
        "trailing_stop_callback_rate": (0, 1, False, False, False),
        "trailing_stop_activation_percentage": (0, 1, True, False, False), # Allow 0%
        "break_even_trigger_atr_multiple": (0, float('inf'), False, True, False),
        "break_even_offset_ticks": (0, 100, True, True, True),
        "signal_score_threshold": (0, float('inf'), False, True, False),
        "atr_period": (1, 1000, True, True, True),
        "ema_short_period": (1, 1000, True, True, True),
        "ema_long_period": (1, 1000, True, True, True),
        "rsi_period": (1, 1000, True, True, True),
        "bollinger_bands_period": (1, 1000, True, True, True),
        "bollinger_bands_std_dev": (0, 10, False, True, False),
        "cci_window": (1, 1000, True, True, True),
        "williams_r_window": (1, 1000, True, True, True),
        "mfi_window": (1, 1000, True, True, True),
        "stoch_rsi_window": (1, 1000, True, True, True),
        "stoch_rsi_rsi_window": (1, 1000, True, True, True),
        "stoch_rsi_k": (1, 1000, True, True, True),
        "stoch_rsi_d": (1, 1000, True, True, True),
        "psar_af": (0, 1, False, False, False),
        "psar_max_af": (0, 1, False, False, False),
        "sma_10_window": (1, 1000, True, True, True),
        "momentum_period": (1, 1000, True, True, True),
        "volume_ma_period": (1, 1000, True, True, True),
        "fibonacci_window": (2, 1000, True, True, True), # Need at least 2 points
        "orderbook_limit": (1, 100, True, True, True),
        "position_confirm_delay_seconds": (0, 60, True, True, False),
        "loop_delay_seconds": (1, 300, True, True, False),
        "stoch_rsi_oversold_threshold": (0, 100, True, False, False),
        "stoch_rsi_overbought_threshold": (0, 100, False, True, False),
        "volume_confirmation_multiplier": (0, float('inf'), False, True, False),
        "limit_order_offset_buy": (0, 0.1, True, False, False), # 10% offset max?
        "limit_order_offset_sell": (0, 0.1, True, False, False),
        "retry_delay": (1, 60, True, True, False),
        "max_concurrent_positions": (1, 100, True, True, True),
    }
    for key, params_tuple in numeric_params.items():
        min_val, max_val, allow_min, allow_max, is_integer = params_tuple
        allow_none = params_tuple[5] if len(params_tuple) > 5 else False # Check if allow_none is provided

        value = final_config.get(key)

        if value is None and allow_none:
            continue # Skip validation if None is allowed and value is None

        try:
            # Convert to Decimal first for robust validation, then to target type
            value_str = str(value)
            if value is None or value_str.strip() == '':
                 raise ValueError("Value is missing or empty")

            dec_value = Decimal(value_str)
            if not dec_value.is_finite():
                raise ValueError("Value is not finite (NaN or Infinity)")

            # Check bounds
            lower_bound_ok = dec_value >= Decimal(str(min_val)) if allow_min else dec_value > Decimal(str(min_val))
            upper_bound_ok = dec_value <= Decimal(str(max_val)) if allow_max else dec_value < Decimal(str(max_val))

            if not (lower_bound_ok and upper_bound_ok):
                raise ValueError(f"Value {dec_value} out of range "
                                 f"({min_val} {'<=' if allow_min else '<'} x {'<=' if allow_max else '<'} {max_val})")

            # Convert to final type (int or float)
            if is_integer:
                if dec_value != dec_value.to_integral_value(rounding=ROUND_DOWN):
                     raise ValueError("Value must be an integer")
                final_config[key] = int(dec_value)
            else:
                final_config[key] = float(dec_value) # Store as float for compatibility

        except (ValueError, TypeError, KeyError, InvalidOperation) as e:
            print(f"{NEON_RED}Invalid value for '{key}' ('{value}'): {e}. Resetting to default '{default_config[key]}'.{RESET}")
            final_config[key] = default_config[key]
            updated = True

    # Specific validation for time_based_exit_minutes (allow None or positive number)
    time_exit = final_config.get("time_based_exit_minutes")
    if time_exit is not None:
        try:
            time_exit_val = float(time_exit)
            if time_exit_val <= 0: raise ValueError("Must be positive if set")
            final_config["time_based_exit_minutes"] = time_exit_val # Store as float
        except (ValueError, TypeError) as e:
             print(f"{NEON_RED}Invalid value for 'time_based_exit_minutes' ({time_exit}): {e}. Resetting to default (None).{RESET}")
             final_config["time_based_exit_minutes"] = None
             updated = True

    # Ensure indicator weights are valid numbers
    for wset_name, wset in final_config.get("weight_sets", {}).items():
        if not isinstance(wset, dict): continue
        for indicator_key, weight_val in wset.items():
            try:
                 # Convert potential int/str to float
                 weight_float = float(weight_val)
                 if not math.isfinite(weight_float): raise ValueError("Weight not finite")
                 # Store as float
                 final_config["weight_sets"][wset_name][indicator_key] = weight_float
            except (ValueError, TypeError) as e:
                 print(f"{NEON_RED}Invalid weight for '{indicator_key}' in set '{wset_name}' ({weight_val}): {e}. Resetting to 0.0.{RESET}")
                 final_config["weight_sets"][wset_name][indicator_key] = 0.0
                 updated = True

    # If config was updated due to invalid values, save it back
    if updated:
        try:
            with open(filepath, "w", encoding="utf-8") as f_write:
                json.dump(final_config, f_write, indent=4, ensure_ascii=False)
            print(f"{NEON_YELLOW}Updated config file {filepath} with corrected/default values.{RESET}")
        except IOError as e:
            print(f"{NEON_RED}Error writing updated config file {filepath}: {e}{RESET}")

    return final_config

def _merge_configs(loaded_config: Dict, default_config: Dict) -> Dict:
    """
    Recursively merges the loaded configuration with default values.
    Ensures all keys from the default config exist in the final config.
    Prioritizes values from the loaded config. Handles nested dictionaries.
    """
    merged = default_config.copy()
    for key, loaded_value in loaded_config.items():
        # If key exists in both and both values are dicts, recurse
        if key in merged and isinstance(loaded_value, dict) and isinstance(merged[key], dict):
            merged[key] = _merge_configs(loaded_value, merged[key])
        else:
            # Otherwise, overwrite default with loaded value, regardless of type
            # This ensures user's config structure takes precedence if keys differ deeply
            merged[key] = loaded_value

    # Ensure all default keys exist at the top level if missing in loaded
    for key, default_value in default_config.items():
         if key not in loaded_config:
             merged[key] = default_value
         # Optional: Add logic here to ensure default nested keys exist if top key was present but nested keys were missing

    return merged

def setup_logger(name: str, level: int = logging.INFO) -> logging.Logger:
    """Sets up a logger with rotating file and colored console handlers."""
    logger = logging.getLogger(name)
    # Prevent adding multiple handlers if logger is reused (e.g., in interactive sessions)
    if logger.hasHandlers():
        for handler in logger.handlers[:]:
            try: handler.close()
            except Exception: pass # Ignore errors closing handlers
            logger.removeHandler(handler)

    logger.setLevel(logging.DEBUG) # Capture all levels at the logger level

    # File Handler (Rotating) - Ensure unique filename per symbol instance if needed
    # For simplicity, using the provided name which might be reused if script restarts quickly
    log_filename = os.path.join(LOG_DIRECTORY, f"{name}.log")
    try:
        file_handler = RotatingFileHandler(
            log_filename, maxBytes=10 * 1024 * 1024, backupCount=5, encoding='utf-8'
        )
        file_formatter = SensitiveFormatter(
            "%(asctime)s.%(msecs)03d %(levelname)-8s [%(name)s:%(lineno)d] %(message)s",
            datefmt='%Y-%m-%d %H:%M:%S' # File logs don't need TZ display usually
        )
        file_handler.setFormatter(file_formatter)
        file_handler.setLevel(logging.DEBUG) # Log DEBUG and above to file
        logger.addHandler(file_handler)
    except PermissionError:
         print(f"{NEON_RED}Permission denied creating log file: {log_filename}. Check permissions.{RESET}")
    except Exception as e:
        print(f"{NEON_RED}Error setting up file logger {log_filename}: {e}{RESET}")

    # Console Handler (Colored)
    stream_handler = logging.StreamHandler()
    # Define formatter with colors and specific date format including TZ abbreviation
    console_formatter = SensitiveFormatter(
        f"{NEON_BLUE}%(asctime)s{RESET} {NEON_YELLOW}%(levelname)-8s{RESET} {NEON_PURPLE}[%(name)s]{RESET} %(message)s",
        datefmt='%Y-%m-%d %H:%M:%S %Z' # Format includes TZ name
    )
    # Use lambda to dynamically get current time in target TZ for formatting
    console_formatter.converter = lambda *args: datetime.now(TIMEZONE).timetuple()

    stream_handler.setFormatter(console_formatter)
    stream_handler.setLevel(level) # Set console level (e.g., INFO)
    logger.addHandler(stream_handler)

    logger.propagate = False # Prevent duplicate logs in root logger
    return logger

# --- CCXT Exchange Setup ---
def initialize_exchange(config: Dict[str, Any], logger: logging.Logger) -> Optional[ccxt.Exchange]:
    """Initializes the CCXT Bybit exchange object with enhanced error handling and V5 setup."""
    lg = logger
    try:
        exchange_options = {
            'apiKey': API_KEY,
            'secret': API_SECRET,
            'enableRateLimit': True, # Use CCXT's built-in rate limiter
            'rateLimit': 150, # Milliseconds per request (adjust based on API limits/needs)
            'options': {
                'defaultType': 'linear', # Essential for Bybit V5 USDT/USDC perpetuals
                'adjustForTimeDifference': True, # Helps with timestamp sync issues
                # Increased timeouts (in milliseconds)
                'fetchTickerTimeout': 15000, 'fetchBalanceTimeout': 20000,
                'createOrderTimeout': 25000, 'cancelOrderTimeout': 20000,
                'fetchPositionsTimeout': 20000, 'fetchOHLCVTimeout': 20000,
                # Add user agent for potential identification / courtesy
                'user-agent': 'ScalpXRX Bot v1.1 (github.com/user/repo)', # Replace with actual repo if applicable
                # Bybit V5 specific options (can add more if needed)
                'recvWindow': 10000, # Increased recvWindow for timestamp tolerance
                # 'brokerId': 'YOUR_BROKER_ID', # If using broker API
            }
        }

        exchange_id = "bybit" # Hardcoded for Bybit focus
        exchange_class = getattr(ccxt, exchange_id)
        exchange = exchange_class(exchange_options)

        # --- Sandbox Mode Setup ---
        if config.get('use_sandbox'):
            lg.warning(f"{NEON_YELLOW}USING SANDBOX MODE (Testnet){RESET}")
            try:
                # Bybit testnet URL is usually automatically handled by ccxt when keys are testnet keys.
                # Explicitly setting sandbox mode might not be needed or supported depending on ccxt version.
                # exchange.set_sandbox_mode(True) # Older ccxt versions might have this
                # Instead, rely on Testnet API keys and verify via initial connection.
                lg.info("Ensuring API keys correspond to Bybit Testnet environment.")
                # Manually set URL if needed (less ideal than relying on keys/ccxt)
                # exchange.urls['api'] = 'https://api-testnet.bybit.com'
                # lg.info("Manually set Bybit API URL to Testnet (if required).")
            except Exception as e:
                lg.error(f"Note: Error attempting to explicitly set sandbox mode (may not be needed/supported): {e}")
        else:
            lg.warning(f"{NEON_RED}!!! USING LIVE (Real Money) Environment !!!{RESET}")

        lg.info(f"Initializing {exchange.id} ({'Sandbox' if config.get('use_sandbox') else 'Live'})...")

        # --- Initial Connection & Permissions Test (Fetch Balance - CONTRACT Account) ---
        # Bybit V5 uses account types. CONTRACT covers USDT/USDC perpetuals.
        account_type_to_test = 'CONTRACT'
        lg.info(f"Attempting initial balance fetch (Account Type: {account_type_to_test})...")
        balance = None
        try:
            params = {'accountType': account_type_to_test} if exchange.id == 'bybit' else {} # Correct param for V5
            balance = safe_api_call(exchange.fetch_balance, lg, params=params)

            if balance and balance.get('info', {}).get('retCode') == 0:
                quote_curr = config.get("quote_currency", "USDT")
                available_quote_val = balance.get(quote_curr, {}).get('free')
                if available_quote_val is None:
                    lg.warning(f"Could not find 'free' balance for {quote_curr} in standard structure. Checking Bybit V5 'info'.")
                    # Try parsing Bybit V5 structure if standard fails
                    try:
                        v5_list = balance.get('info', {}).get('result', {}).get('list', [])
                        if v5_list and isinstance(v5_list, list):
                            # Find the correct account type within the list
                            contract_acc = next((acc for acc in v5_list if acc.get('accountType') == account_type_to_test), None)
                            if contract_acc and isinstance(contract_acc.get('coin'), list):
                                coin_data = next((c for c in contract_acc['coin'] if c.get('coin') == quote_curr), None)
                                if coin_data:
                                    # Prefer 'availableToWithdraw' or 'availableBalance'
                                    available_quote_val = coin_data.get('availableToWithdraw') or coin_data.get('availableBalance')
                                    lg.debug(f"Found Bybit V5 balance: {available_quote_val}")

                    except Exception as parse_err:
                         lg.warning(f"Error parsing Bybit V5 balance structure: {parse_err}")

                available_quote_str = str(available_quote_val) if available_quote_val is not None else 'N/A'
                lg.info(f"{NEON_GREEN}Successfully connected and fetched initial balance.{RESET} (Example: {quote_curr} available: {available_quote_str})")
            elif balance and balance.get('info', {}).get('retCode') != 0:
                 ret_code = balance.get('info', {}).get('retCode')
                 ret_msg = balance.get('info', {}).get('retMsg')
                 lg.error(f"{NEON_RED}Initial balance fetch failed with Bybit error: Code={ret_code}, Msg='{ret_msg}'.{RESET}")
                 # Handle specific common errors
                 if ret_code == 10003: # Invalid API Key
                      lg.critical(f"{NEON_RED}>> Invalid API Key or incorrect environment (Live vs Testnet). Check .env file.{RESET}")
                 elif ret_code == 10004: # Invalid Signature
                      lg.critical(f"{NEON_RED}>> Invalid API Secret or timestamp issue. Check .env file and system clock sync.{RESET}")
                 elif ret_code == 10005: # Permission Denied
                      lg.critical(f"{NEON_RED}>> API Key lacks necessary permissions (Read, Trade/Order). Check key settings on Bybit.{RESET}")
                 elif ret_code == 10010: # IP Whitelist Mismatch
                      lg.critical(f"{NEON_RED}>> IP address not whitelisted for this API key. Check key settings on Bybit.{RESET}")
                 return None # Fatal error
            else:
                 lg.warning(f"{NEON_YELLOW}Initial balance fetch (Type: {account_type_to_test}) returned unexpected data or failed after retries. Check connection/permissions.{RESET}")
                 lg.debug(f"Balance response received: {balance}") # Log full response for debugging

        except ccxt.AuthenticationError as auth_err:
             lg.critical(f"{NEON_RED}CRITICAL Authentication Error during initial balance fetch: {auth_err}{RESET}")
             lg.critical(f"{NEON_RED}>> Ensure API keys (in .env) are correct, have permissions (Read, Trade/Order), match environment (Real/Testnet), and IP whitelist is correct.{RESET}")
             return None # Fatal error
        except ccxt.ExchangeError as balance_err:
             lg.warning(f"{NEON_YELLOW}Exchange error during initial balance fetch: {balance_err}. May proceed cautiously.{RESET}")
             # Could try default fetch_balance here as a fallback if needed
        except Exception as balance_err: # Catches errors from safe_api_call or parsing
             lg.warning(f"{NEON_YELLOW}Could not perform initial balance fetch after retries or due to error: {balance_err}. Proceeding cautiously.{RESET}")

        # --- Load Markets (Crucial for market info, precision, etc.) ---
        lg.info(f"Loading markets for {exchange.id}...")
        try:
             safe_api_call(exchange.load_markets, lg, reload=True) # Force reload
             lg.info(f"Markets loaded successfully for {exchange.id}.")
             # Verify the target symbol exists after loading markets
             target_symbol = config.get('symbol')
             if target_symbol and target_symbol not in exchange.markets:
                  lg.error(f"{NEON_RED}Target symbol '{target_symbol}' not found in loaded markets! Ensure it's correct (e.g., 'BTC/USDT:USDT' for Bybit linear).{RESET}")
                  # Optionally list available similar symbols as hint
                  possible_symbols = [s for s in exchange.symbols if target_symbol.split('/')[0] in s and config.get('quote_currency','USDT') in s]
                  if possible_symbols: lg.warning(f"Available related symbols: {possible_symbols[:10]}") # Show first few
                  return None # Fatal if target symbol is invalid
             elif target_symbol:
                  lg.info(f"Target symbol '{target_symbol}' validated in loaded markets.")

        except Exception as market_err:
             lg.critical(f"{NEON_RED}Failed to load markets after retries: {market_err}. Cannot operate without market data. Exiting.{RESET}")
             return None # Fatal error if markets cannot be loaded

        lg.info(f"CCXT exchange initialized ({exchange.id}). Sandbox: {config.get('use_sandbox')}")
        return exchange

    except ccxt.AuthenticationError as e: # Catch auth errors during class instantiation
        lg.critical(f"{NEON_RED}CCXT Authentication Error during initialization: {e}{RESET}")
        lg.critical(f"{NEON_RED}>> Check API Key/Secret format and validity in your .env file.{RESET}")
    except ccxt.NetworkError as e:
        lg.critical(f"{NEON_RED}CCXT Network Error initializing (Check connection/firewall): {e}{RESET}")
    except ccxt.ExchangeError as e:
        lg.error(f"{NEON_RED}CCXT Exchange Error initializing: {e}{RESET}")
    except Exception as e:
        lg.critical(f"{NEON_RED}Failed to initialize CCXT exchange: {e}{RESET}", exc_info=True)

    return None

# --- API Call Wrapper with Retries ---
def safe_api_call(func, logger: logging.Logger, *args, **kwargs):
    """Wraps an API call with retry logic for network/rate limit/specific exchange errors."""
    lg = logger
    attempts = 0
    max_retries = config.get("max_api_retries", MAX_API_RETRIES)
    retry_delay = config.get("retry_delay", RETRY_DELAY_SECONDS)

    while attempts <= max_retries:
        try:
            result = func(*args, **kwargs)
            # lg.debug(f"API call {func.__name__} successful.") # Optional success log
            return result # Success
        except (ccxt.NetworkError, ccxt.RequestTimeout, requests.exceptions.ConnectionError, requests.exceptions.Timeout, ccxt.ExchangeNotAvailable, ccxt.DDoSProtection) as e:
            wait_time = retry_delay * (1.5 ** attempts) # Exponential backoff
            lg.warning(f"{NEON_YELLOW}Retryable network/availability error in {func.__name__}: {type(e).__name__}. Waiting {wait_time:.1f}s (Attempt {attempts+1}/{max_retries}). Error: {e}{RESET}")
            time.sleep(wait_time)
        except ccxt.RateLimitExceeded as e:
            wait_time_header = getattr(e, 'retry_after', None) # CCXT sometimes provides this
            wait_time = retry_delay * (2 ** attempts) # Stronger backoff for rate limits
            if wait_time_header:
                try: wait_time = max(wait_time, float(wait_time_header) + 0.5) # Add buffer
                except ValueError: pass # Ignore invalid header
            lg.warning(f"{NEON_YELLOW}Rate limit exceeded in {func.__name__}. Waiting {wait_time:.1f}s (Attempt {attempts+1}/{max_retries}). Error: {e}{RESET}")
            time.sleep(wait_time)
        except ccxt.AuthenticationError as e:
             lg.critical(f"{NEON_RED}Authentication Error in {func.__name__}: {e}. Aborting call and likely stopping bot.{RESET}")
             raise e # Don't retry, re-raise immediately - this is critical
        except ccxt.ExchangeError as e:
            # Check if the error is specifically marked as retryable by Bybit V5 codes
            exchange_code = None
            if isinstance(e.args, tuple) and len(e.args) > 0:
                 # CCXT often puts exchange message here, sometimes includes code
                 msg_part = str(e.args[0])
                 # Attempt to extract Bybit V5 code (can be fragile)
                 try:
                      # Example: "bybit {"retCode":10006,"retMsg":"Too many visits!","result":{},..."
                      if "bybit" in msg_part and "retCode" in msg_part:
                           # Basic parsing, might need refinement
                           json_part = msg_part[msg_part.find('{'):]
                           error_info = json.loads(json_part)
                           exchange_code = error_info.get('retCode')
                 except (json.JSONDecodeError, IndexError):
                      pass # Failed to extract code

            err_str = str(e).lower()
            is_retryable_bybit_code = exchange_code in BYBIT_V5_RETRY_CODES
            is_retryable_http_code = getattr(e, 'http_status', None) in RETRY_HTTP_CODES
            # Check for generic messages indicating transient issues
            is_retryable_message = "service unavailable" in err_str or \
                                   "internal server error" in err_str or \
                                   "system busy" in err_str or \
                                   "request timed out" in err_str

            if is_retryable_bybit_code or is_retryable_http_code or is_retryable_message:
                 wait_time = retry_delay * (1.5 ** attempts)
                 lg.warning(f"{NEON_YELLOW}Potentially retryable exchange error in {func.__name__}: {e} (Code: {exchange_code}, HTTP: {getattr(e, 'http_status', 'N/A')}). Waiting {wait_time:.1f}s (Attempt {attempts+1}/{max_retries})...{RESET}")
                 time.sleep(wait_time)
            else:
                 # Log non-retryable exchange errors but don't necessarily crash the whole bot unless critical
                 lg.error(f"{NEON_RED}Non-retryable Exchange Error in {func.__name__}: {e} (Code: {exchange_code}, HTTP: {getattr(e, 'http_status', 'N/A')}){RESET}")
                 # Depending on the error, you might want to raise it or return None/False
                 # For now, re-raise to let the calling function handle it
                 raise e
        except Exception as e:
            # Catch any other unexpected error
            lg.error(f"{NEON_RED}Unexpected error during API call {func.__name__}: {e}{RESET}", exc_info=True)
            raise e # Re-raise unexpected errors immediately

        attempts += 1

    # If loop completes, max retries exceeded
    lg.error(f"{NEON_RED}Max retries ({max_retries}) exceeded for API call {func.__name__}.{RESET}")
    # Raise the last known exception or a generic timeout
    # We raise the exception to allow the calling function to handle the failure state
    raise ccxt.RequestTimeout(f"Max retries exceeded for {func.__name__} after multiple failures.")


# --- CCXT Data Fetching (Using safe_api_call) ---
def fetch_current_price_ccxt(exchange: ccxt.Exchange, symbol: str, logger: logging.Logger) -> Optional[Decimal]:
    """Fetch the current price of a trading symbol using CCXT ticker with fallbacks and retries."""
    lg = logger
    try:
        ticker = safe_api_call(exchange.fetch_ticker, lg, symbol)
        if not ticker:
            lg.error(f"Failed to fetch ticker for {symbol} after retries.")
            return None # Error logged by safe_api_call

        # lg.debug(f"Ticker data for {symbol}: {ticker}") # Can be noisy
        price = None
        # Prioritize Bybit V5 specific field 'lastPrice' if available
        last_price = ticker.get('info', {}).get('lastPrice') or ticker.get('last')
        bid_price = ticker.get('bid')
        ask_price = ticker.get('ask')
        # Use 'markPrice' as a potential fallback if 'last' is unreliable, common in derivatives
        mark_price = ticker.get('info', {}).get('markPrice') or ticker.get('mark')

        # Robust Decimal conversion helper
        def to_decimal(value) -> Optional[Decimal]:
            if value is None: return None
            try:
                d = Decimal(str(value))
                # Ensure the price is finite and positive
                return d if d.is_finite() and d > Decimal('0') else None
            except (InvalidOperation, ValueError, TypeError):
                lg.warning(f"Invalid price format encountered: {value}")
                return None

        p_last = to_decimal(last_price)
        p_bid = to_decimal(bid_price)
        p_ask = to_decimal(ask_price)
        p_mark = to_decimal(mark_price)

        # Determine price with priority: last -> mark -> mid(bid/ask) -> ask -> bid
        if p_last:
            price = p_last; lg.debug(f"Using 'last' price: {price}")
        elif p_mark:
            price = p_mark; lg.debug(f"Using 'mark' price as fallback: {price}")
        elif p_bid and p_ask: # Use bid/ask midpoint
            price = (p_bid + p_ask) / Decimal('2'); lg.debug(f"Using bid/ask midpoint: {price}")
        elif p_ask: # Fallback to ask
            price = p_ask; lg.warning(f"Using 'ask' price fallback: {price}")
        elif p_bid: # Fallback to bid
            price = p_bid; lg.warning(f"Using 'bid' price fallback: {price}")

        # Final validation
        if price is not None and price.is_finite() and price > Decimal('0'):
            return price
        else:
            lg.error(f"{NEON_RED}Failed to extract a valid price from ticker data for {symbol}. Ticker: {ticker}{RESET}")
            return None

    except ccxt.RequestTimeout:
         lg.error(f"{NEON_RED}Timeout fetching current price for {symbol} after retries.{RESET}")
         return None
    except ccxt.AuthenticationError: # Should be caught by safe_api_call but handle defensively
         lg.critical(f"{NEON_RED}Authentication error fetching price for {symbol}. Check API keys/permissions.{RESET}")
         raise # Propagate critical error
    except ccxt.ExchangeError as e:
         lg.error(f"{NEON_RED}Exchange error fetching price for {symbol}: {e}{RESET}")
         return None
    except Exception as e:
        # Catch errors raised by safe_api_call or during parsing
        lg.error(f"{NEON_RED}Error fetching/processing current price for {symbol}: {e}{RESET}", exc_info=False) # Keep log concise
        return None

def fetch_klines_ccxt(exchange: ccxt.Exchange, symbol: str, timeframe: str, limit: int = 250, logger: logging.Logger = None) -> pd.DataFrame:
    """Fetch OHLCV kline data using CCXT with retries and robust validation."""
    lg = logger or logging.getLogger(__name__) # Use provided logger or get default
    empty_df = pd.DataFrame() # Define empty df for return on failure

    if not exchange.has['fetchOHLCV']:
        lg.error(f"Exchange {exchange.id} does not support fetchOHLCV.")
        return empty_df

    try:
        # Use safe_api_call to handle retries
        ohlcv = safe_api_call(exchange.fetch_ohlcv, lg, symbol, timeframe=timeframe, limit=limit)

        if ohlcv is None or not isinstance(ohlcv, list) or len(ohlcv) == 0:
            # Error logged by safe_api_call if failed after retries
            if ohlcv is not None: # Log only if it returned empty list/None without raising error
                lg.warning(f"{NEON_YELLOW}No valid kline data returned for {symbol} {timeframe} (Empty List/None).{RESET}")
            # If safe_api_call raised an error, it's already logged.
            return empty_df

        # Process the data into a pandas DataFrame
        df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])

        if df.empty:
            lg.warning(f"Kline data DataFrame is initially empty for {symbol} {timeframe}.")
            return empty_df

        # Convert timestamp to datetime objects (UTC), coerce errors to NaT
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms', errors='coerce', utc=True)
        df.dropna(subset=['timestamp'], inplace=True) # Drop rows where timestamp conversion failed
        if df.empty:
             lg.warning(f"Kline data empty after dropping invalid timestamps for {symbol} {timeframe}.")
             return empty_df
        df.set_index('timestamp', inplace=True)

        # Convert price/volume columns to numeric Decimal, handling potential errors robustly
        for col in ['open', 'high', 'low', 'close', 'volume']:
             if col not in df.columns:
                  lg.warning(f"Column '{col}' missing in fetched kline data for {symbol}. Skipping.")
                  continue # Skip if column doesn't exist

             try:
                  # Apply robust conversion to Decimal:
                  # 1. Convert to string first to handle various input types (int, float, str).
                  # 2. Handle None/NaN explicitly -> Decimal('NaN').
                  # 3. Handle empty strings -> Decimal('NaN').
                  # 4. Catch potential exceptions during Decimal conversion.
                  def safe_to_decimal(x):
                      if pd.isna(x): return Decimal('NaN')
                      try:
                          val_str = str(x).strip()
                          if not val_str: return Decimal('NaN')
                          return Decimal(val_str)
                      except (InvalidOperation, ValueError, TypeError):
                          return Decimal('NaN')

                  df[col] = df[col].apply(safe_to_decimal)

             except Exception as conv_err: # Catch unexpected errors during apply
                  lg.error(f"Unexpected error converting column '{col}' to Decimal: {conv_err}. Attempting pd.to_numeric fallback.", exc_info=True)
                  # Fallback: Convert to standard numeric (float), coercing errors to NaN
                  df[col] = pd.to_numeric(df[col], errors='coerce')

        # Data Cleaning:
        # 1. Drop rows with NaN in essential price columns (O, H, L, C)
        initial_len = len(df)
        df.dropna(subset=['open', 'high', 'low', 'close'], inplace=True)
        rows_dropped_nan_price = initial_len - len(df)
        if rows_dropped_nan_price > 0:
             lg.debug(f"Dropped {rows_dropped_nan_price} rows with NaN price data for {symbol}.")
             if df.empty: lg.warning("Kline data empty after dropping NaN price rows."); return empty_df

        # 2. Filter out rows with non-positive or non-finite close prices (important!)
        # Ensure we are working with the 'close' column safely
        if 'close' in df.columns:
            close_col = df['close']
            initial_len = len(df)
            # Check the type of the first non-NaN element to decide filtering method
            first_valid_close_idx = close_col.first_valid_index()
            if first_valid_close_idx is not None:
                 first_val_type = type(close_col[first_valid_close_idx])

                 if first_val_type == Decimal:
                     # Use Decimal methods for filtering
                     df = df[close_col.apply(lambda x: isinstance(x, Decimal) and x.is_finite() and x > Decimal('0'))]
                 elif pd.api.types.is_numeric_dtype(close_col.dtype): # Check if float/int
                      # Use numpy methods for filtering float columns
                      df = df[np.isfinite(close_col) & (close_col > 0)]
                 else:
                      lg.warning(f"Close column type ({first_val_type}) not Decimal or standard numeric. Skipping non-positive/finite filter.")

            rows_dropped_invalid_close = initial_len - len(df)
            if rows_dropped_invalid_close > 0:
                lg.debug(f"Dropped {rows_dropped_invalid_close} rows with non-positive/non-finite close prices for {symbol}.")
                if df.empty: lg.warning("Kline data empty after dropping invalid close prices."); return empty_df
        else:
             lg.warning("Column 'close' not found for invalid price filtering.")


        if df.empty:
            # Already logged reasons above if filtering caused emptiness
            return empty_df

        # Sort by timestamp index (should be sorted by exchange, but good practice)
        df.sort_index(inplace=True)
        # Remove duplicate timestamps (e.g., from API glitches), keeping the last occurrence
        initial_len = len(df)
        df = df[~df.index.duplicated(keep='last')]
        rows_dropped_duplicates = initial_len - len(df)
        if rows_dropped_duplicates > 0:
             lg.debug(f"Removed {rows_dropped_duplicates} duplicate timestamp entries for {symbol}.")
             if df.empty: lg.warning("Kline data empty after removing duplicates."); return empty_df

        lg.info(f"Successfully fetched and processed {len(df)} klines for {symbol} {timeframe}")
        return df

    except ccxt.RequestTimeout:
         lg.error(f"{NEON_RED}Timeout fetching klines for {symbol} {timeframe} after retries.{RESET}")
         return empty_df
    except ccxt.AuthenticationError:
         lg.critical(f"{NEON_RED}Authentication error fetching klines for {symbol}. Check API keys/permissions.{RESET}")
         raise # Propagate critical error
    except ccxt.ExchangeError as e:
         lg.error(f"{NEON_RED}Exchange error fetching klines for {symbol}: {e}{RESET}")
         return empty_df
    except Exception as e:
        # Catch errors from safe_api_call or during processing
        lg.error(f"{NEON_RED}Error fetching/processing klines for {symbol}: {e}{RESET}", exc_info=True)
        return empty_df


def fetch_orderbook_ccxt(exchange: ccxt.Exchange, symbol: str, limit: int, logger: logging.Logger) -> Optional[Dict]:
    """Fetch orderbook data using ccxt with retries and validation."""
    lg = logger
    if not exchange.has['fetchOrderBook']:
        lg.error(f"Exchange {exchange.id} does not support fetchOrderBook.")
        return None

    try:
        # Ensure limit is positive integer
        limit = max(1, int(limit))
        orderbook = safe_api_call(exchange.fetch_order_book, lg, symbol, limit=limit)

        if not orderbook: # Error already logged by safe_api_call if it failed
            lg.error(f"Failed to fetch order book for {symbol} after retries.")
            return None

        # Validate structure
        if not isinstance(orderbook, dict) or 'bids' not in orderbook or 'asks' not in orderbook or \
           not isinstance(orderbook.get('bids'), list) or not isinstance(orderbook.get('asks'), list):
            lg.warning(f"Invalid orderbook structure received for {symbol}. Data: {orderbook}")
            return None

        # Check if bids or asks are empty, which is valid but maybe noteworthy
        if not orderbook['bids'] and not orderbook['asks']:
            lg.debug(f"Orderbook received but both bids and asks lists are empty for {symbol}.")
            # Return the empty but valid book
            return orderbook
        elif not orderbook['bids']:
             lg.debug(f"Orderbook for {symbol} has asks but no bids.")
        elif not orderbook['asks']:
             lg.debug(f"Orderbook for {symbol} has bids but no asks.")


        # Basic validation of bid/ask entry format (price, size structure) and numeric conversion
        valid = True
        for side in ['bids', 'asks']:
             if orderbook[side]: # Check first entry if list is not empty
                  entry = orderbook[side][0]
                  if not (isinstance(entry, list) and len(entry) == 2):
                       lg.warning(f"Invalid {side[:-1]} entry format in orderbook: {entry}")
                       valid = False; break
                  try: # Check if price and size are convertible to Decimal and positive
                       price = Decimal(str(entry[0]))
                       size = Decimal(str(entry[1]))
                       if not price.is_finite() or price <= 0 or not size.is_finite() or size < 0:
                           raise ValueError("Price/Size not finite positive")
                  except (ValueError, TypeError, InvalidOperation):
                       lg.warning(f"Non-numeric or invalid data in {side[:-1]} entry: {entry}")
                       valid = False; break
        if not valid:
             lg.error("Orderbook data format validation failed.")
             return None

        lg.debug(f"Successfully fetched orderbook for {symbol} ({len(orderbook['bids'])} bids, {len(orderbook['asks'])} asks).")
        return orderbook

    except ccxt.RequestTimeout:
         lg.error(f"{NEON_RED}Timeout fetching orderbook for {symbol} after retries.{RESET}")
         return None
    except ccxt.AuthenticationError:
         lg.critical(f"{NEON_RED}Authentication error fetching orderbook for {symbol}. Check API keys/permissions.{RESET}")
         raise
    except ccxt.ExchangeError as e:
         lg.error(f"{NEON_RED}Exchange error fetching orderbook for {symbol}: {e}{RESET}")
         return None
    except Exception as e:
        # Catch errors raised by safe_api_call or other validation issues
        lg.error(f"{NEON_RED}Error fetching order book for {symbol}: {e}{RESET}", exc_info=False)
        return None

# --- Trading Analyzer Class ---
class TradingAnalyzer:
    """Analyzes trading data using pandas_ta and generates weighted signals."""

    def __init__(
        self,
        df: pd.DataFrame,
        logger: logging.Logger,
        config_in: Dict[str, Any],
        market_info: Dict[str, Any],
    ) -> None:
        """
        Initializes the TradingAnalyzer.

        Args:
            df: Pandas DataFrame with OHLCV data (expects Decimal values), indexed by timestamp.
            logger: Logger instance for logging messages.
            config_in: Dictionary containing bot configuration.
            market_info: Dictionary containing market details (precision, limits, etc.).
        """
        self.df = df # Expects OHLCV columns with Decimal type from fetch_klines
        self.logger = logger
        self.config = config_in # Use the passed config directly
        self.market_info = market_info
        self.symbol = market_info.get('symbol', 'UNKNOWN_SYMBOL')
        self.interval = self.config.get("interval", "5")
        self.ccxt_interval = CCXT_INTERVAL_MAP.get(self.interval)
        if not self.ccxt_interval:
            self.logger.error(f"Invalid interval '{self.interval}' in config for {self.symbol}.")
            # Bot might fail later if this is not valid

        # Stores latest indicator values (Decimal for prices/ATR, float for others)
        self.indicator_values: Dict[str, Union[Decimal, float, Any]] = {}
        self.signals: Dict[str, int] = {"BUY": 0, "SELL": 0, "HOLD": 1} # Default HOLD
        self.active_weight_set_name = self.config.get("active_weight_set", "default")
        self.weights = self.config.get("weight_sets", {}).get(self.active_weight_set_name, {})
        self.fib_levels_data: Dict[str, Decimal] = {} # Stores calculated fib levels
        self.ta_column_names: Dict[str, Optional[str]] = {} # Maps internal name to actual DataFrame column name

        if not self.weights:
            logger.warning(f"{NEON_YELLOW}Active weight set '{self.active_weight_set_name}' not found or empty for {self.symbol}. Scoring will be zero.{RESET}")
            self.weights = {} # Use empty dict to prevent errors

        # Perform initial calculations only if DataFrame is valid
        if not self.df.empty:
             self._calculate_all_indicators()
             # Only update latest values if calculation didn't wipe the df
             if not self.df.empty:
                  self._update_latest_indicator_values()
                  self.calculate_fibonacci_levels()
             else:
                  self.logger.warning("DataFrame became empty after indicator calculation. Cannot update latest values.")
        else:
             self.logger.warning("TradingAnalyzer initialized with empty DataFrame. No calculations performed.")


    def _get_ta_col_name(self, base_name: str, result_df: pd.DataFrame) -> Optional[str]:
        """Helper to find the actual column name generated by pandas_ta, considering config."""
        df_cols = result_df.columns.tolist()
        # Define expected patterns based on default names AND config parameters
        # Note: pandas_ta naming can sometimes be inconsistent or change slightly.
        # This attempts to cover common patterns.
        expected_patterns = []
        try:
            if base_name == "ATR":
                expected_patterns.append(f"ATRr_{self.config.get('atr_period', DEFAULT_ATR_PERIOD)}")
            elif base_name == "EMA_Short":
                expected_patterns.append(f"EMA_{self.config.get('ema_short_period', DEFAULT_EMA_SHORT_PERIOD)}")
            elif base_name == "EMA_Long":
                expected_patterns.append(f"EMA_{self.config.get('ema_long_period', DEFAULT_EMA_LONG_PERIOD)}")
            elif base_name == "Momentum":
                expected_patterns.append(f"MOM_{self.config.get('momentum_period', DEFAULT_MOMENTUM_PERIOD)}")
            elif base_name == "CCI":
                # CCI name might include the constant factor, e.g., CCI_20_0.015
                # Use startswith for broader matching
                expected_patterns.append(f"CCI_{self.config.get('cci_window', DEFAULT_CCI_WINDOW)}")
            elif base_name == "Williams_R":
                expected_patterns.append(f"WILLR_{self.config.get('williams_r_window', DEFAULT_WILLIAMS_R_WINDOW)}")
            elif base_name == "MFI":
                expected_patterns.append(f"MFI_{self.config.get('mfi_window', DEFAULT_MFI_WINDOW)}")
            elif base_name == "VWAP":
                expected_patterns.append("VWAP_D") # Default daily VWAP from pandas_ta
                expected_patterns.append("VWAP")   # Sometimes just VWAP
            elif base_name == "PSAR_long":
                expected_patterns.append(f"PSARl_{self.config.get('psar_af', DEFAULT_PSAR_AF)}_{self.config.get('psar_max_af', DEFAULT_PSAR_MAX_AF)}")
            elif base_name == "PSAR_short":
                expected_patterns.append(f"PSARs_{self.config.get('psar_af', DEFAULT_PSAR_AF)}_{self.config.get('psar_max_af', DEFAULT_PSAR_MAX_AF)}")
            elif base_name == "SMA10": # Renamed from SMA_10 to match potential pandas_ta output
                expected_patterns.append(f"SMA_{self.config.get('sma_10_window', DEFAULT_SMA_10_WINDOW)}")
            elif base_name == "StochRSI_K":
                p1 = self.config.get('stoch_rsi_window', DEFAULT_STOCH_RSI_WINDOW)
                p2 = self.config.get('stoch_rsi_rsi_window', DEFAULT_STOCH_WINDOW)
                p3 = self.config.get('stoch_rsi_k', DEFAULT_K_WINDOW)
                expected_patterns.append(f"STOCHRSIk_{p1}_{p2}_{p3}") # Check specific format
                expected_patterns.append(f"STOCHRSIk_{p1}") # Simpler format
            elif base_name == "StochRSI_D":
                p1 = self.config.get('stoch_rsi_window', DEFAULT_STOCH_RSI_WINDOW)
                p2 = self.config.get('stoch_rsi_rsi_window', DEFAULT_STOCH_WINDOW)
                p3 = self.config.get('stoch_rsi_k', DEFAULT_K_WINDOW)
                p4 = self.config.get('stoch_rsi_d', DEFAULT_D_WINDOW)
                expected_patterns.append(f"STOCHRSId_{p1}_{p2}_{p3}_{p4}") # Check specific format
                expected_patterns.append(f"STOCHRSId_{p1}") # Simpler format
            elif base_name == "RSI":
                expected_patterns.append(f"RSI_{self.config.get('rsi_period', DEFAULT_RSI_WINDOW)}")
            elif base_name == "BB_Lower":
                bb_p = self.config.get('bollinger_bands_period', DEFAULT_BOLLINGER_BANDS_PERIOD)
                bb_std = float(self.config.get('bollinger_bands_std_dev', DEFAULT_BOLLINGER_BANDS_STD_DEV))
                expected_patterns.append(f"BBL_{bb_p}_{bb_std:.1f}") # Common format
            elif base_name == "BB_Middle":
                bb_p = self.config.get('bollinger_bands_period', DEFAULT_BOLLINGER_BANDS_PERIOD)
                bb_std = float(self.config.get('bollinger_bands_std_dev', DEFAULT_BOLLINGER_BANDS_STD_DEV))
                expected_patterns.append(f"BBM_{bb_p}_{bb_std:.1f}")
            elif base_name == "BB_Upper":
                bb_p = self.config.get('bollinger_bands_period', DEFAULT_BOLLINGER_BANDS_PERIOD)
                bb_std = float(self.config.get('bollinger_bands_std_dev', DEFAULT_BOLLINGER_BANDS_STD_DEV))
                expected_patterns.append(f"BBU_{bb_p}_{bb_std:.1f}")
            elif base_name == "Volume_MA": # Custom name used internally
                expected_patterns.append(f"VOL_SMA_{self.config.get('volume_ma_period', DEFAULT_VOLUME_MA_PERIOD)}")
        except Exception as e:
             self.logger.warning(f"Error generating expected patterns for {base_name}: {e}")


        # 1. Exact Match First
        for pattern in expected_patterns:
            if pattern in df_cols:
                self.logger.debug(f"Mapped '{base_name}' to column '{pattern}' (Exact Match)")
                return pattern

        # 2. StartsWith Match (more flexible for variations like CCI_20_0.015)
        for pattern in expected_patterns:
            for col in df_cols:
                if col.startswith(pattern):
                    self.logger.debug(f"Mapped '{base_name}' to column '{col}' (StartsWith Match: '{pattern}')")
                    return col

        # 3. Fallback: Simple case-insensitive substring search (use with caution)
        base_lower = base_name.lower()
        # Try matching the full base name first
        for col in df_cols:
            if base_lower == col.lower(): # Case-insensitive exact match
                 self.logger.debug(f"Mapped '{base_name}' to '{col}' via case-insensitive exact match.")
                 return col
        # Then try substring
        simple_base = base_lower.split('_')[0] # e.g., "ema_short" -> "ema"
        for col in df_cols:
            col_lower = col.lower()
            if base_lower in col_lower:
                 self.logger.debug(f"Mapped '{base_name}' to '{col}' via substring search ('{base_lower}').")
                 return col
            # Avoid overly broad matches (e.g., 'r' matching 'atr', 'wr', 'psar')
            # Only use simple base if it's reasonably specific (e.g., len > 2)
            elif len(simple_base) > 2 and simple_base in col_lower:
                 # Add extra check to avoid matching EMA_short with EMA_long if simple_base is 'ema'
                 if simple_base == 'ema' and ('short' in base_lower and 'long' in col_lower): continue
                 if simple_base == 'ema' and ('long' in base_lower and 'short' in col_lower): continue
                 self.logger.debug(f"Mapped '{base_name}' to '{col}' via simple substring search ('{simple_base}').")
                 return col

        self.logger.warning(f"Could not find column name for indicator '{base_name}' in DataFrame columns: {df_cols}")
        return None

    def _calculate_all_indicators(self):
        """Calculates all enabled indicators using pandas_ta, handling Decimal conversion."""
        if self.df.empty:
            self.logger.warning(f"DataFrame is empty, cannot calculate indicators for {self.symbol}.")
            return

        # Determine minimum required data length based on *enabled* & *weighted* indicators
        required_periods = []
        indicators_config = self.config.get("indicators", {})
        active_weights = self.weights # Use stored weights dict

        # Helper to add requirement if indicator is enabled AND weighted > 0
        def add_req(key, config_key, default_period):
            # Ensure weight is treated as float for comparison
            weight = 0.0
            try: weight = float(active_weights.get(key, 0.0))
            except (ValueError, TypeError): pass

            if indicators_config.get(key, False) and weight != 0.0:
                 period = self.config.get(config_key, default_period)
                 if isinstance(period, (int, float)) and period > 0:
                      required_periods.append(int(period))
                 else:
                      self.logger.warning(f"Invalid period '{period}' for weighted indicator '{key}', using default '{default_period}' for length check.")
                      required_periods.append(default_period)

        # ATR is always calculated if enabled, regardless of weight (often needed for SL/TP)
        if indicators_config.get("atr", True):
            atr_p = self.config.get("atr_period", DEFAULT_ATR_PERIOD)
            required_periods.append(atr_p if isinstance(atr_p, int) and atr_p > 0 else DEFAULT_ATR_PERIOD)

        add_req("momentum", "momentum_period", DEFAULT_MOMENTUM_PERIOD)
        add_req("cci", "cci_window", DEFAULT_CCI_WINDOW)
        add_req("wr", "williams_r_window", DEFAULT_WILLIAMS_R_WINDOW)
        add_req("mfi", "mfi_window", DEFAULT_MFI_WINDOW)
        add_req("sma_10", "sma_10_window", DEFAULT_SMA_10_WINDOW) # Name change sma_10 -> sma10?
        add_req("rsi", "rsi_period", DEFAULT_RSI_WINDOW)
        add_req("bollinger_bands", "bollinger_bands_period", DEFAULT_BOLLINGER_BANDS_PERIOD)
        add_req("volume_confirmation", "volume_ma_period", DEFAULT_VOLUME_MA_PERIOD)
        # Add Fibonacci window requirement if calculated
        required_periods.append(self.config.get("fibonacci_window", DEFAULT_FIB_WINDOW))

        if indicators_config.get("ema_alignment", False) and float(active_weights.get("ema_alignment", 0.0)) != 0.0:
             ema_s_p = self.config.get("ema_short_period", DEFAULT_EMA_SHORT_PERIOD)
             ema_l_p = self.config.get("ema_long_period", DEFAULT_EMA_LONG_PERIOD)
             if isinstance(ema_s_p, int) and ema_s_p > 0: required_periods.append(ema_s_p)
             if isinstance(ema_l_p, int) and ema_l_p > 0: required_periods.append(ema_l_p)
        if indicators_config.get("stoch_rsi", False) and float(active_weights.get("stoch_rsi", 0.0)) != 0.0:
             st_p1 = self.config.get("stoch_rsi_window", DEFAULT_STOCH_RSI_WINDOW)
             st_p2 = self.config.get("stoch_rsi_rsi_window", DEFAULT_STOCH_WINDOW)
             if isinstance(st_p1, int) and st_p1 > 0: required_periods.append(st_p1)
             if isinstance(st_p2, int) and st_p2 > 0: required_periods.append(st_p2)

        min_required_data = max(required_periods) + 30 if required_periods else 50 # Add buffer (e.g., 30 candles)

        if len(self.df) < min_required_data:
             self.logger.warning(f"{NEON_YELLOW}Insufficient data ({len(self.df)} points) for {self.symbol} to calculate indicators reliably (min required: ~{min_required_data}). Results may contain many NaNs.{RESET}")
             # Don't return; proceed but expect NaNs

        try:
            df_calc = self.df.copy()
            # --- Convert Decimal columns to float for pandas_ta ---
            # Store original types to potentially convert back later if needed
            original_types = {}
            cols_to_convert = ['open', 'high', 'low', 'close', 'volume']
            for col in cols_to_convert:
                 if col in df_calc.columns:
                     # Check first non-NaN value's type
                     first_valid_idx = df_calc[col].first_valid_index()
                     if first_valid_idx is not None:
                          val_type = type(df_calc.loc[first_valid_idx, col])
                          original_types[col] = val_type
                          if val_type == Decimal:
                               self.logger.debug(f"Converting Decimal column '{col}' to float for TA calculation.")
                               # Apply conversion robustly, handle non-finite Decimals -> np.nan
                               df_calc[col] = df_calc[col].apply(lambda x: float(x) if isinstance(x, Decimal) and x.is_finite() else np.nan)
                          elif not pd.api.types.is_numeric_dtype(df_calc[col].dtype):
                               self.logger.debug(f"Column '{col}' is not Decimal and not standard numeric ({df_calc[col].dtype}). Attempting conversion to float.")
                               df_calc[col] = pd.to_numeric(df_calc[col], errors='coerce') # Force numeric conversion
                     elif df_calc[col].isnull().all():
                          self.logger.debug(f"Column '{col}' is all NaN. Ensuring it's float type.")
                          df_calc[col] = df_calc[col].astype(float) # Ensure NaN column is float
                     else: # Mix of NaN and other types? Risky, try to convert anyway
                          self.logger.debug(f"Column '{col}' has mixed NaN/other types. Attempting robust conversion to float.")
                          df_calc[col] = pd.to_numeric(df_calc[col], errors='coerce')

            # --- Calculate Indicators using pandas_ta ---
            # Reset internal column name map
            self.ta_column_names = {}

            # Always calculate ATR if enabled
            if indicators_config.get("atr", True):
                 try:
                      atr_period = int(self.config.get("atr_period", DEFAULT_ATR_PERIOD))
                      if atr_period > 0:
                           df_calc.ta.atr(length=atr_period, append=True)
                           self.ta_column_names["ATR"] = self._get_ta_col_name("ATR", df_calc)
                      else: self.logger.warning("ATR calculation skipped: Invalid period <= 0.")
                 except Exception as e: self.logger.error(f"Error calculating ATR: {e}", exc_info=True)


            # Map internal keys to pandas_ta function names and config keys/defaults
            # Format: "internal_key": ("ta_method_name", "config_period_key", default_period, "base_name_for_lookup")
            ta_map = {
                "momentum": ("mom", "momentum_period", DEFAULT_MOMENTUM_PERIOD, "Momentum"),
                "cci": ("cci", "cci_window", DEFAULT_CCI_WINDOW, "CCI"),
                "wr": ("willr", "williams_r_window", DEFAULT_WILLIAMS_R_WINDOW, "Williams_R"),
                "mfi": ("mfi", "mfi_window", DEFAULT_MFI_WINDOW, "MFI"),
                "sma_10": ("sma", "sma_10_window", DEFAULT_SMA_10_WINDOW, "SMA10"), # Note base name change
                "rsi": ("rsi", "rsi_period", DEFAULT_RSI_WINDOW, "RSI"),
                "vwap": ("vwap", None, None, "VWAP"), # VWAP usually has no period config here
            }

            for key, enabled in indicators_config.items():
                 # Check if enabled AND has a non-zero weight OR is ATR (always calc if enabled)
                 weight = 0.0
                 try: weight = float(active_weights.get(key, 0.0))
                 except (ValueError, TypeError): pass
                 should_calc = enabled and (weight != 0.0 or key == "atr")

                 if not should_calc:
                      #self.logger.debug(f"Skipping indicator calculation (disabled or zero weight): {key}")
                      continue
                 if key == "atr": continue # Already handled

                 self.logger.debug(f"Calculating indicator: {key}")
                 try:
                      if key == "ema_alignment":
                           ema_short_p = int(self.config.get("ema_short_period", DEFAULT_EMA_SHORT_PERIOD))
                           ema_long_p = int(self.config.get("ema_long_period", DEFAULT_EMA_LONG_PERIOD))
                           if ema_short_p > 0:
                                df_calc.ta.ema(length=ema_short_p, append=True)
                                self.ta_column_names["EMA_Short"] = self._get_ta_col_name("EMA_Short", df_calc)
                           if ema_long_p > 0:
                                df_calc.ta.ema(length=ema_long_p, append=True)
                                self.ta_column_names["EMA_Long"] = self._get_ta_col_name("EMA_Long", df_calc)
                      elif key == "psar":
                           psar_af_f = float(self.config.get("psar_af", DEFAULT_PSAR_AF))
                           psar_max_af_f = float(self.config.get("psar_max_af", DEFAULT_PSAR_MAX_AF))
                           if psar_af_f > 0 and psar_max_af_f > 0:
                                psar_result = df_calc.ta.psar(af=psar_af_f, max_af=psar_max_af_f)
                                if psar_result is not None and not psar_result.empty:
                                     df_calc = pd.concat([df_calc, psar_result], axis=1)
                                     # Try to map both long and short PSAR columns
                                     self.ta_column_names["PSAR_long"] = self._get_ta_col_name("PSAR_long", df_calc)
                                     self.ta_column_names["PSAR_short"] = self._get_ta_col_name("PSAR_short", df_calc)
                                else: self.logger.warning(f"PSAR calculation for {self.symbol} returned empty result.")
                           else: self.logger.warning("PSAR calculation skipped: Invalid af/max_af <= 0.")
                      elif key == "stoch_rsi":
                           st_len_i = int(self.config.get("stoch_rsi_window", DEFAULT_STOCH_RSI_WINDOW))
                           st_rsi_len_i = int(self.config.get("stoch_rsi_rsi_window", DEFAULT_STOCH_WINDOW))
                           st_k_i = int(self.config.get("stoch_rsi_k", DEFAULT_K_WINDOW))
                           st_d_i = int(self.config.get("stoch_rsi_d", DEFAULT_D_WINDOW))
                           if all(p > 0 for p in [st_len_i, st_rsi_len_i, st_k_i, st_d_i]):
                                st_result = df_calc.ta.stochrsi(length=st_len_i, rsi_length=st_rsi_len_i, k=st_k_i, d=st_d_i)
                                if st_result is not None and not st_result.empty:
                                     df_calc = pd.concat([df_calc, st_result], axis=1)
                                     self.ta_column_names["StochRSI_K"] = self._get_ta_col_name("StochRSI_K", df_calc)
                                     self.ta_column_names["StochRSI_D"] = self._get_ta_col_name("StochRSI_D", df_calc)
                                else: self.logger.warning(f"StochRSI calculation for {self.symbol} returned empty result.")
                           else: self.logger.warning("StochRSI calculation skipped: Invalid period(s) <= 0.")
                      elif key == "bollinger_bands":
                           bb_p_i = int(self.config.get("bollinger_bands_period", DEFAULT_BOLLINGER_BANDS_PERIOD))
                           bb_std_f = float(self.config.get("bollinger_bands_std_dev", DEFAULT_BOLLINGER_BANDS_STD_DEV))
                           if bb_p_i > 0 and bb_std_f > 0:
                                bb_result = df_calc.ta.bbands(length=bb_p_i, std=bb_std_f)
                                if bb_result is not None and not bb_result.empty:
                                     df_calc = pd.concat([df_calc, bb_result], axis=1)
                                     self.ta_column_names["BB_Lower"] = self._get_ta_col_name("BB_Lower", df_calc)
                                     self.ta_column_names["BB_Middle"] = self._get_ta_col_name("BB_Middle", df_calc)
                                     self.ta_column_names["BB_Upper"] = self._get_ta_col_name("BB_Upper", df_calc)
                                else: self.logger.warning(f"BBands calculation for {self.symbol} returned empty result.")
                           else: self.logger.warning("BBands calculation skipped: Invalid period/std <= 0.")
                      elif key == "volume_confirmation":
                           vol_ma_p_i = int(self.config.get("volume_ma_period", DEFAULT_VOLUME_MA_PERIOD))
                           if 'volume' in df_calc.columns and vol_ma_p_i > 0:
                                vol_ma_col = f"VOL_SMA_{vol_ma_p_i}" # Custom column name
                                # Ensure volume is float for SMA calculation (should be from initial conversion)
                                vol_series = df_calc['volume'].astype(float)
                                df_calc[vol_ma_col] = ta.sma(vol_series.fillna(0), length=vol_ma_p_i)
                                self.ta_column_names["Volume_MA"] = vol_ma_col # Use our custom name
                           elif 'volume' not in df_calc.columns: self.logger.warning("Volume MA calculation skipped: 'volume' column missing.")
                           else: self.logger.warning("Volume MA calculation skipped: Invalid period <= 0.")
                      elif key in ta_map: # General case using ta_map
                           ta_method, config_key, default_p, base_name = ta_map[key]
                           period = None
                           if config_key: # Methods like VWAP might not have a period
                                period = int(self.config.get(config_key, default_p))
                                if period <= 0:
                                     self.logger.warning(f"{key} calculation skipped: Invalid period {period}.")
                                     continue # Skip this indicator

                           method = getattr(df_calc.ta, ta_method, None)
                           if method and callable(method):
                                if period: method(length=period, append=True)
                                else: method(append=True) # Call without length if no period (e.g., vwap)
                                # Map internal key to pandas_ta base name for column lookup
                                self.ta_column_names[base_name] = self._get_ta_col_name(base_name, df_calc)
                           else:
                                self.logger.warning(f"Pandas TA method '{ta_method}' not found or not callable for indicator '{key}'.")

                 except Exception as calc_err:
                      self.logger.error(f"Error calculating indicator '{key}': {calc_err}", exc_info=True)

            # --- Convert ATR column back to Decimal (if it exists and was calculated) ---
            # pandas_ta outputs float, convert ATR back for precise calculations elsewhere
            atr_col = self.ta_column_names.get("ATR")
            if atr_col and atr_col in df_calc.columns:
                 try:
                     # Ensure the column is numeric first (might be object if errors occurred)
                     df_calc[atr_col] = pd.to_numeric(df_calc[atr_col], errors='coerce')
                     # Convert float column back to Decimal, handling potential NaNs/infs
                     df_calc[atr_col] = df_calc[atr_col].apply(lambda x: Decimal(str(x)) if pd.notna(x) and np.isfinite(x) else Decimal('NaN'))
                     self.logger.debug(f"Converted calculated ATR column '{atr_col}' back to Decimal.")
                 except (ValueError, TypeError, InvalidOperation) as conv_err:
                      self.logger.error(f"Failed to convert ATR column '{atr_col}' back to Decimal: {conv_err}")
                 except Exception as e:
                      self.logger.error(f"Unexpected error converting ATR back to Decimal: {e}", exc_info=True)


            # --- Update the instance's DataFrame ---
            # Check for NaN-only columns introduced by calculations and drop them? Maybe too aggressive.
            # Check if essential columns still exist
            essential_cols = ['open', 'high', 'low', 'close']
            if not all(col in df_calc.columns for col in essential_cols):
                 self.logger.error("Essential OHLC columns missing after indicator calculation! DataFrame might be corrupted.")
                 # Decide how to handle this - maybe revert to original df? For now, just log.
                 # self.df = self.df # Revert? Risky if original was also bad.

            self.df = df_calc # Update with calculated indicators
            self.logger.debug(f"Finished indicator calculations. Final DF shape: {self.df.shape}, Columns: {self.df.columns.tolist()}")

        except Exception as e:
            self.logger.error(f"{NEON_RED}Error during indicator calculation setup or execution: {e}{RESET}", exc_info=True)
            # If core calculation fails, maybe clear the df to prevent using stale/bad data?
            # self.df = pd.DataFrame() # Or revert to original? Needs careful thought.


    def _update_latest_indicator_values(self):
        """Updates indicator_values dict with latest values, handling types and NaNs."""
        # Define keys expected based on calculation attempts + base OHLCV
        # Use the keys from ta_column_names map + base OHLCV
        calculated_indicator_keys = list(self.ta_column_names.keys())
        base_ohlcv_keys = ["Open", "High", "Low", "Close", "Volume"]
        expected_keys = calculated_indicator_keys + base_ohlcv_keys
        # Initialize all expected keys with NaN or None (more explicit than np.nan for mixed types)
        default_values = {k: None for k in expected_keys}

        if self.df.empty:
            self.logger.warning(f"Cannot update latest values: DataFrame empty for {self.symbol}.")
            self.indicator_values = default_values
            return
        try:
            # Get the very last row by index position (-1)
            latest_row = self.df.iloc[-1]
        except IndexError:
            self.logger.error(f"Error accessing last row (index -1) for {self.symbol}. DataFrame might be smaller than expected.")
            self.indicator_values = default_values
            return

        if latest_row.isnull().all():
            self.logger.warning(f"Last row contains all NaNs for {self.symbol}. Cannot update values reliably.")
            # Still try to populate with NaNs/None
            self.indicator_values = default_values
            return

        updated_values = {}
        # --- Process TA indicators based on ta_column_names mapping ---
        for internal_key, actual_col_name in self.ta_column_names.items():
            value = None # Default to None
            if actual_col_name and actual_col_name in latest_row.index:
                raw_value = latest_row[actual_col_name]
                # Check if value is NaN (pandas/numpy way) or Decimal('NaN')
                is_nan_value = pd.isna(raw_value) or (isinstance(raw_value, Decimal) and not raw_value.is_finite())

                if not is_nan_value:
                    try:
                        if internal_key == "ATR": # ATR should end up as Decimal
                            # It might be Decimal already if conversion back worked, or float/str otherwise
                            if isinstance(raw_value, Decimal): value = raw_value
                            else: value = Decimal(str(raw_value))
                            # Ensure final ATR is finite positive Decimal or None
                            if not value.is_finite() or value <= 0: value = None

                        else: # Other indicators typically stored as float
                            # Try converting to float robustly
                            value = float(raw_value)
                            # Ensure it's a finite float or None
                            if not np.isfinite(value): value = None

                    except (ValueError, TypeError, InvalidOperation) as conv_err:
                        self.logger.warning(f"Could not convert TA value {internal_key} ('{actual_col_name}': {raw_value}): {conv_err}. Storing None.")
                        value = None # Store None on conversion error
                # If is_nan_value is True, value remains None
            else:
                 # Log only if mapping existed but column didn't in the row (shouldn't happen often)
                 if actual_col_name:
                     self.logger.debug(f"Indicator column '{actual_col_name}' for '{internal_key}' not found in latest data row. Storing None.")
                 # If actual_col_name itself was None (mapping failed), value is already None

            updated_values[internal_key] = value # Store the processed value (Decimal, float, or None)

        # --- Process Base OHLCV (expecting Decimal from initial fetch/processing) ---
        for base_col in ['open', 'high', 'low', 'close', 'volume']:
            key_name = base_col.capitalize()
            value = None # Default to None
            if base_col in latest_row.index:
                 raw_value = latest_row[base_col]
                 if isinstance(raw_value, Decimal) and raw_value.is_finite():
                     # Keep valid positive Decimals, else None
                     value = raw_value if raw_value >= 0 else None # Allow zero volume, but not negative prices
                     if key_name != 'Volume' and value <= 0: value = None # Ensure prices are > 0
                 elif pd.notna(raw_value): # If not Decimal or not finite but not NaN
                      self.logger.warning(f"Base value '{base_col}' ({raw_value}, type {type(raw_value)}) is not a finite Decimal as expected. Storing None.")
                      value = None
                 # If raw_value is NaN, value remains None
            updated_values[key_name] = value

        # Ensure all expected keys are present, even if None
        final_values = {**default_values, **updated_values}
        self.indicator_values = final_values

        # --- Log Summary (formatted, showing None for missing/invalid) ---
        log_vals = {}
        price_prec = self.get_price_precision()
        amount_prec = self.get_amount_precision_places() # For volume

        for k, v in self.indicator_values.items():
            if v is None:
                log_vals[k] = "None"
            elif isinstance(v, Decimal):
                # Use appropriate precision
                prec = price_prec if k in ['Open', 'High', 'Low', 'Close', 'ATR'] else amount_prec if k == 'Volume' else 8
                log_vals[k] = f"{v:.{prec}f}"
            elif isinstance(v, float):
                log_vals[k] = f"{v:.5f}" # Standard float formatting
            else:
                log_vals[k] = str(v) # Fallback for other types

        # Sort keys for consistent log output
        sorted_log_keys = sorted(log_vals.keys())
        sorted_log_vals = {k: log_vals[k] for k in sorted_log_keys}

        self.logger.debug(f"Latest values updated ({self.symbol}): {json.dumps(sorted_log_vals)}")


    def calculate_fibonacci_levels(self, window: Optional[int] = None) -> Dict[str, Decimal]:
        """Calculates Fibonacci retracement levels using Decimal precision."""
        self.fib_levels_data = {} # Reset before calculation
        try:
            window = int(window or self.config.get("fibonacci_window", DEFAULT_FIB_WINDOW))
            if window < 2:
                self.logger.debug(f"Fibonacci window {window} too small (< 2). Skipping calculation.")
                return {}
            if len(self.df) < window:
                self.logger.debug(f"Not enough data ({len(self.df)}) for Fibonacci ({window}) on {self.symbol}.")
                return {}

            df_slice = self.df.tail(window)

            # Ensure 'high'/'low' columns exist and are suitable for max/min
            if 'high' not in df_slice.columns or 'low' not in df_slice.columns:
                 raise KeyError("Missing 'high' or 'low' column for Fibonacci.")

            # Try converting to numeric robustly first, then find max/min
            # This handles if they are Decimal, float, or convertible strings
            high_series_numeric = pd.to_numeric(df_slice["high"], errors='coerce')
            low_series_numeric = pd.to_numeric(df_slice["low"], errors='coerce')

            high_price_raw = high_series_numeric.dropna().max()
            low_price_raw = low_series_numeric.dropna().min()

            if pd.isna(high_price_raw) or pd.isna(low_price_raw):
                self.logger.warning(f"Could not find valid high/low for Fibonacci (Window: {window}) after numeric conversion.")
                return {}

            # Convert max/min to Decimal for calculation
            high = Decimal(str(high_price_raw))
            low = Decimal(str(low_price_raw))

            if not high.is_finite() or not low.is_finite():
                 raise InvalidOperation("High or Low value for Fibonacci is not finite.")

            diff = high - low

            levels = {}
            price_precision = self.get_price_precision()
            rounding_factor = Decimal('1e-' + str(price_precision))

            # Use standard Fibonacci levels defined globally
            fib_percentages = FIB_LEVELS

            if diff > 0:
                for level_pct in fib_percentages:
                    level_name = f"Fib_{level_pct * 100:.1f}%"
                    # Retracement level price = High - (Range * Percentage)
                    level_price_raw = high - (diff * Decimal(str(level_pct)))
                    # Quantize DOWN from high (conservative support/resistance)
                    levels[level_name] = level_price_raw.quantize(rounding_factor, rounding=ROUND_DOWN)
            else: # Handle zero range (high == low)
                self.logger.debug(f"Fibonacci range is zero (High=Low={high}). Setting all levels to this price.")
                level_price_quantized = high.quantize(rounding_factor, rounding=ROUND_DOWN)
                for level_pct in fib_percentages:
                    levels[f"Fib_{level_pct * 100:.1f}%"] = level_price_quantized

            self.fib_levels_data = levels
            log_levels = {k: str(v) for k, v in levels.items()}
            self.logger.debug(f"Calculated Fibonacci levels (Window: {window}): {log_levels}")
            return levels

        except KeyError as e:
            self.logger.error(f"{NEON_RED}Fibonacci error: Missing column '{e}'.{RESET}")
            return {}
        except (ValueError, TypeError, InvalidOperation) as e:
             self.logger.error(f"{NEON_RED}Fibonacci error: Invalid data type or operation. {e}{RESET}")
             return {}
        except Exception as e:
            self.logger.error(f"{NEON_RED}Unexpected Fibonacci calculation error: {e}{RESET}", exc_info=True)
            return {}


    def get_price_precision(self) -> int:
        """Determines price precision (decimal places) from market info."""
        try:
            # 1. Check precision.price (most reliable for decimal places)
            precision_info = self.market_info.get('precision', {})
            price_precision_val = precision_info.get('price')
            if price_precision_val is not None:
                # If it's an integer, it's likely decimal places
                if isinstance(price_precision_val, int) and price_precision_val >= 0:
                    # self.logger.debug(f"Using precision.price (int): {price_precision_val}")
                    return price_precision_val
                # If it's float/str, it's likely the tick size
                try:
                    tick_size = Decimal(str(price_precision_val))
                    if tick_size.is_finite() and tick_size > 0:
                        precision = abs(tick_size.normalize().as_tuple().exponent)
                        # self.logger.debug(f"Using precision.price (tick size {tick_size}): inferred precision {precision}")
                        return precision
                except (TypeError, ValueError, InvalidOperation) as e:
                     self.logger.debug(f"Could not parse precision.price '{price_precision_val}' as tick size: {e}")

            # 2. Fallback: Infer from limits.price.min (less reliable for precision places)
            min_price_val = self.market_info.get('limits', {}).get('price', {}).get('min')
            if min_price_val is not None:
                try:
                    min_price_tick = Decimal(str(min_price_val))
                    # Use min price only if it looks like a tick size (small positive)
                    if min_price_tick.is_finite() and 0 < min_price_tick < Decimal('1'): # Heuristic
                        precision = abs(min_price_tick.normalize().as_tuple().exponent)
                        # self.logger.debug(f"Using limits.price.min ({min_price_tick}): inferred precision {precision}")
                        return precision
                except (TypeError, ValueError, InvalidOperation) as e:
                    self.logger.debug(f"Could not parse limits.price.min '{min_price_val}' for precision: {e}")

            # 3. Fallback: Infer from last close price (least reliable)
            last_close = self.indicator_values.get("Close")
            if isinstance(last_close, Decimal) and last_close.is_finite() and last_close > 0:
                try:
                    # Normalize removes trailing zeros, exponent gives decimal places
                    precision = abs(last_close.normalize().as_tuple().exponent)
                    if 0 <= precision < 10: # Sanity check range
                       # self.logger.debug(f"Using last close price ({last_close}): inferred precision {precision}")
                       return precision
                except Exception as e:
                    self.logger.debug(f"Could not infer precision from last close {last_close}: {e}")

        except Exception as e:
            self.logger.warning(f"Error determining price precision for {self.symbol}: {e}. Falling back.")

        # Final Default Fallback
        default_precision = 4 # A common default, adjust if needed
        self.logger.warning(f"Could not determine price precision for {self.symbol}. Using default: {default_precision}.")
        return default_precision


    def get_min_tick_size(self) -> Decimal:
        """Gets the minimum price increment (tick size) from market info using Decimal."""
        try:
            # 1. Try precision.price (often represents tick size directly)
            precision_info = self.market_info.get('precision', {})
            price_precision_val = precision_info.get('price')
            if price_precision_val is not None:
                 try:
                      # Assume float/str IS the tick size
                      tick = Decimal(str(price_precision_val))
                      if tick.is_finite() and tick > 0:
                           # self.logger.debug(f"Using precision.price as tick size: {tick}")
                           return tick
                 except (TypeError, ValueError, InvalidOperation) as e:
                      # If it was an integer (decimal places), calculate tick size
                      if isinstance(price_precision_val, int) and price_precision_val >= 0:
                           tick = Decimal('1e-' + str(price_precision_val))
                           # self.logger.debug(f"Calculated tick size from precision.price (int {price_precision_val}): {tick}")
                           return tick
                      else:
                           self.logger.debug(f"Could not parse precision.price '{price_precision_val}' as tick size: {e}")

            # 2. Fallback: Try limits.price.min (often same as tick size)
            min_price_val = self.market_info.get('limits', {}).get('price', {}).get('min')
            if min_price_val is not None:
                try:
                    min_tick = Decimal(str(min_price_val))
                    if min_tick.is_finite() and min_tick > 0:
                        # self.logger.debug(f"Using limits.price.min as tick size: {min_tick}")
                        return min_tick
                except (TypeError, ValueError, InvalidOperation) as e:
                     self.logger.debug(f"Could not parse limits.price.min '{min_price_val}' for tick size: {e}")

        except Exception as e:
            self.logger.warning(f"Error determining min tick size for {self.symbol} from market info: {e}.")

        # --- Final Fallback: Calculate from derived decimal places ---
        price_precision_places = self.get_price_precision() # Use the already robust precision getter
        fallback_tick = Decimal('1e-' + str(price_precision_places))
        self.logger.warning(f"Could not determine tick size. Using fallback based on derived precision ({price_precision_places}): {fallback_tick}")
        return fallback_tick


    def get_amount_precision_places(self) -> int:
        """Determines amount precision (decimal places for base currency/contracts) from market info."""
        try:
            # 1. Check precision.amount (most reliable for decimal places)
            precision_info = self.market_info.get('precision', {})
            amount_precision_val = precision_info.get('amount')
            if amount_precision_val is not None:
                # If it's an integer, assume decimal places
                if isinstance(amount_precision_val, int) and amount_precision_val >= 0:
                    # self.logger.debug(f"Using precision.amount (int): {amount_precision_val}")
                    return amount_precision_val
                # If float/str, assume it's the step size
                try:
                    step_size = Decimal(str(amount_precision_val))
                    if step_size.is_finite() and step_size > 0:
                        precision = abs(step_size.normalize().as_tuple().exponent)
                        # self.logger.debug(f"Using precision.amount (step size {step_size}): inferred precision {precision}")
                        return precision
                except (TypeError, ValueError, InvalidOperation): pass # Ignore parse errors here

            # 2. Fallback: Infer from limits.amount.min (less reliable for places)
            min_amount_val = self.market_info.get('limits', {}).get('amount', {}).get('min')
            if min_amount_val is not None:
                try:
                    min_amount_step = Decimal(str(min_amount_val))
                    # Use min amount only if it looks like a step size (positive, finite)
                    if min_amount_step.is_finite() and min_amount_step > 0:
                       # Check if it has decimal places
                       if min_amount_step != min_amount_step.to_integral_value():
                            precision = abs(min_amount_step.normalize().as_tuple().exponent)
                            # self.logger.debug(f"Using limits.amount.min ({min_amount_step}): inferred precision {precision}")
                            return precision
                       elif '.' not in str(min_amount_val): # Integer min amount likely 0 precision
                            # self.logger.debug(f"Using limits.amount.min ({min_amount_step}): inferred precision 0")
                            return 0
                except (TypeError, ValueError, InvalidOperation): pass

        except Exception as e:
            self.logger.warning(f"Error determining amount precision for {self.symbol}: {e}.")

        # Final Default Fallback
        # Contracts often have 0 decimal places, but base assets can vary widely.
        is_contract = self.market_info.get('contract', False) or self.market_info.get('type') in ['swap', 'future']
        default_precision = 0 if is_contract else 8 # Adjust default for non-contracts if needed
        self.logger.warning(f"Could not determine amount precision for {self.symbol}. Using default: {default_precision}.")
        return default_precision


    def get_min_amount_step(self) -> Decimal:
        """Gets the minimum amount increment (step size) from market info using Decimal."""
        try:
            # 1. Try precision.amount (often represents step size directly)
            precision_info = self.market_info.get('precision', {})
            amount_precision_val = precision_info.get('amount')
            if amount_precision_val is not None:
                 try:
                      # Assume float/str IS the step size
                      step = Decimal(str(amount_precision_val))
                      if step.is_finite() and step > 0:
                           # self.logger.debug(f"Using precision.amount as amount step: {step}")
                           return step
                 except (TypeError, ValueError, InvalidOperation):
                      # If it was an integer (decimal places), calculate step size
                      if isinstance(amount_precision_val, int) and amount_precision_val >= 0:
                           step = Decimal('1e-' + str(amount_precision_val))
                           # self.logger.debug(f"Calculated amount step from precision.amount (int {amount_precision_val}): {step}")
                           return step

            # 2. Fallback: Try limits.amount.min (often same as step size)
            min_amount_val = self.market_info.get('limits', {}).get('amount', {}).get('min')
            if min_amount_val is not None:
                try:
                    min_step = Decimal(str(min_amount_val))
                    if min_step.is_finite() and min_step > 0:
                        # self.logger.debug(f"Using limits.amount.min as amount step: {min_step}")
                        return min_step
                except (TypeError, ValueError, InvalidOperation): pass

        except Exception as e:
            self.logger.warning(f"Could not determine min amount step for {self.symbol}: {e}.")

        # --- Final Fallback: Calculate from derived decimal places ---
        amount_precision_places = self.get_amount_precision_places()
        fallback_step = Decimal('1e-' + str(amount_precision_places))
        self.logger.warning(f"Could not determine amount step. Using fallback based on derived precision ({amount_precision_places}): {fallback_step}")
        return fallback_step


    def get_nearest_fibonacci_levels(self, current_price: Decimal, num_levels: int = 5) -> List[Tuple[str, Decimal]]:
        """Finds the N nearest Fibonacci levels to the current price."""
        if not self.fib_levels_data:
            # self.logger.debug(f"Fibonacci levels not calculated for {self.symbol}. Cannot find nearest.")
            return []
        if not isinstance(current_price, Decimal) or not current_price.is_finite() or current_price <= 0:
            self.logger.warning(f"Invalid current price ({current_price}) for Fibonacci comparison on {self.symbol}.")
            return []

        try:
            level_distances = []
            for name, level_price in self.fib_levels_data.items():
                # Ensure the level itself is a valid Decimal
                if isinstance(level_price, Decimal) and level_price.is_finite() and level_price > 0:
                    distance = abs(current_price - level_price)
                    level_distances.append({'name': name, 'level': level_price, 'distance': distance})
                else:
                    self.logger.warning(f"Invalid Fib level value encountered during nearest check: {name}={level_price}. Skipping.")

            if not level_distances:
                 self.logger.debug(f"No valid Fibonacci levels found to compare against for {self.symbol}.")
                 return []

            # Sort by distance (Decimal comparison works correctly)
            level_distances.sort(key=lambda x: x['distance'])

            # Return the top N closest levels as (name, level_price) tuples
            return [(item['name'], item['level']) for item in level_distances[:num_levels]]

        except Exception as e:
            self.logger.error(f"{NEON_RED}Error finding nearest Fibonacci levels for {self.symbol}: {e}{RESET}", exc_info=True)
            return []


    def generate_trading_signal(self, current_price: Decimal, orderbook_data: Optional[Dict]) -> str:
        """Generates final trading signal (BUY/SELL/HOLD) based on weighted score."""
        self.signals = {"BUY": 0, "SELL": 0, "HOLD": 1} # Reset to default HOLD
        final_score = Decimal("0.0")
        total_weight_applied = Decimal("0.0")
        active_indicators = 0
        nan_or_error_indicators = 0
        debug_scores = {} # Store individual scores for logging

        # --- Basic Validation ---
        if not self.indicator_values:
            self.logger.warning("Signal Gen: Indicator values dictionary is empty. Cannot generate signal. Holding.")
            return "HOLD"

        # Check if *any* weighted indicator has a valid numeric value
        has_valid_indicator = False
        for key, weight in self.weights.items():
             if float(weight) != 0.0 and self.config.get("indicators",{}).get(key, False):
                 value = self.indicator_values.get(key)
                 # Check if value is Decimal or float/int and is finite
                 if isinstance(value, Decimal) and value.is_finite(): has_valid_indicator=True; break
                 if isinstance(value, (float, int)) and np.isfinite(value): has_valid_indicator=True; break
        if not has_valid_indicator:
             self.logger.warning("Signal Gen: All weighted & enabled indicators have None/NaN/invalid values. Holding.")
             return "HOLD"

        if not isinstance(current_price, Decimal) or not current_price.is_finite() or current_price <= 0:
            self.logger.warning(f"Signal Gen: Invalid current price ({current_price}). Holding.")
            return "HOLD"
        if not self.weights:
            self.logger.error("Signal Gen: Active weight set missing or empty in config. Holding.")
            return "HOLD"

        # --- Iterate through configured indicators ---
        for indicator_key, enabled in self.config.get("indicators", {}).items():
            if not enabled: continue # Skip if indicator calculation is disabled

            weight_val = self.weights.get(indicator_key) # Get weight from active set
            if weight_val is None: continue # Skip if no weight defined for this indicator

            try:
                # Use Decimal for weight calculations
                weight = Decimal(str(weight_val))
                if not weight.is_finite(): raise ValueError("Weight not finite")
                # Skip if weight is zero, no contribution to score
                if weight == Decimal('0'): continue
            except (ValueError, TypeError, InvalidOperation):
                self.logger.warning(f"Invalid weight format '{weight_val}' for '{indicator_key}'. Skipping score contribution.")
                continue

            # --- Find and Execute the Check Method ---
            check_method_name = f"_check_{indicator_key}"
            score_float = np.nan # Default score if method fails or doesn't exist

            if hasattr(self, check_method_name) and callable(getattr(self, check_method_name)):
                try:
                    method_to_call = getattr(self, check_method_name)
                    # Special handling for orderbook check
                    if indicator_key == "orderbook":
                        if orderbook_data:
                            score_float = method_to_call(orderbook_data, current_price)
                        # else: # No orderbook data, score remains NaN (handled below)
                        #     self.logger.debug("Orderbook check skipped: No data provided.")
                    else:
                        score_float = method_to_call() # Call the specific _check_* method
                except Exception as e:
                    self.logger.error(f"Error executing indicator check {check_method_name}: {e}", exc_info=True)
                    # Keep score_float as np.nan
            elif weight != Decimal('0'): # Log only if a check method is missing for a weighted indicator
                self.logger.warning(f"Check method '{check_method_name}' not found for weighted indicator '{indicator_key}'.")

            # --- Process and Aggregate the Score ---
            # Store raw score for debugging before clamping/conversion
            debug_scores[indicator_key] = f"{score_float:.3f}" if pd.notna(score_float) and np.isfinite(score_float) else "NaN/Error"

            if pd.notna(score_float) and np.isfinite(score_float):
                try:
                    score_dec = Decimal(str(score_float))
                    # Clamp score between -1.0 and 1.0
                    clamped_score = max(Decimal("-1.0"), min(Decimal("1.0"), score_dec))
                    # Add weighted score to final score
                    final_score += clamped_score * weight
                    total_weight_applied += weight # Sum the weights of indicators that contributed
                    active_indicators += 1
                except (ValueError, TypeError, InvalidOperation) as calc_err:
                    self.logger.error(f"Error processing numeric score for {indicator_key} ({score_float}): {calc_err}")
                    nan_or_error_indicators += 1
            else:
                # Score was NaN or method failed/missing
                nan_or_error_indicators += 1

        # --- Determine Final Signal based on Score and Threshold ---
        final_signal = "HOLD"
        # Use Decimal for threshold comparison
        try:
            threshold_str = self.config.get("signal_score_threshold", "1.5")
            threshold = Decimal(str(threshold_str))
            if not threshold.is_finite() or threshold <= 0:
                raise ValueError("Threshold must be positive and finite")
        except (ValueError, TypeError, InvalidOperation):
            self.logger.warning(f"Invalid signal_score_threshold '{threshold_str}'. Using default 1.5.")
            threshold = Decimal("1.5")

        if total_weight_applied == Decimal('0'):
            # This can happen if all weighted indicators resulted in NaN/error or had zero weight
            self.logger.warning(f"Signal Gen ({self.symbol}): No indicators contributed valid scores/weights. Defaulting to HOLD.")
        else:
            # Normalize score? Optional, depends on strategy. Current threshold works on raw weighted sum.
            # normalized_score = final_score / total_weight_applied if total_weight_applied != 0 else Decimal('0')

            if final_score >= threshold:
                final_signal = "BUY"
            elif final_score <= -threshold:
                final_signal = "SELL"
            # Else remains "HOLD"

        # --- Log Summary ---
        price_prec = self.get_price_precision()
        sig_color = NEON_GREEN if final_signal == "BUY" else NEON_RED if final_signal == "SELL" else NEON_YELLOW
        log_msg = (
            f"Signal Summary ({self.symbol} @ {current_price:.{price_prec}f}): "
            f"Set='{self.active_weight_set_name}', Ind=[Act:{active_indicators}, Invalid:{nan_or_error_indicators}], "
            f"AppliedWeight={total_weight_applied:.2f}, RawScore={final_score:.4f}, Thr={threshold:.2f} "
            f"==> {sig_color}{final_signal}{RESET}"
        )
        self.logger.info(log_msg)
        # Log individual scores only at DEBUG level
        self.logger.debug(f"  Indicator Scores ({self.symbol}): {debug_scores}")

        # Update internal signal state
        if final_signal == "BUY": self.signals = {"BUY": 1, "SELL": 0, "HOLD": 0}
        elif final_signal == "SELL": self.signals = {"BUY": 0, "SELL": 1, "HOLD": 0}
        else: self.signals = {"BUY": 0, "SELL": 0, "HOLD": 1} # Back to HOLD

        return final_signal


    # --- Indicator Check Methods (return float score -1.0 to 1.0 or np.nan) ---
    # Ensure methods handle None/NaN/inf values from self.indicator_values gracefully.

    def _check_atr(self) -> float:
        # ATR value itself isn't usually scored, but calculated. Return neutral or NaN.
        atr_val = self.indicator_values.get("ATR")
        if isinstance(atr_val, Decimal) and atr_val.is_finite() and atr_val > 0:
            return 0.0 # Neutral score, value is used elsewhere
        return np.nan # Invalid ATR

    def _check_ema_alignment(self) -> float:
        ema_s = self.indicator_values.get("EMA_Short") # Expect float
        ema_l = self.indicator_values.get("EMA_Long")   # Expect float
        close_dec = self.indicator_values.get("Close") # Expect Decimal

        # Validate inputs: must be finite numbers
        if not (isinstance(ema_s, (float, int)) and np.isfinite(ema_s) and
                isinstance(ema_l, (float, int)) and np.isfinite(ema_l) and
                isinstance(close_dec, Decimal) and close_dec.is_finite()):
            # self.logger.debug("EMA alignment check skipped: Missing or non-finite values.")
            return np.nan

        try:
             price_f = float(close_dec) # Convert price to float for comparison
             # Strong alignment check
             if price_f > ema_s > ema_l: return 1.0 # Strong Bullish Trend
             if price_f < ema_s < ema_l: return -1.0 # Strong Bearish Trend
             # Weaker alignment / crossing
             if price_f > ema_s and price_f > ema_l: return 0.5 # Price above both, EMAs might be crossed
             if price_f < ema_s and price_f < ema_l: return -0.5 # Price below both, EMAs might be crossed
             # Price between EMAs (chop/transition)
             if ema_l < price_f < ema_s: return -0.2 # Between EMAs (bearish cross recently?)
             if ema_s < price_f < ema_l: return 0.2 # Between EMAs (bullish cross recently?)
             return 0.0 # Other cases (e.g., price == EMA)
        except (ValueError, TypeError):
             return np.nan # Handle float conversion error

    def _check_momentum(self) -> float:
        momentum = self.indicator_values.get("Momentum") # Expect float
        if not isinstance(momentum, (float, int)) or not np.isfinite(momentum): return np.nan
        # Normalize momentum? The scale varies wildly. Simple positive/negative might be safer.
        # Or define thresholds based on observation. Using simple direction for now.
        if momentum > 0.01: return 0.7 # Positive momentum
        if momentum < -0.01: return -0.7 # Negative momentum
        return 0.0 # Flat momentum

    def _check_volume_confirmation(self) -> float:
        current_volume_dec = self.indicator_values.get("Volume") # Expect Decimal
        volume_ma_float = self.indicator_values.get("Volume_MA") # Expect float
        # Safely get multiplier from config, default to 1.5
        try: multiplier = float(self.config.get("volume_confirmation_multiplier", 1.5))
        except (ValueError, TypeError): multiplier = 1.5
        if multiplier <= 0: multiplier = 1.5 # Ensure positive multiplier

        # Validate inputs
        if not (isinstance(current_volume_dec, Decimal) and current_volume_dec.is_finite() and current_volume_dec >= 0 and
                isinstance(volume_ma_float, (float, int)) and np.isfinite(volume_ma_float) and volume_ma_float > 0):
            return np.nan

        try:
            # Convert MA to Decimal for comparison
            volume_ma_dec = Decimal(str(volume_ma_float))
            multiplier_dec = Decimal(str(multiplier))

            # Check if volume is significantly above or below the average
            if current_volume_dec > volume_ma_dec * multiplier_dec:
                return 0.8 # High volume confirmation
            elif current_volume_dec < volume_ma_dec / multiplier_dec:
                return -0.4 # Low volume (weak confirmation or exhaustion?) - Less penalty
            else:
                return 0.1 # Neutral volume - slight positive bias?
        except (ValueError, TypeError, InvalidOperation):
            return np.nan

    def _check_stoch_rsi(self) -> float:
        k = self.indicator_values.get("StochRSI_K") # Expect float
        d = self.indicator_values.get("StochRSI_D") # Expect float
        if not (isinstance(k, (float, int)) and np.isfinite(k) and
                isinstance(d, (float, int)) and np.isfinite(d)): return np.nan

        # Get thresholds from config, ensuring they are floats
        try: oversold = float(self.config.get("stoch_rsi_oversold_threshold", 25))
        except (ValueError, TypeError): oversold = 25.0
        try: overbought = float(self.config.get("stoch_rsi_overbought_threshold", 75))
        except (ValueError, TypeError): overbought = 75.0

        # Ensure thresholds are valid (0-100 range)
        oversold = max(0.0, min(100.0, oversold))
        overbought = max(0.0, min(100.0, overbought))
        if oversold >= overbought:
             self.logger.warning("StochRSI oversold threshold >= overbought threshold. Using defaults (25/75).")
             oversold, overbought = 25.0, 75.0

        # Scoring logic
        score = 0.0
        # Extreme levels
        if k < oversold and d < oversold: score = 1.0 # Strong Oversold -> Buy Signal
        elif k > overbought and d > overbought: score = -1.0 # Strong Overbought -> Sell Signal
        # Crosses (simple K > D or K < D)
        elif k > d: score = 0.3 # K above D -> Bullish Bias
        elif k < d: score = -0.3 # K below D -> Bearish Bias

        # Modify score based on location (dampen in middle, slightly amplify near extremes if not already max)
        mid_point = (oversold + overbought) / 2.0
        if oversold < k < overbought: # We are in the middle range
            # Dampen score the closer K is to the midpoint
            dist_from_mid = abs(k - mid_point)
            max_dist = (overbought - oversold) / 2.0
            dampening_factor = (dist_from_mid / max_dist) if max_dist > 0 else 0 # 0 at mid, 1 at edge
            score *= (0.5 + 0.5 * dampening_factor) # Scale score from 50% (at mid) to 100% (at edge)
        # Optional: Slightly amplify score if K is near but not crossing the extreme levels?
        # elif k < oversold + 5 and score > 0: score = min(1.0, score * 1.1) # Example: slightly boost near oversold
        # elif k > overbought - 5 and score < 0: score = max(-1.0, score * 1.1) # Example: slightly boost near overbought

        return max(-1.0, min(1.0, score)) # Clamp final score

    def _check_rsi(self) -> float:
        rsi = self.indicator_values.get("RSI") # Expect float
        if not isinstance(rsi, (float, int)) or not np.isfinite(rsi): return np.nan
        # Scale score linearly between 30 and 70, clamping at extremes
        if rsi <= 30: return 1.0
        if rsi >= 70: return -1.0
        # Linear scaling: score = 1 - 2 * (rsi - 30) / (70 - 30)
        score = 1.0 - 2.0 * (rsi - 30.0) / 40.0
        return max(-1.0, min(1.0, score)) # Clamp just in case

    def _check_cci(self) -> float:
        cci = self.indicator_values.get("CCI") # Expect float
        if not isinstance(cci, (float, int)) or not np.isfinite(cci): return np.nan
        # Scale based on common thresholds +/- 100, +/- 200
        if cci <= -200: return 1.0    # Extreme Oversold
        if cci >= 200: return -1.0   # Extreme Overbought
        if cci <= -100: return 0.7   # Oversold
        if cci >= 100: return -0.7  # Overbought
        # Scale linearly between -100 and 100
        if -100 < cci < 100:
            # Score = - cci / 100 (maps -100 to 1, 0 to 0, 100 to -1)
            score = -cci / 100.0
            return max(-0.5, min(0.5, score)) # Limit score in neutral zone
        return 0.0 # Should not be reached if logic above is correct

    def _check_wr(self) -> float: # Williams %R
        wr = self.indicator_values.get("Williams_R") # Expect float (Range -100 to 0)
        if not isinstance(wr, (float, int)) or not np.isfinite(wr): return np.nan
        # WR is counter-intuitive: Low values (-80 to -100) are Oversold (Buy Signal)
        # High values (-20 to 0) are Overbought (Sell Signal)
        if wr <= -80: return 1.0   # Oversold
        if wr >= -20: return -1.0  # Overbought
        # Linear scaling between -80 and -20
        if -80 < wr < -20:
            # Scale wr from -80..-20 range to 1..-1 range
            # score = 1 - 2 * (wr - (-80)) / (-20 - (-80))
            score = 1.0 - 2.0 * (wr + 80.0) / 60.0
            return max(-1.0, min(1.0, score))
        return 0.0 # Should only happen if wr is exactly -80 or -20?

    def _check_psar(self) -> float:
        psar_l = self.indicator_values.get("PSAR_long")  # Expect float or None/NaN
        psar_s = self.indicator_values.get("PSAR_short") # Expect float or None/NaN
        close = self.indicator_values.get("Close")      # Expect Decimal

        # Check if PSAR values are finite numbers if not None/NaN
        l_active = isinstance(psar_l, (float, int)) and np.isfinite(psar_l)
        s_active = isinstance(psar_s, (float, int)) and np.isfinite(psar_s)
        close_valid = isinstance(close, Decimal) and close.is_finite()

        if not close_valid: return np.nan # Cannot determine trend without price

        if l_active and not s_active:
             # PSAR is below price (long trend signal)
             # Optional: Check if price is actually *above* PSAR dot for confirmation
             try:
                  if close > Decimal(str(psar_l)): return 1.0
                  else: return 0.5 # Price below rising PSAR? Weakening trend.
             except (ValueError, InvalidOperation): return np.nan
        elif s_active and not l_active:
             # PSAR is above price (short trend signal)
             # Optional: Check if price is actually *below* PSAR dot
             try:
                  if close < Decimal(str(psar_s)): return -1.0
                  else: return -0.5 # Price above falling PSAR? Weakening trend.
             except (ValueError, InvalidOperation): return np.nan
        elif not l_active and not s_active:
             # Both inactive, usually at the start before trend is established
             return np.nan
        else: # Both seem active? This indicates a potential flip point or data issue.
             # Check which one is closer to the price or was most recently active
             # For simplicity, return neutral or slight bias based on price vs the dots
             try:
                  psar_l_dec = Decimal(str(psar_l)) if l_active else Decimal('inf')
                  psar_s_dec = Decimal(str(psar_s)) if s_active else Decimal('-inf')
                  if close > psar_l_dec: return 0.1 # Price broke above long dot? Potential flip up.
                  if close < psar_s_dec: return -0.1 # Price broke below short dot? Potential flip down.
                  self.logger.debug(f"PSAR Check: Both L/S potentially active (L={psar_l}, S={psar_s}, Close={close}). Returning neutral.")
                  return 0.0
             except (ValueError, InvalidOperation): return np.nan

    def _check_sma_10(self) -> float:
        # Note: mapped to 'SMA10' in _get_ta_col_name and _calculate_all_indicators
        sma = self.indicator_values.get("SMA10") # Expect float
        close = self.indicator_values.get("Close") # Expect Decimal
        if not (isinstance(sma, (float, int)) and np.isfinite(sma) and
                isinstance(close, Decimal) and close.is_finite()): return np.nan
        try:
             sma_dec = Decimal(str(sma))
             if close > sma_dec: return 0.6 # Price above short-term MA -> Bullish bias
             if close < sma_dec: return -0.6 # Price below short-term MA -> Bearish bias
             return 0.0 # Price is exactly on the MA
        except (ValueError, TypeError, InvalidOperation): return np.nan

    def _check_vwap(self) -> float:
        vwap = self.indicator_values.get("VWAP") # Expect float
        close = self.indicator_values.get("Close") # Expect Decimal
        if not (isinstance(vwap, (float, int)) and np.isfinite(vwap) and
                isinstance(close, Decimal) and close.is_finite()): return np.nan
        try:
             vwap_dec = Decimal(str(vwap))
             # Score based on distance from VWAP? Or just direction?
             # Simple direction for now:
             if close > vwap_dec: return 0.7 # Price above VWAP -> Bullish intraday bias
             if close < vwap_dec: return -0.7 # Price below VWAP -> Bearish intraday bias
             return 0.0
        except (ValueError, TypeError, InvalidOperation): return np.nan

    def _check_mfi(self) -> float: # Money Flow Index
        mfi = self.indicator_values.get("MFI") # Expect float
        if not isinstance(mfi, (float, int)) or not np.isfinite(mfi): return np.nan
        # Similar scaling to RSI
        if mfi <= 20: return 1.0   # Oversold / Potential Buy
        if mfi >= 80: return -1.0  # Overbought / Potential Sell
        # Linear scaling between 20 and 80
        if 20 < mfi < 80:
            # score = 1 - 2 * (mfi - 20) / (80 - 20)
            score = 1.0 - 2.0 * (mfi - 20.0) / 60.0
            return max(-1.0, min(1.0, score))
        return 0.0 # Should only happen if mfi is exactly 20 or 80

    def _check_bollinger_bands(self) -> float:
        bbl = self.indicator_values.get("BB_Lower") # Expect float
        bbm = self.indicator_values.get("BB_Middle") # Expect float
        bbu = self.indicator_values.get("BB_Upper") # Expect float
        close = self.indicator_values.get("Close") # Expect Decimal

        # Validate all inputs are finite numbers
        if not (isinstance(bbl, (float, int)) and np.isfinite(bbl) and
                isinstance(bbm, (float, int)) and np.isfinite(bbm) and
                isinstance(bbu, (float, int)) and np.isfinite(bbu) and
                isinstance(close, Decimal) and close.is_finite()):
            return np.nan

        try:
            # Convert BB levels to Decimal for comparison
            bbl_d, bbm_d, bbu_d = Decimal(str(bbl)), Decimal(str(bbm)), Decimal(str(bbu))
            # Ensure bands are logical (Upper >= Lower)
            if bbu_d < bbl_d:
                self.logger.warning(f"BBands Invalid: Upper ({bbu_d}) < Lower ({bbl_d}). Skipping check.")
                return np.nan
            # Avoid division by zero if bands collapse
            band_width = bbu_d - bbl_d
            if band_width <= 0: return 0.0 # Neutral if zero width

            # --- Scoring Logic ---
            # Strong signals at band touches/pierces
            if close <= bbl_d: return 1.0 # Touch/Below Lower -> Strong Buy Signal
            if close >= bbu_d: return -1.0 # Touch/Above Upper -> Strong Sell Signal

            # Scale score based on position within the bands (relative to middle band)
            # Position = (Close - Mid) / (Half Band Width)
            half_width = band_width / Decimal('2')
            position_normalized = (close - bbm_d) / half_width if half_width > 0 else Decimal('0')
            # position_normalized is roughly -1 at lower band, 0 at middle, +1 at upper band

            # Convert normalized position to score: map -1..+1 range to +1..-1 range
            # Score = -position_normalized
            score = -float(position_normalized) # Convert final score to float

            # Clamp score to [-1, 1] just in case normalization exceeded due to price outside bands
            return max(-1.0, min(1.0, score))

        except (ValueError, TypeError, InvalidOperation):
            return np.nan
# sxs.py
# Enhanced and Upgraded Scalping Bot Framework
# Derived from xrscalper.py, focusing on robust execution, error handling,
# advanced position management (BE, TSL), and Bybit V5 compatibility.

import hashlib
import hmac
import json
import logging
import math
import os
import time
from datetime import datetime, timedelta, timezone
from decimal import ROUND_DOWN, ROUND_UP, Decimal, InvalidOperation, getcontext
from logging.handlers import RotatingFileHandler
from typing import Any, Dict, List, Optional, Tuple, Union

import ccxt
import numpy as np
import pandas as pd
import pandas_ta as ta  # Import pandas_ta
import requests
from colorama import Fore, Style, init
from dotenv import load_dotenv
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from zoneinfo import ZoneInfo

# Initialize colorama and set Decimal precision
getcontext().prec = 36  # Increased precision for complex calculations
init(autoreset=True)
load_dotenv()

# Neon Color Scheme
NEON_GREEN = Fore.LIGHTGREEN_EX
NEON_BLUE = Fore.CYAN
NEON_PURPLE = Fore.MAGENTA
NEON_YELLOW = Fore.YELLOW
NEON_RED = Fore.LIGHTRED_EX
NEON_CYAN = Fore.CYAN
RESET = Style.RESET_ALL

# --- Constants ---
API_KEY = os.getenv("BYBIT_API_KEY")
API_SECRET = os.getenv("BYBIT_API_SECRET")
if not API_KEY or not API_SECRET:
    raise ValueError("BYBIT_API_KEY and BYBIT_API_SECRET must be set in .env")

CONFIG_FILE = "config.json"
LOG_DIRECTORY = "bot_logs"
# Timezone for logging and display
TIMEZONE = ZoneInfo("America/Chicago")  # Adjust as needed
MAX_API_RETRIES = 5  # Max retries for recoverable API errors
RETRY_DELAY_SECONDS = 7  # Increased delay between retries
VALID_INTERVALS = ["1", "3", "5", "15", "30", "60", "120", "240", "D", "W", "M"]
CCXT_INTERVAL_MAP = { # Map our intervals to ccxt's expected format
    "1": "1m", "3": "3m", "5": "5m", "15": "15m", "30": "30m",
    "60": "1h", "120": "2h", "240": "4h", "D": "1d", "W": "1w", "M": "1M"
}
RETRY_ERROR_CODES = [429, 500, 502, 503, 504] # HTTP status codes considered retryable
# Default indicator periods (can be overridden by config.json)
DEFAULT_ATR_PERIOD = 14
DEFAULT_CCI_WINDOW = 20
DEFAULT_WILLIAMS_R_WINDOW = 14
DEFAULT_MFI_WINDOW = 14
DEFAULT_STOCH_RSI_WINDOW = 14
DEFAULT_STOCH_WINDOW = 12
DEFAULT_K_WINDOW = 3
DEFAULT_D_WINDOW = 3
DEFAULT_RSI_WINDOW = 14
DEFAULT_BOLLINGER_BANDS_PERIOD = 20
DEFAULT_BOLLINGER_BANDS_STD_DEV = 2.0
DEFAULT_SMA_10_WINDOW = 10
DEFAULT_EMA_SHORT_PERIOD = 9
DEFAULT_EMA_LONG_PERIOD = 21
DEFAULT_MOMENTUM_PERIOD = 7
DEFAULT_VOLUME_MA_PERIOD = 15
DEFAULT_FIB_WINDOW = 50
DEFAULT_PSAR_AF = 0.02
DEFAULT_PSAR_MAX_AF = 0.2

FIB_LEVELS = [0.0, 0.236, 0.382, 0.5, 0.618, 0.786, 1.0] # Standard Fibonacci levels
LOOP_DELAY_SECONDS = 10 # Time between the end of one cycle and the start of the next
POSITION_CONFIRM_DELAY_SECONDS = 10 # Increased wait time after placing order before confirming position
# QUOTE_CURRENCY dynamically loaded from config

os.makedirs(LOG_DIRECTORY, exist_ok=True)

class SensitiveFormatter(logging.Formatter):
    """Formatter to redact sensitive information (API keys) from logs."""
    def format(self, record: logging.LogRecord) -> str:
        msg = super().format(record)
        if API_KEY:
            msg = msg.replace(API_KEY, "***API_KEY***")
        if API_SECRET:
            msg = msg.replace(API_SECRET, "***API_SECRET***")
        return msg

def load_config(filepath: str) -> Dict[str, Any]:
    """
    Load configuration from JSON file, creating default if not found,
    and ensuring all default keys are present with validation.
    """
    # Define the default configuration structure and values
    default_config = {
        # Trading pair and timeframe
        "symbol": "BTC/USDT:USDT", # Bybit linear perpetual example
        "interval": "5", # Default timeframe (e.g., "5" for 5 minutes)

        # API and Bot Behavior
        "retry_delay": RETRY_DELAY_SECONDS, # Delay between API retries
        "enable_trading": False, # Safety Feature: Must be explicitly set to true to trade
        "use_sandbox": True, # Safety Feature: Use testnet by default
        "max_concurrent_positions": 1, # Max open positions for this symbol instance
        "quote_currency": "USDT", # Quote currency for balance checks and sizing
        "position_confirm_delay_seconds": POSITION_CONFIRM_DELAY_SECONDS, # Delay after order before confirming position
        "loop_delay_seconds": LOOP_DELAY_SECONDS, # Delay between main loop cycles

        # Risk Management
        "risk_per_trade": 0.01, # Fraction of balance to risk (e.g., 0.01 = 1%)
        "leverage": 20, # Desired leverage (Ensure supported by exchange/market)
        "stop_loss_multiple": 1.8, # ATR multiple for initial SL (used for sizing/initial fixed SL)
        "take_profit_multiple": 0.7, # ATR multiple for initial TP

        # Order Execution
        "entry_order_type": "market", # "market" or "limit"
        "limit_order_offset_buy": 0.0005, # % offset from price for BUY limit (0.0005 = 0.05%)
        "limit_order_offset_sell": 0.0005, # % offset from price for SELL limit

        # Advanced Position Management
        "enable_trailing_stop": True, # Use exchange-native Trailing Stop Loss
        "trailing_stop_callback_rate": 0.005, # Trail distance % (e.g., 0.005 = 0.5%)
        "trailing_stop_activation_percentage": 0.003, # % profit move from entry to activate TSL
        "enable_break_even": True, # Enable moving SL to break-even point
        "break_even_trigger_atr_multiple": 1.0, # Move SL when profit >= X * ATR
        "break_even_offset_ticks": 2, # Place BE SL X ticks beyond entry price
        "time_based_exit_minutes": None, # Optional: Exit after X minutes (e.g., 60)

        # Indicator Periods & Parameters
        "atr_period": DEFAULT_ATR_PERIOD,
        "ema_short_period": DEFAULT_EMA_SHORT_PERIOD,
        "ema_long_period": DEFAULT_EMA_LONG_PERIOD,
        "rsi_period": DEFAULT_RSI_WINDOW,
        "bollinger_bands_period": DEFAULT_BOLLINGER_BANDS_PERIOD,
        "bollinger_bands_std_dev": DEFAULT_BOLLINGER_BANDS_STD_DEV,
        "cci_window": DEFAULT_CCI_WINDOW,
        "williams_r_window": DEFAULT_WILLIAMS_R_WINDOW,
        "mfi_window": DEFAULT_MFI_WINDOW,
        "stoch_rsi_window": DEFAULT_STOCH_RSI_WINDOW, # StochRSI main window
        "stoch_rsi_rsi_window": DEFAULT_STOCH_WINDOW, # Underlying RSI window for StochRSI
        "stoch_rsi_k": DEFAULT_K_WINDOW, # StochRSI K period
        "stoch_rsi_d": DEFAULT_D_WINDOW, # StochRSI D period
        "psar_af": DEFAULT_PSAR_AF, # PSAR Acceleration Factor
        "psar_max_af": DEFAULT_PSAR_MAX_AF, # PSAR Max Acceleration Factor
        "sma_10_window": DEFAULT_SMA_10_WINDOW,
        "momentum_period": DEFAULT_MOMENTUM_PERIOD,
        "volume_ma_period": DEFAULT_VOLUME_MA_PERIOD,
        "fibonacci_window": DEFAULT_FIB_WINDOW,

        # Indicator Calculation & Scoring Control
        "orderbook_limit": 25, # Depth of order book levels to fetch/analyze
        "signal_score_threshold": 1.5, # Score needed to trigger BUY/SELL signal
        "stoch_rsi_oversold_threshold": 25, # Threshold for StochRSI oversold score
        "stoch_rsi_overbought_threshold": 75, # Threshold for StochRSI overbought score
        "volume_confirmation_multiplier": 1.5, # Volume > Multiplier * VolMA for confirmation
        "scalping_signal_threshold": 2.5, # Alternative threshold for specific weight sets (if needed)
        "indicators": { # Toggle calculation and scoring contribution
            "ema_alignment": True, "momentum": True, "volume_confirmation": True,
            "stoch_rsi": True, "rsi": True, "bollinger_bands": True, "vwap": True,
            "cci": True, "wr": True, "psar": True, "sma_10": True, "mfi": True,
            "orderbook": True,
        },
        "weight_sets": { # Define scoring weights for different strategies
            "scalping": { # Example: Faster, momentum-focused
                "ema_alignment": 0.2, "momentum": 0.3, "volume_confirmation": 0.2,
                "stoch_rsi": 0.6, "rsi": 0.2, "bollinger_bands": 0.3, "vwap": 0.4,
                "cci": 0.3, "wr": 0.3, "psar": 0.2, "sma_10": 0.1, "mfi": 0.2, "orderbook": 0.15,
            },
            "default": { # Example: Balanced
                "ema_alignment": 0.3, "momentum": 0.2, "volume_confirmation": 0.1,
                "stoch_rsi": 0.4, "rsi": 0.3, "bollinger_bands": 0.2, "vwap": 0.3,
                "cci": 0.2, "wr": 0.2, "psar": 0.3, "sma_10": 0.1, "mfi": 0.2, "orderbook": 0.1,
            }
        },
        "active_weight_set": "default" # Select the active weight set
    }

    config = default_config.copy()
    if os.path.exists(filepath):
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                loaded_config = json.load(f)
            # Merge loaded config with defaults, ensuring all keys exist
            config = _merge_configs(loaded_config, default_config)
            print(f"{NEON_GREEN}Loaded configuration from {filepath}{RESET}")
        except (json.JSONDecodeError, IOError) as e:
            print(f"{NEON_RED}Error loading config file {filepath}: {e}. Using default config.{RESET}")
            # Attempt to recreate default file if loading failed
            try:
                with open(filepath, "w", encoding="utf-8") as f_write:
                    json.dump(default_config, f_write, indent=4)
                print(f"{NEON_YELLOW}Recreated default config file: {filepath}{RESET}")
            except IOError as e_create:
                print(f"{NEON_RED}Error recreating default config file: {e_create}{RESET}")
            config = default_config # Use in-memory default
    else:
        # Config file doesn't exist, create it with defaults
        print(f"{NEON_YELLOW}Config file not found. Creating default config at {filepath}{RESET}")
        try:
            with open(filepath, "w", encoding="utf-8") as f:
                json.dump(default_config, f, indent=4)
            config = default_config
        except IOError as e:
            print(f"{NEON_RED}Error creating default config file {filepath}: {e}{RESET}")
            # Continue with in-memory default config if creation fails

    # --- Validation Section ---
    updated = False # Flag to track if config needs saving back

    # Validate symbol
    if not config.get("symbol") or not isinstance(config.get("symbol"), str):
         print(f"{NEON_RED}CRITICAL: 'symbol' is missing, empty, or invalid in config. Resetting to default: '{default_config['symbol']}'{RESET}")
         config["symbol"] = default_config["symbol"]
         updated = True

    # Validate interval
    if config.get("interval") not in VALID_INTERVALS:
        print(f"{NEON_RED}Invalid interval '{config.get('interval')}' in config. Resetting to default '{default_config['interval']}'. Valid: {VALID_INTERVALS}{RESET}")
        config["interval"] = default_config["interval"]
        updated = True

    # Validate entry order type
    if config.get("entry_order_type") not in ["market", "limit"]:
        print(f"{NEON_RED}Invalid entry_order_type '{config.get('entry_order_type')}' in config. Resetting to 'market'.{RESET}")
        config["entry_order_type"] = "market"
        updated = True

    # Validate active weight set exists
    if config.get("active_weight_set") not in config.get("weight_sets", {}):
         print(f"{NEON_RED}Active weight set '{config.get('active_weight_set')}' not found in 'weight_sets'. Resetting to 'default'.{RESET}")
         config["active_weight_set"] = "default" # Ensure 'default' exists in defaults
         updated = True

    # Validate numeric parameters (ranges and types)
    numeric_params = {
        # key: (min_val, max_val, allow_min_equal, allow_max_equal, is_integer)
        "risk_per_trade": (0, 1, False, False, False),
        "leverage": (1, 1000, True, True, True), # Adjust max leverage realistically
        "stop_loss_multiple": (0, float('inf'), False, True, False),
        "take_profit_multiple": (0, float('inf'), False, True, False),
        "trailing_stop_callback_rate": (0, 1, False, False, False),
        "trailing_stop_activation_percentage": (0, 1, True, False, False), # Allow 0%
        "break_even_trigger_atr_multiple": (0, float('inf'), False, True, False),
        "break_even_offset_ticks": (0, 100, True, True, True),
        "signal_score_threshold": (0, float('inf'), False, True, False),
        "atr_period": (1, 1000, True, True, True),
        "ema_short_period": (1, 1000, True, True, True),
        "ema_long_period": (1, 1000, True, True, True),
        "rsi_period": (1, 1000, True, True, True),
        "bollinger_bands_period": (1, 1000, True, True, True),
        "bollinger_bands_std_dev": (0, 10, False, True, False),
        "cci_window": (1, 1000, True, True, True),
        "williams_r_window": (1, 1000, True, True, True),
        "mfi_window": (1, 1000, True, True, True),
        "stoch_rsi_window": (1, 1000, True, True, True),
        "stoch_rsi_rsi_window": (1, 1000, True, True, True),
        "stoch_rsi_k": (1, 1000, True, True, True),
        "stoch_rsi_d": (1, 1000, True, True, True),
        "psar_af": (0, 1, False, False, False),
        "psar_max_af": (0, 1, False, False, False),
        "sma_10_window": (1, 1000, True, True, True),
        "momentum_period": (1, 1000, True, True, True),
        "volume_ma_period": (1, 1000, True, True, True),
        "fibonacci_window": (2, 1000, True, True, True), # Need at least 2 points
        "orderbook_limit": (1, 100, True, True, True),
        "position_confirm_delay_seconds": (0, 60, True, True, False),
        "loop_delay_seconds": (1, 300, True, True, False),
        "stoch_rsi_oversold_threshold": (0, 100, True, False, False),
        "stoch_rsi_overbought_threshold": (0, 100, False, True, False),
        "volume_confirmation_multiplier": (0, float('inf'), False, True, False),
        "limit_order_offset_buy": (0, 0.1, True, False, False), # 10% offset max?
        "limit_order_offset_sell": (0, 0.1, True, False, False),
    }
    for key, (min_val, max_val, allow_min, allow_max, is_integer) in numeric_params.items():
        try:
            value_str = str(config[key]) # Convert potential int/float to str first
            value = Decimal(value_str) if not is_integer else int(Decimal(value_str))

            # Check bounds
            lower_bound_ok = value >= min_val if allow_min else value > min_val
            upper_bound_ok = value <= max_val if allow_max else value < max_val

            if not (lower_bound_ok and upper_bound_ok):
                raise ValueError(f"Value {value} out of range "
                                 f"({min_val} {'<=' if allow_min else '<'} x {'<=' if allow_max else '<'} {max_val})")

            # Store the validated value (could be int or float/Decimal)
            config[key] = int(value) if is_integer else float(value) # Store float for simplicity unless int needed

        except (ValueError, TypeError, KeyError, InvalidOperation) as e:
            print(f"{NEON_RED}Invalid value for '{key}' ({config.get(key)}): {e}. Resetting to default '{default_config[key]}'.{RESET}")
            config[key] = default_config[key]
            updated = True

    # Specific validation for time_based_exit_minutes (allow None or positive number)
    time_exit = config.get("time_based_exit_minutes")
    if time_exit is not None:
        try:
            time_exit_val = float(time_exit)
            if time_exit_val <= 0: raise ValueError("Must be positive if set")
            config["time_based_exit_minutes"] = time_exit_val # Store as float
        except (ValueError, TypeError) as e:
             print(f"{NEON_RED}Invalid value for 'time_based_exit_minutes' ({time_exit}): {e}. Resetting to default (None).{RESET}")
             config["time_based_exit_minutes"] = None
             updated = True

    # If config was updated due to invalid values, save it back
    if updated:
        try:
            with open(filepath, "w", encoding="utf-8") as f_write:
                # Use ensure_ascii=False for better readability if non-ASCII chars exist
                json.dump(config, f_write, indent=4, ensure_ascii=False)
            print(f"{NEON_YELLOW}Updated config file {filepath} with corrected/default values.{RESET}")
        except IOError as e:
            print(f"{NEON_RED}Error writing updated config file {filepath}: {e}{RESET}")

    return config

def _merge_configs(loaded_config: Dict, default_config: Dict) -> Dict:
    """
    Recursively merges the loaded configuration with default values.
    Ensures all keys from the default config exist in the final config.
    Prioritizes values from the loaded config.
    """
    merged = default_config.copy()
    for key, value in loaded_config.items():
        # If key exists in both and both values are dicts, recurse
        if isinstance(value, dict) and isinstance(merged.get(key), dict):
            merged[key] = _merge_configs(value, merged[key])
        else:
            # Otherwise, overwrite default with loaded value
            merged[key] = value
    return merged

def setup_logger(name: str, level: int = logging.INFO) -> logging.Logger:
    """Sets up a logger with rotating file and colored console handlers."""
    logger = logging.getLogger(name)
    # Prevent adding multiple handlers if logger is reused
    if logger.hasHandlers():
        for handler in logger.handlers[:]:
            try: handler.close()
            except: pass # Ignore errors closing handlers
            logger.removeHandler(handler)

    logger.setLevel(logging.DEBUG) # Capture all levels at the logger level

    # File Handler (Rotating)
    log_filename = os.path.join(LOG_DIRECTORY, f"{name}.log")
    try:
        file_handler = RotatingFileHandler(
            log_filename, maxBytes=10 * 1024 * 1024, backupCount=5, encoding='utf-8'
        )
        file_formatter = SensitiveFormatter(
            "%(asctime)s.%(msecs)03d %(levelname)-8s [%(name)s:%(lineno)d] %(message)s",
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        file_handler.setFormatter(file_formatter)
        file_handler.setLevel(logging.DEBUG) # Log DEBUG and above to file
        logger.addHandler(file_handler)
    except Exception as e:
        print(f"Error setting up file logger {log_filename}: {e}")

    # Console Handler (Colored)
    stream_handler = logging.StreamHandler()
    stream_formatter = SensitiveFormatter(
        f"{NEON_BLUE}%(asctime)s{RESET} - {NEON_YELLOW}%(levelname)-8s{RESET} - {NEON_PURPLE}[%(name)s]{RESET} - %(message)s",
        datefmt='%Y-%m-%d %H:%M:%S %Z' # Include Timezone abbreviation
    )
    # Use UTC internally for consistency, display local time in logs via formatter
    stream_formatter.converter = time.gmtime # Log record times in UTC
    # Set the formatter's timezone for display purposes (using datefmt %Z)
    # Ensure the TIMEZONE object is used correctly by the formatter
    logging.Formatter.converter = lambda *args: datetime.now(TIMEZONE).timetuple()

    stream_handler.setFormatter(stream_formatter)
    stream_handler.setLevel(level) # Set console level (e.g., INFO)
    logger.addHandler(stream_handler)

    logger.propagate = False # Prevent duplicate logs in root logger
    return logger

# --- CCXT Exchange Setup ---
def initialize_exchange(config: Dict[str, Any], logger: logging.Logger) -> Optional[ccxt.Exchange]:
    """Initializes the CCXT Bybit exchange object with enhanced error handling."""
    lg = logger
    try:
        exchange_options = {
            'apiKey': API_KEY,
            'secret': API_SECRET,
            'enableRateLimit': True, # Use CCXT's built-in rate limiter
            'rateLimit': 150, # Adjust based on Bybit V5 limits (e.g., 100ms for 10/s might be safer)
            'options': {
                'defaultType': 'linear', # Essential for Bybit V5 USDT perpetuals
                'adjustForTimeDifference': True, # Helps with timestamp sync issues
                # Increased timeouts
                'fetchTickerTimeout': 15000, 'fetchBalanceTimeout': 20000,
                'createOrderTimeout': 25000, 'cancelOrderTimeout': 20000,
                'fetchPositionsTimeout': 20000, 'fetchOHLCVTimeout': 20000,
                # Add user agent for potential identification
                'user-agent': 'ScalpXRX Bot v1.0',
                # Consider Bybit V5 specific options if needed
                # 'recvWindow': 10000 # Example: Increase if timestamp errors persist
            }
        }

        # Default to Bybit, could be made configurable
        exchange_id = "bybit"
        exchange_class = getattr(ccxt, exchange_id)
        exchange = exchange_class(exchange_options)

        # --- Sandbox Mode Setup ---
        if config.get('use_sandbox'):
            lg.warning(f"{NEON_YELLOW}USING SANDBOX MODE (Testnet){RESET}")
            try:
                exchange.set_sandbox_mode(True)
                lg.info(f"Sandbox mode explicitly enabled for {exchange.id}.")
            except AttributeError:
                lg.warning(f"{exchange.id} does not support set_sandbox_mode via ccxt. Ensuring API keys are for Testnet.")
                # Manually set Bybit testnet URL if needed
                if exchange.id == 'bybit':
                    exchange.urls['api'] = 'https://api-testnet.bybit.com'
                    lg.info("Manually set Bybit API URL to Testnet.")
            except Exception as e:
                lg.error(f"Error enabling sandbox mode: {e}")
        else:
            lg.info(f"{NEON_GREEN}Using LIVE (Real Money) Environment.{RESET}")


        lg.info(f"Initializing {exchange.id}...")
        # --- Initial Connection & Permissions Test (Fetch Balance) ---
        account_type_to_test = 'CONTRACT' # Prioritize CONTRACT for V5 derivatives
        lg.info(f"Attempting initial balance fetch (Account Type: {account_type_to_test})...")
        try:
            params = {'type': account_type_to_test} if exchange.id == 'bybit' else {}
            # Use safe_api_call for robustness
            balance = safe_api_call(exchange.fetch_balance, lg, params=params)

            if balance:
                quote_curr = config.get("quote_currency", "USDT")
                # Handle potential differences in balance structure more robustly
                available_quote_val = None
                if quote_curr in balance:
                    available_quote_val = balance[quote_curr].get('free')
                if available_quote_val is None and 'free' in balance and quote_curr in balance['free']:
                    available_quote_val = balance['free'][quote_curr]
                # Add check for Bybit V5 structure if needed (though fetch_balance often standardizes)

                available_quote_str = str(available_quote_val) if available_quote_val is not None else 'N/A'
                lg.info(f"{NEON_GREEN}Successfully connected and fetched initial balance.{RESET} (Example: {quote_curr} available: {available_quote_str})")
            else:
                 lg.warning(f"{NEON_YELLOW}Initial balance fetch (Type: {account_type_to_test}) returned no data. Check connection/permissions.{RESET}")

        except ccxt.AuthenticationError as auth_err:
             lg.error(f"{NEON_RED}Authentication Error during initial balance fetch: {auth_err}{RESET}")
             lg.error(f"{NEON_RED}>> Ensure API keys (in .env) are correct, have permissions (Read, Trade), match environment (Real/Testnet), and IP whitelist is correct.{RESET}")
             return None # Fatal error
        except ccxt.ExchangeError as balance_err:
             # Fallback if specific account type failed
             lg.warning(f"{NEON_YELLOW}Exchange error fetching balance (Type: {account_type_to_test}): {balance_err}. Trying default fetch...{RESET}")
             try:
                  balance = safe_api_call(exchange.fetch_balance, lg)
                  if balance:
                       quote_curr = config.get("quote_currency", "USDT")
                       available_quote_val = None
                       if quote_curr in balance:
                           available_quote_val = balance[quote_curr].get('free')
                       if available_quote_val is None and 'free' in balance and quote_curr in balance['free']:
                           available_quote_val = balance['free'][quote_curr]
                       available_quote_str = str(available_quote_val) if available_quote_val is not None else 'N/A'
                       lg.info(f"{NEON_GREEN}Successfully fetched balance using default parameters.{RESET} (Example: {quote_curr} available: {available_quote_str})")
                  else:
                       lg.warning(f"{NEON_YELLOW}Default balance fetch also returned no data.{RESET}")
             except Exception as fallback_err:
                  lg.warning(f"{NEON_YELLOW}Default balance fetch also failed: {fallback_err}. Check API permissions/account type/network.{RESET}")
        except Exception as balance_err: # Catches errors from safe_api_call
             lg.warning(f"{NEON_YELLOW}Could not perform initial balance fetch after retries or due to error: {balance_err}. Proceeding cautiously.{RESET}")


        # --- Load Markets (Crucial for market info, precision, etc.) ---
        lg.info(f"Loading markets for {exchange.id}...")
        try:
             safe_api_call(exchange.load_markets, lg, reload=True) # Force reload
             lg.info(f"Markets loaded successfully for {exchange.id}.")
        except Exception as market_err:
             lg.error(f"{NEON_RED}Failed to load markets after retries: {market_err}. Cannot operate without market data. Exiting.{RESET}")
             return None # Fatal error if markets cannot be loaded

        lg.info(f"CCXT exchange initialized ({exchange.id}). Sandbox: {config.get('use_sandbox')}")
        return exchange

    except ccxt.AuthenticationError as e: # Catch auth errors during class instantiation
        lg.error(f"{NEON_RED}CCXT Authentication Error during initialization: {e}{RESET}")
        lg.error(f"{NEON_RED}>> Check API Key/Secret format and validity in your .env file.{RESET}")
    except ccxt.ExchangeError as e:
        lg.error(f"{NEON_RED}CCXT Exchange Error initializing: {e}{RESET}")
    except ccxt.NetworkError as e:
        lg.error(f"{NEON_RED}CCXT Network Error initializing: {e}{RESET}")
    except Exception as e:
        lg.error(f"{NEON_RED}Failed to initialize CCXT exchange: {e}{RESET}", exc_info=True)

    return None

# --- API Call Wrapper with Retries ---
def safe_api_call(func, logger: logging.Logger, *args, **kwargs):
    """Wraps an API call with retry logic for network/rate limit/specific exchange errors."""
    lg = logger
    attempts = 0
    last_exception = None
    while attempts <= MAX_API_RETRIES:
        try:
            result = func(*args, **kwargs)
            # lg.debug(f"API call {func.__name__} successful.") # Optional success log
            return result # Success
        except (ccxt.NetworkError, ccxt.RequestTimeout, requests.exceptions.ConnectionError, requests.exceptions.Timeout, ccxt.ExchangeNotAvailable, ccxt.DDoSProtection) as e:
            last_exception = e
            wait_time = RETRY_DELAY_SECONDS * (1.5 ** attempts) # Exponential backoff
            lg.warning(f"{NEON_YELLOW}Retryable network/availability error in {func.__name__}: {type(e).__name__}. Waiting {wait_time:.1f}s (Attempt {attempts+1}/{MAX_API_RETRIES}). Error: {e}{RESET}")
            time.sleep(wait_time)
        except ccxt.RateLimitExceeded as e:
            last_exception = e
            wait_time_header = getattr(e, 'retry_after', None)
            wait_time = RETRY_DELAY_SECONDS * (2 ** attempts) # Stronger backoff
            if wait_time_header:
                try: wait_time = max(wait_time, float(wait_time_header) + 0.5) # Add buffer
                except: pass # Ignore invalid header
            lg.warning(f"{NEON_YELLOW}Rate limit exceeded in {func.__name__}. Waiting {wait_time:.1f}s (Attempt {attempts+1}/{MAX_API_RETRIES}). Error: {e}{RESET}")
            time.sleep(wait_time)
        except ccxt.AuthenticationError as e:
             lg.error(f"{NEON_RED}Authentication Error in {func.__name__}: {e}. Aborting call.{RESET}")
             raise e # Don't retry, re-raise immediately
        except ccxt.ExchangeError as e:
            last_exception = e
            bybit_retry_codes = [
                10001, # Internal server error
                10006, # Request frequent
                # Add other transient error codes based on Bybit docs/experience
            ]
            exchange_code = getattr(e, 'code', None)
            err_str = str(e).lower()
            is_retryable_exchange_err = exchange_code in bybit_retry_codes or \
                                        "internal server error" in err_str or \
                                        "request validation failed" in err_str # Check message too

            if is_retryable_exchange_err:
                 wait_time = RETRY_DELAY_SECONDS * (1.5 ** attempts)
                 lg.warning(f"{NEON_YELLOW}Potentially retryable exchange error in {func.__name__}: {e} (Code: {exchange_code}). Waiting {wait_time:.1f}s (Attempt {attempts+1}/{MAX_API_RETRIES})...{RESET}")
                 time.sleep(wait_time)
            else:
                 lg.error(f"{NEON_RED}Non-retryable Exchange Error in {func.__name__}: {e} (Code: {exchange_code}){RESET}")
                 raise e # Re-raise non-retryable ones
        except Exception as e:
            last_exception = e
            lg.error(f"{NEON_RED}Unexpected error in {func.__name__}: {e}{RESET}", exc_info=True)
            raise e # Re-raise unexpected errors immediately

        attempts += 1

    # If loop completes, max retries exceeded
    lg.error(f"{NEON_RED}Max retries ({MAX_API_RETRIES}) exceeded for {func.__name__}.{RESET}")
    if last_exception:
        raise last_exception # Raise the last known exception
    else:
        # Fallback if no exception was captured (shouldn't normally happen)
        raise ccxt.RequestTimeout(f"Max retries exceeded for {func.__name__} (no specific exception captured)")


# --- CCXT Data Fetching (Using safe_api_call) ---
def fetch_current_price_ccxt(exchange: ccxt.Exchange, symbol: str, logger: logging.Logger) -> Optional[Decimal]:
    """Fetch the current price of a trading symbol using CCXT ticker with fallbacks and retries."""
    lg = logger
    try:
        ticker = safe_api_call(exchange.fetch_ticker, lg, symbol)
        if not ticker:
            return None # Error logged by safe_api_call

        lg.debug(f"Ticker data for {symbol}: {ticker}")
        price = None
        # Prioritize 'last', then 'average', then mid-price, then ask/bid
        last_price = ticker.get('last')
        bid_price = ticker.get('bid')
        ask_price = ticker.get('ask')
        avg_price = ticker.get('average') # Some exchanges provide volume-weighted avg or simple mid

        # Robust Decimal conversion helper
        def to_decimal(value) -> Optional[Decimal]:
            if value is None: return None
            try:
                d = Decimal(str(value))
                # Ensure the price is finite and positive
                return d if d.is_finite() and d > 0 else None
            except (InvalidOperation, ValueError, TypeError):
                lg.warning(f"Invalid price format encountered: {value}")
                return None

        p_last = to_decimal(last_price)
        p_bid = to_decimal(bid_price)
        p_ask = to_decimal(ask_price)
        p_avg = to_decimal(avg_price)

        # Determine price with priority
        if p_last:
            price = p_last; lg.debug(f"Using 'last' price: {price}")
        elif p_avg: # Use 'average' if last is missing but average exists
            price = p_avg; lg.debug(f"Using 'average' price: {price}")
        elif p_bid and p_ask: # Use bid/ask midpoint if others missing
            price = (p_bid + p_ask) / 2; lg.debug(f"Using bid/ask midpoint: {price}")
        elif p_ask: # Fallback to ask if only ask is valid
            price = p_ask; lg.warning(f"Using 'ask' price fallback (bid invalid/missing): {price}")
        elif p_bid: # Fallback to bid if only bid is valid
            price = p_bid; lg.warning(f"Using 'bid' price fallback (ask invalid/missing): {price}")

        # Final validation
        if price is not None and price.is_finite() and price > 0:
            return price
        else:
            lg.error(f"{NEON_RED}Failed to extract a valid price from ticker data for {symbol}. Ticker: {ticker}{RESET}")
            return None

    except Exception as e:
        # Catch errors raised by safe_api_call or during parsing
        lg.error(f"{NEON_RED}Error fetching current price for {symbol}: {e}{RESET}", exc_info=False) # Keep log concise
        return None

def fetch_klines_ccxt(exchange: ccxt.Exchange, symbol: str, timeframe: str, limit: int = 250, logger: logging.Logger = None) -> pd.DataFrame:
    """Fetch OHLCV kline data using CCXT with retries and robust validation."""
    lg = logger or logging.getLogger(__name__)
    if not exchange.has['fetchOHLCV']:
        lg.error(f"Exchange {exchange.id} does not support fetchOHLCV.")
        return pd.DataFrame()

    try:
        # Use safe_api_call to handle retries
        ohlcv = safe_api_call(exchange.fetch_ohlcv, lg, symbol, timeframe=timeframe, limit=limit)

        if ohlcv is None or not isinstance(ohlcv, list) or len(ohlcv) == 0:
            # Error logged by safe_api_call if failed after retries
            if ohlcv is not None: # Log only if it returned empty list/None without raising error
                lg.warning(f"{NEON_YELLOW}No valid kline data returned for {symbol} {timeframe}.{RESET}")
            return pd.DataFrame()

        # Process the data into a pandas DataFrame
        df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])

        if df.empty:
            lg.warning(f"Kline data DataFrame is empty for {symbol} {timeframe}.")
            return df

        # Convert timestamp to datetime objects (UTC), coerce errors
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms', errors='coerce', utc=True)
        df.dropna(subset=['timestamp'], inplace=True)
        df.set_index('timestamp', inplace=True)

        # Convert price/volume columns to numeric Decimal, handling potential empty strings or invalid formats
        for col in ['open', 'high', 'low', 'close', 'volume']:
             try:
                  # Apply robust conversion to Decimal, handle empty strings/None explicitly
                  df[col] = df[col].apply(lambda x: Decimal(str(x)) if pd.notna(x) and str(x).strip() != '' else Decimal('NaN'))
             except (TypeError, ValueError, InvalidOperation) as conv_err:
                  lg.warning(f"Could not convert column '{col}' to Decimal, attempting numeric fallback: {conv_err}")
                  df[col] = pd.to_numeric(df[col], errors='coerce') # Fallback to float/NaN

        # Data Cleaning: Drop rows with NaN in essential price columns or non-positive/non-finite close price
        initial_len = len(df)
        close_col = df['close'] # Reference the column for checks
        df.dropna(subset=['open', 'high', 'low', 'close'], inplace=True)

        # Filter out rows with non-positive or non-finite close prices
        if not df.empty:
            first_val_type = type(close_col.iloc[0]) if not close_col.empty else None
            if first_val_type == Decimal:
                # Use Decimal methods for filtering
                df = df[close_col.apply(lambda x: x.is_finite() and x > 0)]
            elif pd.api.types.is_numeric_dtype(close_col.dtype): # Check if float/int
                 # Use numpy methods for filtering float columns
                 df = df[np.isfinite(close_col) & (close_col > 0)]

        rows_dropped = initial_len - len(df)
        if rows_dropped > 0:
            lg.debug(f"Dropped {rows_dropped} rows with NaN/invalid price data for {symbol}.")

        if df.empty:
            lg.warning(f"Kline data for {symbol} {timeframe} empty after cleaning.")
            return pd.DataFrame()

        # Sort by timestamp index and remove duplicates (keeping the last occurrence)
        df.sort_index(inplace=True)
        df = df[~df.index.duplicated(keep='last')]

        lg.info(f"Successfully fetched and processed {len(df)} klines for {symbol} {timeframe}")
        return df

    except Exception as e:
        # Catch errors from safe_api_call or during processing
        lg.error(f"{NEON_RED}Error fetching/processing klines for {symbol}: {e}{RESET}", exc_info=True)
        return pd.DataFrame()


def fetch_orderbook_ccxt(exchange: ccxt.Exchange, symbol: str, limit: int, logger: logging.Logger) -> Optional[Dict]:
    """Fetch orderbook data using ccxt with retries and validation."""
    lg = logger
    if not exchange.has['fetchOrderBook']:
        lg.error(f"Exchange {exchange.id} does not support fetchOrderBook.")
        return None

    try:
        orderbook = safe_api_call(exchange.fetch_order_book, lg, symbol, limit=limit)

        if not orderbook: # Error already logged by safe_api_call if it failed
            return None
        # Validate structure
        if not isinstance(orderbook, dict) or 'bids' not in orderbook or 'asks' not in orderbook or \
           not isinstance(orderbook['bids'], list) or not isinstance(orderbook['asks'], list):
            lg.warning(f"Invalid orderbook structure received for {symbol}. Data: {orderbook}")
            return None

        if not orderbook['bids'] and not orderbook['asks']:
            lg.warning(f"Orderbook received but both bids and asks lists are empty for {symbol}.")
            # Return the empty but valid book
            return orderbook

        # Basic validation of bid/ask entry format (price, size structure)
        valid = True
        for side in ['bids', 'asks']:
             if orderbook[side]: # Check first entry if list is not empty
                  entry = orderbook[side][0]
                  if not (isinstance(entry, list) and len(entry) == 2):
                       lg.warning(f"Invalid {side[:-1]} entry format in orderbook: {entry}")
                       valid = False; break
                  try: # Check if price and size are numeric (allow float conversion)
                       _ = float(entry[0]); _ = float(entry[1])
                  except (ValueError, TypeError):
                       lg.warning(f"Non-numeric data in {side[:-1]} entry: {entry}")
                       valid = False; break
        if not valid:
             lg.error("Orderbook data format validation failed.")
             return None

        lg.debug(f"Successfully fetched orderbook for {symbol} ({len(orderbook['bids'])} bids, {len(orderbook['asks'])} asks).")
        return orderbook

    except Exception as e:
        # Catch errors raised by safe_api_call or other validation issues
        lg.error(f"{NEON_RED}Error fetching order book for {symbol}: {e}{RESET}", exc_info=False)
        return None

# --- Trading Analyzer Class ---
class TradingAnalyzer:
    """Analyzes trading data using pandas_ta and generates weighted signals."""

    def __init__(
        self,
        df: pd.DataFrame,
        logger: logging.Logger,
        config: Dict[str, Any],
        market_info: Dict[str, Any],
    ) -> None:
        """
        Initializes the TradingAnalyzer.

        Args:
            df: Pandas DataFrame with OHLCV data (expects Decimal values), indexed by timestamp.
            logger: Logger instance for logging messages.
            config: Dictionary containing bot configuration.
            market_info: Dictionary containing market details (precision, limits, etc.).
        """
        self.df = df # Expects OHLCV columns with Decimal type from fetch_klines
        self.logger = logger
        self.config = config
        self.market_info = market_info
        self.symbol = market_info.get('symbol', 'UNKNOWN_SYMBOL')
        self.interval = config.get("interval", "5")
        self.ccxt_interval = CCXT_INTERVAL_MAP.get(self.interval)
        if not self.ccxt_interval:
            self.logger.error(f"Invalid interval '{self.interval}' in config for {self.symbol}.")
            # Bot might fail later if this is not valid

        # Stores latest indicator values (Decimal for prices/ATR, float for others)
        self.indicator_values: Dict[str, Union[Decimal, float, Any]] = {}
        self.signals: Dict[str, int] = {"BUY": 0, "SELL": 0, "HOLD": 1} # Default HOLD
        self.active_weight_set_name = config.get("active_weight_set", "default")
        self.weights = config.get("weight_sets", {}).get(self.active_weight_set_name, {})
        self.fib_levels_data: Dict[str, Decimal] = {} # Stores calculated fib levels
        self.ta_column_names: Dict[str, Optional[str]] = {} # Maps internal name to actual DataFrame column name

        if not self.weights:
            logger.warning(f"{NEON_YELLOW}Active weight set '{self.active_weight_set_name}' not found or empty for {self.symbol}. Scoring will be zero.{RESET}")
            self.weights = {} # Use empty dict to prevent errors

        # Perform initial calculations only if DataFrame is valid
        if not self.df.empty:
             self._calculate_all_indicators()
             self._update_latest_indicator_values() # Run AFTER indicator calculation
             self.calculate_fibonacci_levels()
        else:
             self.logger.warning("TradingAnalyzer initialized with empty DataFrame. No calculations performed.")


    def _get_ta_col_name(self, base_name: str, result_df: pd.DataFrame) -> Optional[str]:
        """Helper to find the actual column name generated by pandas_ta."""
        # Define expected patterns, potentially using f-strings for dynamic parts
        expected_patterns = {
            "ATR": [f"ATRr_{self.config.get('atr_period', DEFAULT_ATR_PERIOD)}"],
            "EMA_Short": [f"EMA_{self.config.get('ema_short_period', DEFAULT_EMA_SHORT_PERIOD)}"],
            "EMA_Long": [f"EMA_{self.config.get('ema_long_period', DEFAULT_EMA_LONG_PERIOD)}"],
            "Momentum": [f"MOM_{self.config.get('momentum_period', DEFAULT_MOMENTUM_PERIOD)}"],
            # CCI often includes the constant (e.g., 100.0) which pandas_ta adds
            "CCI": [f"CCI_{self.config.get('cci_window', DEFAULT_CCI_WINDOW)}"],
            "Williams_R": [f"WILLR_{self.config.get('williams_r_window', DEFAULT_WILLIAMS_R_WINDOW)}"],
            "MFI": [f"MFI_{self.config.get('mfi_window', DEFAULT_MFI_WINDOW)}"],
            "VWAP": ["VWAP_D"], # Default pandas_ta VWAP often daily anchored
            "PSAR_long": [f"PSARl_{self.config.get('psar_af', DEFAULT_PSAR_AF)}_{self.config.get('psar_max_af', DEFAULT_PSAR_MAX_AF)}"],
            "PSAR_short": [f"PSARs_{self.config.get('psar_af', DEFAULT_PSAR_AF)}_{self.config.get('psar_max_af', DEFAULT_PSAR_MAX_AF)}"],
            "SMA10": [f"SMA_{self.config.get('sma_10_window', DEFAULT_SMA_10_WINDOW)}"],
            # StochRSI names can be complex, include core parameters
            "StochRSI_K": [f"STOCHRSIk_{self.config.get('stoch_rsi_window', DEFAULT_STOCH_RSI_WINDOW)}_{self.config.get('stoch_rsi_rsi_window', DEFAULT_STOCH_WINDOW)}_{self.config.get('stoch_rsi_k', DEFAULT_K_WINDOW)}"],
            "StochRSI_D": [f"STOCHRSId_{self.config.get('stoch_rsi_window', DEFAULT_STOCH_RSI_WINDOW)}_{self.config.get('stoch_rsi_rsi_window', DEFAULT_STOCH_WINDOW)}_{self.config.get('stoch_rsi_k', DEFAULT_K_WINDOW)}_{self.config.get('stoch_rsi_d', DEFAULT_D_WINDOW)}"],
            "RSI": [f"RSI_{self.config.get('rsi_period', DEFAULT_RSI_WINDOW)}"],
            # BBands names include period and std dev (formatted to 1 decimal place by default)
            "BB_Lower": [f"BBL_{self.config.get('bollinger_bands_period', DEFAULT_BOLLINGER_BANDS_PERIOD)}_{float(self.config.get('bollinger_bands_std_dev', DEFAULT_BOLLINGER_BANDS_STD_DEV)):.1f}"],
            "BB_Middle": [f"BBM_{self.config.get('bollinger_bands_period', DEFAULT_BOLLINGER_BANDS_PERIOD)}_{float(self.config.get('bollinger_bands_std_dev', DEFAULT_BOLLINGER_BANDS_STD_DEV)):.1f}"],
            "BB_Upper": [f"BBU_{self.config.get('bollinger_bands_period', DEFAULT_BOLLINGER_BANDS_PERIOD)}_{float(self.config.get('bollinger_bands_std_dev', DEFAULT_BOLLINGER_BANDS_STD_DEV)):.1f}"],
            # Custom name used for Volume MA
            "Volume_MA": [f"VOL_SMA_{self.config.get('volume_ma_period', DEFAULT_VOLUME_MA_PERIOD)}"]
        }

        patterns = expected_patterns.get(base_name, [])
        df_cols = result_df.columns.tolist()

        # Exact match or startswith preferred
        for col in df_cols:
            for pattern in patterns:
                # Use startswith for flexibility (e.g., CCI_20_100.0 matches CCI_20)
                if col.startswith(pattern):
                    self.logger.debug(f"Mapped '{base_name}' to column '{col}'")
                    return col

        # Fallback: Simple case-insensitive substring search
        base_lower = base_name.lower()
        simple_base = base_lower.split('_')[0] # e.g., "ema_short" -> "ema"
        for col in df_cols:
            col_lower = col.lower()
            # Check full base name first, then simpler version
            if base_lower in col_lower:
                 self.logger.debug(f"Mapped '{base_name}' to '{col}' via substring search ('{base_lower}').")
                 return col
            # Avoid overly broad matches with simple base (e.g., 'r' matching 'atr')
            # Ensure simple_base is reasonably specific
            elif len(simple_base) > 2 and simple_base in col_lower:
                 self.logger.debug(f"Mapped '{base_name}' to '{col}' via substring search ('{simple_base}').")
                 return col

        self.logger.warning(f"Could not find column name for indicator '{base_name}' in DataFrame columns: {df_cols}")
        return None

    def _calculate_all_indicators(self):
        """Calculates all enabled indicators using pandas_ta."""
        if self.df.empty:
            self.logger.warning(f"DataFrame is empty, cannot calculate indicators for {self.symbol}.")
            return

        # Determine minimum required data length based on enabled & weighted indicators
        required_periods = []
        indicators_config = self.config.get("indicators", {})
        active_weights = self.weights # Use stored weights

        # Helper to add requirement if indicator is enabled AND weighted
        def add_req(key, config_key, default_period):
            if indicators_config.get(key, False) and float(active_weights.get(key, 0)) != 0:
                required_periods.append(self.config.get(config_key, default_period))

        add_req("atr", "atr_period", DEFAULT_ATR_PERIOD) # ATR always calculated if possible
        add_req("momentum", "momentum_period", DEFAULT_MOMENTUM_PERIOD)
        add_req("cci", "cci_window", DEFAULT_CCI_WINDOW)
        add_req("wr", "williams_r_window", DEFAULT_WILLIAMS_R_WINDOW)
        add_req("mfi", "mfi_window", DEFAULT_MFI_WINDOW)
        add_req("sma_10", "sma_10_window", DEFAULT_SMA_10_WINDOW)
        add_req("rsi", "rsi_period", DEFAULT_RSI_WINDOW)
        add_req("bollinger_bands", "bollinger_bands_period", DEFAULT_BOLLINGER_BANDS_PERIOD)
        add_req("volume_confirmation", "volume_ma_period", DEFAULT_VOLUME_MA_PERIOD)
        required_periods.append(self.config.get("fibonacci_window", DEFAULT_FIB_WINDOW)) # For Fib levels

        if indicators_config.get("ema_alignment", False) and float(active_weights.get("ema_alignment", 0)) != 0:
             required_periods.append(self.config.get("ema_short_period", DEFAULT_EMA_SHORT_PERIOD))
             required_periods.append(self.config.get("ema_long_period", DEFAULT_EMA_LONG_PERIOD))
        if indicators_config.get("stoch_rsi", False) and float(active_weights.get("stoch_rsi", 0)) != 0:
            required_periods.append(self.config.get("stoch_rsi_window", DEFAULT_STOCH_RSI_WINDOW))
            required_periods.append(self.config.get("stoch_rsi_rsi_window", DEFAULT_STOCH_WINDOW))

        min_required_data = max(required_periods) + 30 if required_periods else 50 # Add buffer

        if len(self.df) < min_required_data:
             self.logger.warning(f"{NEON_YELLOW}Insufficient data ({len(self.df)} points) for {self.symbol} to calculate indicators reliably (min recommended: {min_required_data}). Results may contain NaNs.{RESET}")

        try:
            df_calc = self.df.copy()
            # --- Convert Decimal columns to float for pandas_ta ---
            # Store original types to potentially convert back later if needed
            original_types = {}
            for col in ['open', 'high', 'low', 'close', 'volume']:
                 if col in df_calc.columns:
                     # Check first non-NaN value's type
                     first_valid_idx = df_calc[col].first_valid_index()
                     if first_valid_idx is not None:
                          original_types[col] = type(df_calc.loc[first_valid_idx, col])
                          if original_types[col] == Decimal:
                               self.logger.debug(f"Converting Decimal column '{col}' to float for TA calculation.")
                               # Apply conversion robustly, handle non-finite Decimals
                               df_calc[col] = df_calc[col].apply(lambda x: float(x) if isinstance(x, Decimal) and x.is_finite() else np.nan)
                     # If column exists but is all NaN, it's fine
                     elif not df_calc[col].isnull().all(): # If not all NaN, but first is NaN, try converting anyway
                          if isinstance(df_calc[col].iloc[0], Decimal): # Check type even if NaN initially
                               self.logger.debug(f"Converting Decimal column '{col}' (starting with NaN) to float.")
                               df_calc[col] = df_calc[col].apply(lambda x: float(x) if isinstance(x, Decimal) and x.is_finite() else np.nan)

            # --- Calculate Indicators using pandas_ta ---
            # Always calculate ATR
            atr_period = self.config.get("atr_period", DEFAULT_ATR_PERIOD)
            df_calc.ta.atr(length=atr_period, append=True)
            self.ta_column_names["ATR"] = self._get_ta_col_name("ATR", df_calc)

            # Calculate others based on config and weight
            key_map = { # Map internal keys to config keys and defaults if needed
                "momentum": ("momentum_period", DEFAULT_MOMENTUM_PERIOD),
                "cci": ("cci_window", DEFAULT_CCI_WINDOW),
                "wr": ("williams_r_window", DEFAULT_WILLIAMS_R_WINDOW),
                "mfi": ("mfi_window", DEFAULT_MFI_WINDOW),
                "sma_10": ("sma_10_window", DEFAULT_SMA_10_WINDOW),
                "rsi": ("rsi_period", DEFAULT_RSI_WINDOW),
            }

            for key, enabled in indicators_config.items():
                if key == "atr": continue # Already done
                if enabled and float(active_weights.get(key, 0)) != 0:
                    self.logger.debug(f"Calculating indicator: {key}")
                    try:
                        if key == "ema_alignment":
                            ema_short = self.config.get("ema_short_period", DEFAULT_EMA_SHORT_PERIOD)
                            ema_long = self.config.get("ema_long_period", DEFAULT_EMA_LONG_PERIOD)
                            df_calc.ta.ema(length=ema_short, append=True)
                            self.ta_column_names["EMA_Short"] = self._get_ta_col_name("EMA_Short", df_calc)
                            df_calc.ta.ema(length=ema_long, append=True)
                            self.ta_column_names["EMA_Long"] = self._get_ta_col_name("EMA_Long", df_calc)
                        elif key == "psar":
                            psar_af = self.config.get("psar_af", DEFAULT_PSAR_AF)
                            psar_max_af = self.config.get("psar_max_af", DEFAULT_PSAR_MAX_AF)
                            psar_result = df_calc.ta.psar(af=psar_af, max_af=psar_max_af)
                            if psar_result is not None and not psar_result.empty:
                                df_calc = pd.concat([df_calc, psar_result], axis=1)
                                self.ta_column_names["PSAR_long"] = self._get_ta_col_name("PSAR_long", df_calc)
                                self.ta_column_names["PSAR_short"] = self._get_ta_col_name("PSAR_short", df_calc)
                        elif key == "stoch_rsi":
                            st_len = self.config.get("stoch_rsi_window", DEFAULT_STOCH_RSI_WINDOW)
                            st_rsi_len = self.config.get("stoch_rsi_rsi_window", DEFAULT_STOCH_WINDOW)
                            st_k = self.config.get("stoch_rsi_k", DEFAULT_K_WINDOW)
                            st_d = self.config.get("stoch_rsi_d", DEFAULT_D_WINDOW)
                            st_result = df_calc.ta.stochrsi(length=st_len, rsi_length=st_rsi_len, k=st_k, d=st_d)
                            if st_result is not None and not st_result.empty:
                                df_calc = pd.concat([df_calc, st_result], axis=1)
                                self.ta_column_names["StochRSI_K"] = self._get_ta_col_name("StochRSI_K", df_calc)
                                self.ta_column_names["StochRSI_D"] = self._get_ta_col_name("StochRSI_D", df_calc)
                        elif key == "bollinger_bands":
                            bb_p = self.config.get("bollinger_bands_period", DEFAULT_BOLLINGER_BANDS_PERIOD)
                            bb_std = float(self.config.get("bollinger_bands_std_dev", DEFAULT_BOLLINGER_BANDS_STD_DEV))
                            bb_result = df_calc.ta.bbands(length=bb_p, std=bb_std)
                            if bb_result is not None and not bb_result.empty:
                                df_calc = pd.concat([df_calc, bb_result], axis=1)
                                self.ta_column_names["BB_Lower"] = self._get_ta_col_name("BB_Lower", df_calc)
                                self.ta_column_names["BB_Middle"] = self._get_ta_col_name("BB_Middle", df_calc)
                                self.ta_column_names["BB_Upper"] = self._get_ta_col_name("BB_Upper", df_calc)
                        elif key == "volume_confirmation":
                            vol_ma_p = self.config.get("volume_ma_period", DEFAULT_VOLUME_MA_PERIOD)
                            vol_ma_col = f"VOL_SMA_{vol_ma_p}"
                            # Ensure volume is float for SMA calculation
                            vol_series = df_calc['volume'].astype(float) # Already converted above if needed
                            df_calc[vol_ma_col] = ta.sma(vol_series.fillna(0), length=vol_ma_p)
                            self.ta_column_names["Volume_MA"] = vol_ma_col
                        elif key == "vwap":
                             df_calc.ta.vwap(append=True)
                             self.ta_column_names["VWAP"] = self._get_ta_col_name("VWAP", df_calc)
                        elif key in key_map: # General case using key_map
                            config_k, default_p = key_map[key]
                            period = self.config.get(config_k, default_p)
                            method = getattr(df_calc.ta, key, None)
                            if method and callable(method):
                                method(length=period, append=True)
                                # Map internal key to pandas_ta base name for column lookup
                                ta_base_map = {"cci": "CCI", "wr": "Williams_R", "mfi": "MFI", "sma_10": "SMA10", "rsi": "RSI", "momentum": "Momentum"}
                                ta_base_name = ta_base_map.get(key, key.upper()) # Simple mapping
                                self.ta_column_names[ta_base_name] = self._get_ta_col_name(ta_base_name, df_calc)
                            else:
                                self.logger.warning(f"Pandas TA method '{key}' not found or not callable.")

                    except Exception as calc_err:
                        self.logger.error(f"Error calculating indicator '{key}': {calc_err}", exc_info=True)

            # --- Convert ATR column back to Decimal ---
            # pandas_ta outputs float, convert ATR back for precise calculations
            atr_col = self.ta_column_names.get("ATR")
            if atr_col and atr_col in df_calc.columns:
                 try:
                     # Convert float column back to Decimal, handling potential NaNs/infs
                     df_calc[atr_col] = df_calc[atr_col].apply(lambda x: Decimal(str(x)) if pd.notna(x) and np.isfinite(x) else Decimal('NaN'))
                     self.logger.debug(f"Converted calculated ATR column '{atr_col}' back to Decimal.")
                 except (ValueError, TypeError, InvalidOperation) as conv_err:
                      self.logger.error(f"Failed to convert ATR column '{atr_col}' back to Decimal: {conv_err}")

            # Update the instance's DataFrame
            self.df = df_calc
            self.logger.debug(f"Finished indicator calculations. Final DF columns: {self.df.columns.tolist()}")

        except Exception as e:
            self.logger.error(f"{NEON_RED}Error during indicator calculation setup or execution: {e}{RESET}", exc_info=True)


    def _update_latest_indicator_values(self):
        """Updates indicator_values dict with latest values, handling types."""
        # Define keys expected based on calculation attempts + base OHLCV
        expected_keys = list(self.ta_column_names.keys()) + ["Open", "High", "Low", "Close", "Volume"]
        default_values = {k: np.nan for k in expected_keys} # Initialize with NaN

        if self.df.empty:
            self.logger.warning(f"Cannot update latest values: DataFrame empty for {self.symbol}.")
            self.indicator_values = default_values
            return
        try:
            # Use the last valid index in case of missing data points
            last_valid_index = self.df.last_valid_index()
            if last_valid_index is None: raise IndexError("No valid index found.")
            latest = self.df.loc[last_valid_index]
        except (IndexError, KeyError):
            self.logger.error(f"Error accessing latest valid row/index for {self.symbol}.")
            self.indicator_values = default_values
            return

        if latest.isnull().all():
            self.logger.warning(f"Last valid row contains all NaNs for {self.symbol}. Cannot update values.")
            self.indicator_values = default_values
            return

        updated_values = {}
        # --- Process TA indicators ---
        for key, col_name in self.ta_column_names.items():
            if col_name and col_name in latest.index:
                value = latest[col_name]
                # Ensure value is finite number (not NaN, not inf)
                if pd.notna(value) and np.isfinite(value):
                    try:
                        if key == "ATR": # ATR should be Decimal
                            updated_values[key] = value if isinstance(value, Decimal) else Decimal(str(value))
                        else: # Others as float
                            updated_values[key] = float(value)
                    except (ValueError, TypeError, InvalidOperation) as conv_err:
                        self.logger.warning(f"Could not convert TA value {key} ('{col_name}': {value}): {conv_err}. Storing NaN.")
                        updated_values[key] = np.nan
                else: updated_values[key] = np.nan # Store NaN if value is NaN or inf
            else:
                 # Log only if calculation was attempted (key exists in ta_column_names)
                 if key in self.ta_column_names:
                     self.logger.debug(f"Indicator column '{col_name}' for '{key}' not found in latest data. Storing NaN.")
                 updated_values[key] = np.nan

        # --- Process Base OHLCV (should be Decimal from fetch) ---
        for base_col in ['open', 'high', 'low', 'close', 'volume']:
            key_name = base_col.capitalize()
            value = latest.get(base_col)
            if pd.notna(value) and isinstance(value, Decimal) and value.is_finite():
                 updated_values[key_name] = value
            elif pd.notna(value): # If not Decimal or not finite
                 self.logger.warning(f"Base value '{base_col}' ({value}) is not a finite Decimal. Storing NaN.")
                 updated_values[key_name] = np.nan
            else: # Value is NaN
                 updated_values[key_name] = np.nan

        self.indicator_values = updated_values

        # --- Log Summary (formatted) ---
        log_vals = {}
        price_prec = self.get_price_precision()
        for k, v in self.indicator_values.items():
            # Log only finite numeric values
            if pd.notna(v) and isinstance(v, (Decimal, float, int)) and np.isfinite(v):
                if isinstance(v, Decimal):
                    prec = price_prec if k in ['Open', 'High', 'Low', 'Close', 'ATR'] else 8
                    log_vals[k] = f"{v:.{prec}f}"
                elif isinstance(v, float): log_vals[k] = f"{v:.5f}"
                else: log_vals[k] = str(v)
            # else: log_vals[k] = "NaN" # Optionally log NaNs

        self.logger.debug(f"Latest values updated ({self.symbol}): {log_vals}")


    def calculate_fibonacci_levels(self, window: Optional[int] = None) -> Dict[str, Decimal]:
        """Calculates Fibonacci levels using Decimal precision."""
        window = window or self.config.get("fibonacci_window", DEFAULT_FIB_WINDOW)
        if len(self.df) < window:
            self.logger.debug(f"Not enough data ({len(self.df)}) for Fibonacci ({window}) on {self.symbol}.")
            self.fib_levels_data = {}; return {}

        df_slice = self.df.tail(window)
        try:
            # Ensure 'high'/'low' are numeric (handle Decimal or float)
            high_series = pd.to_numeric(df_slice["high"], errors='coerce')
            low_series = pd.to_numeric(df_slice["low"], errors='coerce')
            high_price_raw = high_series.dropna().max()
            low_price_raw = low_series.dropna().min()

            if pd.isna(high_price_raw) or pd.isna(low_price_raw):
                self.logger.warning(f"Could not find valid high/low for Fibonacci (Window: {window}).")
                self.fib_levels_data = {}; return {}

            high = Decimal(str(high_price_raw))
            low = Decimal(str(low_price_raw))
            diff = high - low

            levels = {}
            price_precision = self.get_price_precision()
            rounding_factor = Decimal('1e-' + str(price_precision))

            if diff > 0:
                for level_pct in FIB_LEVELS:
                    level_name = f"Fib_{level_pct * 100:.1f}%"
                    # Level price = High - (Range * Percentage)
                    level_price = high - (diff * Decimal(str(level_pct)))
                    # Quantize down from high (conservative support)
                    levels[level_name] = level_price.quantize(rounding_factor, rounding=ROUND_DOWN)
            else: # Handle zero range
                self.logger.debug(f"Fibonacci range is zero (High=Low={high}). Setting all levels to this price.")
                level_price_quantized = high.quantize(rounding_factor, rounding=ROUND_DOWN)
                for level_pct in FIB_LEVELS:
                    levels[f"Fib_{level_pct * 100:.1f}%"] = level_price_quantized

            self.fib_levels_data = levels
            log_levels = {k: str(v) for k, v in levels.items()}
            self.logger.debug(f"Calculated Fibonacci levels (Window: {window}): {log_levels}")
            return levels

        except KeyError as e:
            self.logger.error(f"{NEON_RED}Fibonacci error: Missing column '{e}'.{RESET}")
            self.fib_levels_data = {}; return {}
        except (ValueError, TypeError, InvalidOperation) as e:
             self.logger.error(f"{NEON_RED}Fibonacci error: Invalid data type for high/low. {e}{RESET}")
             self.fib_levels_data = {}; return {}
        except Exception as e:
            self.logger.error(f"{NEON_RED}Unexpected Fibonacci calculation error: {e}{RESET}", exc_info=True)
            self.fib_levels_data = {}; return {}

    def get_price_precision(self) -> int:
        """Determines price precision (decimal places) from market info."""
        try:
            # 1. Check precision.price (most reliable)
            precision_info = self.market_info.get('precision', {})
            price_precision_val = precision_info.get('price')
            if price_precision_val is not None:
                if isinstance(price_precision_val, int) and price_precision_val >= 0:
                    return price_precision_val
                try: # Assume float/str represents tick size
                    tick_size = Decimal(str(price_precision_val))
                    if tick_size.is_finite() and tick_size > 0:
                        return abs(tick_size.normalize().as_tuple().exponent)
                except (TypeError, ValueError, InvalidOperation) as e:
                     self.logger.debug(f"Could not parse precision.price '{price_precision_val}' as tick size: {e}")

            # 2. Fallback: Infer from limits.price.min (less reliable)
            min_price_val = self.market_info.get('limits', {}).get('price', {}).get('min')
            if min_price_val is not None:
                try:
                    min_price_tick = Decimal(str(min_price_val))
                    if min_price_tick.is_finite() and 0 < min_price_tick < Decimal('0.1'): # Heuristic
                        return abs(min_price_tick.normalize().as_tuple().exponent)
                except (TypeError, ValueError, InvalidOperation) as e:
                    self.logger.debug(f"Could not parse limits.price.min '{min_price_val}' for precision: {e}")

            # 3. Fallback: Infer from last close price (least reliable)
            last_close = self.indicator_values.get("Close")
            if isinstance(last_close, Decimal) and last_close.is_finite() and last_close > 0:
                try:
                    precision = abs(last_close.normalize().as_tuple().exponent)
                    if 0 <= precision < 10: return precision # Sanity check
                except Exception: pass

        except Exception as e:
            self.logger.warning(f"Error determining price precision for {self.symbol}: {e}. Falling back.")

        default_precision = 4
        self.logger.warning(f"Could not determine price precision for {self.symbol}. Using default: {default_precision}.")
        return default_precision

    def get_min_tick_size(self) -> Decimal:
        """Gets the minimum price increment (tick size) from market info."""
        try:
            # 1. Try precision.price
            precision_info = self.market_info.get('precision', {})
            price_precision_val = precision_info.get('price')
            if price_precision_val is not None:
                if isinstance(price_precision_val, (float, str, int)):
                     try:
                          if isinstance(price_precision_val, int): # Decimal places
                               if price_precision_val >= 0:
                                    tick = Decimal('1e-' + str(price_precision_val))
                                    if tick.is_finite() and tick > 0: return tick
                          else: # float or str -> Assume it IS the tick size
                               tick = Decimal(str(price_precision_val))
                               if tick.is_finite() and tick > 0: return tick
                     except (TypeError, ValueError, InvalidOperation) as e:
                          self.logger.debug(f"Could not parse precision.price '{price_precision_val}' as tick size: {e}")

            # 2. Fallback: Try limits.price.min
            min_price_val = self.market_info.get('limits', {}).get('price', {}).get('min')
            if min_price_val is not None:
                try:
                    min_tick = Decimal(str(min_price_val))
                    if min_tick.is_finite() and 0 < min_tick < Decimal('0.1'): # Heuristic check
                        return min_tick
                except (TypeError, ValueError, InvalidOperation) as e:
                     self.logger.debug(f"Could not parse limits.price.min '{min_price_val}' for tick size: {e}")

        except Exception as e:
            self.logger.warning(f"Could not determine min tick size for {self.symbol} from market info: {e}.")

        # --- Final Fallback: Calculate from derived decimal places ---
        price_precision_places = self.get_price_precision()
        fallback_tick = Decimal('1e-' + str(price_precision_places))
        self.logger.debug(f"Using fallback tick size based on derived precision ({price_precision_places}): {fallback_tick}")
        return fallback_tick

    def get_amount_precision_places(self) -> int:
        """Determines amount precision (decimal places) from market info."""
        try:
            precision_info = self.market_info.get('precision', {})
            amount_precision_val = precision_info.get('amount')
            if amount_precision_val is not None:
                if isinstance(amount_precision_val, int) and amount_precision_val >= 0:
                    return amount_precision_val
                try: # Assume step size
                    step_size = Decimal(str(amount_precision_val))
                    if step_size.is_finite() and step_size > 0:
                        return abs(step_size.normalize().as_tuple().exponent)
                except (TypeError, ValueError, InvalidOperation): pass

            min_amount_val = self.market_info.get('limits', {}).get('amount', {}).get('min')
            if min_amount_val is not None:
                try:
                    min_amount_step = Decimal(str(min_amount_val))
                    if min_amount_step.is_finite() and 0 < min_amount_step <= Decimal('1'):
                       if min_amount_step < 1: # Looks like step size
                           return abs(min_amount_step.normalize().as_tuple().exponent)
                       elif min_amount_step >= 1 and '.' not in str(min_amount_val): return 0 # Integer min amount likely 0 precision
                except (TypeError, ValueError, InvalidOperation): pass

        except Exception as e:
            self.logger.warning(f"Error determining amount precision for {self.symbol}: {e}.")

        default_precision = 8
        self.logger.warning(f"Could not determine amount precision for {self.symbol}. Using default: {default_precision}.")
        return default_precision

    def get_min_amount_step(self) -> Decimal:
        """Gets the minimum amount increment (step size) from market info."""
        try:
            precision_info = self.market_info.get('precision', {})
            amount_precision_val = precision_info.get('amount')
            if amount_precision_val is not None:
                if isinstance(amount_precision_val, (float, str, int)):
                     try:
                          if isinstance(amount_precision_val, int): # Decimal places
                               if amount_precision_val >= 0:
                                    step = Decimal('1e-' + str(amount_precision_val))
                                    if step.is_finite() and step > 0: return step
                          else: # Float/Str = step size itself
                               step = Decimal(str(amount_precision_val))
                               if step.is_finite() and step > 0: return step
                     except (TypeError, ValueError, InvalidOperation): pass

            min_amount_val = self.market_info.get('limits', {}).get('amount', {}).get('min')
            if min_amount_val is not None:
                try:
                    min_step = Decimal(str(min_amount_val))
                    # Assume min limit IS the step size if it's positive and finite
                    if min_step.is_finite() and min_step > 0: return min_step
                except (TypeError, ValueError, InvalidOperation): pass

        except Exception as e:
            self.logger.warning(f"Could not determine min amount step for {self.symbol}: {e}.")

        amount_precision_places = self.get_amount_precision_places()
        fallback_step = Decimal('1e-' + str(amount_precision_places))
        self.logger.debug(f"Using fallback amount step based on derived precision ({amount_precision_places}): {fallback_step}")
        return fallback_step


    def get_nearest_fibonacci_levels(self, current_price: Decimal, num_levels: int = 5) -> List[Tuple[str, Decimal]]:
        """Finds the N nearest Fibonacci levels to the current price."""
        if not self.fib_levels_data:
            self.logger.debug(f"Fibonacci levels not calculated for {self.symbol}.")
            return []
        if not isinstance(current_price, Decimal) or not current_price.is_finite() or current_price <= 0:
            self.logger.warning(f"Invalid current price ({current_price}) for Fibonacci comparison on {self.symbol}.")
            return []

        try:
            level_distances = []
            for name, level_price in self.fib_levels_data.items():
                if isinstance(level_price, Decimal) and level_price.is_finite() and level_price > 0:
                    distance = abs(current_price - level_price)
                    level_distances.append({'name': name, 'level': level_price, 'distance': distance})
                else:
                    self.logger.warning(f"Invalid Fib level value encountered: {name}={level_price}. Skipping.")

            level_distances.sort(key=lambda x: x['distance'])
            return [(item['name'], item['level']) for item in level_distances[:num_levels]]

        except Exception as e:
            self.logger.error(f"{NEON_RED}Error finding nearest Fibonacci levels for {self.symbol}: {e}{RESET}", exc_info=True)
            return []

    def calculate_ema_alignment_score(self) -> float:
        """Calculates EMA alignment score."""
        ema_s = self.indicator_values.get("EMA_Short") # Float
        ema_l = self.indicator_values.get("EMA_Long") # Float
        close_dec = self.indicator_values.get("Close") # Decimal

        if not (isinstance(ema_s, (float, int)) and np.isfinite(ema_s) and
                isinstance(ema_l, (float, int)) and np.isfinite(ema_l) and
                isinstance(close_dec, Decimal) and close_dec.is_finite()):
            self.logger.debug("EMA alignment check skipped: Missing or non-finite values.")
            return np.nan

        price_f = float(close_dec)
        if price_f > ema_s > ema_l: return 1.0 # Strong Bullish
        elif price_f < ema_s < ema_l: return -1.0 # Strong Bearish
        else: return 0.0 # Mixed / Crossing

    def generate_trading_signal(self, current_price: Decimal, orderbook_data: Optional[Dict]) -> str:
        """Generates final trading signal (BUY/SELL/HOLD) based on weighted score."""
        self.signals = {"BUY": 0, "SELL": 0, "HOLD": 1} # Default HOLD
        final_score = Decimal("0.0")
        total_weight = Decimal("0.0")
        active_count, nan_count = 0, 0
        debug_scores = {}

        # --- Basic Validation ---
        if not self.indicator_values:
            self.logger.warning("Signal Gen: Indicator values empty."); return "HOLD"
        core_ok = any(
            pd.notna(v) and np.isfinite(v)
            for k, v in self.indicator_values.items()
            if k not in ['Open', 'High', 'Low', 'Close', 'Volume'] and float(self.weights.get(k, 0)) != 0
        )
        if not core_ok:
            self.logger.warning("Signal Gen: All weighted core indicators NaN/invalid."); return "HOLD"
        if not isinstance(current_price, Decimal) or not current_price.is_finite() or current_price <= 0:
            self.logger.warning(f"Signal Gen: Invalid current price ({current_price})."); return "HOLD"
        if not self.weights:
            self.logger.error("Signal Gen: Active weight set missing/empty."); return "HOLD"

        # --- Iterate through indicators ---
        for indicator_key, enabled in self.config.get("indicators", {}).items():
            if not enabled: continue
            weight_str = self.weights.get(indicator_key)
            if weight_str is None: continue # No weight defined

            try:
                weight = Decimal(str(weight_str))
                if not weight.is_finite(): raise ValueError("Weight not finite")
                if weight == 0: continue # Skip zero weight
            except (ValueError, TypeError, InvalidOperation):
                self.logger.warning(f"Invalid weight '{weight_str}' for '{indicator_key}'. Skipping."); continue

            check_method_name = f"_check_{indicator_key}"
            score_float = np.nan
            if hasattr(self, check_method_name) and callable(getattr(self, check_method_name)):
                try:
                    method = getattr(self, check_method_name)
                    if indicator_key == "orderbook":
                        if orderbook_data: score_float = method(orderbook_data, current_price)
                        elif weight != 0: self.logger.debug("Orderbook check skipped: No data.")
                    else: score_float = method()
                except Exception as e:
                    self.logger.error(f"Error executing check {check_method_name}: {e}", exc_info=True)
            elif weight != 0:
                self.logger.warning(f"Check method '{check_method_name}' not found for weighted indicator '{indicator_key}'.")

            # Store score for debugging
            debug_scores[indicator_key] = f"{score_float:.3f}" if pd.notna(score_float) and np.isfinite(score_float) else str(score_float)

            # Aggregate score if valid
            if pd.notna(score_float) and np.isfinite(score_float):
                try:
                    score_dec = Decimal(str(score_float))
                    clamped_score = max(Decimal("-1.0"), min(Decimal("1.0"), score_dec))
                    final_score += clamped_score * weight
                    total_weight += weight
                    active_count += 1
                except (ValueError, TypeError, InvalidOperation) as calc_err:
                    self.logger.error(f"Error processing score for {indicator_key}: {calc_err}"); nan_count += 1
            else:
                nan_count += 1

        # --- Determine Final Signal ---
        final_signal = "HOLD"
        if total_weight == 0:
            self.logger.warning(f"No indicators contributed valid scores/weights ({self.symbol}). Defaulting to HOLD.")
        else:
            try:
                threshold_str = self.config.get("signal_score_threshold", "1.5")
                threshold = Decimal(str(threshold_str))
                if not threshold.is_finite() or threshold <= 0: raise ValueError("Threshold non-positive/finite")
            except (ValueError, TypeError, InvalidOperation):
                self.logger.warning(f"Invalid signal_score_threshold '{threshold_str}'. Using default 1.5.")
                threshold = Decimal("1.5")

            if final_score >= threshold: final_signal = "BUY"
            elif final_score <= -threshold: final_signal = "SELL"

        # --- Log Summary ---
        price_prec = self.get_price_precision()
        sig_color = NEON_GREEN if final_signal == "BUY" else NEON_RED if final_signal == "SELL" else NEON_YELLOW
        log_msg = (
            f"Signal Summary ({self.symbol} @ {current_price:.{price_prec}f}): "
            f"Set='{self.active_weight_set_name}', Ind=[Act:{active_count}, NaN:{nan_count}], "
            f"Weight={total_weight:.2f}, Score={final_score:.4f} (Thr: +/-{threshold:.2f}) "
            f"==> {sig_color}{final_signal}{RESET}"
        )
        self.logger.info(log_msg)
        self.logger.debug(f"  Indicator Scores ({self.symbol}): {debug_scores}")

        # Update internal signal state
        if final_signal == "BUY": self.signals = {"BUY": 1, "SELL": 0, "HOLD": 0}
        elif final_signal == "SELL": self.signals = {"BUY": 0, "SELL": 1, "HOLD": 0}
        else: self.signals = {"BUY": 0, "SELL": 0, "HOLD": 1}
        return final_signal

    # --- Indicator Check Methods (return float score -1.0 to 1.0 or np.nan) ---
    # Ensure methods handle potential NaN/inf values from self.indicator_values
    def _check_ema_alignment(self) -> float:
        return self.calculate_ema_alignment_score()

    def _check_momentum(self) -> float:
        momentum = self.indicator_values.get("Momentum")
        if not isinstance(momentum, (float, int)) or not np.isfinite(momentum): return np.nan
        threshold = 0.1 # Example threshold, adjust based on expected MOM range
        if threshold == 0: return 0.0
        score = momentum / threshold
        return max(-1.0, min(1.0, score)) # Clamp

    def _check_volume_confirmation(self) -> float:
        current_volume = self.indicator_values.get("Volume") # Decimal
        volume_ma = self.indicator_values.get("Volume_MA") # Float
        multiplier = float(self.config.get("volume_confirmation_multiplier", 1.5))
        if not (isinstance(current_volume, Decimal) and current_volume.is_finite() and
                isinstance(volume_ma, (float, int)) and np.isfinite(volume_ma) and volume_ma > 0 and multiplier > 0):
            return np.nan
        try:
            volume_ma_dec = Decimal(str(volume_ma)); multiplier_dec = Decimal(str(multiplier))
            if current_volume > volume_ma_dec * multiplier_dec: return 0.7 # High volume
            elif current_volume < volume_ma_dec / multiplier_dec: return -0.4 # Low volume
            else: return 0.0 # Neutral
        except (ValueError, TypeError, InvalidOperation): return np.nan

    def _check_stoch_rsi(self) -> float:
        k = self.indicator_values.get("StochRSI_K")
        d = self.indicator_values.get("StochRSI_D")
        if not (isinstance(k, (float, int)) and np.isfinite(k) and
                isinstance(d, (float, int)) and np.isfinite(d)): return np.nan
        oversold = float(self.config.get("stoch_rsi_oversold_threshold", 25))
        overbought = float(self.config.get("stoch_rsi_overbought_threshold", 75))
        score = 0.0
        if k < oversold and d < oversold: score = 1.0
        elif k > overbought and d > overbought: score = -1.0
        diff = k - d
        if abs(diff) > 5: score = max(score, 0.6) if diff > 0 else min(score, -0.6) # Stronger cross signal
        elif k > d: score = max(score, 0.2) # Mild bullish
        elif k < d: score = min(score, -0.2) # Mild bearish
        if 40 < k < 60: score *= 0.5 # Dampen in neutral zone
        return score

    def _check_rsi(self) -> float:
        rsi = self.indicator_values.get("RSI")
        if not isinstance(rsi, (float, int)) or not np.isfinite(rsi): return np.nan
        if rsi <= 30: return 1.0;   elif rsi >= 70: return -1.0
        if rsi < 40: return 0.5;    elif rsi > 60: return -0.5
        if 40 <= rsi <= 60: return (rsi - 50) / 50.0 # Scale -0.2 to +0.2
        return 0.0

    def _check_cci(self) -> float:
        cci = self.indicator_values.get("CCI")
        if not isinstance(cci, (float, int)) or not np.isfinite(cci): return np.nan
        if cci <= -150: return 1.0; elif cci >= 150: return -1.0
        if cci < -80: return 0.6;   elif cci > 80: return -0.6
        if cci > 0: return -0.1;    elif cci < 0: return 0.1
        return 0.0

    def _check_wr(self) -> float:
        wr = self.indicator_values.get("Williams_R")
        if not isinstance(wr, (float, int)) or not np.isfinite(wr): return np.nan
        if wr <= -80: return 1.0;   elif wr >= -20: return -1.0
        if wr < -50: return 0.4;    elif wr > -50: return -0.4
        return 0.0

    def _check_psar(self) -> float:
        psar_l = self.indicator_values.get("PSAR_long"); psar_s = self.indicator_values.get("PSAR_short")
        # Check if values are finite numbers if not NaN
        l_act = pd.notna(psar_l) and isinstance(psar_l, (float, int)) and np.isfinite(psar_l)
        s_act = pd.notna(psar_s) and isinstance(psar_s, (float, int)) and np.isfinite(psar_s)

        if l_act and not s_act: return 1.0 # Long trend
        elif s_act and not l_act: return -1.0 # Short trend
        elif not l_act and not s_act: return np.nan # Indeterminate
        else: self.logger.warning(f"PSAR unusual: L={psar_l}, S={psar_s}"); return 0.0 # Both active? Error.

    def _check_sma_10(self) -> float:
        sma = self.indicator_values.get("SMA10"); close = self.indicator_values.get("Close")
        if not (isinstance(sma, (float, int)) and np.isfinite(sma) and
                isinstance(close, Decimal) and close.is_finite()): return np.nan
        try: sma_dec = Decimal(str(sma))
        except (ValueError, TypeError, InvalidOperation): return np.nan
        if close > sma_dec: return 0.6
        elif close < sma_dec: return -0.6
        else: return 0.0

    def _check_vwap(self) -> float:
        vwap = self.indicator_values.get("VWAP"); close = self.indicator_values.get("Close")
        if not (isinstance(vwap, (float, int)) and np.isfinite(vwap) and
                isinstance(close, Decimal) and close.is_finite()): return np.nan
        try: vwap_dec = Decimal(str(vwap))
        except (ValueError, TypeError, InvalidOperation): return np.nan
        if close > vwap_dec: return 0.7
        elif close < vwap_dec: return -0.7
        else: return 0.0

    def _check_mfi(self) -> float:
        mfi = self.indicator_values.get("MFI")
        if not isinstance(mfi, (float, int)) or not np.isfinite(mfi): return np.nan
        if mfi <= 20: return 1.0;   elif mfi >= 80: return -1.0
        if mfi < 40: return 0.4;    elif mfi > 60: return -0.4
        return 0.0

    def _check_bollinger_bands(self) -> float:
        bbl=self.indicator_values.get("BB_Lower"); bbm=self.indicator_values.get("BB_Middle"); bbu=self.indicator_values.get("BB_Upper")
        close = self.indicator_values.get("Close")
        if not (isinstance(bbl, (float, int)) and np.isfinite(bbl) and
                isinstance(bbm, (float, int)) and np.isfinite(bbm) and
                isinstance(bbu, (float, int)) and np.isfinite(bbu) and
                isinstance(close, Decimal) and close.is_finite()): return np.nan
        try:
            bbl_d, bbm_d, bbu_d = Decimal(str(bbl)), Decimal(str(bbm)), Decimal(str(bbu))
            if bbu_d <= bbl_d: return 0.0 # Avoid division by zero if bands collapse/invalid
        except (ValueError, TypeError, InvalidOperation): return np.nan

        if close <= bbl_d: return 1.0 # Touch/Below Lower -> Buy Signal
        if close >= bbu_d: return -1.0 # Touch/Above Upper -> Sell Signal

        # Scale score based on position between middle and outer bands
        if close > bbm_d: # Above middle
             dist_from_mid = close - bbm_d
             upper_range = bbu_d - bbm_d
             # Score decreases from 0.5 (at mid) to 0.0 (at upper band)
             score = 0.5 * float(1 - (dist_from_mid / upper_range if upper_range > 0 else 0))
             return max(0.0, min(score, 0.5)) # Clamp [0.0, 0.5]
        else: # Below middle
             dist_from_mid = bbm_d - close
             lower_range = bbm_d - bbl_d
             # Score increases from -0.5 (at mid) to 0.0 (at lower band)
             score = -0.5 * float(1 - (dist_from_mid / lower_range if lower_range > 0 else 0))
             return max(-0.5, min(score, 0.0)) # Clamp [-0.5, 0.0]

    def _check_orderbook(self, orderbook_data: Optional[Dict], current_price: Decimal) -> float:
        if not orderbook_data or not orderbook_data.get('bids') or not orderbook_data.get('asks'):
            self.logger.debug("Orderbook check skipped: No data or missing bids/asks.")
            return np.nan
        try:
            bids = orderbook_data['bids']; asks = orderbook_data['asks']
            levels = min(len(bids), len(asks), 10) # Use top 10 levels
            if levels == 0: return 0.0 # Neutral if no common levels

            bid_v = sum(Decimal(str(b[1])) for b in bids[:levels] if len(b)==2)
            ask_v = sum(Decimal(str(a[1])) for a in asks[:levels] if len(a)==2)
            total_v = bid_v + ask_v
            if total_v == 0: return 0.0 # Avoid division by zero

            obi = (bid_v - ask_v) / total_v # Order Book Imbalance ratio
            score = float(max(Decimal("-1.0"), min(Decimal("1.0"), obi))) # Clamp and convert

            self.logger.debug(f"OB Check: Lvl={levels}, BidV={bid_v:.4f}, AskV={ask_v:.4f}, OBI={obi:.4f} -> Score={score:.4f}")
            return score
        except (IndexError, ValueError, TypeError, InvalidOperation) as e:
             self.logger.warning(f"Orderbook analysis failed: {e}", exc_info=True); return np.nan

    def calculate_entry_tp_sl(
        self, entry_price_estimate: Decimal, signal: str
    ) -> Tuple[Optional[Decimal], Optional[Decimal], Optional[Decimal]]:
        """Calculates potential TP and initial SL based on entry estimate, signal, and ATR."""
        if signal not in ["BUY", "SELL"]: return entry_price_estimate, None, None
        atr = self.indicator_values.get("ATR") # Decimal
        if not isinstance(atr, Decimal) or not atr.is_finite() or atr <= 0:
            self.logger.warning(f"Calc TP/SL Fail ({signal}): Invalid ATR ({atr})."); return entry_price_estimate, None, None
        if not isinstance(entry_price_estimate, Decimal) or not entry_price_estimate.is_finite() or entry_price_estimate <= 0:
            self.logger.warning(f"Calc TP/SL Fail ({signal}): Invalid entry estimate ({entry_price_estimate})."); return entry_price_estimate, None, None

        try:
            tp_mult = Decimal(str(self.config.get("take_profit_multiple", "1.0")))
            sl_mult = Decimal(str(self.config.get("stop_loss_multiple", "1.5")))
            prec = self.get_price_precision()
            rnd = Decimal('1e-' + str(prec))
            tick = self.get_min_tick_size()

            tp_off = atr * tp_mult; sl_off = atr * sl_mult
            tp_raw, sl_raw = None, None

            if signal == "BUY": tp_raw, sl_raw = entry_price_estimate + tp_off, entry_price_estimate - sl_off
            else: tp_raw, sl_raw = entry_price_estimate - tp_off, entry_price_estimate + sl_off

            # Quantize TP/SL using market precision
            # Round TP towards neutral (less profit), SL away from neutral (more room) -> Conservative
            tp_q = tp_raw.quantize(rnd, rounding=ROUND_DOWN if signal=="BUY" else ROUND_UP) if tp_raw and tp_raw.is_finite() else None
            sl_q = sl_raw.quantize(rnd, rounding=ROUND_DOWN if signal=="BUY" else ROUND_UP) if sl_raw and sl_raw.is_finite() else None

            # --- Validation & Adjustment ---
            final_tp, final_sl = tp_q, sl_q
            # Ensure SL is strictly beyond entry by at least one tick
            if final_sl:
                if signal == "BUY" and final_sl >= entry_price_estimate:
                    final_sl = (entry_price_estimate - tick).quantize(rnd, rounding=ROUND_DOWN)
                    self.logger.debug(f"Adjusted BUY SL below entry: {sl_q} -> {final_sl}")
                elif signal == "SELL" and final_sl <= entry_price_estimate:
                    final_sl = (entry_price_estimate + tick).quantize(rnd, rounding=ROUND_UP)
                    self.logger.debug(f"Adjusted SELL SL above entry: {sl_q} -> {final_sl}")

            # Ensure TP offers profit (strictly beyond entry)
            if final_tp:
                 if signal == "BUY" and final_tp <= entry_price_estimate:
                      self.logger.warning(f"BUY TP {final_tp} <= Entry {entry_price_estimate}. Nullifying TP."); final_tp = None
                 elif signal == "SELL" and final_tp >= entry_price_estimate:
                      self.logger.warning(f"SELL TP {final_tp} >= Entry {entry_price_estimate}. Nullifying TP."); final_tp = None

            # Ensure SL/TP are positive
            if final_sl and final_sl <= 0: self.logger.error(f"SL calc non-positive ({final_sl}). Nullifying SL."); final_sl = None
            if final_tp and final_tp <= 0: self.logger.warning(f"TP calc non-positive ({final_tp}). Nullifying TP."); final_tp = None

            tp_str = f"{final_tp:.{prec}f}" if final_tp else "None"; sl_str = f"{final_sl:.{prec}f}" if final_sl else "None"
            self.logger.debug(f"Calc TP/SL ({signal}): Entry={entry_price_estimate:.{prec}f}, ATR={atr:.{prec+2}f}, TP={tp_str}, SL={sl_str}")
            return entry_price_estimate, final_tp, final_sl
        except Exception as e:
            self.logger.error(f"Unexpected error calculating TP/SL: {e}", exc_info=True)
            return entry_price_estimate, None, None

# --- Trading Logic Helper Functions ---
def fetch_balance(exchange: ccxt.Exchange, currency: str, logger: logging.Logger) -> Optional[Decimal]:
    """Fetches available balance for a specific currency with retries and robust parsing."""
    lg = logger
    try:
        balance_info = None
        params = {}
        account_type_to_log = "default"
        if exchange.id == 'bybit':
            params = {'type': 'CONTRACT'}
            account_type_to_log = 'CONTRACT'

        lg.debug(f"Fetching balance for {currency} (Account: {account_type_to_log})...")
        balance_info = safe_api_call(exchange.fetch_balance, lg, params=params)

        if not balance_info:
             lg.error(f"Failed to fetch balance info for {currency} after retries.")
             lg.debug("Attempting balance fetch with default parameters as fallback...")
             balance_info = safe_api_call(exchange.fetch_balance, lg)
             if not balance_info:
                  lg.error(f"Fallback balance fetch also failed for {currency}.")
                  return None

        # --- Parse the balance_info ---
        free_balance = None

        # 1. Standard CCXT: balance[currency]['free']
        if currency in balance_info and balance_info[currency].get('free') is not None:
            free_balance = balance_info[currency]['free']
            lg.debug(f"Found balance via standard ['{currency}']['free']: {free_balance}")

        # 2. Bybit V5 Nested: info.result.list[].coin[].availableToWithdraw / availableBalance
        elif not free_balance and exchange.id == 'bybit' and 'info' in balance_info and 'result' in balance_info['info'] and isinstance(balance_info['info']['result'].get('list'), list):
            for account in balance_info['info']['result']['list']:
                if isinstance(account.get('coin'), list):
                    for coin_data in account['coin']:
                        if coin_data.get('coin') == currency:
                            free = coin_data.get('availableToWithdraw') or coin_data.get('availableBalance') or coin_data.get('walletBalance')
                            if free is not None:
                                free_balance = free
                                lg.debug(f"Found balance via Bybit V5 nested ['available...']: {free_balance}")
                                break
                    if free_balance is not None: break
            if free_balance is None:
                lg.warning(f"{currency} balance details not found within Bybit V5 'info.result.list[].coin[]'.")

        # 3. Fallback: Top-level 'free' dictionary (less common)
        elif not free_balance and 'free' in balance_info and currency in balance_info['free'] and balance_info['free'][currency] is not None:
             free_balance = balance_info['free'][currency]
             lg.debug(f"Found balance via top-level 'free' dict: {free_balance}")

        # 4. Final Fallback: Use 'total' if 'free' is unavailable (use with caution)
        if free_balance is None:
             total_balance = balance_info.get(currency, {}).get('total')
             if total_balance is not None:
                  lg.warning(f"{NEON_YELLOW}Using 'total' balance ({total_balance}) as fallback for available {currency}. This might include collateral.{RESET}")
                  free_balance = total_balance
             else:
                  lg.error(f"{NEON_RED}Could not determine any balance ('free' or 'total') for {currency}.{RESET}")
                  lg.debug(f"Full balance_info structure: {json.dumps(balance_info, indent=2)}")
                  return None # No balance found

        # Convert the found balance to Decimal
        try:
            final_balance = Decimal(str(free_balance))
            if final_balance < 0:
                 lg.error(f"Parsed balance for {currency} is negative ({final_balance}). Treating as zero.")
                 final_balance = Decimal('0')
            lg.info(f"Available {currency} balance: {final_balance:.4f}")
            return final_balance
        except (ValueError, TypeError, InvalidOperation) as e:
            lg.error(f"Failed to convert balance string '{free_balance}' to Decimal for {currency}: {e}")
            return None

    except Exception as e:
        lg.error(f"{NEON_RED}Error fetching balance for {currency}: {e}{RESET}", exc_info=False)
        return None


def get_market_info(exchange: ccxt.Exchange, symbol: str, logger: logging.Logger) -> Optional[Dict]:
    """Gets market information with retries for loading."""
    lg = logger
    try:
        # Ensure markets are loaded, reload if necessary with retries
        if not exchange.markets or symbol not in exchange.markets:
             lg.info(f"Market info for {symbol} not loaded or symbol not found, attempting to load/reload markets...")
             try:
                 safe_api_call(exchange.load_markets, lg, reload=True)
             except Exception as load_err:
                  lg.error(f"{NEON_RED}Failed to load/reload markets after retries: {load_err}{RESET}")
                  return None # Cannot proceed without markets

        if symbol not in exchange.markets:
             lg.error(f"{NEON_RED}Market {symbol} still not found after reloading.{RESET}")
             if symbol == "BTC/USDT": lg.warning(f"{NEON_YELLOW}Hint: For Bybit linear perpetual, try '{symbol}:USDT'{RESET}")
             return None

        market = exchange.market(symbol)
        if market:
            # Add custom flags for convenience
            market['is_contract'] = market.get('contract', False) or market.get('type') in ['swap', 'future']
            market['is_linear'] = market.get('linear', False)
            market['is_inverse'] = market.get('inverse', False)
            # Log key details
            lg.debug(f"Market Info ({symbol}): ID={market.get('id')}, Base={market.get('base')}, Quote={market.get('quote')}, "
                     f"Type={market.get('type')}, Contract={market['is_contract']}, Linear={market['is_linear']}, Inverse={market['is_inverse']}")
            return market
        else: lg.error(f"{NEON_RED}Market dict not found for validated symbol {symbol}.{RESET}"); return None
    except ccxt.BadSymbol as e: lg.error(f"{NEON_RED}Invalid symbol '{symbol}': {e}{RESET}"); return None
    except Exception as e: lg.error(f"{NEON_RED}Unexpected error getting market info: {e}{RESET}", exc_info=True); return None


def calculate_position_size(
    balance: Decimal,
    risk_per_trade: float,
    initial_stop_loss_price: Decimal,
    entry_price: Decimal,
    market_info: Dict,
    exchange: ccxt.Exchange,
    logger: Optional[logging.Logger] = None
) -> Optional[Decimal]:
    """Calculates position size based on risk, SL, balance, and market constraints."""
    lg = logger or logging.getLogger(__name__)
    symbol = market_info.get('symbol', 'UNKNOWN')
    quote_currency = market_info.get('quote', config.get("quote_currency", "USDT"))
    base_currency = market_info.get('base', 'BASE')
    is_contract = market_info.get('is_contract', False)
    is_inverse = market_info.get('is_inverse', False)
    size_unit = "Contracts" if is_contract else base_currency

    # --- Input Validation ---
    if not isinstance(balance, Decimal) or not balance.is_finite() or balance <= 0:
        lg.error(f"Size Calc Fail ({symbol}): Invalid balance ({balance}).")
        return None
    if not (0 < risk_per_trade < 1):
        lg.error(f"Size Calc Fail ({symbol}): Invalid risk_per_trade ({risk_per_trade}).")
        return None
    if not isinstance(initial_stop_loss_price, Decimal) or not initial_stop_loss_price.is_finite() or initial_stop_loss_price <= 0:
        lg.error(f"Size Calc Fail ({symbol}): Invalid initial_stop_loss_price ({initial_stop_loss_price}).")
        return None
    if not isinstance(entry_price, Decimal) or not entry_price.is_finite() or entry_price <= 0:
        lg.error(f"Size Calc Fail ({symbol}): Invalid entry_price ({entry_price}).")
        return None
    if initial_stop_loss_price == entry_price:
        lg.error(f"Size Calc Fail ({symbol}): SL price equals entry price.")
        return None
    if 'limits' not in market_info or 'precision' not in market_info:
        lg.error(f"Size Calc Fail ({symbol}): Market info missing 'limits' or 'precision'.")
        return None
    if is_inverse:
        lg.error(f"{NEON_RED}Inverse contract sizing not implemented. Aborting sizing for {symbol}.{RESET}")
        return None

    try:
        risk_amount_quote = balance * Decimal(str(risk_per_trade))
        sl_distance_per_unit = abs(entry_price - initial_stop_loss_price)
        if sl_distance_per_unit <= 0:
            lg.error(f"Size Calc Fail ({symbol}): SL distance zero/negative.")
            return None

        contract_size_str = market_info.get('contractSize', '1')
        try:
            contract_size = Decimal(str(contract_size_str))
            if not contract_size.is_finite() or contract_size <= 0: raise ValueError("Invalid contract size")
        except (ValueError, TypeError, InvalidOperation):
            lg.warning(f"Invalid contract size '{contract_size_str}', using 1."); contract_size = Decimal('1')

        # --- Calculate Initial Size (Linear/Spot) ---
        risk_per_contract_quote = sl_distance_per_unit * contract_size
        if not risk_per_contract_quote.is_finite() or risk_per_contract_quote <= 0:
             lg.error(f"Size Calc Fail ({symbol}): Risk per contract zero/negative/NaN.")
             return None

        calculated_size = risk_amount_quote / risk_per_contract_quote

        if not calculated_size.is_finite() or calculated_size <= 0:
            lg.error(f"Initial size calc resulted in zero/negative/NaN: {calculated_size}.")
            return None

        lg.info(f"Position Sizing ({symbol}): Balance={balance:.2f}, Risk={risk_per_trade:.2%}, RiskAmt={risk_amount_quote:.4f} {quote_currency}")
        lg.info(f"  Entry={entry_price}, SL={initial_stop_loss_price}, SL Dist={sl_distance_per_unit}")
        lg.info(f"  ContractSize={contract_size}, Initial Calc. Size = {calculated_size:.8f} {size_unit}")

        # --- Apply Market Limits and Precision ---
        analyzer = TradingAnalyzer(pd.DataFrame(), lg, config, market_info) # Temp instance
        min_amount = Decimal(str(market_info.get('limits', {}).get('amount', {}).get('min', '0')))
        max_amount = Decimal(str(market_info.get('limits', {}).get('amount', {}).get('max', 'inf')))
        min_cost = Decimal(str(market_info.get('limits', {}).get('cost', {}).get('min', '0')))
        max_cost = Decimal(str(market_info.get('limits', {}).get('cost', {}).get('max', 'inf')))
        amount_step = analyzer.get_min_amount_step()

        adjusted_size = calculated_size
        # 1. Clamp by Amount Limits
        original_size = adjusted_size
        if adjusted_size < min_amount: adjusted_size = min_amount
        if adjusted_size > max_amount: adjusted_size = max_amount
        if adjusted_size != original_size:
             lg.warning(f"{NEON_YELLOW}Size adjusted by Amount Limits: {original_size:.8f} -> {adjusted_size:.8f} {size_unit}{RESET}")

        # 2. Apply Amount Step Size (Round DOWN)
        if amount_step.is_finite() and amount_step > 0:
            original_size = adjusted_size
            adjusted_size = (adjusted_size // amount_step) * amount_step
            if adjusted_size != original_size:
                 lg.info(f"Applied Amount Step Size ({amount_step}): {original_size:.8f} -> {adjusted_size:.8f}")
        elif not amount_step.is_finite():
             lg.warning(f"Amount step size is not finite ({amount_step}). Skipping step adjustment.")
        else: # Step is zero or negative
             lg.warning(f"Amount step size is zero/negative ({amount_step}). Skipping step adjustment.")

        # 3. Re-check Min Amount & Cost Limits with final adjusted size
        if adjusted_size < min_amount:
             lg.error(f"{NEON_RED}Final size {adjusted_size} < Min Amount {min_amount} after step adjustment. Cannot order.{RESET}")
             return None
        # Cost = Size * Price * ContractValue (for linear/spot)
        estimated_cost = adjusted_size * entry_price * contract_size
        lg.debug(f"  Cost Check: Final Size={adjusted_size:.8f}, Est. Cost={estimated_cost:.4f} (Min:{min_cost}, Max:{max_cost})")
        if min_cost.is_finite() and min_cost > 0 and estimated_cost < min_cost:
             lg.error(f"{NEON_RED}Est. cost {estimated_cost:.4f} < Min Cost {min_cost}. Cannot order.{RESET}")
             return None
        if max_cost.is_finite() and max_cost > 0 and estimated_cost > max_cost:
             lg.error(f"{NEON_RED}Est. cost {estimated_cost:.4f} > Max Cost {max_cost}. Cannot order.{RESET}")
             return None

        # --- Final Validation ---
        final_size = adjusted_size
        if not final_size.is_finite() or final_size <= 0:
             lg.error(f"{NEON_RED}Final size zero/negative/NaN ({final_size}). Aborted.{RESET}")
             return None

        lg.info(f"{NEON_GREEN}Final calculated position size for {symbol}: {final_size} {size_unit}{RESET}")
        return final_size
    except Exception as e:
        lg.error(f"{NEON_RED}Unexpected error calculating position size: {e}{RESET}", exc_info=True)
        return None


def get_open_position(exchange: ccxt.Exchange, symbol: str, logger: logging.Logger) -> Optional[Dict]:
    """Checks for an open position using fetch_positions with robust parsing for Bybit V5."""
    lg = logger
    if not exchange.has.get('fetchPositions'):
        lg.warning(f"Exchange {exchange.id} does not support fetchPositions. Cannot check position status.")
        return None

    try:
        lg.debug(f"Fetching positions for symbol: {symbol}")
        params = {}
        market = exchange.market(symbol) # Needed for market ID if fetching single
        if not market: raise ValueError(f"Market info not loaded for {symbol}")

        if exchange.id == 'bybit':
            params = {'symbol': market['id']} # Use market ID for Bybit V5 fetch

        # Use safe_api_call for the fetch operation
        positions: List[Dict] = safe_api_call(exchange.fetch_positions, lg, symbols=[symbol], params=params)

        if positions is None: # safe_api_call failed after retries
             lg.error("Position fetch failed after retries.")
             # Optional Fallback: Try fetching all positions
             lg.debug("Attempting to fetch ALL positions as fallback...")
             all_positions = safe_api_call(exchange.fetch_positions, lg)
             if all_positions:
                  positions = [p for p in all_positions if p.get('symbol') == symbol]
                  lg.debug(f"Fetched {len(all_positions)} total positions, found {len(positions)} matching {symbol}.")
             else:
                  lg.error("Fallback fetch of all positions also failed.")
                  return None

        # --- Process the fetched positions list ---
        active_position = None
        size_threshold = Decimal('1e-9') # Threshold for considering size non-zero

        for pos in positions:
            pos_symbol = pos.get('symbol')
            if pos_symbol != symbol: continue

            pos_size_str = None
            if pos.get('contracts') is not None: pos_size_str = str(pos['contracts'])
            elif isinstance(pos.get('info'), dict) and pos['info'].get('size') is not None:
                 pos_size_str = str(pos['info']['size']) # Bybit V5

            if pos_size_str is None: continue

            try:
                position_size = Decimal(pos_size_str)
                if abs(position_size) > size_threshold:
                    active_position = pos
                    lg.debug(f"Found potential active position entry for {symbol} with size {position_size}.")
                    break # Assume one position per symbol/side/mode
            except (ValueError, TypeError, InvalidOperation) as parse_err:
                lg.warning(f"Could not parse position size '{pos_size_str}': {parse_err}")

        # --- Post-Process the found active position ---
        if active_position:
            try:
                analyzer = TradingAnalyzer(pd.DataFrame(), lg, config, market) # Temp instance
                price_prec = analyzer.get_price_precision()
                amt_prec = analyzer.get_amount_precision_places()

                # Standardize Size (always Decimal)
                size_decimal = Decimal(str(active_position.get('contracts', active_position.get('info',{}).get('size', '0'))))
                active_position['contractsDecimal'] = size_decimal

                # Standardize Side
                side = active_position.get('side')
                if side not in ['long', 'short']:
                    if size_decimal > size_threshold: side = 'long'
                    elif size_decimal < -size_threshold: side = 'short'
                    else: lg.warning(f"Pos size {size_decimal} near zero, cannot determine side."); return None
                    active_position['side'] = side
                    lg.debug(f"Inferred position side as '{side}'.")

                # Standardize Entry Price (Decimal)
                entry_price_str = active_position.get('entryPrice') or active_position.get('info', {}).get('avgPrice')
                active_position['entryPriceDecimal'] = Decimal(str(entry_price_str)) if entry_price_str else None

                # Standardize Liq Price (Decimal)
                liq_price_str = active_position.get('liquidationPrice') or active_position.get('info', {}).get('liqPrice')
                active_position['liquidationPriceDecimal'] = Decimal(str(liq_price_str)) if liq_price_str else None

                # Standardize PNL (Decimal)
                pnl_str = active_position.get('unrealizedPnl') or active_position.get('info', {}).get('unrealisedPnl')
                active_position['unrealizedPnlDecimal'] = Decimal(str(pnl_str)) if pnl_str else None

                # Extract SL/TP/TSL from 'info' (Bybit V5) and store as Decimal
                info_dict = active_position.get('info', {})
                sl_str = info_dict.get('stopLoss')
                tp_str = info_dict.get('takeProfit')
                tsl_dist_str = info_dict.get('trailingStop') # Distance value
                tsl_act_str = info_dict.get('activePrice') # Activation price

                active_position['stopLossPriceDecimal'] = Decimal(str(sl_str)) if sl_str and str(sl_str).replace('.','',1).isdigit() and Decimal(sl_str) != 0 else None
                active_position['takeProfitPriceDecimal'] = Decimal(str(tp_str)) if tp_str and str(tp_str).replace('.','',1).isdigit() and Decimal(tp_str) != 0 else None
                active_position['trailingStopLossValueDecimal'] = Decimal(str(tsl_dist_str)) if tsl_dist_str and str(tsl_dist_str).replace('.','',1).isdigit() and Decimal(tsl_dist_str) != 0 else None
                active_position['trailingStopActivationPriceDecimal'] = Decimal(str(tsl_act_str)) if tsl_act_str and str(tsl_act_str).replace('.','',1).isdigit() and Decimal(tsl_act_str) != 0 else None

                # Get timestamp (prefer updatedTime from info for Bybit V5)
                timestamp_ms = info_dict.get('updatedTime') or active_position.get('timestamp')
                active_position['timestamp_ms'] = int(timestamp_ms) if timestamp_ms else None
                timestamp_dt_str = datetime.fromtimestamp(timestamp_ms / 1000, tz=timezone.utc).strftime('%Y-%m-%d %H:%M:%S %Z') if timestamp_ms else "N/A"

                # Log Formatted Info
                entry_fmt = f"{active_position['entryPriceDecimal']:.{price_prec}f}" if active_position['entryPriceDecimal'] else 'N/A'
                size_fmt = f"{abs(size_decimal):.{amt_prec}f}"
                liq_fmt = f"{active_position['liquidationPriceDecimal']:.{price_prec}f}" if active_position['liquidationPriceDecimal'] else 'N/A'
                lev_str = info_dict.get('leverage', active_position.get('leverage'))
                lev_fmt = f"{Decimal(str(lev_str)):.1f}x" if lev_str else 'N/A'
                pnl_fmt = f"{active_position['unrealizedPnlDecimal']:.{price_prec}f}" if active_position['unrealizedPnlDecimal'] else 'N/A'
                sl_fmt = f"{active_position['stopLossPriceDecimal']:.{price_prec}f}" if active_position['stopLossPriceDecimal'] else 'N/A'
                tp_fmt = f"{active_position['takeProfitPriceDecimal']:.{price_prec}f}" if active_position['takeProfitPriceDecimal'] else 'N/A'
                tsl_d_fmt = f"{active_position['trailingStopLossValueDecimal']:.{price_prec}f}" if active_position['trailingStopLossValueDecimal'] else 'N/A'
                tsl_a_fmt = f"{active_position['trailingStopActivationPriceDecimal']:.{price_prec}f}" if active_position['trailingStopActivationPriceDecimal'] else 'N/A'

                logger.info(f"{NEON_GREEN}Active {side.upper()} position found ({symbol}):{RESET} "
                            f"Size={size_fmt}, Entry={entry_fmt}, Liq={liq_fmt}, Lev={lev_fmt}, PnL={pnl_fmt}, "
                            f"SL={sl_fmt}, TP={tp_fmt}, TSL(Dist/Act): {tsl_d_fmt}/{tsl_a_fmt} (Updated: {timestamp_dt_str})")
                logger.debug(f"Full processed position details: {active_position}")
                return active_position

            except (ValueError, TypeError, InvalidOperation, KeyError) as proc_err:
                 lg.error(f"Error processing active position details for {symbol}: {proc_err}", exc_info=True)
                 lg.debug(f"Problematic raw position data: {active_position}")
                 return None

        else:
            logger.info(f"No active open position found for {symbol}.")
            return None

    except ccxt.ArgumentsRequired as e:
         # Handle cases where fetching single symbol isn't supported by trying fetch all
         lg.warning(f"Fetching single position failed ({e}). Trying to fetch all positions...")
         try:
             all_positions = safe_api_call(exchange.fetch_positions, lg) # Fetch all
             if all_positions:
                  positions = [p for p in all_positions if p.get('symbol') == symbol]
                  lg.debug(f"Fetched {len(all_positions)} total positions, found {len(positions)} matching {symbol}.")
                  # Now re-run the processing logic (This code block is duplicated, consider refactoring)
                  active_position = None; size_threshold = Decimal('1e-9')
                  for pos in positions:
                      pos_symbol = pos.get('symbol')
                      if pos_symbol != symbol: continue
                      pos_size_str = None
                      if pos.get('contracts') is not None: pos_size_str = str(pos['contracts'])
                      elif isinstance(pos.get('info'), dict) and pos['info'].get('size') is not None: pos_size_str = str(pos['info']['size'])
                      if pos_size_str is None: continue
                      try:
                          position_size = Decimal(pos_size_str)
                          if abs(position_size) > size_threshold: active_position = pos; break
                      except (ValueError, TypeError, InvalidOperation): continue
                  if active_position:
                      # Repeat the post-processing logic here... (Refactor opportunity)
                      try:
                           # ... (Duplicate of post-processing block above) ...
                           return active_position # Return processed position
                      except Exception as proc_err_fallback:
                           lg.error(f"Error processing fallback position details for {symbol}: {proc_err_fallback}", exc_info=True)
                           return None
                  else: logger.info(f"No active open position found for {symbol} in fallback fetch."); return None
             else: lg.error("Fallback fetch of all positions also failed."); return None
         except Exception as fallback_e:
              lg.error(f"Error during fallback fetch of all positions: {fallback_e}", exc_info=True)
              return None
    except Exception as e:
        lg.error(f"{NEON_RED}Unexpected error fetching/processing positions for {symbol}: {e}{RESET}", exc_info=True)
        return None


def set_leverage_ccxt(exchange: ccxt.Exchange, symbol: str, leverage: int, market_info: Dict, logger: logging.Logger) -> bool:
    """Sets leverage using CCXT, handling Bybit V5 specifics."""
    lg = logger
    if not market_info.get('is_contract', False):
        lg.debug(f"Leverage setting skipped for {symbol} (Not a contract market).")
        return True # No action needed
    if not isinstance(leverage, int) or leverage <= 0:
        lg.warning(f"Leverage setting skipped: Invalid leverage value ({leverage}). Must be positive integer.")
        return False
    if not exchange.has.get('setLeverage') and not exchange.has.get('setMarginMode'):
        lg.error(f"Exchange {exchange.id} supports neither setLeverage nor setMarginMode. Cannot set leverage.")
        return False

    try:
        lg.info(f"Attempting to set leverage for {symbol} to {leverage}x...")
        params = {}
        if exchange.id == 'bybit':
            leverage_str = str(leverage) # Bybit V5 requires string leverage in params
            params = {'buyLeverage': leverage_str, 'sellLeverage': leverage_str}
            lg.debug(f"Using Bybit V5 params for set_leverage: {params}")

        response = safe_api_call(exchange.set_leverage, lg, leverage, symbol, params)
        lg.debug(f"Set leverage raw response for {symbol}: {response}")

        lg.info(f"{NEON_GREEN}Leverage for {symbol} set/requested to {leverage}x (Check position details for confirmation).{RESET}")
        return True

    except ccxt.ExchangeError as e:
        err_str = str(e).lower(); code = getattr(e, 'code', None)
        lg.error(f"{NEON_RED}Exchange error setting leverage for {symbol}: {e} (Code: {code}){RESET}")
        if exchange.id == 'bybit':
            if code == 110045 or "leverage not modified" in err_str:
                 lg.info(f"{NEON_YELLOW}Leverage for {symbol} likely already set to {leverage}x (Exchange: {e}).{RESET}")
                 return True # Treat as success
            elif code in [110028, 110009, 110055] or "margin mode" in err_str:
                  lg.error(f"{NEON_YELLOW} >> Hint: Check Margin Mode (Isolated/Cross) setting.{RESET}")
            elif code == 110044 or "risk limit" in err_str:
                  lg.error(f"{NEON_YELLOW} >> Hint: Leverage {leverage}x may exceed Risk Limit tier.{RESET}")
            elif code == 110013 or "parameter error" in err_str:
                  lg.error(f"{NEON_YELLOW} >> Hint: Leverage value {leverage}x might be invalid/out of range.{RESET}")
    except Exception as e:
        lg.error(f"{NEON_RED}Failed to set leverage for {symbol} after retries or due to unexpected error: {e}{RESET}", exc_info=False)

    return False


def place_trade(
    exchange: ccxt.Exchange,
    symbol: str,
    trade_signal: str, # "BUY" or "SELL"
    position_size: Decimal,
    market_info: Dict,
    logger: Optional[logging.Logger] = None,
    order_type: str = 'market',
    limit_price: Optional[Decimal] = None,
    reduce_only: bool = False,
    params: Optional[Dict] = None # For extra exchange-specific params
) -> Optional[Dict]:
    """Places an order (market or limit) using CCXT with retries and enhanced logging."""
    lg = logger or logging.getLogger(__name__)
    side = 'buy' if trade_signal == "BUY" else 'sell'
    is_contract = market_info.get('is_contract', False)
    size_unit = "Contracts" if is_contract else market_info.get('base', '')
    action_desc = "Close/Reduce" if reduce_only else "Open/Increase"

    # --- Validate Inputs ---
    try:
        amount_float = float(position_size) # CCXT usually requires float
        if amount_float <= 0: raise ValueError("Position size must be positive")
    except (ValueError, TypeError) as e:
        lg.error(f"Trade Aborted ({action_desc} {side} {symbol}): Invalid size {position_size}: {e}")
        return None
    if order_type == 'limit':
         if limit_price is None or not isinstance(limit_price, Decimal) or not limit_price.is_finite() or limit_price <= 0:
             lg.error(f"Trade Aborted ({action_desc} {side} {symbol}): Limit order needs valid positive limit_price.")
             return None
         try: price_float = float(limit_price) # CCXT needs float price
         except (ValueError, TypeError): lg.error(f"Invalid limit_price format {limit_price}."); return None
    else: price_float = None

    # --- Prepare Parameters ---
    order_params = {'reduceOnly': reduce_only}
    if exchange.id == 'bybit': order_params['positionIdx'] = 0 # Assume one-way mode default
    if order_type == 'market' and reduce_only: order_params['timeInForce'] = 'IOC'
    if params: order_params = {**params, **order_params} # Ensure our settings override external

    # --- Log Order Details ---
    analyzer = TradingAnalyzer(pd.DataFrame(), lg, config, market_info) # Temp instance for precision
    amt_prec = analyzer.get_amount_precision_places()
    lg.info(f"Attempting to place {action_desc} {side.upper()} {order_type.upper()} order for {symbol}:")
    lg.info(f"  Size: {amount_float:.{amt_prec}f} {size_unit}")
    if order_type == 'limit': lg.info(f"  Limit Price: {limit_price}")
    lg.info(f"  ReduceOnly: {reduce_only}, Params: {order_params}")

    # --- Execute Order via safe_api_call ---
    try:
        order = safe_api_call(
            exchange.create_order, lg,
            symbol=symbol, type=order_type, side=side,
            amount=amount_float, price=price_float, params=order_params
        )
        if order and order.get('id'):
            lg.info(f"{NEON_GREEN}{action_desc} Order Placed Successfully!{RESET}")
            lg.info(f"  ID: {order.get('id')}, Status: {order.get('status', '?')}, Filled: {order.get('filled', 0.0)}, AvgPx: {order.get('average')}")
            lg.debug(f"Raw order response: {order}")
            return order
        else: # Includes case where safe_api_call returns None after retries
             lg.error(f"{NEON_RED}Order placement failed for {symbol}. Response: {order}{RESET}"); return None
    except ccxt.InsufficientFunds as e: lg.error(f"{NEON_RED}Insufficient funds: {e}{RESET}")
    except ccxt.InvalidOrder as e:
        lg.error(f"{NEON_RED}Invalid order params: {e}{RESET}")
        err = str(e).lower()
        if "tick size" in err: lg.error(" >> Hint: Check limit price tick size.")
        if "step size" in err: lg.error(" >> Hint: Check amount step size.")
        if "minnotional" in err or "cost" in err: lg.error(" >> Hint: Order cost below minimum?")
        if "reduce-only" in err or (getattr(e,'code',None)==110014 and exchange.id=='bybit'): lg.error(" >> Hint: Reduce-only failed (pos closed?).")
    except ccxt.ExchangeError as e: lg.error(f"{NEON_RED}Exchange error placing order: {e} (Code: {getattr(e,'code',None)}){RESET}")
    except Exception as e: lg.error(f"{NEON_RED}Failed placing {action_desc} order: {e}{RESET}", exc_info=False)

    return None


def _set_position_protection(
    exchange: ccxt.Exchange, symbol: str, market_info: Dict, position_info: Dict,
    logger: logging.Logger, stop_loss_price: Optional[Decimal] = None,
    take_profit_price: Optional[Decimal] = None, trailing_stop_distance: Optional[Decimal] = None,
    tsl_activation_price: Optional[Decimal] = None,
) -> bool:
    """Internal helper using Bybit V5 API to set SL, TP, or TSL."""
    lg = logger
    if 'bybit' not in exchange.id.lower(): lg.error("Protection via private_post only for Bybit."); return False
    if not market_info.get('is_contract'): lg.warning(f"Protection skipped ({symbol}: Not contract)."); return False
    if not position_info: lg.error(f"Cannot set protection ({symbol}): Missing position info."); return False

    pos_side = position_info.get('side'); entry_price = position_info.get('entryPriceDecimal')
    pos_idx = 0 # Default for One-Way
    try: pos_idx_val = position_info.get('info', {}).get('positionIdx'); pos_idx = int(pos_idx_val) if pos_idx_val is not None else 0
    except (ValueError, TypeError): lg.warning("Could not parse positionIdx, using default 0.")

    if pos_side not in ['long', 'short']: lg.error("Invalid position side."); return False
    if not isinstance(entry_price, Decimal) or not entry_price.is_finite() or entry_price <= 0:
        lg.error("Invalid entry price."); return False

    # --- Validate Protection Parameters ---
    has_sl = isinstance(stop_loss_price, Decimal) and stop_loss_price.is_finite() and stop_loss_price > 0
    has_tp = isinstance(take_profit_price, Decimal) and take_profit_price.is_finite() and take_profit_price > 0
    has_tsl = (isinstance(trailing_stop_distance, Decimal) and trailing_stop_distance.is_finite() and trailing_stop_distance > 0 and
               isinstance(tsl_activation_price, Decimal) and tsl_activation_price.is_finite() and tsl_activation_price > 0)

    # Check SL/TP/TSL Act relative to entry
    if has_sl and ((pos_side=='long' and stop_loss_price >= entry_price) or (pos_side=='short' and stop_loss_price <= entry_price)): lg.error(f"Invalid SL {stop_loss_price} vs Entry {entry_price}. Ignoring SL."); has_sl = False
    if has_tp and ((pos_side=='long' and take_profit_price <= entry_price) or (pos_side=='short' and take_profit_price >= entry_price)): lg.error(f"Invalid TP {take_profit_price} vs Entry {entry_price}. Ignoring TP."); has_tp = False
    if has_tsl and ((pos_side=='long' and tsl_activation_price <= entry_price) or (pos_side=='short' and tsl_activation_price >= entry_price)): lg.error(f"Invalid TSL Act {tsl_activation_price} vs Entry {entry_price}. Ignoring TSL."); has_tsl = False
    if has_sl and has_tp and stop_loss_price == take_profit_price: lg.error("SL price equals TP price. Ignoring both."); has_sl = False; has_tp = False

    if not has_sl and not has_tp and not has_tsl: lg.info(f"No valid protection params remaining for {symbol}."); return True

    # --- Prepare API Parameters ---
    category = 'linear' if market_info.get('is_linear', True) else 'inverse'
    params = {'category': category, 'symbol': market_info['id'], 'tpslMode': 'Full',
              'tpTriggerBy': 'LastPrice', 'slTriggerBy': 'LastPrice', 'positionIdx': pos_idx}
    log_parts = [f"Setting protection for {symbol} ({pos_side.upper()} PosIdx:{pos_idx}):"]

    try: # Format parameters
        analyzer = TradingAnalyzer(pd.DataFrame(), lg, config, market_info) # Temp instance
        min_tick = analyzer.get_min_tick_size()
        def fmt_p(p): return exchange.price_to_precision(symbol, float(p)) if isinstance(p,Decimal) and p.is_finite() and p>0 else None
        def fmt_d(d):
             if not (isinstance(d, Decimal) and d.is_finite() and d > 0): return None
             prec = abs(min_tick.normalize().as_tuple().exponent) if min_tick > 0 else analyzer.get_price_precision()
             fmt_str = exchange.decimal_to_precision(d, exchange.ROUND, prec, exchange.NO_PADDING)
             # Ensure distance >= min_tick
             return str(min_tick) if min_tick > 0 and Decimal(fmt_str) < min_tick else fmt_str

        # Set TSL first (overrides SL on Bybit V5)
        if has_tsl:
            tsl_d_fmt, tsl_a_fmt = fmt_d(trailing_stop_distance), fmt_p(tsl_activation_price)
            if tsl_d_fmt and tsl_a_fmt:
                params['trailingStop']=tsl_d_fmt; params['activePrice']=tsl_a_fmt
                log_parts.append(f"  TSL: Dist={tsl_d_fmt}, Act={tsl_a_fmt}"); has_sl=False # Disable fixed SL
            else: lg.error("Failed formatting TSL params."); has_tsl=False # Mark TSL failed

        if has_sl: # Only set if TSL wasn't set
            sl_fmt = fmt_p(stop_loss_price)
            if sl_fmt: params['stopLoss']=sl_fmt; log_parts.append(f"  FixSL: {sl_fmt}")
            else: lg.error("Failed formatting Fixed SL."); has_sl=False # Mark SL failed

        if has_tp:
            tp_fmt = fmt_p(take_profit_price)
            if tp_fmt: params['takeProfit']=tp_fmt; log_parts.append(f"  FixTP: {tp_fmt}")
            else: lg.error("Failed formatting Fixed TP."); has_tp=False # Mark TP failed

    except Exception as fmt_err: lg.error(f"Error formatting protection params: {fmt_err}", exc_info=True); return False

    # Check if any parameters were actually added
    if not params.get('stopLoss') and not params.get('takeProfit') and not params.get('trailingStop'):
        lg.warning(f"No valid protection parameters formatted for {symbol}. No API call."); return False

    # --- Make API Call ---
    lg.info("\n".join(log_parts)); lg.debug(f"  API Call: private_post('/v5/position/set-trading-stop', {params})")
    try:
        response = safe_api_call(exchange.private_post, lg, '/v5/position/set-trading-stop', params)
        lg.debug(f"Set protection response: {response}")
        code=response.get('retCode'); msg=response.get('retMsg','Err'); ext=response.get('retExtInfo',{})
        if code == 0:
            if "not modified" in msg.lower(): lg.info(f"{NEON_YELLOW}Protection already set or partially modified ({symbol}). Msg: {msg}{RESET}")
            else: lg.info(f"{NEON_GREEN}Protection set/updated successfully ({symbol}).{RESET}")
            return True
        else:
            lg.error(f"{NEON_RED}Failed set protection ({symbol}): {msg} (Code:{code}) Ext:{ext}{RESET}")
            if code == 110013: lg.error(" >> Hint(110013): Param Error? Check prices vs entry/tick, TSL values.")
            elif code == 110036: lg.error(f" >> Hint(110036): TSL Act Price '{params.get('activePrice')}' invalid?")
            elif code == 110086: lg.error(" >> Hint(110086): SL price == TP price.")
            elif code == 110025: lg.error(" >> Hint(110025): Position closed or posIdx mismatch?")
            return False
    except Exception as e: lg.error(f"Failed protection API call: {e}", exc_info=False); return False


def set_trailing_stop_loss(
    exchange: ccxt.Exchange, symbol: str, market_info: Dict, position_info: Dict,
    config: Dict[str, Any], logger: logging.Logger, take_profit_price: Optional[Decimal] = None
) -> bool:
    """Calculates and sets Exchange-Native Trailing Stop Loss."""
    lg = logger
    if not config.get("enable_trailing_stop"): lg.debug(f"TSL disabled ({symbol})."); return False

    try: # Validate inputs
        cb_rate = Decimal(str(config["trailing_stop_callback_rate"]))
        act_pct = Decimal(str(config["trailing_stop_activation_percentage"]))
        entry = position_info['entryPriceDecimal']; side = position_info['side']
        if cb_rate <= 0: raise ValueError("callback_rate must be > 0")
        if act_pct < 0: raise ValueError("activation_percentage must be >= 0")
        if not isinstance(entry, Decimal) or not entry.is_finite() or entry <= 0: raise ValueError("Invalid entry price")
        if side not in ['long','short']: raise ValueError("Invalid side")
    except (KeyError, ValueError, TypeError, InvalidOperation) as e:
        lg.error(f"Invalid TSL config or pos info ({symbol}): {e}.", exc_info=True); return False

    try: # Calculate parameters
        analyzer = TradingAnalyzer(pd.DataFrame(), lg, config, market_info) # Temp instance
        prec = analyzer.get_price_precision(); rnd = Decimal(f'1e-{prec}'); tick = analyzer.get_min_tick_size()

        act_off = entry * act_pct; act_price = None
        if side == 'long':
             raw_activation = entry + act_off
             act_price = raw_activation.quantize(rnd, rounding=ROUND_UP)
             if act_price <= entry: act_price = (entry+tick).quantize(rnd,rounding=ROUND_UP) # Ensure > entry
        else: # short
             raw_activation = entry - act_off
             act_price = raw_activation.quantize(rnd, rounding=ROUND_DOWN)
             if act_price >= entry: act_price = (entry-tick).quantize(rnd,rounding=ROUND_DOWN) # Ensure < entry

        if not act_price.is_finite() or act_price <= 0:
            lg.error(f"Invalid TSL Act price calc ({act_price})."); return False

        dist_raw = act_price * cb_rate; dist = None
        if tick > 0:
             dist = (dist_raw / tick).quantize(Decimal('1'), rounding=ROUND_UP) * tick # Round up to nearest tick
             dist = max(dist, tick) # Ensure at least one tick
        else: dist = dist_raw.quantize(rnd, rounding=ROUND_UP) # Fallback rounding

        if not dist.is_finite() or dist <= 0:
            lg.error(f"Invalid TSL Dist calc ({dist})."); return False

        lg.info(f"Calc TSL Params ({symbol} {side.upper()}): ActPrice={act_price:.{prec}f}, Dist={dist:.{prec}f}")
        if isinstance(take_profit_price, Decimal) and take_profit_price.is_finite() and take_profit_price > 0:
            lg.info(f"  Also setting TP: {take_profit_price:.{prec}f}")

        # Set protection via helper
        return _set_position_protection(exchange, symbol, market_info, position_info, lg,
                                        stop_loss_price=None, # TSL overrides fixed SL
                                        take_profit_price=take_profit_price if (isinstance(take_profit_price, Decimal) and take_profit_price.is_finite() and take_profit_price > 0) else None,
                                        trailing_stop_distance=dist,
                                        tsl_activation_price=act_price)
    except Exception as e: lg.error(f"Error calculating/setting TSL: {e}", exc_info=True); return False


# --- Main Analysis and Trading Loop ---
def analyze_and_trade_symbol(exchange: ccxt.Exchange, symbol: str, config: Dict[str, Any], logger: logging.Logger) -> None:
    """Performs one cycle of analysis and trading logic for a single symbol."""
    lg = logger
    lg.info(f"---== Analyzing {symbol} ({config['interval']}) Cycle Start ==---")
    cycle_start_time = time.monotonic()

    try:
        # --- Get Market Info (Critical) ---
        market_info = get_market_info(exchange, symbol, lg)
        if not market_info: raise ValueError(f"Fatal: Failed to get market info for {symbol}.")

        # --- Fetch Data ---
        ccxt_interval = CCXT_INTERVAL_MAP.get(config["interval"])
        if not ccxt_interval: raise ValueError(f"Invalid interval '{config['interval']}'.")
        klines_df = fetch_klines_ccxt(exchange, symbol, ccxt_interval, limit=500, logger=lg)
        if klines_df.empty or len(klines_df) < 50: raise ValueError(f"Insufficient kline data ({len(klines_df)}).")

        current_price = fetch_current_price_ccxt(exchange, symbol, lg)
        if current_price is None: # Fallback to last close
             lg.warning("Using last close from klines as current price.")
             try:
                 last_close = klines_df['close'].iloc[-1] # Assumes klines_df uses Decimal
                 if not isinstance(last_close, Decimal) or not last_close.is_finite():
                     raise ValueError("Last close is not a valid Decimal.")
                 current_price = last_close
                 if current_price <= 0: raise ValueError("Last close price non-positive.")
             except (IndexError, KeyError, ValueError, TypeError, InvalidOperation) as e:
                 raise ValueError(f"Failed to get valid last close price: {e}")

        # Fetch order book if needed for scoring
        orderbook_data = None
        active_weights = config.get("weight_sets", {}).get(config.get("active_weight_set", "default"), {})
        if config.get("indicators",{}).get("orderbook", False) and float(active_weights.get("orderbook", 0)) != 0:
            orderbook_data = fetch_orderbook_ccxt(exchange, symbol, int(config["orderbook_limit"]), lg) # Ensure limit is int
            if not orderbook_data: lg.warning(f"Failed orderbook fetch for {symbol}. Proceeding without.")

        # --- Analyze Data & Generate Signal ---
        analyzer = TradingAnalyzer(klines_df.copy(), lg, config, market_info)
        if not analyzer.indicator_values: raise ValueError("Indicator calculation failed.")
        signal = analyzer.generate_trading_signal(current_price, orderbook_data)

        # --- Calculate Potential TP/SL & Log Summary ---
        _, tp_calc, sl_calc = analyzer.calculate_entry_tp_sl(current_price, signal)
        price_prec = analyzer.get_price_precision(); current_atr = analyzer.indicator_values.get("ATR")
        lg.info(f"Current Price: {current_price:.{price_prec}f}")
        lg.info(f"ATR: {current_atr:.{price_prec+2}f}" if isinstance(current_atr, Decimal) else 'ATR: N/A')
        lg.info(f"Calc Initial SL (sizing): {sl_calc or 'N/A'}, TP (target): {tp_calc or 'N/A'}")
        lg.info(f"Mgmt: TSL={'On' if config['enable_trailing_stop'] else 'Off'}, BE={'On' if config['enable_break_even'] else 'Off'}, TimeExit={config.get('time_based_exit_minutes') or 'Off'}")

        # --- Trading Execution Logic ---
        if not config.get("enable_trading"):
            lg.debug("Trading disabled. Cycle complete."); return

        open_position = get_open_position(exchange, symbol, lg)

        # --- Scenario 1: No Open Position ---
        if open_position is None:
            if signal in ["BUY", "SELL"]:
                lg.info(f"*** {signal} Signal & No Position: Initiating Trade Sequence ***")
                balance = fetch_balance(exchange, config["quote_currency"], lg)
                if balance is None or balance <= 0: raise ValueError("Balance fetch failed or zero/negative.")
                if sl_calc is None: raise ValueError("Initial SL calculation failed (required for sizing).")

                if market_info.get('is_contract') and int(config.get("leverage", 0)) > 0:
                    if not set_leverage_ccxt(exchange, symbol, int(config["leverage"]), market_info, lg):
                        raise ValueError("Failed to set leverage.")

                pos_size = calculate_position_size(balance, config["risk_per_trade"], sl_calc, current_price, market_info, exchange, lg)
                if pos_size is None or pos_size <= 0: raise ValueError(f"Position size calculation failed ({pos_size}).")

                # --- Place Order (Market or Limit) ---
                entry_type = config.get("entry_order_type", "market"); limit_px = None
                if entry_type == "limit":
                     try:
                         offset = Decimal(str(config[f"limit_order_offset_{signal.lower()}"]))
                         rnd_f = Decimal(f'1e-{price_prec}')
                         raw_px = current_price * (1 - offset if signal=='BUY' else 1 + offset)
                         limit_px = raw_px.quantize(rnd_f, rounding=ROUND_DOWN if signal=='BUY' else ROUND_UP)
                         if not limit_px.is_finite() or limit_px <= 0: raise ValueError("Limit price non-positive/finite")
                         lg.info(f"Calc Limit Entry for {signal}: {limit_px}")
                     except (KeyError, ValueError, InvalidOperation) as e:
                          lg.error(f"Limit price calc failed ({e}). Switching to Market."); entry_type="market"; limit_px=None

                trade_order = place_trade(exchange, symbol, signal, pos_size, market_info, lg, entry_type, limit_px)

                # --- Post-Order Handling ---
                if trade_order and trade_order.get('id'):
                    order_id, status = trade_order['id'], trade_order.get('status')
                    if status == 'closed' or entry_type == 'market':
                        delay = config["position_confirm_delay_seconds"] if entry_type=='market' else 2
                        lg.info(f"Order {order_id} placed/filled. Waiting {delay}s for confirmation...")
                        time.sleep(delay)
                        confirmed_pos = get_open_position(exchange, symbol, lg)
                        if confirmed_pos:
                            lg.info(f"{NEON_GREEN}Position Confirmed!{RESET}")
                            try:
                                entry_act = confirmed_pos.get('entryPriceDecimal') or current_price # Use actual or estimate
                                lg.info(f"Actual Entry ~ {entry_act:.{price_prec}f}")
                                _, tp_final, sl_final = analyzer.calculate_entry_tp_sl(entry_act, signal) # Recalculate based on actual entry
                                protection_ok = False
                                if config["enable_trailing_stop"]:
                                     lg.info(f"Setting TSL (TP target: {tp_final})...")
                                     protection_ok = set_trailing_stop_loss(exchange, symbol, market_info, confirmed_pos, config, lg, tp_final)
                                elif sl_final or tp_final:
                                     lg.info(f"Setting Fixed SL ({sl_final}) / TP ({tp_final})...")
                                     protection_ok = _set_position_protection(exchange, symbol, market_info, confirmed_pos, lg, sl_final, tp_final)
                                else: lg.warning("No valid protection calculated (TSL disabled or calc failed).")

                                if protection_ok: lg.info(f"{NEON_GREEN}=== TRADE ENTRY & PROTECTION COMPLETE ({symbol} {signal}) ===")
                                else: lg.error(f"{NEON_RED}=== TRADE PLACED BUT PROTECTION FAILED ({symbol} {signal}) ===\n{NEON_YELLOW}>>> MANUAL MONITORING REQUIRED! <<<")
                            except Exception as post_err:
                                 lg.error(f"Error setting protection: {post_err}", exc_info=True); lg.warning(f"{NEON_YELLOW}Position open, manual check needed!{RESET}")
                        else: lg.error(f"{NEON_RED}Order {order_id} placed/filled BUT POSITION NOT CONFIRMED! Manual check!{RESET}")
                    elif status == 'open' and entry_type == 'limit':
                         lg.info(f"Limit order {order_id} OPEN. Will check status next cycle.")
                    else: lg.error(f"Order {order_id} status: {status}. Trade did not open as expected.")
                else: lg.error(f"{NEON_RED}=== TRADE EXECUTION FAILED. Order placement error. ===")
            else: lg.info("Signal HOLD, no position. No action.")

        # --- Scenario 2: Existing Open Position ---
        else:
            pos_side = open_position['side']; pos_size = open_position['contractsDecimal']
            entry_price = open_position['entryPriceDecimal']; pos_ts_ms = open_position['timestamp_ms']
            lg.info(f"Managing existing {pos_side.upper()} position. Size: {pos_size}, Entry: {entry_price}")

            # --- Check for Exit Signal (Opposite Direction) ---
            if (pos_side == 'long' and signal == "SELL") or (pos_side == 'short' and signal == "BUY"):
                lg.warning(f"{NEON_YELLOW}*** EXIT Signal ({signal}) opposes {pos_side} position. Closing... ***{RESET}")
                try:
                    close_sig = "SELL" if pos_side == 'long' else "BUY"
                    size_close = abs(pos_size)
                    if size_close <= 0: raise ValueError("Position size is zero/negative.")
                    lg.info(f"==> Placing {close_sig} MARKET order (reduceOnly=True) | Size: {size_close} <==")
                    close_order = place_trade(exchange, symbol, close_sig, size_close, market_info, lg, 'market', reduce_only=True)
                    if close_order: lg.info(f"{NEON_GREEN}Close order placed successfully. ID: {close_order.get('id','?')}{RESET}")
                    else: lg.error(f"{NEON_RED}Failed placing CLOSE order! Manual check!{RESET}")
                except Exception as close_err:
                    lg.error(f"Error closing position: {close_err}", exc_info=True); lg.warning(f"{NEON_YELLOW}Manual close may be needed!{RESET}")
                return # Exit cycle after close attempt

            # --- Check for Time-Based Exit ---
            time_exit = config.get("time_based_exit_minutes")
            if isinstance(time_exit, (int, float)) and time_exit > 0 and pos_ts_ms:
                 try:
                      elapsed_mins = (time.time() * 1000 - pos_ts_ms) / 60000
                      lg.debug(f"Time Exit Check: Elapsed={elapsed_mins:.2f}m, Limit={time_exit}m")
                      if elapsed_mins >= time_exit:
                           lg.warning(f"{NEON_YELLOW}*** TIME-BASED EXIT ({elapsed_mins:.1f} >= {time_exit}m). Closing... ***{RESET}")
                           close_sig = "SELL" if pos_side == 'long' else "BUY"
                           size_close = abs(pos_size)
                           if size_close <= 0: raise ValueError("Position size is zero/negative.")
                           close_order = place_trade(exchange, symbol, close_sig, size_close, market_info, lg, 'market', reduce_only=True)
                           if close_order: lg.info(f"{NEON_GREEN}Time-based CLOSE order placed. ID: {close_order.get('id','?')}{RESET}")
                           else: lg.error(f"{NEON_RED}Failed time-based CLOSE order! Manual check!{RESET}")
                           return # Exit cycle
                 except Exception as time_err: lg.error(f"Error in time exit check: {time_err}")

            # --- Position Management (Break-Even) ---
            is_tsl_active = open_position.get('trailingStopLossValueDecimal') is not None
            if config["enable_break_even"] and not is_tsl_active:
                 lg.debug("Checking Break-Even conditions...")
                 try:
                     if entry_price is None or not entry_price.is_finite() or entry_price <= 0: raise ValueError("Invalid entry price for BE")
                     if not isinstance(current_atr, Decimal) or not current_atr.is_finite() or current_atr <= 0: raise ValueError("Invalid ATR for BE")

                     be_trig_atr = Decimal(str(config["break_even_trigger_atr_multiple"]))
                     be_off_ticks = int(config["break_even_offset_ticks"])
                     min_tick = analyzer.get_min_tick_size()

                     price_diff = current_price - entry_price if pos_side == 'long' else entry_price - current_price
                     profit_atr = price_diff / current_atr if current_atr > 0 else Decimal(0)
                     lg.debug(f"BE Check: ProfitATRs={profit_atr:.2f}, TargetATRs={be_trig_atr}")

                     if profit_atr >= be_trig_atr:
                          tick_offset = min_tick * be_off_ticks
                          be_sl = (entry_price + tick_offset).quantize(min_tick, rounding=ROUND_UP) if pos_side=='long' else \
                                  (entry_price - tick_offset).quantize(min_tick, rounding=ROUND_DOWN)
                          if not be_sl.is_finite() or be_sl <= 0: raise ValueError(f"Calculated BE SL non-positive/finite ({be_sl})")

                          curr_sl = open_position.get('stopLossPriceDecimal')
                          update_needed = False
                          if curr_sl is None: update_needed = True; lg.info("BE triggered: No current SL.")
                          elif pos_side=='long' and be_sl > curr_sl: update_needed = True; lg.info(f"BE triggered: Target {be_sl} > Current {curr_sl}.")
                          elif pos_side=='short' and be_sl < curr_sl: update_needed = True; lg.info(f"BE triggered: Target {be_sl} < Current {curr_sl}.")
                          else: lg.debug(f"BE triggered but current SL {curr_sl} already adequate.")

                          if update_needed:
                               lg.warning(f"{NEON_PURPLE}*** Moving SL to Break-Even ({symbol} @ {be_sl}) ***{RESET}")
                               curr_tp = open_position.get('takeProfitPriceDecimal') # Preserve existing TP
                               success = _set_position_protection(exchange, symbol, market_info, open_position, lg, be_sl, curr_tp)
                               if success: lg.info(f"{NEON_GREEN}Break-Even SL updated.{RESET}")
                               else: lg.error(f"{NEON_RED}Failed updating Break-Even SL.{RESET}")
                     else: lg.debug("BE Profit target not reached.")
                 except ValueError as ve: lg.warning(f"BE Check skipped: {ve}")
                 except Exception as be_err: lg.error(f"Error during BE check: {be_err}", exc_info=True)
            elif is_tsl_active: lg.debug("BE check skipped: TSL active.")
            else: lg.debug("BE check skipped: Disabled in config.")

            # Placeholder for other potential management logic
            # lg.debug("End of position management checks.")

    # --- Error Handling for the entire cycle ---
    except ValueError as data_err: # Catch data/config related errors
        lg.error(f"{NEON_RED}Data/Config Error ({symbol}): {data_err}. Skipping cycle.{RESET}")
    except ccxt.AuthenticationError as auth_err: # Catch critical auth errors
         lg.critical(f"{NEON_RED}CRITICAL: Authentication Failed: {auth_err}. Stopping bot.{RESET}")
         raise SystemExit("Authentication Failed") # Stop the bot
    except (ccxt.NetworkError, ccxt.RequestTimeout, ccxt.ExchangeNotAvailable, ccxt.DDoSProtection) as net_err:
         lg.error(f"{NEON_RED}Network/Exchange Availability Error ({symbol}): {net_err}. Skipping cycle.{RESET}")
    except Exception as cycle_err: # Catch unexpected errors
        lg.error(f"{NEON_RED}Unexpected Cycle Error ({symbol}): {cycle_err}{RESET}", exc_info=True)
        # Decide behavior: continue or stop? For now, just log and continue.

    finally:
        # --- Cycle End Logging ---
        cycle_end_time = time.monotonic()
        lg.debug(f"---== Analysis Cycle End ({symbol}, {cycle_end_time - cycle_start_time:.2f}s) ==---")


def main() -> None:
    """Main function to initialize the bot and run the analysis loop."""
    global CONFIG, QUOTE_CURRENCY, config # Allow modification of globals

    # Setup initial logger
    init_logger = setup_logger("ScalpXRX_Init", level=logging.INFO)
    start_time_str = datetime.now(TIMEZONE).strftime('%Y-%m-%d %H:%M:%S %Z')
    init_logger.info(f"--- Starting ScalpXRX Bot ({start_time_str}) ---")

    try:
        CONFIG = load_config(CONFIG_FILE)
        config = CONFIG # Make config accessible without global keyword in helpers if needed
        QUOTE_CURRENCY = config.get("quote_currency", "USDT")
        TARGET_SYMBOL = config.get("symbol")

        if not TARGET_SYMBOL:
            init_logger.critical("CRITICAL: 'symbol' not defined in config.json. Exiting.")
            return

        # Setup logger specific to the target symbol for the main loop
        safe_symbol_name = TARGET_SYMBOL.replace('/', '_').replace(':', '-')
        symbol_logger_name = f"ScalpXRX_{safe_symbol_name}"
        main_logger = setup_logger(symbol_logger_name, level=logging.INFO) # Use INFO for console by default
        main_logger.info(f"Logging initialized for symbol: {TARGET_SYMBOL}")
        main_logger.info(f"Config loaded. Quote: {QUOTE_CURRENCY}, Interval: {config['interval']}")
        try: ta_version = ta.version
        except: ta_version = "N/A" # Handle if pandas_ta version attribute missing
        main_logger.info(f"Versions: CCXT={ccxt.__version__}, Pandas={pd.__version__}, PandasTA={ta_version}")


        # --- Trading Enabled Warning ---
        if config.get("enable_trading"):
            main_logger.warning(f"{NEON_YELLOW}!!! LIVE TRADING IS ENABLED !!!{RESET}")
            env_type = "SANDBOX (Testnet)" if config.get("use_sandbox") else f"{NEON_RED}!!! REAL MONEY !!!"
            main_logger.warning(f"Environment: {env_type}{RESET}")
            risk_pct = config.get('risk_per_trade', 0) * 100
            lev = config.get('leverage', 1)
            main_logger.warning(f"Settings: Risk/Trade={risk_pct:.2f}%, Leverage={lev}x")
            for i in range(3, 0, -1):
                main_logger.warning(f"Starting in {i}...")
                time.sleep(1)
        else:
            main_logger.info("Trading is disabled in config. Running in analysis-only mode.")

        # --- Initialize Exchange ---
        exchange = initialize_exchange(config, main_logger)
        if not exchange:
            main_logger.critical("Failed to initialize exchange. Exiting.")
            return

        # --- Main Loop ---
        main_logger.info(f"Starting main analysis loop for {TARGET_SYMBOL}...")
        loop_interval = max(1, config.get("loop_delay_seconds", LOOP_DELAY_SECONDS)) # Ensure positive delay
        while True:
            try:
                analyze_and_trade_symbol(exchange, TARGET_SYMBOL, config, main_logger)
            except SystemExit as e: # Catch SystemExit for clean shutdown
                 main_logger.critical(f"SystemExit triggered: {e}. Shutting down.")
                 break
            except KeyboardInterrupt: # Allow Ctrl+C to break loop
                 main_logger.info("KeyboardInterrupt detected in loop. Shutting down.")
                 break
            except Exception as loop_err:
                # Catch unexpected errors from analyze_and_trade_symbol if they weren't caught internally
                main_logger.error(f"{NEON_RED}Error in main loop iteration: {loop_err}{RESET}", exc_info=True)
                # Decide whether to continue or stop based on the error type?
                # For now, log and continue, but could add logic to stop on critical errors.

            # Delay before next cycle
            main_logger.debug(f"Waiting {loop_interval} seconds before next cycle...")
            time.sleep(loop_interval)

    except KeyboardInterrupt:
        init_logger.info("KeyboardInterrupt received during startup/shutdown. Shutting down...")
    except Exception as startup_err:
        init_logger.critical(f"Critical error during startup: {startup_err}", exc_info=True)
    finally:
        end_time_str = datetime.now(TIMEZONE).strftime('%Y-%m-%d %H:%M:%S %Z')
        init_logger.info(f"--- ScalpXRX Bot Shutdown ({end_time_str}) ---")
        logging.shutdown() # Ensure all logs are flushed


if __name__ == "__main__":
    # Assign config globally after loading if helper functions rely on it implicitly
    # (Though passing config explicitly is generally better practice)
    config = load_config(CONFIG_FILE)
    QUOTE_CURRENCY = config.get("quote_currency", "USDT")
    main()
    


    def _check_orderbook(self, orderbook_data: Optional[Dict], current_price: Decimal)