# File: analysis.py
import logging
from decimal import Decimal, ROUND_DOWN, ROUND_UP, InvalidOperation
from typing import Any, Dict, Optional, Tuple

import numpy as np
import pandas as pd
import pandas_ta as ta

# Import constants and utility functions
from utils import (CCXT_INTERVAL_MAP, DEFAULT_INDICATOR_PERIODS, FIB_LEVELS,
                   NEON_GREEN, NEON_RED, NEON_YELLOW, RESET,
                   get_min_tick_size, get_price_precision)

class TradingAnalyzer:
    """Analyzes trading data using pandas_ta and generates weighted signals."""

    def __init__(
        self,
        df: pd.DataFrame,
        logger: logging.Logger,
        config: Dict[str, Any],
        market_info: Dict[str, Any],
    ) -> None:
        """
        Initializes the TradingAnalyzer.

        Args:
            df: Pandas DataFrame with OHLCV data, indexed by timestamp.
            logger: Logger instance for logging messages.
            config: Dictionary containing bot configuration.
            market_info: Dictionary containing market details (precision, limits, etc.).
        """
        self.df = df
        self.logger = logger
        self.config = config
        self.market_info = market_info
        self.symbol = market_info.get('symbol', 'UNKNOWN_SYMBOL')
        # Get interval from config, default to '5' if missing
        self.interval = config.get("interval", "5")
        # Map to CCXT format, handle missing mapping
        self.ccxt_interval = CCXT_INTERVAL_MAP.get(self.interval)
        if not self.ccxt_interval:
             self.logger.error(f"Invalid interval '{self.interval}' in config, cannot map to CCXT timeframe. Defaulting calculation logic if possible, but fetching will fail.")
             # Handle fallback or raise error depending on desired behavior
             # For now, let it proceed but log the error.

        # Stores latest calculated indicator values (float or Decimal)
        self.indicator_values: Dict[str, Any] = {}
        # Stores binary signal states (BUY:1, SELL:1, HOLD:1) - only one can be 1
        self.signals: Dict[str, int] = {"BUY": 0, "SELL": 0, "HOLD": 1} # Default HOLD
        # Get the name of the active weight set from config
        self.active_weight_set_name = config.get("active_weight_set", "default")
        # Get the actual weight dictionary for the active set
        self.weights = config.get("weight_sets",{}).get(self.active_weight_set_name, {})
        # Stores calculated Fibonacci levels
        self.fib_levels_data: Dict[str, Decimal] = {}
        # Stores the actual column names generated by pandas_ta for mapping
        self.ta_column_names: Dict[str, Optional[str]] = {}

        if not self.weights:
             logger.error(f"Active weight set '{self.active_weight_set_name}' not found or empty in config for {self.symbol}.")
             # Handle this case, maybe use default weights or stop

        # Perform initial calculations upon instantiation
        self._calculate_all_indicators()
        self._update_latest_indicator_values()
        self.calculate_fibonacci_levels() # Calculate Fib levels based on initial data


    def _get_ta_col_name(self, base_name: str, result_df: pd.DataFrame) -> Optional[str]:
        """
        Helper to find the actual column name generated by pandas_ta based on common patterns.

        Args:
            base_name: The conceptual name of the indicator (e.g., "ATR", "EMA_Short").
            result_df: The DataFrame containing the calculated indicator columns.

        Returns:
            The actual column name if found, otherwise None.
        """
        default_periods = DEFAULT_INDICATOR_PERIODS
        cfg = self.config

        # Standardize access to nested psar defaults
        psar_defaults = default_periods.get('psar', {})
        psar_af_default = psar_defaults.get('af')
        psar_max_af_default = psar_defaults.get('max_af')

        expected_patterns = {
            "ATR": [f"ATRr_{cfg.get('atr_period', default_periods.get('atr_period'))}"],
            "EMA_Short": [f"EMA_{cfg.get('ema_short_period', default_periods.get('ema_short_period'))}"],
            "EMA_Long": [f"EMA_{cfg.get('ema_long_period', default_periods.get('ema_long_period'))}"],
            "Momentum": [f"MOM_{cfg.get('momentum_period', default_periods.get('momentum_period'))}"],
            "CCI": [f"CCI_{cfg.get('cci_window', default_periods.get('cci_window'))}"],
            "Williams_R": [f"WILLR_{cfg.get('williams_r_window', default_periods.get('williams_r_window'))}"],
            "MFI": [f"MFI_{cfg.get('mfi_window', default_periods.get('mfi_window'))}"],
            "VWAP": ["VWAP_D"],
            "PSAR_long": [f"PSARl_{cfg.get('psar_af', psar_af_default)}_{cfg.get('psar_max_af', psar_max_af_default)}"],
            "PSAR_short": [f"PSARs_{cfg.get('psar_af', psar_af_default)}_{cfg.get('psar_max_af', psar_max_af_default)}"],
            "SMA10": [f"SMA_{cfg.get('sma_10_window', default_periods.get('sma_10_window'))}"],
            "StochRSI_K": [
                f"STOCHRSIk_{cfg.get('stoch_rsi_window', default_periods.get('stoch_rsi_window'))}_{cfg.get('stoch_rsi_rsi_window', default_periods.get('stoch_rsi_rsi_window'))}_{cfg.get('stoch_rsi_k', default_periods.get('stoch_rsi_k'))}",
                f"STOCHRSIk_{cfg.get('stoch_rsi_window', default_periods.get('stoch_rsi_window'))}" # Simpler name if other params are default
            ],
            "StochRSI_D": [
                f"STOCHRSId_{cfg.get('stoch_rsi_window', default_periods.get('stoch_rsi_window'))}_{cfg.get('stoch_rsi_rsi_window', default_periods.get('stoch_rsi_rsi_window'))}_{cfg.get('stoch_rsi_k', default_periods.get('stoch_rsi_k'))}_{cfg.get('stoch_rsi_d', default_periods.get('stoch_rsi_d'))}",
                 f"STOCHRSId_{cfg.get('stoch_rsi_window', default_periods.get('stoch_rsi_window'))}"
            ],
            "RSI": [f"RSI_{cfg.get('rsi_period', default_periods.get('rsi_period'))}"],
            "BB_Lower": [ # Need to handle potential None from cfg.get for std_dev
                f"BBL_{cfg.get('bollinger_bands_period', default_periods.get('bollinger_bands_period'))}_{float(cfg.get('bollinger_bands_std_dev', default_periods.get('bollinger_bands_std_dev', 2.0))):.1f}",
                f"BBL_{cfg.get('bollinger_bands_period', default_periods.get('bollinger_bands_period'))}"
            ],
            "BB_Middle": [
                f"BBM_{cfg.get('bollinger_bands_period', default_periods.get('bollinger_bands_period'))}_{float(cfg.get('bollinger_bands_std_dev', default_periods.get('bollinger_bands_std_dev', 2.0))):.1f}",
                f"BBM_{cfg.get('bollinger_bands_period', default_periods.get('bollinger_bands_period'))}"
            ],
            "BB_Upper": [
                f"BBU_{cfg.get('bollinger_bands_period', default_periods.get('bollinger_bands_period'))}_{float(cfg.get('bollinger_bands_std_dev', default_periods.get('bollinger_bands_std_dev', 2.0))):.1f}",
                f"BBU_{cfg.get('bollinger_bands_period', default_periods.get('bollinger_bands_period'))}"
            ],
            "Volume_MA": [f"VOL_SMA_{cfg.get('volume_ma_period', default_periods.get('volume_ma_period'))}"]
        }

        patterns = expected_patterns.get(base_name, [])
        for col in result_df.columns:
             for pattern in patterns:
                 if pattern and col.startswith(pattern): # Ensure pattern is not None
                     self.logger.debug(f"Mapped '{base_name}' to column '{col}'")
                     return col

        base_name_lower = base_name.lower()
        for col in result_df.columns:
            if base_name_lower in col.lower():
                self.logger.debug(f"Found column '{col}' for base '{base_name}' using fallback substring search.")
                return col

        self.logger.warning(f"Could not find column name for indicator '{base_name}' in DataFrame columns: {result_df.columns.tolist()}")
        return None

    def get_period(self, key: str, sub_key: Optional[str] = None) -> Any:
        """
        Safely retrieves a period/parameter value from config, falling back to defaults.
        Handles flat keys and nested keys (if sub_key is provided).
        """
        if sub_key:
            config_parent = self.config.get(key)
            config_val = None
            if isinstance(config_parent, dict):
                config_val = config_parent.get(sub_key)

            default_parent = DEFAULT_INDICATOR_PERIODS.get(key, {})
            default_val = None
            if isinstance(default_parent, dict): # Ensure default_parent is a dict before .get()
                default_val = default_parent.get(sub_key)
            
            return config_val if config_val is not None else default_val
        else:
            # For flat structure like: key: value
            return self.config.get(key, DEFAULT_INDICATOR_PERIODS.get(key))


    def _calculate_all_indicators(self):
        """Calculates all enabled indicators using pandas_ta and stores column names."""
        if self.df.empty:
            self.logger.warning(f"{NEON_YELLOW}DataFrame is empty, cannot calculate indicators for {self.symbol}.{RESET}")
            return

        required_periods = []
        indicators_config = self.config.get("indicators", {})
        
        if indicators_config.get("atr", True): required_periods.append(self.get_period("atr_period"))
        if indicators_config.get("ema_alignment"):
            required_periods.append(self.get_period("ema_short_period"))
            required_periods.append(self.get_period("ema_long_period"))
        if indicators_config.get("momentum"): required_periods.append(self.get_period("momentum_period"))
        if indicators_config.get("cci"): required_periods.append(self.get_period("cci_window"))
        if indicators_config.get("wr"): required_periods.append(self.get_period("williams_r_window"))
        if indicators_config.get("mfi"): required_periods.append(self.get_period("mfi_window"))
        if indicators_config.get("sma_10"): required_periods.append(self.get_period("sma_10_window"))
        if indicators_config.get("stoch_rsi"):
            required_periods.append(self.get_period("stoch_rsi_window"))
            required_periods.append(self.get_period("stoch_rsi_rsi_window"))
        if indicators_config.get("rsi"): required_periods.append(self.get_period("rsi_period"))
        if indicators_config.get("bollinger_bands"): required_periods.append(self.get_period("bollinger_bands_period"))
        if indicators_config.get("volume_confirmation"): required_periods.append(self.get_period("volume_ma_period"))
        required_periods.append(self.get_period("fibonacci_window"))

        required_periods = [p for p in required_periods if p is not None and isinstance(p, (int, float)) and p > 0]
        min_required_data = max(required_periods) + 20 if required_periods else 50

        if len(self.df) < min_required_data:
             self.logger.warning(f"{NEON_YELLOW}Insufficient data ({len(self.df)} points) for {self.symbol} to calculate all indicators reliably (min recommended: {min_required_data}). Results may contain NaNs.{RESET}")

        try:
            df_calc = self.df.copy()

            atr_period = self.get_period("atr_period")
            if atr_period:
                df_calc.ta.atr(length=atr_period, append=True)
                self.ta_column_names["ATR"] = self._get_ta_col_name("ATR", df_calc)
            
            if indicators_config.get("ema_alignment", False):
                ema_short = self.get_period("ema_short_period")
                ema_long = self.get_period("ema_long_period")
                if ema_short:
                    df_calc.ta.ema(length=ema_short, append=True)
                    self.ta_column_names["EMA_Short"] = self._get_ta_col_name("EMA_Short", df_calc)
                if ema_long:
                    df_calc.ta.ema(length=ema_long, append=True)
                    self.ta_column_names["EMA_Long"] = self._get_ta_col_name("EMA_Long", df_calc)

            if indicators_config.get("momentum", False):
                mom_period = self.get_period("momentum_period")
                if mom_period:
                    df_calc.ta.mom(length=mom_period, append=True)
                    self.ta_column_names["Momentum"] = self._get_ta_col_name("Momentum", df_calc)

            if indicators_config.get("cci", False):
                cci_period = self.get_period("cci_window")
                if cci_period:
                    df_calc.ta.cci(length=cci_period, append=True)
                    self.ta_column_names["CCI"] = self._get_ta_col_name("CCI", df_calc)

            if indicators_config.get("wr", False):
                wr_period = self.get_period("williams_r_window")
                if wr_period:
                    df_calc.ta.willr(length=wr_period, append=True)
                    self.ta_column_names["Williams_R"] = self._get_ta_col_name("Williams_R", df_calc)

            if indicators_config.get("mfi", False):
                mfi_period = self.get_period("mfi_window")
                if mfi_period:
                    mfi_series = df_calc.ta.mfi(length=mfi_period) 
                    if mfi_series is not None and not mfi_series.empty:
                         if isinstance(mfi_series, pd.Series):
                              mfi_series = mfi_series.to_frame()
                         df_calc = pd.concat([df_calc, mfi_series], axis=1)
                    self.ta_column_names["MFI"] = self._get_ta_col_name("MFI", df_calc)


            if indicators_config.get("vwap", False):
                vwap_series = df_calc.ta.vwap() 
                if vwap_series is not None and not vwap_series.empty:
                    if isinstance(vwap_series, pd.Series):
                        vwap_series = vwap_series.to_frame()
                    df_calc = pd.concat([df_calc, vwap_series], axis=1)
                self.ta_column_names["VWAP"] = self._get_ta_col_name("VWAP", df_calc)

            if indicators_config.get("psar", False):
                psar_af = self.get_period("psar_af") 
                psar_max_af = self.get_period("psar_max_af")
                if psar_af is not None and psar_max_af is not None:
                    psar_result = df_calc.ta.psar(af=psar_af, max_af=psar_max_af)
                    if psar_result is not None and not psar_result.empty:
                        df_calc = pd.concat([df_calc, psar_result], axis=1)
                        self.ta_column_names["PSAR_long"] = self._get_ta_col_name("PSAR_long", df_calc)
                        self.ta_column_names["PSAR_short"] = self._get_ta_col_name("PSAR_short", df_calc)

            if indicators_config.get("sma_10", False):
                sma10_period = self.get_period("sma_10_window")
                if sma10_period:
                    df_calc.ta.sma(length=sma10_period, append=True)
                    self.ta_column_names["SMA10"] = self._get_ta_col_name("SMA10", df_calc)

            if indicators_config.get("stoch_rsi", False):
                stoch_rsi_len = self.get_period("stoch_rsi_window")
                stoch_rsi_rsi_len = self.get_period("stoch_rsi_rsi_window")
                stoch_rsi_k = self.get_period("stoch_rsi_k")
                stoch_rsi_d = self.get_period("stoch_rsi_d")
                if all(p is not None for p in [stoch_rsi_len, stoch_rsi_rsi_len, stoch_rsi_k, stoch_rsi_d]):
                    stochrsi_result = df_calc.ta.stochrsi(length=stoch_rsi_len, rsi_length=stoch_rsi_rsi_len, k=stoch_rsi_k, d=stoch_rsi_d)
                    if stochrsi_result is not None and not stochrsi_result.empty:
                         df_calc = pd.concat([df_calc, stochrsi_result], axis=1)
                         self.ta_column_names["StochRSI_K"] = self._get_ta_col_name("StochRSI_K", df_calc)
                         self.ta_column_names["StochRSI_D"] = self._get_ta_col_name("StochRSI_D", df_calc)

            if indicators_config.get("rsi", False):
                rsi_period = self.get_period("rsi_period")
                if rsi_period:
                    df_calc.ta.rsi(length=rsi_period, append=True)
                    self.ta_column_names["RSI"] = self._get_ta_col_name("RSI", df_calc)

            if indicators_config.get("bollinger_bands", False):
                bb_period = self.get_period("bollinger_bands_period")
                bb_std_val = self.get_period("bollinger_bands_std_dev") # Corrected: No sub_key
                bb_std = float(bb_std_val) if bb_std_val is not None else 2.0

                if bb_period:
                    bbands_result = df_calc.ta.bbands(length=bb_period, std=bb_std)
                    if bbands_result is not None and not bbands_result.empty:
                        df_calc = pd.concat([df_calc, bbands_result], axis=1)
                        self.ta_column_names["BB_Lower"] = self._get_ta_col_name("BB_Lower", df_calc)
                        self.ta_column_names["BB_Middle"] = self._get_ta_col_name("BB_Middle", df_calc)
                        self.ta_column_names["BB_Upper"] = self._get_ta_col_name("BB_Upper", df_calc)

            if indicators_config.get("volume_confirmation", False):
                vol_ma_period = self.get_period("volume_ma_period")
                if vol_ma_period:
                    vol_ma_col_name = f"VOL_SMA_{vol_ma_period}"
                    volume_series = df_calc['volume'].fillna(0)
                    
                    if not volume_series.empty:
                        # Workaround for older pandas lacking is_decimal_dtype
                        if volume_series.dtype == 'object':
                            first_valid_element = volume_series.dropna().iloc[0] if not volume_series.dropna().empty else None
                            if isinstance(first_valid_element, Decimal):
                                self.logger.debug(f"Volume series for {self.symbol} contains Decimal objects. Converting to float for ta.sma.")
                                volume_series = volume_series.astype(float)
                        # For pandas 1.0.0+ you could use:
                        # elif hasattr(pd.api.types, 'is_decimal_dtype') and pd.api.types.is_decimal_dtype(volume_series):
                        #     self.logger.debug(f"Volume series for {self.symbol} is decimal_dtype. Converting to float for ta.sma.")
                        #     volume_series = volume_series.astype(float)
                        elif not pd.api.types.is_numeric_dtype(volume_series):
                            try:
                                self.logger.debug(f"Volume series for {self.symbol} is not numeric ({volume_series.dtype}). Attempting astype(float).")
                                volume_series = volume_series.astype(float)
                            except Exception as e:
                                self.logger.error(f"Could not convert volume_series to float for {self.symbol}: {e}. Volume MA may be incorrect.")
                                
                    df_calc[vol_ma_col_name] = ta.sma(volume_series, length=vol_ma_period)
                    self.ta_column_names["Volume_MA"] = vol_ma_col_name

            self.df = df_calc
            self.logger.debug(f"Finished indicator calculations for {self.symbol}. Final DF columns: {self.df.columns.tolist()}")

        except AttributeError as e:
             self.logger.error(f"{NEON_RED}AttributeError calculating indicators for {self.symbol}: {e}{RESET}. Check pandas_ta usage and data.", exc_info=True)
        except Exception as e:
            self.logger.error(f"{NEON_RED}Error calculating indicators with pandas_ta for {self.symbol}: {e}{RESET}", exc_info=True)


    def _update_latest_indicator_values(self):
        """Updates the indicator_values dict with the latest (most recent) values from self.df."""
        decimal_keys = ["ATR", "Open", "High", "Low", "Close", "Volume",
                        "EMA_Short", "EMA_Long", "VWAP", "PSAR_long", "PSAR_short",
                        "SMA10", "BB_Lower", "BB_Middle", "BB_Upper", "Volume_MA"]

        if self.df.empty or self.df.iloc[-1].isnull().all():
            msg = "DataFrame empty" if self.df.empty else "Last row contains all NaNs"
            self.logger.warning(f"Cannot update latest values for {self.symbol}: {msg}.")
            self.indicator_values = {k: np.nan for k in list(self.ta_column_names.keys()) + ["Close", "Volume", "High", "Low", "Open"]}
            for dk in decimal_keys:
                if dk not in self.indicator_values: self.indicator_values[dk] = np.nan
            return

        try:
            latest = self.df.iloc[-1]
            updated_values = {}

            for key, col_name in self.ta_column_names.items():
                if col_name and col_name in latest.index:
                    value = latest[col_name]
                    if pd.notna(value):
                        try:
                            if key in decimal_keys:
                                updated_values[key] = Decimal(str(value))
                            else: 
                                updated_values[key] = float(value)
                        except (ValueError, TypeError, InvalidOperation) as conv_err:
                            self.logger.warning(f"Could not convert value for TA {key} ('{col_name}': {value}) for {self.symbol}. Storing NaN. Error: {conv_err}")
                            updated_values[key] = np.nan
                    else:
                        updated_values[key] = np.nan
                else:
                    if key in self.ta_column_names:
                        self.logger.debug(f"Indicator column '{col_name}' for key '{key}' not found in latest data row for {self.symbol}. Storing NaN.")
                    updated_values[key] = np.nan
            
            for base_col in ['open', 'high', 'low', 'close', 'volume']:
                 key_name = base_col.capitalize()
                 value = latest.get(base_col)
                 if pd.notna(value):
                      try:
                           updated_values[key_name] = Decimal(str(value))
                      except (ValueError, TypeError, InvalidOperation) as conv_err:
                           self.logger.warning(f"Could not convert base value for '{base_col}' ({value}) to Decimal for {self.symbol}. Storing NaN. Error: {conv_err}")
                           updated_values[key_name] = np.nan
                 else:
                      updated_values[key_name] = np.nan
            
            for dk in decimal_keys:
                if dk not in updated_values:
                    self.logger.debug(f"Decimal-expected key '{dk}' not found in updated_values. Setting to NaN for {self.symbol}.")
                    updated_values[dk] = np.nan


            self.indicator_values = updated_values
            
            valid_values_log = {}
            price_prec = get_price_precision(self.market_info, self.logger)
            for k, v in self.indicator_values.items():
                 if pd.notna(v):
                     if isinstance(v, Decimal):
                          prec = price_prec if k in ["ATR", "Open", "High", "Low", "Close", "EMA_Short", "EMA_Long", "VWAP", "PSAR_long", "PSAR_short", "SMA10", "BB_Lower", "BB_Middle", "BB_Upper"] else (8 if k == "Volume" or k == "Volume_MA" else 4)
                          valid_values_log[k] = f"{v:.{prec}f}"
                     elif isinstance(v, float):
                          valid_values_log[k] = f"{v:.4f}"
                     else:
                          valid_values_log[k] = str(v)
            self.logger.debug(f"Latest indicator values updated for {self.symbol}: {valid_values_log}")

        except IndexError:
             self.logger.error(f"Error accessing latest row (iloc[-1]) for {self.symbol}. DataFrame might be empty or too short after cleaning.")
             self.indicator_values = {k: np.nan for k in list(self.ta_column_names.keys()) + ["Close", "Volume", "High", "Low", "Open"]}
             for dk in decimal_keys:
                if dk not in self.indicator_values: self.indicator_values[dk] = np.nan
        except Exception as e:
             self.logger.error(f"Unexpected error updating latest indicator values for {self.symbol}: {e}", exc_info=True)
             self.indicator_values = {k: np.nan for k in list(self.ta_column_names.keys()) + ["Close", "Volume", "High", "Low", "Open"]}
             for dk in decimal_keys:
                if dk not in self.indicator_values: self.indicator_values[dk] = np.nan

    # --- Fibonacci Calculation ---
    def calculate_fibonacci_levels(self, window: Optional[int] = None) -> Dict[str, Decimal]:
        cfg_window = self.get_period("fibonacci_window")
        window = window or cfg_window

        if not isinstance(window, int) or window <= 0:
            self.logger.warning(f"Invalid Fibonacci window ({window}) for {self.symbol}. Calculation skipped.")
            self.fib_levels_data = {}
            return {}

        if len(self.df) < window:
            self.logger.debug(f"Not enough data ({len(self.df)} points) for Fibonacci window ({window}) on {self.symbol}.")
            self.fib_levels_data = {} 
            return {}

        df_slice = self.df.tail(window)

        try:
            high_price_raw = df_slice["high"].dropna().max()
            low_price_raw = df_slice["low"].dropna().min()

            if pd.isna(high_price_raw) or pd.isna(low_price_raw):
                 self.logger.warning(f"Could not find valid high/low prices within the last {window} periods for Fibonacci calculation on {self.symbol}.")
                 self.fib_levels_data = {}
                 return {}

            high = Decimal(str(high_price_raw))
            low = Decimal(str(low_price_raw))
            diff = high - low
            levels = {}
            price_precision = get_price_precision(self.market_info, self.logger)
            min_tick_size = get_min_tick_size(self.market_info, self.logger)

            if diff > 0:
                for level_pct in FIB_LEVELS:
                    level_name = f"Fib_{level_pct * 100:.1f}%"
                    level_price_raw = high - (diff * Decimal(str(level_pct)))
                    if min_tick_size is not None and min_tick_size > 0:
                        level_price_quantized = (level_price_raw / min_tick_size).quantize(Decimal('1'), rounding=ROUND_DOWN) * min_tick_size
                    else: 
                        rounding_factor = Decimal('1e-' + str(price_precision))
                        level_price_quantized = level_price_raw.quantize(rounding_factor, rounding=ROUND_DOWN)
                    levels[level_name] = level_price_quantized
            else:
                 self.logger.debug(f"Fibonacci range is zero or negative (High={high}, Low={low}) for {self.symbol} over last {window} periods. All levels set to High/Low.")
                 if min_tick_size is not None and min_tick_size > 0:
                     level_price_quantized = (high / min_tick_size).quantize(Decimal('1'), rounding=ROUND_DOWN) * min_tick_size
                 else: 
                     rounding_factor = Decimal('1e-' + str(price_precision))
                     level_price_quantized = high.quantize(rounding_factor, rounding=ROUND_DOWN)
                 for level_pct in FIB_LEVELS:
                     levels[f"Fib_{level_pct * 100:.1f}%"] = level_price_quantized

            self.fib_levels_data = levels
            log_levels = {k: f"{v:.{price_precision}f}" for k, v in levels.items()} 
            self.logger.debug(f"Calculated Fibonacci levels for {self.symbol} (Window: {window}): {log_levels}")
            return levels

        except KeyError as e:
             self.logger.error(f"{NEON_RED}Fibonacci calculation error for {self.symbol}: Missing column '{e}'. Ensure 'high' and 'low' columns exist.{RESET}")
             self.fib_levels_data = {}
             return {}
        except Exception as e:
            self.logger.error(f"{NEON_RED}Unexpected Fibonacci calculation error for {self.symbol}: {e}{RESET}", exc_info=True)
            self.fib_levels_data = {}
            return {}

    def get_nearest_fibonacci_levels(
        self, current_price: Decimal, num_levels: int = 5
    ) -> list[Tuple[str, Decimal]]:
        if not self.fib_levels_data:
            self.logger.debug(f"Fibonacci levels not calculated yet for {self.symbol}. Cannot find nearest.")
            return []
        if not isinstance(current_price, Decimal) or pd.isna(current_price) or current_price <= 0:
            self.logger.warning(f"Invalid current price ({current_price}) provided for Fibonacci comparison on {self.symbol}.")
            return []

        try:
            level_distances = []
            for name, level_price in self.fib_levels_data.items():
                if isinstance(level_price, Decimal) and level_price > 0:
                    distance = abs(current_price - level_price)
                    level_distances.append({'name': name, 'level': level_price, 'distance': distance})
                else:
                     self.logger.warning(f"Invalid or non-decimal value found in fib_levels_data: {name}={level_price}. Skipping.")

            level_distances.sort(key=lambda x: x['distance'])
            return [(item['name'], item['level']) for item in level_distances[:num_levels]]

        except Exception as e:
            self.logger.error(f"{NEON_RED}Error finding nearest Fibonacci levels for {self.symbol}: {e}{RESET}", exc_info=True)
            return []

    # --- EMA Alignment Calculation ---
    def calculate_ema_alignment_score(self) -> float:
        ema_short_val = self.indicator_values.get("EMA_Short")
        ema_long_val = self.indicator_values.get("EMA_Long")
        close_val = self.indicator_values.get("Close")

        try:
            if not all(isinstance(v, Decimal) and pd.notna(v) for v in [ema_short_val, ema_long_val, close_val]):
                self.logger.debug(f"EMA alignment check skipped for {self.symbol}: Not all required values (EMA_Short, EMA_Long, Close) are valid Decimals.")
                return np.nan
            ema_short = ema_short_val
            ema_long = ema_long_val
            current_price = close_val

        except (TypeError, ValueError): 
            self.logger.debug(f"EMA alignment check skipped for {self.symbol}: Error converting EMA/Close values to Decimal.")
            return np.nan

        if current_price > ema_short > ema_long: return 1.0
        elif current_price < ema_short < ema_long: return -1.0
        else: return 0.0


    # --- Signal Generation & Scoring ---
    def generate_trading_signal(
        self, current_price: Decimal, orderbook_data: Optional[Dict]
    ) -> str:
        self.signals = {"BUY": 0, "SELL": 0, "HOLD": 1} 
        final_signal_score = Decimal("0.0")
        total_weight_applied = Decimal("0.0")
        active_indicator_count = 0
        nan_indicator_count = 0
        debug_scores = {} 

        if not self.indicator_values:
             self.logger.warning(f"{NEON_YELLOW}Cannot generate signal for {self.symbol}: Indicator values dictionary is empty.{RESET}")
             return "HOLD"
        core_indicators_present = any(
            pd.notna(v) for k, v in self.indicator_values.items()
            if k not in ['Open', 'High', 'Low', 'Close', 'Volume'] 
        )
        if not core_indicators_present:
            self.logger.warning(f"{NEON_YELLOW}Cannot generate signal for {self.symbol}: All core indicator values are NaN.{RESET}")
            return "HOLD"
        if pd.isna(current_price) or not isinstance(current_price, Decimal) or current_price <= 0:
             self.logger.warning(f"{NEON_YELLOW}Cannot generate signal for {self.symbol}: Invalid current price ({current_price}).{RESET}")
             return "HOLD"

        active_weights = self.config.get("weight_sets", {}).get(self.active_weight_set_name)
        if not active_weights:
             self.logger.error(f"Active weight set '{self.active_weight_set_name}' missing or empty in config for {self.symbol}. Cannot generate signal.")
             return "HOLD"

        for indicator_key, enabled in self.config.get("indicators", {}).items():
            if not enabled: continue
            weight_str = active_weights.get(indicator_key)
            if weight_str is None: continue

            try:
                weight = Decimal(str(weight_str))
                if weight == 0: continue
            except (InvalidOperation, ValueError, TypeError):
                self.logger.warning(f"Invalid weight format '{weight_str}' for indicator '{indicator_key}' in weight set '{self.active_weight_set_name}'. Skipping.")
                continue

            check_method_name = f"_check_{indicator_key}"
            if hasattr(self, check_method_name) and callable(getattr(self, check_method_name)):
                method_to_call = getattr(self, check_method_name)
                indicator_score_float = np.nan 

                try:
                    if indicator_key == "orderbook":
                         if orderbook_data:
                             indicator_score_float = method_to_call(orderbook_data, current_price)
                         else:
                              if weight != 0:
                                 self.logger.debug(f"Orderbook check skipped for {self.symbol}: No orderbook data provided.")
                    else:
                         indicator_score_float = method_to_call()

                except Exception as e:
                    self.logger.error(f"Error executing indicator check method {check_method_name} for {self.symbol}: {e}", exc_info=True)

                debug_scores[indicator_key] = f"{indicator_score_float:.3f}" if pd.notna(indicator_score_float) else "NaN"

                if pd.notna(indicator_score_float):
                    try:
                        score_decimal = Decimal(str(indicator_score_float))
                        clamped_score = max(Decimal("-1.0"), min(Decimal("1.0"), score_decimal))
                        score_contribution = clamped_score * weight
                        final_signal_score += score_contribution
                        total_weight_applied += weight
                        active_indicator_count += 1
                    except (InvalidOperation, ValueError, TypeError) as calc_err:
                        self.logger.error(f"Error processing score for {indicator_key} (Score: {indicator_score_float}, Weight: {weight}): {calc_err}")
                        nan_indicator_count += 1
                else:
                    nan_indicator_count += 1
            else:
                if weight != 0:
                    self.logger.warning(f"Indicator check method '{check_method_name}' not found for enabled/weighted indicator: {indicator_key} ({self.symbol})")


        final_signal = "HOLD"
        if total_weight_applied == 0:
             self.logger.warning(f"No indicators contributed valid scores to the signal calculation for {self.symbol}. Defaulting to HOLD.")
        else:
            threshold_str = self.config.get("signal_score_threshold", "0.7")
            try:
                threshold = Decimal(str(threshold_str))
            except (InvalidOperation, ValueError, TypeError):
                self.logger.warning(f"Invalid signal_score_threshold '{threshold_str}'. Using default 0.7.")
                threshold = Decimal("0.7")

            if final_signal_score >= threshold:
                final_signal = "BUY"
            elif final_signal_score <= -threshold:
                final_signal = "SELL"

        price_prec = get_price_precision(self.market_info, self.logger)
        log_msg = (
            f"Signal Summary ({self.symbol} @ {current_price:.{price_prec}f}): "
            f"Set='{self.active_weight_set_name}', Indicators=[Active:{active_indicator_count}, NaN:{nan_indicator_count}], "
            f"TotalWeight={total_weight_applied:.2f}, "
            f"FinalScore={final_signal_score:.4f} (Threshold: +/-{threshold:.2f}) "
            f"==> {NEON_GREEN if final_signal == 'BUY' else NEON_RED if final_signal == 'SELL' else NEON_YELLOW}{final_signal}{RESET}"
        )
        self.logger.info(log_msg)
        self.logger.debug(f"  Indicator Scores ({self.symbol}): {debug_scores}")

        if final_signal == "BUY": self.signals = {"BUY": 1, "SELL": 0, "HOLD": 0}
        elif final_signal == "SELL": self.signals = {"BUY": 0, "SELL": 1, "HOLD": 0}
        else: self.signals = {"BUY": 0, "SELL": 0, "HOLD": 1}

        return final_signal


    # --- Indicator Check Methods (returning float score -1.0 to 1.0 or np.nan) ---

    def _check_ema_alignment(self) -> float:
        if "EMA_Short" not in self.indicator_values or "EMA_Long" not in self.indicator_values:
             self.logger.debug("EMA Alignment check skipped: EMA values not found in indicator_values.")
             return np.nan
        return self.calculate_ema_alignment_score()

    def _check_momentum(self) -> float:
        momentum_val = self.indicator_values.get("Momentum") 
        last_close_val = self.indicator_values.get("Close")   

        if pd.isna(momentum_val) or not isinstance(last_close_val, Decimal) or last_close_val <= 0:
            return np.nan
        
        try:
            momentum = Decimal(str(momentum_val)) 
            last_close = last_close_val

            mom_pct = momentum / last_close 
            threshold_pct = Decimal("0.001") 

            if mom_pct > threshold_pct:
                return min(1.0, float(mom_pct / (threshold_pct * Decimal("5"))))
            elif mom_pct < -threshold_pct:
                return max(-1.0, float(mom_pct / (threshold_pct * Decimal("5"))))
            else: 
                return float(mom_pct / threshold_pct) 
        except (InvalidOperation, ValueError, TypeError) as e:
            self.logger.warning(f"Error during momentum check ({self.symbol}): {e}")
            return 0.0


    def _check_volume_confirmation(self) -> float:
        current_volume_val = self.indicator_values.get("Volume")
        volume_ma_val = self.indicator_values.get("Volume_MA")
        
        multiplier_str = str(self.config.get("volume_confirmation_multiplier", "1.5"))

        current_volume_decimal: Optional[Decimal] = None
        volume_ma_decimal: Optional[Decimal] = None
        multiplier_decimal: Optional[Decimal] = None

        try:
            if pd.notna(current_volume_val) and isinstance(current_volume_val, Decimal):
                current_volume_decimal = current_volume_val
            elif pd.notna(current_volume_val):
                current_volume_decimal = Decimal(str(current_volume_val))
            
            if pd.notna(volume_ma_val) and isinstance(volume_ma_val, Decimal):
                volume_ma_decimal = volume_ma_val
            elif pd.notna(volume_ma_val):
                 volume_ma_decimal = Decimal(str(volume_ma_val))

            multiplier_decimal = Decimal(multiplier_str)

        except (InvalidOperation, ValueError, TypeError) as e:
            self.logger.warning(f"Error converting values for volume confirmation ({self.symbol}): {e}")
            return np.nan

        if current_volume_decimal is None or current_volume_decimal < 0 or \
           volume_ma_decimal is None or volume_ma_decimal <= 0 or \
           multiplier_decimal is None or multiplier_decimal <= 0:
            self.logger.debug(
                f"Volume confirmation check skipped ({self.symbol}): Invalid input values. "
                f"CurrentVol={current_volume_decimal}, VolMA={volume_ma_decimal}, Mult={multiplier_decimal}"
            )
            return np.nan

        try:
            volume_ratio = current_volume_decimal / volume_ma_decimal
            
            if volume_ratio > multiplier_decimal:
                base_score = Decimal("0.5")
                scaling_factor_denominator = multiplier_decimal * Decimal("4")
                if scaling_factor_denominator == 0:
                     additional_score_factor = Decimal("0.5") 
                else:
                     additional_score_factor = (volume_ratio - multiplier_decimal) / scaling_factor_denominator
                score = base_score + additional_score_factor
                return min(1.0, float(score))
                
            elif volume_ratio < (Decimal("1") / multiplier_decimal):
                return -0.4 
            else: 
                return 0.0

        except ZeroDivisionError:
             self.logger.warning(f"ZeroDivisionError during volume ratio calculation for {self.symbol} (VolMA likely zero).")
             return 0.0
        except (InvalidOperation, ValueError, TypeError) as e:
            self.logger.warning(f"Error during volume confirmation calculation ({self.symbol}): {e}")
            return np.nan


    def _check_stoch_rsi(self) -> float:
        k = self.indicator_values.get("StochRSI_K")
        d = self.indicator_values.get("StochRSI_D")

        if pd.isna(k) or pd.isna(d):
            return np.nan

        oversold = float(self.config.get("stoch_rsi_oversold_threshold", 25))
        overbought = float(self.config.get("stoch_rsi_overbought_threshold", 75))
        score = 0.0
        if k < oversold and d < oversold: score = 1.0
        elif k > overbought and d > overbought: score = -1.0

        diff = k - d
        if abs(diff) > 5:
             if diff > 0: score = max(score, 0.6) if score >= 0 else 0.6
             else: score = min(score, -0.6) if score <= 0 else -0.6
        elif k > d : score = max(score, 0.2)
        elif k < d: score = min(score, -0.2)

        if 40 < k < 60 and 40 < d < 60 : score *= 0.5
        return score

    def _check_rsi(self) -> float:
        rsi = self.indicator_values.get("RSI")
        if pd.isna(rsi): return np.nan
        if rsi <= 30: return 1.0
        if rsi >= 70: return -1.0
        if rsi < 40: return 0.5
        if rsi > 60: return -0.5
        if 40 <= rsi <= 60: return (rsi - 50.0) / 50.0
        return 0.0


    def _check_cci(self) -> float:
        cci = self.indicator_values.get("CCI")
        if pd.isna(cci): return np.nan
        if cci <= -150: return 1.0
        if cci >= 150: return -1.0
        if cci < -80: return 0.6
        if cci > 80: return -0.6
        if -80 <= cci < 0: return 0.1
        if 0 < cci <= 80: return -0.1
        if cci == 0: return 0.0
        return 0.0


    def _check_wr(self) -> float:
        wr = self.indicator_values.get("Williams_R")
        if pd.isna(wr): return np.nan
        if wr <= -80: return 1.0
        if wr >= -20: return -1.0
        if -80 < wr < -50: return 0.4
        if -50 < wr < -20: return -0.4
        if wr == -50: return 0.0
        return 0.0

    def _check_psar(self) -> float:
        psar_long_val = self.indicator_values.get("PSAR_long")
        psar_short_val = self.indicator_values.get("PSAR_short")
        long_active = isinstance(psar_long_val, Decimal) and pd.notna(psar_long_val)
        short_active = isinstance(psar_short_val, Decimal) and pd.notna(psar_short_val)

        if long_active and not short_active: return 1.0
        elif short_active and not long_active: return -1.0
        elif not long_active and not short_active: return np.nan
        else: 
            self.logger.warning(f"PSAR check ({self.symbol}) unexpected state: Long={psar_long_val}, Short={psar_short_val}")
            return 0.0


    def _check_sma_10(self) -> float:
        sma_10_val = self.indicator_values.get("SMA10")
        last_close_val = self.indicator_values.get("Close")
        if not isinstance(sma_10_val, Decimal) or pd.isna(sma_10_val) or \
           not isinstance(last_close_val, Decimal) or pd.isna(last_close_val): # Added pd.isna checks
            return np.nan
        if last_close_val > sma_10_val: return 0.6
        elif last_close_val < sma_10_val: return -0.6
        else: return 0.0


    def _check_vwap(self) -> float:
        vwap_val = self.indicator_values.get("VWAP")
        last_close_val = self.indicator_values.get("Close")
        if not isinstance(vwap_val, Decimal) or pd.isna(vwap_val) or \
           not isinstance(last_close_val, Decimal) or pd.isna(last_close_val): # Added pd.isna checks
            return np.nan
        if last_close_val > vwap_val: return 0.7
        elif last_close_val < vwap_val: return -0.7
        else: return 0.0


    def _check_mfi(self) -> float:
        mfi = self.indicator_values.get("MFI")
        if pd.isna(mfi): return np.nan
        if mfi <= 20: return 1.0
        if mfi >= 80: return -1.0
        if mfi < 40: return 0.4
        if mfi > 60: return -0.4
        return 0.0


    def _check_bollinger_bands(self) -> float:
        bb_lower_val = self.indicator_values.get("BB_Lower")
        bb_middle_val = self.indicator_values.get("BB_Middle")
        bb_upper_val = self.indicator_values.get("BB_Upper")
        last_close_val = self.indicator_values.get("Close")

        if not all(isinstance(v, Decimal) and pd.notna(v) for v in [bb_lower_val, bb_middle_val, bb_upper_val, last_close_val]):
            return np.nan

        bb_lower, bb_middle, bb_upper, last_close = bb_lower_val, bb_middle_val, bb_upper_val, last_close_val

        if last_close <= bb_lower: return 1.0
        if last_close >= bb_upper: return -1.0

        band_width = bb_upper - bb_lower
        if band_width > 0:
            try:
                relative_position = (last_close - bb_middle) / (band_width / Decimal("2.0"))
                score = max(Decimal("-1.0"), min(Decimal("1.0"), relative_position))
                return float(score * Decimal("0.7"))
            except (InvalidOperation, ValueError, TypeError):
                 self.logger.warning(f"Error calculating relative position within Bollinger Bands for {self.symbol}.")
                 return 0.0
        return 0.0


    def _check_orderbook(self, orderbook_data: Optional[Dict], current_price: Decimal) -> float:
        if not orderbook_data:
            self.logger.debug(f"Orderbook check skipped for {self.symbol}: No data provided.")
            return np.nan
        try:
            bids = orderbook_data.get('bids', [])
            asks = orderbook_data.get('asks', [])
            if not bids or not asks:
                self.logger.debug(f"Orderbook check skipped for {self.symbol}: Missing bids or asks.")
                return np.nan

            num_levels_to_check = self.config.get("orderbook_check_levels", 10)
            top_bids = bids[:num_levels_to_check]
            top_asks = asks[:num_levels_to_check]
            bid_volume_sum = sum(Decimal(str(bid[1])) for bid in top_bids if len(bid) == 2 and pd.notna(bid[1])) 
            ask_volume_sum = sum(Decimal(str(ask[1])) for ask in top_asks if len(ask) == 2 and pd.notna(ask[1])) 
            total_volume = bid_volume_sum + ask_volume_sum

            if total_volume == 0:
                self.logger.debug(f"Orderbook check ({self.symbol}): Zero total volume in top {num_levels_to_check} levels.")
                return 0.0

            obi_decimal = (bid_volume_sum - ask_volume_sum) / total_volume
            score = float(obi_decimal)
            self.logger.debug(
                f"Orderbook check ({self.symbol}): Top {num_levels_to_check} levels -> "
                f"BidVol={bid_volume_sum:.4f}, AskVol={ask_volume_sum:.4f}, "
                f"OBI={obi_decimal:.4f} -> Score={score:.4f}"
            )
            return score
        except (InvalidOperation, ValueError, TypeError) as e:
             self.logger.warning(f"{NEON_YELLOW}Orderbook analysis failed for {self.symbol} (data conversion error): {e}{RESET}", exc_info=False)
             return np.nan
        except Exception as e:
            self.logger.warning(f"{NEON_YELLOW}Orderbook analysis failed for {self.symbol} (unexpected error): {e}{RESET}", exc_info=True)
            return np.nan


    # --- Risk Management Calculations ---
    def calculate_entry_tp_sl(
        self, entry_price_estimate: Decimal, signal: str
    ) -> Tuple[Optional[Decimal], Optional[Decimal], Optional[Decimal]]:
        if signal not in ["BUY", "SELL"]:
            self.logger.debug(f"TP/SL calculation skipped: Signal is '{signal}'.")
            return entry_price_estimate, None, None

        atr_val = self.indicator_values.get("ATR")

        if not isinstance(atr_val, Decimal) or pd.isna(atr_val) or atr_val <= 0:
            self.logger.warning(f"{NEON_YELLOW}Cannot calculate TP/SL for {self.symbol} {signal}: Invalid or missing ATR ({atr_val}).{RESET}")
            return entry_price_estimate, None, None
        if not isinstance(entry_price_estimate, Decimal) or pd.isna(entry_price_estimate) or entry_price_estimate <= 0:
            self.logger.warning(f"{NEON_YELLOW}Cannot calculate TP/SL for {self.symbol} {signal}: Invalid entry price estimate ({entry_price_estimate}).{RESET}")
            return entry_price_estimate, None, None

        try:
            tp_multiple_str = self.config.get("take_profit_multiple", "1.0")
            sl_multiple_str = self.config.get("stop_loss_multiple", "1.5")
            tp_multiple = Decimal(str(tp_multiple_str))
            sl_multiple = Decimal(str(sl_multiple_str))

            price_precision = get_price_precision(self.market_info, self.logger)
            min_tick = get_min_tick_size(self.market_info, self.logger)

            tp_offset = atr_val * tp_multiple
            sl_offset = atr_val * sl_multiple

            take_profit_raw: Optional[Decimal] = None
            stop_loss_raw: Optional[Decimal] = None

            if signal == "BUY":
                take_profit_raw = entry_price_estimate + tp_offset
                stop_loss_raw = entry_price_estimate - sl_offset
            elif signal == "SELL":
                take_profit_raw = entry_price_estimate - tp_offset
                stop_loss_raw = entry_price_estimate + sl_offset

            take_profit_quantized: Optional[Decimal] = None
            stop_loss_quantized: Optional[Decimal] = None
            rounding_factor_default = Decimal('1e-' + str(price_precision))

            if take_profit_raw is not None:
                 tp_rounding = ROUND_UP if signal == "BUY" else ROUND_DOWN
                 if min_tick is not None and min_tick > 0:
                     take_profit_quantized = (take_profit_raw / min_tick).quantize(Decimal('1'), rounding=tp_rounding) * min_tick
                 else:
                     take_profit_quantized = take_profit_raw.quantize(rounding_factor_default, rounding=tp_rounding)

            if stop_loss_raw is not None:
                 sl_rounding = ROUND_DOWN if signal == "BUY" else ROUND_UP
                 if min_tick is not None and min_tick > 0:
                     stop_loss_quantized = (stop_loss_raw / min_tick).quantize(Decimal('1'), rounding=sl_rounding) * min_tick
                 else:
                     stop_loss_quantized = stop_loss_raw.quantize(rounding_factor_default, rounding=sl_rounding)

            final_tp = take_profit_quantized
            final_sl = stop_loss_quantized

            if final_sl is not None and min_tick is not None and min_tick > 0:
                 if signal == "BUY" and final_sl >= entry_price_estimate:
                      final_sl = ((entry_price_estimate - min_tick) / min_tick).quantize(Decimal('1'), rounding=ROUND_DOWN) * min_tick
                 elif signal == "SELL" and final_sl <= entry_price_estimate:
                      final_sl = ((entry_price_estimate + min_tick) / min_tick).quantize(Decimal('1'), rounding=ROUND_UP) * min_tick

            if final_tp is not None:
                 if signal == "BUY" and final_tp <= entry_price_estimate:
                      self.logger.warning(f"{NEON_YELLOW}BUY TP calculation non-profitable (TP {final_tp} <= Entry {entry_price_estimate}). Setting TP to None.{RESET}")
                      final_tp = None
                 elif signal == "SELL" and final_tp >= entry_price_estimate:
                      self.logger.warning(f"{NEON_YELLOW}SELL TP calculation non-profitable (TP {final_tp} >= Entry {entry_price_estimate}). Setting TP to None.{RESET}")
                      final_tp = None

            if final_sl is not None and final_sl <= 0:
                self.logger.error(f"{NEON_RED}Stop loss calculation resulted in non-positive price ({final_sl}). Setting SL to None.{RESET}")
                final_sl = None
            if final_tp is not None and final_tp <= 0:
                self.logger.warning(f"{NEON_YELLOW}Take profit calculation resulted in non-positive price ({final_tp}). Setting TP to None.{RESET}")
                final_tp = None
            
            tp_str = f"{final_tp:.{price_precision}f}" if final_tp else "None"
            sl_str = f"{final_sl:.{price_precision}f}" if final_sl else "None"
            self.logger.debug(
                f"Calculated TP/SL for {self.symbol} {signal}: "
                f"EntryEst={entry_price_estimate:.{price_precision}f}, "
                f"ATR={atr_val:.{price_precision+1}f}, "
                f"TP={tp_str} (Mult: {tp_multiple}), "
                f"SL={sl_str} (Mult: {sl_multiple})"
            )
            return entry_price_estimate, final_tp, final_sl

        except (InvalidOperation, ValueError, TypeError) as e:
             self.logger.error(f"{NEON_RED}Error calculating TP/SL for {self.symbol} {signal} (Decimal/Type Error): {e}{RESET}", exc_info=False)
             return entry_price_estimate, None, None
        except Exception as e:
             self.logger.error(f"{NEON_RED}Unexpected error calculating TP/SL for {self.symbol} {signal}: {e}{RESET}", exc_info=True)
             return entry_price_estimate, None, None