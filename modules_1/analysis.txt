# File: analysis.py
import logging
from decimal import Decimal, ROUND_DOWN, ROUND_UP, InvalidOperation
from typing import Any, Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
import pandas_ta as ta

# Import constants and utility functions
from utils import (CCXT_INTERVAL_MAP, DEFAULT_INDICATOR_PERIODS, FIB_LEVELS,
                   NEON_GREEN, NEON_RED, NEON_YELLOW, RESET,
                   get_min_tick_size, get_price_precision)

# Define constants for frequently used keys to avoid typos
ATR_KEY = "ATR"
EMA_SHORT_KEY = "EMA_Short"
EMA_LONG_KEY = "EMA_Long"
MOMENTUM_KEY = "Momentum"
CCI_KEY = "CCI"
WILLIAMS_R_KEY = "Williams_R"
MFI_KEY = "MFI"
VWAP_KEY = "VWAP"
PSAR_LONG_KEY = "PSAR_long"
PSAR_SHORT_KEY = "PSAR_short"
SMA10_KEY = "SMA10"
STOCHRSI_K_KEY = "StochRSI_K"
STOCHRSI_D_KEY = "StochRSI_D"
RSI_KEY = "RSI"
BB_LOWER_KEY = "BB_Lower"
BB_MIDDLE_KEY = "BB_Middle"
BB_UPPER_KEY = "BB_Upper"
VOLUME_MA_KEY = "Volume_MA"
OPEN_KEY = "Open"
HIGH_KEY = "High"
LOW_KEY = "Low"
CLOSE_KEY = "Close"
VOLUME_KEY = "Volume"

# Keys for indicators that should ideally be stored as Decimal for precision
# Primarily price-based values and ATR. Others can often be float.
DECIMAL_INDICATOR_KEYS = {ATR_KEY, OPEN_KEY, HIGH_KEY, LOW_KEY, CLOSE_KEY, VOLUME_KEY,
                          BB_LOWER_KEY, BB_MIDDLE_KEY, BB_UPPER_KEY, PSAR_LONG_KEY, PSAR_SHORT_KEY}


class TradingAnalyzer:
    """
    Analyzes trading data using pandas_ta, generates weighted signals,
    calculates Fibonacci levels, and determines potential TP/SL points.
    """

    def __init__(
        self,
        df: pd.DataFrame,
        logger: logging.Logger,
        config: Dict[str, Any],
        market_info: Dict[str, Any],
    ) -> None:
        """
        Initializes the TradingAnalyzer.

        Args:
            df: Pandas DataFrame with OHLCV data, indexed by timestamp.
                Must contain columns: 'open', 'high', 'low', 'close', 'volume'.
            logger: Logger instance for logging messages.
            config: Dictionary containing bot configuration, including indicator settings,
                    weights, and thresholds.
            market_info: Dictionary containing market details (precision, limits, symbol, etc.).
        """
        if not isinstance(df, pd.DataFrame):
            raise TypeError("Input 'df' must be a pandas DataFrame.")
        if not all(col in df.columns for col in ['open', 'high', 'low', 'close', 'volume']):
            raise ValueError("DataFrame must contain 'open', 'high', 'low', 'close', 'volume' columns.")

        self.df = df.copy() # Work on a copy to avoid modifying the original externally
        self.logger = logger
        self.config = config
        self.market_info = market_info
        self.symbol = market_info.get('symbol', 'UNKNOWN_SYMBOL')
        self.interval = config.get("interval", "5m") # Default to '5m' if missing

        # Map interval to CCXT format
        self.ccxt_interval = CCXT_INTERVAL_MAP.get(self.interval)
        if not self.ccxt_interval:
             # Log error but allow continuation if possible, fetching might fail later
             self.logger.error(f"Invalid interval '{self.interval}' in config for {self.symbol}, cannot map to CCXT timeframe. Calculation logic might proceed, but data fetching will likely fail.")

        # Stores latest calculated indicator values (float or Decimal)
        self.indicator_values: Dict[str, Any] = {}
        # Stores binary signal states (BUY:1, SELL:1, HOLD:1) - only one can be 1
        self.signals: Dict[str, int] = {"BUY": 0, "SELL": 0, "HOLD": 1} # Default HOLD
        # Get the name of the active weight set from config
        self.active_weight_set_name = config.get("active_weight_set", "default")
        # Get the actual weight dictionary for the active set
        self.weights = config.get("weight_sets", {}).get(self.active_weight_set_name, {})
        # Stores calculated Fibonacci levels
        self.fib_levels_data: Dict[str, Decimal] = {}
        # Stores the actual column names generated by pandas_ta for mapping
        self.ta_column_names: Dict[str, Optional[str]] = {}

        if not self.weights:
             # Log error, consider raising an exception if weights are essential
             logger.error(f"Active weight set '{self.active_weight_set_name}' not found or empty in config for {self.symbol}. Signal generation will likely fail or produce HOLD.")
             # Depending on requirements, could raise ValueError here.

        # Perform initial calculations upon instantiation
        self._calculate_all_indicators()
        self._update_latest_indicator_values()
        self.calculate_fibonacci_levels() # Calculate Fib levels based on initial data


    def _get_ta_col_name(self, base_name: str, result_df: pd.DataFrame) -> Optional[str]:
        """
        Helper to find the actual column name generated by pandas_ta based on common patterns.
        Relies on pandas_ta naming conventions.

        Args:
            base_name: The conceptual name of the indicator (e.g., "ATR", "EMA_Short").
            result_df: The DataFrame containing the calculated indicator columns.

        Returns:
            The actual column name if found, otherwise None.
        """
        # Use DEFAULT_INDICATOR_PERIODS as fallback if key missing in config
        def get_period(key, default_key=None):
             # Check top-level config first, then indicator-specific config
             val = self.config.get(key)
             if val is None:
                 val = self.config.get("indicators", {}).get(key) # Check under 'indicators' too
             # Fallback to default if still not found
             if val is None:
                 default_key = default_key or key # Use key itself if no specific default key given
                 val = DEFAULT_INDICATOR_PERIODS.get(default_key)
             return val

        # Define expected patterns for pandas_ta column names
        # These are based on common pandas_ta outputs and may need adjustment
        # if pandas_ta changes its naming or specific parameters are used.
        expected_patterns = {
            ATR_KEY: [f"ATRr_{get_period('atr_period')}"],
            EMA_SHORT_KEY: [f"EMA_{get_period('ema_short_period')}"],
            EMA_LONG_KEY: [f"EMA_{get_period('ema_long_period')}"],
            MOMENTUM_KEY: [f"MOM_{get_period('momentum_period')}"],
            CCI_KEY: [f"CCI_{get_period('cci_window')}_{get_period('cci_constant', 'cci_constant'):.1f}", f"CCI_{get_period('cci_window')}"], # CCI can include constant
            WILLIAMS_R_KEY: [f"WILLR_{get_period('williams_r_window')}"],
            MFI_KEY: [f"MFI_{get_period('mfi_window')}"],
            VWAP_KEY: ["VWAP_D"], # Often includes anchor like 'D' for daily
            PSAR_LONG_KEY: [f"PSARl_{get_period('psar_af', 'psar_af'):.2f}_{get_period('psar_max_af', 'psar_max_af'):.2f}"], # PSAR includes af/max_af
            PSAR_SHORT_KEY: [f"PSARs_{get_period('psar_af', 'psar_af'):.2f}_{get_period('psar_max_af', 'psar_max_af'):.2f}"],
            SMA10_KEY: [f"SMA_{get_period('sma_10_window')}"],
            STOCHRSI_K_KEY: [
                f"STOCHRSIk_{get_period('stoch_rsi_window')}_{get_period('stoch_rsi_rsi_window')}_{get_period('stoch_rsi_k')}_{get_period('stoch_rsi_d')}", # Sometimes includes D period too
                f"STOCHRSIk_{get_period('stoch_rsi_window')}_{get_period('stoch_rsi_rsi_window')}_{get_period('stoch_rsi_k')}"
            ],
            STOCHRSI_D_KEY: [
                f"STOCHRSId_{get_period('stoch_rsi_window')}_{get_period('stoch_rsi_rsi_window')}_{get_period('stoch_rsi_k')}_{get_period('stoch_rsi_d')}"
            ],
            RSI_KEY: [f"RSI_{get_period('rsi_period')}"],
            BB_LOWER_KEY: [
                f"BBL_{get_period('bollinger_bands_period')}_{float(get_period('bollinger_bands_std_dev')):.1f}"
            ],
            BB_MIDDLE_KEY: [
                f"BBM_{get_period('bollinger_bands_period')}_{float(get_period('bollinger_bands_std_dev')):.1f}"
            ],
            BB_UPPER_KEY: [
                f"BBU_{get_period('bollinger_bands_period')}_{float(get_period('bollinger_bands_std_dev')):.1f}"
            ],
            VOLUME_MA_KEY: [f"VOL_SMA_{get_period('volume_ma_period')}"] # Custom name used in calc
        }

        patterns = expected_patterns.get(base_name, [])
        # Search dataframe columns for a match starting with any pattern
        for col in result_df.columns:
             for pattern in patterns:
                 # Use startswith for flexibility (e.g., CCI might have CCI_20_100.0)
                 if col.startswith(pattern):
                     self.logger.debug(f"Mapped '{base_name}' to column '{col}' for {self.symbol}")
                     return col

        # Fallback: Simple substring search (less reliable but might catch variations)
        # Convert base_name to lower for case-insensitive fallback search
        base_name_lower = base_name.lower()
        # Prioritize exact match if possible during fallback
        if base_name in result_df.columns:
             self.logger.debug(f"Found column '{base_name}' for base '{base_name}' using exact match fallback.")
             return base_name
        # Then try case-insensitive substring
        for col in result_df.columns:
            if base_name_lower in col.lower():
                self.logger.debug(f"Found column '{col}' for base '{base_name}' using fallback substring search.")
                return col

        self.logger.warning(f"Could not find column name for indicator '{base_name}' in DataFrame columns for {self.symbol}: {result_df.columns.tolist()}")
        return None


    def _calculate_all_indicators(self):
        """Calculates all enabled indicators using pandas_ta and stores column names."""
        if self.df.empty:
            self.logger.warning(f"{NEON_YELLOW}DataFrame is empty, cannot calculate indicators for {self.symbol}.{RESET}")
            return

        # --- Check Sufficient Data Length ---
        # Use DEFAULT_INDICATOR_PERIODS as fallback if key missing in config
        def get_period(key, default_key=None):
             # Check top-level config first, then indicator-specific config
             val = self.config.get(key)
             if val is None:
                 val = self.config.get("indicators", {}).get(key) # Check under 'indicators' too
             # Fallback to default if still not found
             if val is None:
                 default_key = default_key or key # Use key itself if no specific default key given
                 val = DEFAULT_INDICATOR_PERIODS.get(default_key)
             # Ensure period is an integer
             try:
                 return int(val) if val is not None else None
             except (ValueError, TypeError):
                 self.logger.warning(f"Invalid non-integer period value '{val}' for key '{key}'. Using default.")
                 return DEFAULT_INDICATOR_PERIODS.get(default_key or key)

        # Create a list of required periods based on enabled indicators in config
        required_periods = []
        indicators_config = self.config.get("indicators", {})

        # Check if indicator is enabled AND get its period
        if indicators_config.get("atr", True): # ATR is often essential, default enable check to True
            required_periods.append(get_period("atr_period"))
        if indicators_config.get("ema_alignment", False):
            required_periods.append(get_period("ema_short_period"))
            required_periods.append(get_period("ema_long_period"))
        if indicators_config.get("momentum", False): required_periods.append(get_period("momentum_period"))
        if indicators_config.get("cci", False): required_periods.append(get_period("cci_window"))
        if indicators_config.get("wr", False): required_periods.append(get_period("williams_r_window"))
        if indicators_config.get("mfi", False): required_periods.append(get_period("mfi_window"))
        # VWAP doesn't have a standard period parameter in basic ta.vwap
        # PSAR doesn't have a length period, uses af/max_af
        if indicators_config.get("sma_10", False): required_periods.append(get_period("sma_10_window"))
        if indicators_config.get("stoch_rsi", False):
            required_periods.append(get_period("stoch_rsi_window"))
            required_periods.append(get_period("stoch_rsi_rsi_window"))
            # K and D periods are applied after StochRSI calc, main windows are limiting factors
        if indicators_config.get("rsi", False): required_periods.append(get_period("rsi_period"))
        if indicators_config.get("bollinger_bands", False): required_periods.append(get_period("bollinger_bands_period"))
        if indicators_config.get("volume_confirmation", False): required_periods.append(get_period("volume_ma_period"))
        # Fibonacci window for price range, not strictly an indicator period but needs data
        required_periods.append(get_period("fibonacci_window"))

        # Filter out None values from periods list before finding max
        valid_periods = [p for p in required_periods if p is not None and p > 0]

        # Determine minimum data length needed (max period + some buffer)
        min_required_data = max(valid_periods) + 20 if valid_periods else 50 # Default min 50 if no periods found

        if len(self.df) < min_required_data:
             self.logger.warning(f"{NEON_YELLOW}Insufficient data ({len(self.df)} points) for {self.symbol} to calculate all indicators reliably (min recommended: {min_required_data}). Results may contain NaNs.{RESET}")
             # Continue calculation, but expect potential issues

        try:
            # Work on a copy to avoid modifying the original DataFrame passed to the class
            df_calc = self.df.copy()

            # --- Always calculate ATR if enabled or needed ---
            # ATR is crucial for SL/TP/Sizing, calculate if enabled or default enabled
            if indicators_config.get("atr", True):
                atr_period = get_period("atr_period")
                if atr_period:
                    # Use pandas_ta's atr method
                    df_calc.ta.atr(length=atr_period, append=True)
                    # Find and store the actual column name generated by ta.atr
                    self.ta_column_names[ATR_KEY] = self._get_ta_col_name(ATR_KEY, df_calc)
                else:
                    self.logger.warning(f"ATR calculation skipped for {self.symbol}: Invalid period ({atr_period}).")

            # --- Calculate indicators based on config ---
            if indicators_config.get("ema_alignment", False):
                ema_short = get_period("ema_short_period")
                ema_long = get_period("ema_long_period")
                if ema_short and ema_long:
                    df_calc.ta.ema(length=ema_short, append=True)
                    self.ta_column_names[EMA_SHORT_KEY] = self._get_ta_col_name(EMA_SHORT_KEY, df_calc)
                    df_calc.ta.ema(length=ema_long, append=True)
                    self.ta_column_names[EMA_LONG_KEY] = self._get_ta_col_name(EMA_LONG_KEY, df_calc)
                else:
                     self.logger.warning(f"EMA Alignment calculation skipped for {self.symbol}: Invalid periods (Short: {ema_short}, Long: {ema_long}).")

            if indicators_config.get("momentum", False):
                mom_period = get_period("momentum_period")
                if mom_period:
                    df_calc.ta.mom(length=mom_period, append=True)
                    self.ta_column_names[MOMENTUM_KEY] = self._get_ta_col_name(MOMENTUM_KEY, df_calc)
                else:
                    self.logger.warning(f"Momentum calculation skipped for {self.symbol}: Invalid period ({mom_period}).")

            if indicators_config.get("cci", False):
                cci_period = get_period("cci_window")
                cci_constant = float(self.config.get("cci_constant", DEFAULT_INDICATOR_PERIODS['cci_constant']))
                if cci_period:
                    df_calc.ta.cci(length=cci_period, constant=cci_constant, append=True)
                    self.ta_column_names[CCI_KEY] = self._get_ta_col_name(CCI_KEY, df_calc)
                else:
                    self.logger.warning(f"CCI calculation skipped for {self.symbol}: Invalid period ({cci_period}).")

            if indicators_config.get("wr", False):
                wr_period = get_period("williams_r_window")
                if wr_period:
                    df_calc.ta.willr(length=wr_period, append=True)
                    self.ta_column_names[WILLIAMS_R_KEY] = self._get_ta_col_name(WILLIAMS_R_KEY, df_calc)
                else:
                    self.logger.warning(f"Williams %R calculation skipped for {self.symbol}: Invalid period ({wr_period}).")

            if indicators_config.get("mfi", False):
                mfi_period = get_period("mfi_window")
                if mfi_period:
                    df_calc.ta.mfi(length=mfi_period, append=True)
                    self.ta_column_names[MFI_KEY] = self._get_ta_col_name(MFI_KEY, df_calc)
                else:
                    self.logger.warning(f"MFI calculation skipped for {self.symbol}: Invalid period ({mfi_period}).")

            if indicators_config.get("vwap", False):
                # Standard VWAP often anchors daily ('D'). Ensure your data covers enough time.
                # pandas_ta's default might be daily anchored. Check behavior if needed.
                df_calc.ta.vwap(append=True) # Use default settings first
                self.ta_column_names[VWAP_KEY] = self._get_ta_col_name(VWAP_KEY, df_calc)

            if indicators_config.get("psar", False):
                psar_af = float(self.config.get('psar_af', DEFAULT_INDICATOR_PERIODS['psar_af']))
                psar_max_af = float(self.config.get('psar_max_af', DEFAULT_INDICATOR_PERIODS['psar_max_af']))
                # psar returns a DataFrame with multiple columns (long, short, af, reversal)
                psar_result = df_calc.ta.psar(af=psar_af, max_af=psar_max_af)
                if psar_result is not None and not psar_result.empty:
                    # Concatenate the results back to the main calculation DataFrame
                    df_calc = pd.concat([df_calc, psar_result], axis=1)
                    # Get the column names for long and short PSAR signals
                    self.ta_column_names[PSAR_LONG_KEY] = self._get_ta_col_name(PSAR_LONG_KEY, df_calc)
                    self.ta_column_names[PSAR_SHORT_KEY] = self._get_ta_col_name(PSAR_SHORT_KEY, df_calc)
                else:
                    self.logger.warning(f"PSAR calculation did not return results for {self.symbol}.")

            if indicators_config.get("sma_10", False):
                sma10_period = get_period("sma_10_window")
                if sma10_period:
                    df_calc.ta.sma(length=sma10_period, append=True)
                    self.ta_column_names[SMA10_KEY] = self._get_ta_col_name(SMA10_KEY, df_calc)
                else:
                    self.logger.warning(f"SMA10 calculation skipped for {self.symbol}: Invalid period ({sma10_period}).")

            if indicators_config.get("stoch_rsi", False):
                stoch_rsi_len = get_period("stoch_rsi_window")
                stoch_rsi_rsi_len = get_period("stoch_rsi_rsi_window")
                stoch_rsi_k = get_period("stoch_rsi_k")
                stoch_rsi_d = get_period("stoch_rsi_d")
                if all([stoch_rsi_len, stoch_rsi_rsi_len, stoch_rsi_k, stoch_rsi_d]):
                    # stochrsi returns a DataFrame with K and D columns
                    stochrsi_result = df_calc.ta.stochrsi(length=stoch_rsi_len, rsi_length=stoch_rsi_rsi_len, k=stoch_rsi_k, d=stoch_rsi_d)
                    if stochrsi_result is not None and not stochrsi_result.empty:
                         df_calc = pd.concat([df_calc, stochrsi_result], axis=1)
                         # Get the specific column names for K and D
                         self.ta_column_names[STOCHRSI_K_KEY] = self._get_ta_col_name(STOCHRSI_K_KEY, df_calc)
                         self.ta_column_names[STOCHRSI_D_KEY] = self._get_ta_col_name(STOCHRSI_D_KEY, df_calc)
                    else:
                         self.logger.warning(f"StochRSI calculation did not return results for {self.symbol}.")
                else:
                     self.logger.warning(f"StochRSI calculation skipped for {self.symbol}: Invalid parameters (Len:{stoch_rsi_len}, RsiLen:{stoch_rsi_rsi_len}, K:{stoch_rsi_k}, D:{stoch_rsi_d}).")

            if indicators_config.get("rsi", False):
                rsi_period = get_period("rsi_period")
                if rsi_period:
                    df_calc.ta.rsi(length=rsi_period, append=True)
                    self.ta_column_names[RSI_KEY] = self._get_ta_col_name(RSI_KEY, df_calc)
                else:
                    self.logger.warning(f"RSI calculation skipped for {self.symbol}: Invalid period ({rsi_period}).")

            if indicators_config.get("bollinger_bands", False):
                bb_period = get_period("bollinger_bands_period")
                bb_std = float(self.config.get('bollinger_bands_std_dev', DEFAULT_INDICATOR_PERIODS['bollinger_bands_std_dev']))
                if bb_period:
                    # bbands returns a DataFrame with lower, middle, upper, bandwidth, percent
                    bbands_result = df_calc.ta.bbands(length=bb_period, std=bb_std)
                    if bbands_result is not None and not bbands_result.empty:
                        # Concatenate results back
                        df_calc = pd.concat([df_calc, bbands_result], axis=1)
                        # Get column names for lower, middle, upper bands
                        self.ta_column_names[BB_LOWER_KEY] = self._get_ta_col_name(BB_LOWER_KEY, df_calc)
                        self.ta_column_names[BB_MIDDLE_KEY] = self._get_ta_col_name(BB_MIDDLE_KEY, df_calc)
                        self.ta_column_names[BB_UPPER_KEY] = self._get_ta_col_name(BB_UPPER_KEY, df_calc)
                    else:
                         self.logger.warning(f"Bollinger Bands calculation did not return results for {self.symbol}.")
                else:
                    self.logger.warning(f"Bollinger Bands calculation skipped for {self.symbol}: Invalid period ({bb_period}).")

            if indicators_config.get("volume_confirmation", False):
                vol_ma_period = get_period("volume_ma_period")
                if vol_ma_period:
                    # Use a distinct name for the volume MA column
                    vol_ma_col_name = f"VOL_SMA_{vol_ma_period}"
                    # Calculate SMA on the 'volume' column, filling potential NaNs with 0 for calculation
                    df_calc[vol_ma_col_name] = ta.sma(df_calc['volume'].fillna(0), length=vol_ma_period)
                    # Store the custom column name
                    self.ta_column_names[VOLUME_MA_KEY] = vol_ma_col_name
                else:
                    self.logger.warning(f"Volume MA calculation skipped for {self.symbol}: Invalid period ({vol_ma_period}).")

            # Update the instance's DataFrame with the calculated indicators
            self.df = df_calc
            self.logger.debug(f"Finished indicator calculations for {self.symbol}. Final DF columns: {self.df.columns.tolist()}")

        except AttributeError as e:
             # This can happen if pandas_ta methods are called incorrectly or on incompatible data
             self.logger.error(f"{NEON_RED}AttributeError calculating indicators for {self.symbol}: {e}{RESET}. Check pandas_ta usage and data.", exc_info=True)
        except Exception as e:
            # Catch any other unexpected errors during calculation
            self.logger.error(f"{NEON_RED}Error calculating indicators with pandas_ta for {self.symbol}: {e}{RESET}", exc_info=True)


    def _update_latest_indicator_values(self):
        """Updates the indicator_values dict with the latest (most recent) values from self.df."""
        if self.df.empty:
            self.logger.warning(f"Cannot update latest values: DataFrame empty for {self.symbol}.")
            # Initialize with NaNs if empty
            self.indicator_values = {k: np.nan for k in list(self.ta_column_names.keys()) + [OPEN_KEY, HIGH_KEY, LOW_KEY, CLOSE_KEY, VOLUME_KEY]}
            return
        if self.df.iloc[-1].isnull().all():
            self.logger.warning(f"Cannot update latest values: Last row contains all NaNs for {self.symbol}.")
            # Initialize with NaNs if last row is unusable
            self.indicator_values = {k: np.nan for k in list(self.ta_column_names.keys()) + [OPEN_KEY, HIGH_KEY, LOW_KEY, CLOSE_KEY, VOLUME_KEY]}
            return

        try:
            # Get the last row (most recent data)
            latest = self.df.iloc[-1]
            updated_values = {}

            # --- Process TA indicator columns stored in ta_column_names ---
            for key, col_name in self.ta_column_names.items():
                if col_name and col_name in latest.index:
                    value = latest[col_name]
                    # Check if the value is valid (not NaN)
                    if pd.notna(value):
                        try:
                            # Store specific keys as Decimal, others as float
                            if key in DECIMAL_INDICATOR_KEYS:
                                updated_values[key] = Decimal(str(value))
                            else:
                                updated_values[key] = float(value)
                        except (ValueError, TypeError, InvalidOperation) as conv_err:
                            self.logger.warning(f"Could not convert value for {key} ('{col_name}': {value}) for {self.symbol}. Storing NaN. Error: {conv_err}")
                            updated_values[key] = np.nan
                    else:
                        # Store NaN if the value in the DataFrame is NaN
                        updated_values[key] = np.nan
                else:
                    # Log if the column was expected but not found (and calculation was attempted)
                    if key in self.ta_column_names: # Check if key exists (meaning calc was attempted)
                        self.logger.debug(f"Indicator column '{col_name}' for key '{key}' not found in latest data row for {self.symbol}. Storing NaN.")
                    updated_values[key] = np.nan # Store NaN if column missing

            # --- Add essential price/volume data (potentially overwriting if also in ta_column_names) ---
            # These are directly from the OHLCV data, ensure they are Decimal
            for base_col, key_name in [('open', OPEN_KEY), ('high', HIGH_KEY), ('low', LOW_KEY), ('close', CLOSE_KEY), ('volume', VOLUME_KEY)]:
                 value = latest.get(base_col) # Use .get() for safety if column might be missing
                 if pd.notna(value):
                      try:
                           updated_values[key_name] = Decimal(str(value))
                      except (ValueError, TypeError, InvalidOperation) as conv_err:
                           self.logger.warning(f"Could not convert base value for '{base_col}' ({value}) to Decimal for {self.symbol}. Storing NaN. Error: {conv_err}")
                           updated_values[key_name] = np.nan
                 else:
                      updated_values[key_name] = np.nan # Store NaN if base value is missing/NaN

            # Update the instance's dictionary
            self.indicator_values = updated_values

            # --- Log the updated values (formatted for readability) ---
            # Create a dictionary for logging, formatting Decimals and floats appropriately
            valid_values_log = {}
            price_prec = get_price_precision(self.market_info, self.logger) # Use utility function
            for k, v in self.indicator_values.items():
                 if pd.notna(v):
                     if isinstance(v, Decimal):
                          # Determine precision for logging (more for price/ATR, less for volume?)
                          # Use market price precision for price-related values
                          prec = price_prec if k in DECIMAL_INDICATOR_KEYS - {VOLUME_KEY} else 6 # More precision for price-like decimals
                          # Avoid scientific notation for small numbers if possible, format nicely
                          valid_values_log[k] = f"{v:.{prec}f}"
                     elif isinstance(v, float):
                          # Format floats with reasonable precision for indicators
                          valid_values_log[k] = f"{v:.5f}"
                     else: # Handle other types if necessary (e.g., strings, though unlikely here)
                          valid_values_log[k] = str(v)
                 # Optionally include NaN values in the log
                 # else:
                 #     valid_values_log[k] = "NaN"

            self.logger.debug(f"Latest indicator values updated for {self.symbol}: {valid_values_log}")

        except IndexError:
             # This error occurs if the DataFrame is empty or iloc[-1] fails
             self.logger.error(f"Error accessing latest row (iloc[-1]) for {self.symbol}. DataFrame might be empty or too short after cleaning.")
             # Reset to NaNs if access fails
             self.indicator_values = {k: np.nan for k in list(self.ta_column_names.keys()) + [OPEN_KEY, HIGH_KEY, LOW_KEY, CLOSE_KEY, VOLUME_KEY]}
        except Exception as e:
             # Catch any other unexpected errors during the update process
             self.logger.error(f"Unexpected error updating latest indicator values for {self.symbol}: {e}", exc_info=True)
             # Reset to NaNs as a safety measure
             self.indicator_values = {k: np.nan for k in list(self.ta_column_names.keys()) + [OPEN_KEY, HIGH_KEY, LOW_KEY, CLOSE_KEY, VOLUME_KEY]}

    # --- Fibonacci Calculation ---
    def calculate_fibonacci_levels(self, window: Optional[int] = None) -> Dict[str, Decimal]:
        """
        Calculates Fibonacci retracement levels based on the high/low over a specified window.
        Uses Decimal for precision. Stores results in self.fib_levels_data.

        Args:
            window: The number of recent periods (candles) to consider for high/low.
                    Defaults to the value in config['fibonacci_window'].

        Returns:
            A dictionary where keys are Fibonacci level names (e.g., "Fib_23.6%")
            and values are the corresponding price levels as Decimal objects.
            Returns an empty dictionary if calculation is not possible.
        """
        # Use provided window or get from config, falling back to default
        try:
            window_val = window or self.config.get("fibonacci_window", DEFAULT_INDICATOR_PERIODS['fibonacci_window'])
            window = int(window_val)
            if window <= 0:
                raise ValueError("Fibonacci window must be positive.")
        except (ValueError, TypeError):
             self.logger.warning(f"Invalid Fibonacci window '{window_val}'. Using default {DEFAULT_INDICATOR_PERIODS['fibonacci_window']}.")
             window = DEFAULT_INDICATOR_PERIODS['fibonacci_window']

        # Check if DataFrame is long enough for the window
        if len(self.df) < window:
            self.logger.debug(f"Not enough data ({len(self.df)} points) for Fibonacci window ({window}) on {self.symbol}.")
            self.fib_levels_data = {} # Clear any previous data
            return {}

        # Get the relevant slice of the DataFrame
        df_slice = self.df.tail(window)

        try:
            # Find the maximum high and minimum low in the window, drop NaNs first
            high_price_raw = df_slice["high"].dropna().max()
            low_price_raw = df_slice["low"].dropna().min()

            # Check if valid high/low prices were found
            if pd.isna(high_price_raw) or pd.isna(low_price_raw):
                 self.logger.warning(f"Could not find valid high/low prices within the last {window} periods for Fibonacci calculation on {self.symbol}.")
                 self.fib_levels_data = {}
                 return {}

            # Convert raw high/low to Decimal
            high = Decimal(str(high_price_raw))
            low = Decimal(str(low_price_raw))

            # Calculate the difference (range)
            diff = high - low

            # Initialize the levels dictionary
            levels = {}
            # Get market price precision and tick size for rounding
            price_precision = get_price_precision(self.market_info, self.logger)
            min_tick_size = get_min_tick_size(self.market_info, self.logger)

            # Check if there's a valid range (high > low)
            if diff > 0:
                # Calculate each Fibonacci level
                for level_pct in FIB_LEVELS:
                    level_name = f"Fib_{level_pct * 100:.1f}%"
                    # Calculate level price: High - (Range * Percentage)
                    level_price_raw = high - (diff * Decimal(str(level_pct)))

                    # Quantize the calculated price to the market's tick size/precision
                    # Use ROUND_DOWN for levels based on range from high (conservative support)
                    if min_tick_size > 0:
                        # Ensure quantization doesn't result in zero or negative price
                        if level_price_raw > 0:
                            level_price_quantized = (level_price_raw / min_tick_size).quantize(Decimal('1'), rounding=ROUND_DOWN) * min_tick_size
                            # Ensure quantized value is still positive
                            level_price_quantized = max(min_tick_size, level_price_quantized)
                        else:
                            level_price_quantized = min_tick_size # Set to minimum possible price if calculation goes non-positive
                    else: # Fallback to decimal places
                        rounding_factor = Decimal('1e-' + str(price_precision))
                        level_price_quantized = level_price_raw.quantize(rounding_factor, rounding=ROUND_DOWN)
                        # Ensure positive after rounding
                        level_price_quantized = max(rounding_factor, level_price_quantized)

                    levels[level_name] = level_price_quantized
            else:
                 # Handle case where high == low (no range)
                 self.logger.debug(f"Fibonacci range is zero or negative (High={high}, Low={low}) for {self.symbol} over last {window} periods. All levels set to High/Low.")
                 # Quantize the single price level
                 if min_tick_size > 0:
                     level_price_quantized = (high / min_tick_size).quantize(Decimal('1'), rounding=ROUND_DOWN) * min_tick_size
                     level_price_quantized = max(min_tick_size, level_price_quantized) # Ensure positive
                 else: # Fallback
                     rounding_factor = Decimal('1e-' + str(price_precision))
                     level_price_quantized = high.quantize(rounding_factor, rounding=ROUND_DOWN)
                     level_price_quantized = max(rounding_factor, level_price_quantized) # Ensure positive
                 # Assign this price to all levels
                 for level_pct in FIB_LEVELS:
                     levels[f"Fib_{level_pct * 100:.1f}%"] = level_price_quantized

            # Store the calculated levels in the instance variable
            self.fib_levels_data = levels
            # Log the calculated levels (convert Decimals to strings for logging)
            log_levels = {k: str(v) for k, v in levels.items()}
            self.logger.debug(f"Calculated Fibonacci levels for {self.symbol} (Window: {window}): {log_levels}")
            return levels

        except KeyError as e:
             self.logger.error(f"{NEON_RED}Fibonacci calculation error for {self.symbol}: Missing column '{e}'. Ensure 'high' and 'low' columns exist.{RESET}")
             self.fib_levels_data = {}
             return {}
        except Exception as e:
            # Catch any other unexpected errors
            self.logger.error(f"{NEON_RED}Unexpected Fibonacci calculation error for {self.symbol}: {e}{RESET}", exc_info=True)
            self.fib_levels_data = {}
            return {}

    def get_nearest_fibonacci_levels(
        self, current_price: Decimal, num_levels: int = 5
    ) -> list[Tuple[str, Decimal]]:
        """
        Finds the N nearest Fibonacci levels (support and resistance) to the current price.

        Args:
            current_price: The current market price as a Decimal.
            num_levels: The maximum number of nearest levels (combined support/resistance) to return.

        Returns:
            A list of tuples, where each tuple contains (level_name, level_price).
            The list is sorted by proximity to the current price. Returns empty list on error.
        """
        # Check if Fibonacci levels have been calculated
        if not self.fib_levels_data:
            self.logger.debug(f"Fibonacci levels not calculated yet for {self.symbol}. Cannot find nearest.")
            return []
        # Validate input price
        if not isinstance(current_price, Decimal) or pd.isna(current_price) or current_price <= 0:
            self.logger.warning(f"Invalid current price ({current_price}) provided for Fibonacci comparison on {self.symbol}.")
            return []
        # Validate num_levels
        if not isinstance(num_levels, int) or num_levels <= 0:
            self.logger.warning(f"Invalid num_levels ({num_levels}) provided for Fibonacci comparison. Using default 5.")
            num_levels = 5

        try:
            level_distances = []
            # Iterate through the calculated Fibonacci levels
            for name, level_price in self.fib_levels_data.items():
                # Ensure the level price is a valid Decimal
                if isinstance(level_price, Decimal) and level_price > 0:
                    # Calculate the absolute distance between current price and level price
                    distance = abs(current_price - level_price)
                    # Store name, price, and distance
                    level_distances.append({'name': name, 'level': level_price, 'distance': distance})
                else:
                     self.logger.warning(f"Invalid or non-decimal value found in fib_levels_data: {name}={level_price}. Skipping.")

            # Sort the levels based on their distance to the current price (ascending)
            level_distances.sort(key=lambda x: x['distance'])

            # Return the top N nearest levels as (name, price) tuples
            return [(item['name'], item['level']) for item in level_distances[:num_levels]]

        except Exception as e:
            self.logger.error(f"{NEON_RED}Error finding nearest Fibonacci levels for {self.symbol}: {e}{RESET}", exc_info=True)
            return []

    # --- EMA Alignment Calculation ---
    def calculate_ema_alignment_score(self) -> float:
        """
        Calculates EMA alignment score based on the latest EMA_Short, EMA_Long, and Close price.

        Returns:
             1.0 if Price > EMA_Short > EMA_Long (Strong Bullish Alignment)
            -1.0 if Price < EMA_Short < EMA_Long (Strong Bearish Alignment)
             0.0 otherwise (Mixed or Crossing)
             np.nan if any required value is missing or not a valid number.
        """
        # Retrieve latest values
        ema_short = self.indicator_values.get(EMA_SHORT_KEY) # Should be float or NaN
        ema_long = self.indicator_values.get(EMA_LONG_KEY)   # Should be float or NaN
        close_decimal = self.indicator_values.get(CLOSE_KEY) # Should be Decimal or NaN

        # Convert Close price to float for comparison, handle potential NaN/None
        current_price_float = np.nan
        if isinstance(close_decimal, Decimal) and not close_decimal.is_nan():
            try:
                current_price_float = float(close_decimal)
            except (ValueError, TypeError):
                pass # Keep as NaN if conversion fails

        # Check if all necessary values are available and valid numbers
        if pd.isna(ema_short) or pd.isna(ema_long) or pd.isna(current_price_float):
            self.logger.debug("EMA alignment check skipped: Missing or invalid required values (EMA_Short, EMA_Long, or Close).")
            return np.nan # Return NaN if data is missing or invalid

        # Check for bullish alignment
        if current_price_float > ema_short > ema_long:
            return 1.0
        # Check for bearish alignment
        elif current_price_float < ema_short < ema_long:
            return -1.0
        # Otherwise, EMAs are crossed or price is between them (neutral/mixed alignment)
        else:
            return 0.0


    # --- Signal Generation & Scoring ---
    def generate_trading_signal(
        self, current_price: Decimal, orderbook_data: Optional[Dict] = None
    ) -> str:
        """
        Generates a final trading signal (BUY/SELL/HOLD) based on a weighted score
        from various enabled indicator checks.

        Args:
            current_price: The current market price (Decimal).
            orderbook_data: Optional order book data dictionary from fetch_orderbook_ccxt.

        Returns:
            "BUY", "SELL", or "HOLD" string signal.
        """
        # Reset signal states
        self.signals = {"BUY": 0, "SELL": 0, "HOLD": 1} # Default to HOLD
        final_signal_score = Decimal("0.0")
        total_weight_applied = Decimal("0.0")
        active_indicator_count = 0
        nan_indicator_count = 0
        debug_scores = {} # For detailed logging

        # --- Pre-checks ---
        if not self.indicator_values:
             self.logger.warning(f"{NEON_YELLOW}Cannot generate signal for {self.symbol}: Indicator values dictionary is empty.{RESET}")
             return "HOLD"
        # Check if at least one core indicator has a valid value (not NaN)
        core_indicators_present = any(
            pd.notna(v) for k, v in self.indicator_values.items()
            if k not in [OPEN_KEY, HIGH_KEY, LOW_KEY, CLOSE_KEY, VOLUME_KEY] # Exclude raw OHLCV
        )
        if not core_indicators_present:
            self.logger.warning(f"{NEON_YELLOW}Cannot generate signal for {self.symbol}: All core indicator values are NaN.{RESET}")
            return "HOLD"
        # Check current price validity
        if pd.isna(current_price) or not isinstance(current_price, Decimal) or current_price <= 0:
             self.logger.warning(f"{NEON_YELLOW}Cannot generate signal for {self.symbol}: Invalid current price ({current_price}).{RESET}")
             return "HOLD"

        # Get the active weight set from config
        active_weights = self.config.get("weight_sets", {}).get(self.active_weight_set_name)
        if not active_weights:
             self.logger.error(f"Active weight set '{self.active_weight_set_name}' missing or empty in config for {self.symbol}. Cannot generate signal.")
             return "HOLD"

        # --- Iterate through configured indicators ---
        for indicator_key, enabled in self.config.get("indicators", {}).items():
            # Skip if indicator is disabled in the config
            if not enabled: continue

            # Get the weight for this indicator from the active weight set
            weight_str = active_weights.get(indicator_key)
            # Skip if no weight is defined for this enabled indicator
            if weight_str is None: continue

            try:
                # Convert weight to Decimal, skip if weight is zero
                weight = Decimal(str(weight_str))
                if weight.is_zero(): continue
            except (InvalidOperation, ValueError, TypeError):
                self.logger.warning(f"Invalid weight format '{weight_str}' for indicator '{indicator_key}' in weight set '{self.active_weight_set_name}' for {self.symbol}. Skipping.")
                continue

            # --- Call the corresponding check method ---
            check_method_name = f"_check_{indicator_key}"
            if hasattr(self, check_method_name) and callable(getattr(self, check_method_name)):
                method_to_call = getattr(self, check_method_name)
                indicator_score_float = np.nan # Initialize score as NaN

                try:
                    # Special case for orderbook check which needs extra data
                    if indicator_key == "orderbook":
                         # Only call if orderbook data is available
                         if orderbook_data:
                             indicator_score_float = method_to_call(orderbook_data, current_price)
                         else:
                             # Log if orderbook indicator is enabled/weighted but data is missing
                              if not weight.is_zero(): # Only log if it would have contributed
                                 self.logger.debug(f"Orderbook check skipped for {self.symbol}: No orderbook data provided.")
                    else:
                         # Call standard check methods
                         indicator_score_float = method_to_call() # Expected to return float score or np.nan

                except Exception as e:
                    self.logger.error(f"Error executing indicator check method {check_method_name} for {self.symbol}: {e}", exc_info=True)
                    # Keep score as NaN

                # Store score for debugging, format nicely
                debug_scores[indicator_key] = f"{indicator_score_float:.3f}" if pd.notna(indicator_score_float) else "NaN"

                # --- Aggregate score if valid ---
                if pd.notna(indicator_score_float):
                    try:
                        # Convert float score to Decimal for weighted sum
                        score_decimal = Decimal(str(indicator_score_float))
                        # Clamp score between -1 and 1 before applying weight
                        clamped_score = max(Decimal("-1.0"), min(Decimal("1.0"), score_decimal))
                        # Calculate contribution to final score
                        score_contribution = clamped_score * weight
                        final_signal_score += score_contribution
                        # Track total weight applied for normalization/debugging
                        total_weight_applied += weight
                        active_indicator_count += 1
                    except (InvalidOperation, ValueError, TypeError) as calc_err:
                        self.logger.error(f"Error processing score for {indicator_key} (Score: {indicator_score_float}, Weight: {weight}) for {self.symbol}: {calc_err}")
                        nan_indicator_count += 1 # Count as NaN if processing failed
                else:
                    # Count indicators that returned NaN
                    nan_indicator_count += 1
            else:
                # Log warning if a check method is missing for an enabled/weighted indicator
                if not weight.is_zero(): # Only warn if it was supposed to contribute
                    self.logger.warning(f"Indicator check method '{check_method_name}' not found for enabled/weighted indicator: {indicator_key} ({self.symbol})")


        # --- Determine Final Signal based on Score ---
        final_signal = "HOLD" # Default
        if total_weight_applied.is_zero():
             self.logger.warning(f"No indicators contributed valid scores to the signal calculation for {self.symbol}. Defaulting to HOLD.")
        else:
            # Use raw score for thresholding as weights already scale contributions
            threshold_str = self.config.get("signal_score_threshold", "1.5")
            try:
                threshold = Decimal(str(threshold_str))
                if threshold < 0:
                    self.logger.warning(f"Signal score threshold cannot be negative ('{threshold_str}'). Using absolute value.")
                    threshold = abs(threshold)
            except (InvalidOperation, ValueError, TypeError):
                self.logger.warning(f"Invalid signal_score_threshold '{threshold_str}'. Using default 1.5.")
                threshold = Decimal("1.5")

            if final_signal_score >= threshold:
                final_signal = "BUY"
            elif final_signal_score <= -threshold:
                final_signal = "SELL"
            # else: final_signal remains "HOLD"

        # --- Log Summary ---
        price_prec = get_price_precision(self.market_info, self.logger)
        log_msg = (
            f"Signal Summary ({self.symbol} @ {current_price:.{price_prec}f}): "
            f"Set='{self.active_weight_set_name}', Indicators=[Active:{active_indicator_count}, NaN:{nan_indicator_count}], "
            f"TotalWeight={total_weight_applied:.2f}, "
            f"FinalScore={final_signal_score:.4f} (Threshold: +/-{threshold:.2f}) "
            # Colorize the final signal
            f"==> {NEON_GREEN if final_signal == 'BUY' else NEON_RED if final_signal == 'SELL' else NEON_YELLOW}{final_signal}{RESET}"
        )
        self.logger.info(log_msg)
        # Log detailed scores only at DEBUG level
        self.logger.debug(f"  Indicator Scores ({self.symbol}): {debug_scores}")

        # Update the signals dictionary
        if final_signal == "BUY": self.signals = {"BUY": 1, "SELL": 0, "HOLD": 0}
        elif final_signal == "SELL": self.signals = {"BUY": 0, "SELL": 1, "HOLD": 0}
        else: self.signals = {"BUY": 0, "SELL": 0, "HOLD": 1} # HOLD

        return final_signal


    # --- Indicator Check Methods (returning float score -1.0 to 1.0 or np.nan) ---
    # Each method should access self.indicator_values to get the latest calculated data.

    def _check_ema_alignment(self) -> float:
        """Checks EMA alignment. Requires EMA_Short, EMA_Long, Close."""
        # Check if required keys are present (values might still be NaN)
        if EMA_SHORT_KEY not in self.indicator_values or EMA_LONG_KEY not in self.indicator_values:
             self.logger.debug("EMA Alignment check skipped: EMA keys not found in indicator_values.")
             return np.nan
        # Delegate to the calculation method which handles NaN checks inside
        return self.calculate_ema_alignment_score()

    def _check_momentum(self) -> float:
        """Checks Momentum indicator relative to price."""
        momentum = self.indicator_values.get(MOMENTUM_KEY) # Should be float or NaN
        if pd.isna(momentum):
            return np.nan

        last_close = self.indicator_values.get(CLOSE_KEY) # Decimal or NaN
        if not isinstance(last_close, Decimal) or last_close.is_nan() or last_close <= 0:
            self.logger.debug("Momentum check skipped: Invalid or missing Close price.")
            return 0.0 # Cannot scale if price is invalid, return neutral

        try:
            # Calculate momentum as a percentage of price
            mom_pct = Decimal(str(momentum)) / last_close
            # Define a threshold for significant momentum (e.g., 0.1% or 0.001)
            # This could be made configurable
            threshold_pct = Decimal(self.config.get("momentum_threshold_pct", "0.001"))

            if threshold_pct <= 0: # Avoid division by zero or invalid logic
                self.logger.warning("Momentum threshold percentage must be positive. Using 0.001.")
                threshold_pct = Decimal("0.001")

            # Scale the score based on how many times the momentum exceeds the threshold
            # Example: If mom_pct is 2x threshold, score is 0.4 (scaled by 1/5)
            # If mom_pct is 5x threshold or more, score is +/- 1.0
            scaling_factor = Decimal("5.0") # How many thresholds equal a full score? Configurable?
            score = float(mom_pct / (threshold_pct * scaling_factor))

            # Clamp the score between -1.0 and 1.0
            return max(-1.0, min(1.0, score))

        except (InvalidOperation, ValueError, TypeError, ZeroDivisionError) as e:
            self.logger.warning(f"Error during momentum check calculation for {self.symbol}: {e}")
            return 0.0 # Return neutral on calculation error


    def _check_volume_confirmation(self) -> float:
        """Checks if current volume confirms the potential trend relative to its MA."""
        current_volume = self.indicator_values.get(VOLUME_KEY) # Should be Decimal or NaN
        volume_ma_float = self.indicator_values.get(VOLUME_MA_KEY) # Should be float or NaN

        # Get multiplier from config, default to 1.5
        try:
            multiplier = float(self.config.get("volume_confirmation_multiplier", 1.5))
            if multiplier <= 0:
                self.logger.warning("Volume confirmation multiplier must be positive. Using 1.5.")
                multiplier = 1.5
        except (ValueError, TypeError):
             self.logger.warning("Invalid volume confirmation multiplier. Using 1.5.")
             multiplier = 1.5

        # Check if values are available and valid
        if pd.isna(current_volume) or not isinstance(current_volume, Decimal) or current_volume < 0 or \
           pd.isna(volume_ma_float) or volume_ma_float < 0: # Allow zero volume/MA
            return np.nan

        try:
            # Convert Volume MA float to Decimal for comparison
            volume_ma = Decimal(str(volume_ma_float))
            multiplier_decimal = Decimal(str(multiplier))

            # Compare current volume to MA * multiplier
            if volume_ma > 0: # Avoid division by zero if MA is zero
                volume_ratio = current_volume / volume_ma
                threshold_high = multiplier_decimal
                # Define a low threshold (e.g., inverse of multiplier, or fixed like 0.5)
                threshold_low = Decimal(1) / multiplier_decimal

                if volume_ratio > threshold_high:
                    # High volume confirms trend (positive score, scale with ratio?)
                    # Scale score from 0.5 up to 1.0 as ratio increases
                    # Example: score = 0.5 + 0.5 * (ratio - thresh_high) / thresh_high
                    # Capped at 1.0
                    score = 0.5 + 0.5 * float(min(Decimal(1.0), (volume_ratio - threshold_high) / threshold_high))
                    return min(1.0, score)
                elif volume_ratio < threshold_low:
                    # Low volume might indicate lack of confirmation (negative score)
                    # Scale score from -0.5 down to -1.0 as ratio decreases
                    # Example: score = -0.5 - 0.5 * (thresh_low - ratio) / thresh_low
                    # Capped at -1.0
                    score = -0.5 - 0.5 * float(min(Decimal(1.0), (threshold_low - volume_ratio) / threshold_low))
                    return max(-1.0, score)
                else:
                    # Neutral volume (between low and high thresholds)
                    # Optionally scale linearly between thresholds
                    mid_point = (threshold_high + threshold_low) / 2
                    range_width = (threshold_high - threshold_low)
                    if range_width > 0:
                        # Scale from -0.5 (at threshold_low) to +0.5 (at threshold_high)
                        score = float((volume_ratio - mid_point) / (range_width / 2) * Decimal("0.5"))
                        return max(-0.5, min(0.5, score))
                    else:
                        return 0.0 # Should not happen if multiplier > 1
            else:
                # Volume MA is zero. If current volume is also zero, neutral.
                # If current volume is positive but MA is zero (e.g., start of data), maybe slightly positive?
                return 0.0 if current_volume == 0 else 0.1
        except (InvalidOperation, ValueError, TypeError, ZeroDivisionError) as e:
            self.logger.warning(f"Error during volume confirmation check for {self.symbol}: {e}")
            return np.nan

    def _check_stoch_rsi(self) -> float:
        """Checks Stochastic RSI K and D lines using configurable thresholds."""
        k = self.indicator_values.get(STOCHRSI_K_KEY) # Float or NaN
        d = self.indicator_values.get(STOCHRSI_D_KEY) # Float or NaN

        if pd.isna(k) or pd.isna(d):
            return np.nan

        # Get thresholds from config
        try:
            oversold = float(self.config.get("stoch_rsi_oversold_threshold", 25))
            overbought = float(self.config.get("stoch_rsi_overbought_threshold", 75))
            # Ensure valid range 0-100
            oversold = max(0, min(100, oversold))
            overbought = max(0, min(100, overbought))
            if oversold >= overbought:
                self.logger.warning(f"StochRSI oversold ({oversold}) >= overbought ({overbought}). Using defaults 25/75.")
                oversold, overbought = 25, 75
        except (ValueError, TypeError):
             self.logger.warning("Invalid StochRSI thresholds in config. Using defaults 25/75.")
             oversold, overbought = 25, 75

        score = 0.0
        # Oversold condition -> Bullish signal
        if k < oversold and d < oversold:
            score = 1.0
        # Overbought condition -> Bearish signal
        elif k > overbought and d > overbought:
            score = -1.0

        # Consider K/D crossing or relationship for additional nuance
        diff = k - d
        crossing_threshold = float(self.config.get("stoch_rsi_crossing_threshold", 5))

        # Significant crossing potential
        if abs(diff) > crossing_threshold:
             if diff > 0: # K crossing above D -> Bullish momentum
                  # Enhance existing score or set if neutral
                  score = max(score, 0.6) if score >= 0 else 0.6
             else: # K crossing below D -> Bearish momentum
                  # Enhance existing score or set if neutral
                  score = min(score, -0.6) if score <= 0 else -0.6
        # Weaker signal if K is just above/below D without strong crossing
        elif k > d :
             score = max(score, 0.2) # Mildly bullish
        elif k < d:
             score = min(score, -0.2) # Mildly bearish

        # Dampen score if in the mid-range (less decisive)
        mid_range_low = float(self.config.get("stoch_rsi_mid_range_low", 40))
        mid_range_high = float(self.config.get("stoch_rsi_mid_range_high", 60))
        if mid_range_low < k < mid_range_high:
            score *= float(self.config.get("stoch_rsi_mid_range_dampening", 0.5))

        return score

    def _check_rsi(self) -> float:
        """Checks standard RSI using configurable thresholds."""
        rsi = self.indicator_values.get(RSI_KEY) # Float or NaN
        if pd.isna(rsi):
            return np.nan

        # Get thresholds from config
        try:
            oversold = float(self.config.get("rsi_oversold_threshold", 30))
            overbought = float(self.config.get("rsi_overbought_threshold", 70))
            # Ensure valid range 0-100
            oversold = max(0, min(100, oversold))
            overbought = max(0, min(100, overbought))
            if oversold >= overbought:
                self.logger.warning(f"RSI oversold ({oversold}) >= overbought ({overbought}). Using defaults 30/70.")
                oversold, overbought = 30, 70
        except (ValueError, TypeError):
             self.logger.warning("Invalid RSI thresholds in config. Using defaults 30/70.")
             oversold, overbought = 30, 70

        # Strong signals at extremes
        if rsi <= oversold: return 1.0
        if rsi >= overbought: return -1.0

        # Intermediate levels for weaker signals (e.g., halfway between mid and extreme)
        mid_point = 50.0
        lower_intermediate = (oversold + mid_point) / 2
        upper_intermediate = (overbought + mid_point) / 2

        if oversold < rsi <= lower_intermediate: return 0.5 # Approaching Oversold -> Moderate Buy
        if upper_intermediate <= rsi < overbought: return -0.5 # Approaching Overbought -> Moderate Sell

        # Mid-range (between intermediate levels) - scale score linearly
        if lower_intermediate < rsi < upper_intermediate:
             # Scale from -0.5 (at upper_intermediate) to +0.5 (at lower_intermediate)
             # Centered at 0.0 at the midpoint (50)
             score = (mid_point - rsi) / (upper_intermediate - mid_point) * 0.5
             return max(-0.5, min(0.5, score)) # Clamp just in case

        return 0.0 # Should cover all ranges


    def _check_cci(self) -> float:
        """Checks Commodity Channel Index (CCI) using configurable thresholds."""
        cci = self.indicator_values.get(CCI_KEY) # Float or NaN
        if pd.isna(cci):
            return np.nan

        # Get thresholds from config
        try:
            strong_os = float(self.config.get("cci_strong_oversold", -150))
            strong_ob = float(self.config.get("cci_strong_overbought", 150))
            moderate_os = float(self.config.get("cci_moderate_oversold", -80))
            moderate_ob = float(self.config.get("cci_moderate_overbought", 80))
            # Basic validation
            if not (strong_os < moderate_os < 0 < moderate_ob < strong_ob):
                 self.logger.warning("Invalid CCI threshold configuration. Using defaults (-150/-80, 80/150).")
                 strong_os, moderate_os, moderate_ob, strong_ob = -150, -80, 80, 150
        except (ValueError, TypeError):
             self.logger.warning("Invalid CCI thresholds in config. Using defaults (-150/-80, 80/150).")
             strong_os, moderate_os, moderate_ob, strong_ob = -150, -80, 80, 150

        # CCI Interpretation
        if cci <= strong_os: return 1.0  # Strongly Oversold -> Buy
        if cci >= strong_ob: return -1.0 # Strongly Overbought -> Sell
        if strong_os < cci <= moderate_os: return 0.6   # Moderately Oversold
        if moderate_ob <= cci < strong_ob: return -0.6  # Moderately Overbought
        # Consider zero line cross or direction near zero
        if moderate_os < cci < 0: return 0.1 # Weak bullish (below zero but not oversold)
        if 0 < cci < moderate_ob: return -0.1 # Weak bearish (above zero but not overbought)
        if cci == 0: return 0.0
        return 0.0 # Default neutral


    def _check_wr(self) -> float:
        """Checks Williams %R using configurable thresholds."""
        wr = self.indicator_values.get(WILLIAMS_R_KEY) # Float or NaN (-100 to 0)
        if pd.isna(wr):
            return np.nan

        # Get thresholds from config (Note: WR is -100 to 0)
        try:
            oversold = float(self.config.get("wr_oversold_threshold", -80)) # e.g., -80
            overbought = float(self.config.get("wr_overbought_threshold", -20)) # e.g., -20
            # Ensure valid range -100 to 0 and oversold < overbought
            oversold = max(-100, min(0, oversold))
            overbought = max(-100, min(0, overbought))
            if oversold >= overbought:
                self.logger.warning(f"Williams %R oversold ({oversold}) >= overbought ({overbought}). Using defaults -80/-20.")
                oversold, overbought = -80, -20
        except (ValueError, TypeError):
             self.logger.warning("Invalid Williams %R thresholds in config. Using defaults -80/-20.")
             oversold, overbought = -80, -20

        # Williams %R Interpretation
        if wr <= oversold: return 1.0 # e.g., <= -80 -> Buy Signal
        if wr >= overbought: return -1.0 # e.g., >= -20 -> Sell Signal

        # Intermediate signals (e.g., halfway between mid and extreme)
        mid_point = -50.0
        lower_intermediate = (oversold + mid_point) / 2 # e.g., (-80 - 50) / 2 = -65
        upper_intermediate = (overbought + mid_point) / 2 # e.g., (-20 - 50) / 2 = -35

        if oversold < wr <= lower_intermediate: return 0.4 # Moving out of oversold potentially
        if upper_intermediate <= wr < overbought: return -0.4 # Moving out of overbought potentially

        # Mid-range scaling (optional)
        if lower_intermediate < wr < upper_intermediate:
             # Scale from -0.4 (at upper) to +0.4 (at lower), 0 at midpoint -50
             score = (mid_point - wr) / (upper_intermediate - mid_point) * 0.4
             return max(-0.4, min(0.4, score)) # Clamp

        if wr == mid_point: return 0.0 # Midpoint is neutral
        return 0.0

    def _check_psar(self) -> float:
        """Checks Parabolic SAR (PSAR) trend direction."""
        # PSAR values are price levels (Decimal) or NaN
        psar_long_signal = self.indicator_values.get(PSAR_LONG_KEY)
        psar_short_signal = self.indicator_values.get(PSAR_SHORT_KEY)

        # Check which signal is active (non-NaN and valid Decimal)
        long_active = isinstance(psar_long_signal, Decimal) and not psar_long_signal.is_nan()
        short_active = isinstance(psar_short_signal, Decimal) and not psar_short_signal.is_nan()

        if long_active and not short_active:
            return 1.0 # Uptrend indicated by PSAR
        elif short_active and not long_active:
            return -1.0 # Downtrend indicated by PSAR
        elif not long_active and not short_active:
            # This might happen at the start of data or if calculation failed
            return np.nan
        else:
            # Should not happen with standard PSAR calculation (both active simultaneously)
            # Could happen if indicator_values update failed partially
            self.logger.warning(f"PSAR check encountered unexpected state for {self.symbol}: Long={psar_long_signal}, Short={psar_short_signal}")
            return 0.0 # Neutral or error state


    def _check_sma_10(self) -> float:
        """Checks price position relative to SMA 10."""
        sma_10 = self.indicator_values.get(SMA10_KEY) # Float or NaN
        last_close_decimal = self.indicator_values.get(CLOSE_KEY) # Decimal or NaN

        if pd.isna(sma_10) or not isinstance(last_close_decimal, Decimal) or last_close_decimal.is_nan():
            return np.nan

        # Simple check: Price above SMA is bullish, below is bearish
        # Use Decimal comparison for accuracy
        if last_close_decimal > Decimal(str(sma_10)):
            return 0.6 # Moderate bullish signal
        elif last_close_decimal < Decimal(str(sma_10)):
            return -0.6 # Moderate bearish signal
        else:
            return 0.0 # Price is exactly on SMA


    def _check_vwap(self) -> float:
        """Checks price position relative to VWAP."""
        vwap = self.indicator_values.get(VWAP_KEY) # Float or NaN
        last_close_decimal = self.indicator_values.get(CLOSE_KEY) # Decimal or NaN

        if pd.isna(vwap) or not isinstance(last_close_decimal, Decimal) or last_close_decimal.is_nan():
            return np.nan

        # Price above VWAP is generally considered bullish intraday, below is bearish
        # Use Decimal comparison
        if last_close_decimal > Decimal(str(vwap)):
            return 0.7 # Stronger bullish signal than SMA 10 perhaps
        elif last_close_decimal < Decimal(str(vwap)):
            return -0.7 # Stronger bearish signal
        else:
            return 0.0


    def _check_mfi(self) -> float:
        """Checks Money Flow Index (MFI) using configurable thresholds."""
        mfi = self.indicator_values.get(MFI_KEY) # Float or NaN
        if pd.isna(mfi):
            return np.nan

        # Get thresholds from config (Similar to RSI)
        try:
            oversold = float(self.config.get("mfi_oversold_threshold", 20))
            overbought = float(self.config.get("mfi_overbought_threshold", 80))
            # Ensure valid range 0-100
            oversold = max(0, min(100, oversold))
            overbought = max(0, min(100, overbought))
            if oversold >= overbought:
                self.logger.warning(f"MFI oversold ({oversold}) >= overbought ({overbought}). Using defaults 20/80.")
                oversold, overbought = 20, 80
        except (ValueError, TypeError):
             self.logger.warning("Invalid MFI thresholds in config. Using defaults 20/80.")
             oversold, overbought = 20, 80

        # MFI Interpretation
        if mfi <= oversold: return 1.0
        if mfi >= overbought: return -1.0

        # Intermediate levels (e.g., halfway between mid and extreme)
        mid_point = 50.0
        lower_intermediate = (oversold + mid_point) / 2
        upper_intermediate = (overbought + mid_point) / 2

        if oversold < mfi <= lower_intermediate: return 0.4
        if upper_intermediate <= mfi < overbought: return -0.4

        # Mid-range (optional scaling, similar to RSI)
        if lower_intermediate < mfi < upper_intermediate:
             score = (mid_point - mfi) / (upper_intermediate - mid_point) * 0.4
             return max(-0.4, min(0.4, score)) # Clamp

        return 0.0 # Mid-range


    def _check_bollinger_bands(self) -> float:
        """Checks price position relative to Bollinger Bands."""
        # Values should be Decimal or NaN
        bb_lower = self.indicator_values.get(BB_LOWER_KEY)
        bb_middle = self.indicator_values.get(BB_MIDDLE_KEY)
        bb_upper = self.indicator_values.get(BB_UPPER_KEY)
        last_close = self.indicator_values.get(CLOSE_KEY)

        # Check if all values are valid Decimals
        if not all(isinstance(v, Decimal) and not v.is_nan() for v in [bb_lower, bb_middle, bb_upper, last_close]):
            return np.nan

        # Check if price touches or crosses bands (potential reversal/breakout)
        if last_close <= bb_lower:
             # Price at or below lower band -> Potential bounce (Buy signal)
             return 1.0
        if last_close >= bb_upper:
             # Price at or above upper band -> Potential pullback (Sell signal)
             return -1.0

        # Check position relative to middle band (often an SMA)
        # Calculate distance relative to band width for scaling
        band_width = bb_upper - bb_lower
        if band_width > 0: # Avoid division by zero if bands collapse
            try:
                # Calculate position relative to middle band, scaled by half-width
                # Score ranges from -1 (at lower band) to +1 (at upper band)
                # Use Decimal for calculation consistency
                half_width = band_width / Decimal("2.0")
                relative_position_dec = (last_close - bb_middle) / half_width

                # Clamp the score between -1 and 1 (should be already, but safety)
                score_dec = max(Decimal("-1.0"), min(Decimal("1.0"), relative_position_dec))

                # Scale the score to be less intense than touching the bands (e.g., max +/- 0.7)
                # This means a score of 1.0 (at upper band) becomes 0.7
                # A score of -1.0 (at lower band) becomes -0.7
                # A score of 0.0 (at middle band) remains 0.0
                scaled_score = float(score_dec * Decimal("0.7"))
                return scaled_score
            except (InvalidOperation, ValueError, TypeError, ZeroDivisionError):
                 self.logger.warning(f"Error calculating relative position within Bollinger Bands for {self.symbol}.")
                 return 0.0 # Neutral on error
        # If price is exactly on middle band or bands collapsed
        return 0.0


    def _check_orderbook(self, orderbook_data: Optional[Dict], current_price: Decimal) -> float:
        """
        Analyzes order book depth (imbalance) as a sentiment indicator.
        Returns float score (-1.0 to 1.0) or NaN.
        """
        if not orderbook_data:
            self.logger.debug("Orderbook check skipped: No data provided.")
            return np.nan

        try:
            bids = orderbook_data.get('bids', []) # List of [price, size]
            asks = orderbook_data.get('asks', []) # List of [price, size]

            # Ensure we have both bids and asks to compare
            if not bids or not asks:
                self.logger.debug(f"Orderbook check skipped for {self.symbol}: Missing bids or asks.")
                return np.nan

            # --- Simple Order Book Imbalance (OBI) Calculation ---
            # Consider N levels deep or within X% of current price
            num_levels_to_check = int(self.config.get("orderbook_levels_check", 10))
            # Alternative: Check within a price range percentage
            # price_range_pct = Decimal(self.config.get("orderbook_price_range_pct", "0.005")) # 0.5%
            # min_bid_price = current_price * (Decimal(1) - price_range_pct)
            # max_ask_price = current_price * (Decimal(1) + price_range_pct)

            top_bids = bids[:num_levels_to_check]
            top_asks = asks[:num_levels_to_check]
            # Filter by price range (if using that method):
            # bids_in_range = [b for b in bids if Decimal(str(b[0])) >= min_bid_price]
            # asks_in_range = [a for a in asks if Decimal(str(a[0])) <= max_ask_price]

            # Sum the sizes (quantities) at these levels
            # Use Decimal for summation to maintain precision
            bid_volume_sum = sum(Decimal(str(bid[1])) for bid in top_bids if len(bid) == 2 and bid[1] is not None)
            ask_volume_sum = sum(Decimal(str(ask[1])) for ask in top_asks if len(ask) == 2 and ask[1] is not None)

            # Calculate total volume in the checked range
            total_volume = bid_volume_sum + ask_volume_sum

            # Avoid division by zero if total volume is zero (inactive market?)
            if total_volume <= 0:
                self.logger.debug(f"Orderbook check ({self.symbol}): Zero or negative total volume in top {num_levels_to_check} levels.")
                return 0.0 # Neutral signal

            # Calculate Order Book Imbalance ratio
            # OBI = (BidVolume - AskVolume) / TotalVolume
            # Ranges from -1 (all asks) to +1 (all bids)
            obi_decimal = (bid_volume_sum - ask_volume_sum) / total_volume

            # Convert OBI Decimal to float score
            score = float(obi_decimal)

            # --- Log the analysis ---
            self.logger.debug(
                f"Orderbook check ({self.symbol}): Top {num_levels_to_check} levels -> "
                f"BidVol={bid_volume_sum:.4f}, AskVol={ask_volume_sum:.4f}, "
                f"OBI={obi_decimal:.4f} -> Score={score:.4f}"
            )

            # --- Refinements (Optional) ---
            # 1. Weighted OBI: Give more weight to levels closer to the spread.
            # 2. Volume Clusters: Look for large individual orders ("walls").
            # 3. Spread Analysis: Consider the bid-ask spread size.

            # Return the calculated score, clamped just in case
            return max(-1.0, min(1.0, score))

        except (InvalidOperation, ValueError, TypeError, IndexError, ZeroDivisionError) as e:
             self.logger.warning(f"{NEON_YELLOW}Orderbook analysis failed for {self.symbol} (data processing error): {e}{RESET}", exc_info=False)
             return np.nan # Return NaN on error
        except Exception as e:
            self.logger.warning(f"{NEON_YELLOW}Orderbook analysis failed for {self.symbol} (unexpected error): {e}{RESET}", exc_info=True)
            return np.nan # Return NaN on error


    # --- Risk Management Calculations ---
    def calculate_entry_tp_sl(
        self, entry_price_estimate: Decimal, signal: str
    ) -> Tuple[Optional[Decimal], Optional[Decimal], Optional[Decimal]]:
        """
        Calculates potential Take Profit (TP) and initial Stop Loss (SL) levels
        based on an estimated entry price, the signal direction, ATR, and config multipliers.

        This initial SL is primarily used for position sizing. The actual SL set on the
        exchange might be different (e.g., adjusted by BE logic or replaced by TSL).

        Args:
            entry_price_estimate: An estimated entry price (Decimal) for the trade.
                                  (Could be current price or anticipated limit fill price).
            signal: The trading signal ("BUY" or "SELL").

        Returns:
            A tuple containing: (entry_price_estimate, take_profit, stop_loss)
            All values are Decimals or None if calculation fails or results are invalid.
        """
        # Only calculate for valid BUY/SELL signals
        if signal not in ["BUY", "SELL"]:
            self.logger.debug(f"TP/SL calculation skipped: Signal is '{signal}'.")
            return entry_price_estimate, None, None

        # --- Retrieve necessary values ---
        atr_val = self.indicator_values.get(ATR_KEY) # Should be Decimal or NaN

        # --- Validate Inputs ---
        if not isinstance(atr_val, Decimal) or atr_val.is_nan() or atr_val <= 0:
            self.logger.warning(f"{NEON_YELLOW}Cannot calculate TP/SL for {self.symbol} {signal}: Invalid or missing ATR ({atr_val}).{RESET}")
            return entry_price_estimate, None, None
        if not isinstance(entry_price_estimate, Decimal) or entry_price_estimate.is_nan() or entry_price_estimate <= 0:
            self.logger.warning(f"{NEON_YELLOW}Cannot calculate TP/SL for {self.symbol} {signal}: Invalid entry price estimate ({entry_price_estimate}).{RESET}")
            return entry_price_estimate, None, None

        try:
            # --- Get Multipliers from Config ---
            # Convert multipliers to Decimal for precise calculations
            tp_multiple_str = self.config.get("take_profit_multiple", "1.5") # Default 1.5 R:R if missing
            sl_multiple_str = self.config.get("stop_loss_multiple", "1.0")   # Default 1.0 ATR SL if missing
            tp_multiple = Decimal(str(tp_multiple_str))
            sl_multiple = Decimal(str(sl_multiple_str))

            # Ensure multipliers are positive
            if tp_multiple <= 0 or sl_multiple <= 0:
                self.logger.error(f"{NEON_RED}TP/SL multipliers must be positive (TP: {tp_multiple}, SL: {sl_multiple}). Cannot calculate.{RESET}")
                return entry_price_estimate, None, None

            # --- Get Market Precision Info ---
            price_precision = get_price_precision(self.market_info, self.logger)
            min_tick = get_min_tick_size(self.market_info, self.logger)

            # --- Calculate Offsets ---
            # Use SL multiple for the initial risk distance
            risk_offset = atr_val * sl_multiple
            # TP offset is based on the risk offset and the TP multiple (Risk:Reward ratio)
            tp_offset = risk_offset * tp_multiple # TP distance = SL distance * R:R multiple

            # --- Calculate Raw TP/SL Prices ---
            take_profit_raw: Optional[Decimal] = None
            stop_loss_raw: Optional[Decimal] = None

            if signal == "BUY":
                take_profit_raw = entry_price_estimate + tp_offset
                stop_loss_raw = entry_price_estimate - risk_offset # SL uses risk_offset
            elif signal == "SELL":
                take_profit_raw = entry_price_estimate - tp_offset
                stop_loss_raw = entry_price_estimate + risk_offset # SL uses risk_offset

            # --- Quantize TP/SL to Market Precision ---
            # Quantize TP towards profit direction (UP for BUY, DOWN for SELL)
            # Quantize SL towards loss direction (DOWN for BUY, UP for SELL) - more conservative SL
            take_profit_quantized: Optional[Decimal] = None
            stop_loss_quantized: Optional[Decimal] = None

            # Helper for quantization
            def quantize_price(price: Decimal, rounding_mode: str) -> Optional[Decimal]:
                if price is None or price.is_nan(): return None
                quantized_price = None
                if min_tick > 0:
                    if price > 0:
                        quantized_price = (price / min_tick).quantize(Decimal('1'), rounding=rounding_mode) * min_tick
                        # Ensure positive after quantization
                        quantized_price = max(min_tick, quantized_price)
                    else:
                        quantized_price = min_tick # Cannot have non-positive price
                else: # Fallback to decimal places
                    rounding_factor = Decimal('1e-' + str(price_precision))
                    quantized_price = price.quantize(rounding_factor, rounding=rounding_mode)
                    # Ensure positive after rounding
                    quantized_price = max(rounding_factor, quantized_price)
                return quantized_price if quantized_price > 0 else None


            if take_profit_raw is not None:
                 tp_rounding = ROUND_UP if signal == "BUY" else ROUND_DOWN # Round TP slightly further into profit
                 take_profit_quantized = quantize_price(take_profit_raw, tp_rounding)

            if stop_loss_raw is not None:
                 sl_rounding = ROUND_DOWN if signal == "BUY" else ROUND_UP # Round SL slightly further into loss (safer)
                 stop_loss_quantized = quantize_price(stop_loss_raw, sl_rounding)

            # --- Validation and Adjustments ---
            final_tp = take_profit_quantized
            final_sl = stop_loss_quantized

            # Ensure SL/TP are not None before proceeding with checks
            if final_sl is None or final_tp is None:
                 self.logger.error(f"{NEON_RED}TP or SL calculation resulted in None after quantization for {self.symbol} {signal}. Check ATR/Multipliers/Price.")
                 return entry_price_estimate, None, None # Cannot proceed if either is None

            # 1. Ensure SL is strictly beyond entry
            if signal == "BUY" and final_sl >= entry_price_estimate:
                 self.logger.warning(f"{NEON_YELLOW}BUY SL calculation resulted in SL >= Entry (SL:{final_sl}, Entry:{entry_price_estimate}). Setting SL to None.{RESET}")
                 final_sl = None
            elif signal == "SELL" and final_sl <= entry_price_estimate:
                 self.logger.warning(f"{NEON_YELLOW}SELL SL calculation resulted in SL <= Entry (SL:{final_sl}, Entry:{entry_price_estimate}). Setting SL to None.{RESET}")
                 final_sl = None

            # 2. Ensure TP provides potential profit (strictly beyond entry)
            if final_sl is not None: # Only check TP if SL is valid
                if signal == "BUY" and final_tp <= entry_price_estimate:
                     self.logger.warning(f"{NEON_YELLOW}BUY TP calculation non-profitable (TP {final_tp} <= Entry {entry_price_estimate}). Setting TP to None.{RESET}")
                     final_tp = None
                elif signal == "SELL" and final_tp >= entry_price_estimate:
                     self.logger.warning(f"{NEON_YELLOW}SELL TP calculation non-profitable (TP {final_tp} >= Entry {entry_price_estimate}). Setting TP to None.{RESET}")
                     final_tp = None

            # 3. Ensure SL/TP are positive prices (already handled by quantize_price, but double check)
            if final_sl is not None and final_sl <= 0:
                self.logger.error(f"{NEON_RED}Stop loss calculation resulted in non-positive price ({final_sl}). Setting SL to None.{RESET}")
                final_sl = None
            if final_tp is not None and final_tp <= 0:
                self.logger.warning(f"{NEON_YELLOW}Take profit calculation resulted in non-positive price ({final_tp}). Setting TP to None.{RESET}")
                final_tp = None

            # --- Log Calculation Results ---
            tp_str = f"{final_tp:.{price_precision}f}" if final_tp else "None"
            sl_str = f"{final_sl:.{price_precision}f}" if final_sl else "None"
            self.logger.debug(
                f"Calculated TP/SL for {self.symbol} {signal}: "
                f"EntryEst={entry_price_estimate:.{price_precision}f}, "
                f"ATR={atr_val:.{price_precision+2}f}, " # Show ATR with more precision
                f"SL_Mult={sl_multiple}, TP_Mult={tp_multiple} (R:R), "
                f"RiskOffset={risk_offset:.{price_precision+2}f}, TP_Offset={tp_offset:.{price_precision+2}f}, "
                f"TP={tp_str}, SL={sl_str}"
            )

            # Return None if any validation failed
            if final_sl is None or final_tp is None:
                return entry_price_estimate, None, None
            else:
                return entry_price_estimate, final_tp, final_sl

        except (InvalidOperation, ValueError, TypeError) as e:
             self.logger.error(f"{NEON_RED}Error calculating TP/SL for {self.symbol} {signal} (Decimal/Type Error): {e}{RESET}", exc_info=False)
             return entry_price_estimate, None, None
        except Exception as e:
             # Catch any other unexpected errors during calculation
             self.logger.error(f"{NEON_RED}Unexpected error calculating TP/SL for {self.symbol} {signal}: {e}{RESET}", exc_info=True)
             return entry_price_estimate, None, None

