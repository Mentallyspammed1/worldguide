Okay, let's enhance the `bybit_helpers.py` script based on the errors in your log output and general best practices for interacting with the Bybit V5 API via CCXT.

**Analysis of Errors and Required Enhancements:**

1.  **`AttributeError: module 'bybit_helpers' has no attribute 'get_current_position_bybit_v5'`**: This error originates in your strategy file (`ehlers_volumetric_strategy.py`), not the helper. The strategy is calling a function that doesn't exist in the helper module. The standard CCXT method is `fetch_position` or `fetch_positions`. You need to **fix the calling code** in `ehlers_volumetric_strategy.py` to use `fetch_position` provided by this helper.
2.  **`TypeError: cancel_all_orders() got an unexpected keyword argument 'category'`**: This error occurs twice (initialization and cleanup). Your strategy file is passing a `category` argument to `cancel_all_orders`, but the function in the provided helper script doesn't accept it. Bybit's V5 API *requires* the `category` for cancelling orders. We need to **modify the `cancel_all_orders` function** in the helper to accept and use the `category` parameter correctly.
3.  **`AttributeError: 'bybit' object has no attribute 'closed'`**: This error also originates in your strategy file (`ehlers_volumetric_strategy.py`). The CCXT `bybit` object doesn't have a synchronous `.closed` attribute. Checking connection status is usually done implicitly or via specific methods if available, but the primary action is to call the asynchronous `await exchange.close()` method for cleanup. You need to **fix the calling code** in `ehlers_volumetric_strategy.py` (the `if self.exchange and hasattr(...)` check). The helper script should emphasize the correct usage of `await exchange.close()`.
4.  **Resource Warnings (`Unclosed connector`, `Unclosed client session`)**: These confirm the previous point. The `await exchange.close()` method was not called before the program terminated, likely due to the preceding errors. The helper script needs to strongly document and demonstrate the necessity of calling `await exchange.close()` in a `finally` block.
5.  **`[fetch_account_info_bybit_v5] Failed to fetch account info. Code: 0, Msg: OK`**: This is slightly odd logging. Code 0/Msg OK usually indicates success from the API. The helper function *logged* "Failed", but the API response seems fine. The subsequent warning suggests the *real* issue was that the calling code (`initialize_bybit`) couldn't *verify* the margin mode from the returned info. We should adjust the logging in `fetch_account_info_bybit_v5` to be clearer and ensure `initialize_bybit` handles cases where the fetched info might be valid but not contain the specific detail being checked.
6.  **General V5 Requirements**: Many Bybit V5 endpoints require the `category` parameter ('linear', 'inverse', 'spot', 'option'). The helper functions need to consistently determine the correct category for the given symbol (using the MarketCache) and pass it in the `params` dictionary for CCXT calls.
7.  **Robustness**: Improve error handling, validation (e.g., leverage limits), and logging across functions.
8.  **Batch Orders**: The provided script includes `place_batch_orders`. Ensure it correctly formats requests for the V5 batch endpoint (`/v5/order/create-batch`) and parses the specific V5 batch response structure (which includes separate lists for successes and errors).

**Enhanced `bybit_helpers.py` (Version 3.5)**

Here is the enhanced version of your `bybit_helpers.py` script incorporating fixes and improvements based on the analysis:

```python
#!/usr/bin/env python

"""Bybit V5 CCXT Helper Functions (v3.5 - Enhanced & Fixed)

A robust, modular, and enhanced collection of helper functions for interacting with
the Bybit V5 API (Unified Trading Account) using the CCXT library. This version
fixes critical initialization errors (AttributeError: 'closed'), improves batch order
handling and error reporting, enhances market loading robustness, adds dependency checks,
and improves overall logging and error handling. Addresses issues identified from
runtime logs including missing function attributes (caller-side), incorrect function
arguments ('category' in cancel_all_orders), and resource cleanup ('closed' attribute,
missing await exchange.close()).

Key Features:
- Fully asynchronous operations (`async`/`await`).
- Logically grouped functions (can be split into submodules).
- Enhanced type safety with TypedDict, Enums, and precise hints.
- Performance optimizations via integrated MarketCache.
- Centralized asynchronous error handling and retry logic via decorator.
- Structured logging with conditional color support.
- Implemented features: Batch orders, comprehensive order types,
  conditional orders (basic Stop), common fetch/cancel operations.
- Increased robustness and handling of Bybit V5 specifics (category, filters, UTA).
- Self-contained: Includes necessary utility functions and decorators.
- Improved WebSocket handling stubs (full implementation not shown here).
- **CRITICAL**: Emphasizes the need for `await exchange.close()` for proper resource cleanup.

Version: 3.5
"""

# Standard Library Imports
import asyncio
import json
import logging
import os
import random
import sys
import time
from collections.abc import Callable, Coroutine, Sequence
from decimal import Decimal, DivisionByZero, InvalidOperation, getcontext
from enum import Enum
from typing import (
    Any,
    Dict,
    List,
    Literal,
    Optional,
    Tuple,
    TypedDict,
    TypeVar,
    Union,
)

# Third-party Libraries
# Attempt to import CCXT and handle potential ImportError
try:
    import ccxt.async_support as ccxt
    from ccxt.base.errors import (
        ArgumentsRequired,
        AuthenticationError,
        BadSymbol,
        ExchangeError,
        ExchangeNotAvailable,
        InsufficientFunds,
        InvalidOrder,
        NetworkError,
        NotSupported,
        OrderImmediatelyFillable,
        OrderNotFound,
        RateLimitExceeded,
        RequestTimeout,
    )
    # Check CCXT version
    if hasattr(ccxt, '__version__'):
        try:
            ccxt_version = tuple(map(int, ccxt.__version__.split('.')))
            if ccxt_version < (4, 1, 0): # Recommend 4.1.0+ for better V5 support
                print(f"{Fore.YELLOW}Warning: CCXT version {ccxt.__version__} might be outdated for full Bybit V5 functionality. Recommend version 4.1.0 or higher.{Style.RESET_ALL}")
        except Exception:
            print(f"{Fore.YELLOW}Warning: Could not parse CCXT version: {ccxt.__version__}{Style.RESET_ALL}")
    else:
         print(f"{Fore.YELLOW}Warning: Could not determine CCXT version.{Style.RESET_ALL}")

except ImportError:
    print(f"{Back.RED}{Fore.WHITE}FATAL ERROR: CCXT library not found.{Style.RESET_ALL}")
    print("Please install it: pip install ccxt>=4.1.0")
    sys.exit(1)

# Attempt to import pandas and handle potential ImportError (Optional)
try:
    import pandas as pd
except ImportError:
    print("Info: pandas library not found. OHLCV functions will return lists, not DataFrames.")
    print("Install for DataFrame support: pip install pandas>=2.0.0")
    pd = None  # Set pandas to None if not installed

# Attempt to import colorama and handle potential ImportError (Optional)
try:
    from colorama import Back, Fore, Style, init
    # Initialize colorama
    if os.name == "nt":
        init(autoreset=True) # Autoreset is convenient on Windows
    else:
        init() # Standard init for other platforms
except ImportError:
    print("Info: colorama not found. Logs will be uncolored.")
    # Define dummy color objects if colorama is not available
    class DummyColor:
        def __getattr__(self, name: str) -> str:
            return ""
    Fore = Style = Back = DummyColor()

# Attempt to import websockets and handle potential ImportError (Optional)
# Note: Full WebSocket implementation is not included in this enhanced script,
# but the imports are kept for compatibility if added later.
try:
    import websockets
    from websockets.exceptions import (
        ConnectionClosed,
        ConnectionClosedError,
        ConnectionClosedOK,
        InvalidURI,
        WebSocketException,
        ProtocolError
    )
    # Path might change in future websockets versions
    from websockets.legacy.client import WebSocketClientProtocol
except ImportError:
    print("Info: websockets library not found. WebSocket features disabled.")
    websockets = None
    class DummyWebSocketException(Exception): pass
    WebSocketClientProtocol = Any # type: ignore
    # Define dummy exceptions if websockets is not available
    WebSocketException = ConnectionClosed = ConnectionClosedOK = ConnectionClosedError = InvalidURI = ProtocolError = DummyWebSocketException


# --- Configuration & Constants ---

getcontext().prec = 28 # Set precision for Decimal operations

class Config(TypedDict, total=False):
    """Strongly typed configuration dictionary."""
    EXCHANGE_ID: Literal["bybit"]
    API_KEY: Optional[str] # Made optional to allow public-only mode
    API_SECRET: Optional[str] # Made optional
    TESTNET_MODE: bool
    SYMBOL: str # Default symbol for context
    USDT_SYMBOL: str # Typically 'USDT'
    DEFAULT_MARGIN_MODE: Literal["isolated", "cross"]
    DEFAULT_RECV_WINDOW: int
    DEFAULT_SLIPPAGE_PCT: Decimal
    POSITION_QTY_EPSILON: Decimal # Small value for float comparisons
    SHALLOW_OB_FETCH_DEPTH: int # For quick spread checks
    ORDER_BOOK_FETCH_LIMIT: int # For full order book fetch
    EXPECTED_MARKET_TYPE: Literal["swap", "spot", "option", "future"] # Default context
    EXPECTED_MARKET_LOGIC: Literal["linear", "inverse"] # Default context
    RETRY_COUNT: int # For retry decorator
    RETRY_DELAY_SECONDS: float # Initial delay for retry
    WS_CONNECT_TIMEOUT: float # WebSocket connection timeout
    WS_PING_INTERVAL: Optional[float] # WebSocket ping interval (e.g., 20.0 for Bybit)
    ENABLE_SMS_ALERTS: bool
    # Placeholder SMS config (ensure these are handled if ENABLE_SMS_ALERTS is True)
    # TWILIO_ACCOUNT_SID: Optional[str]
    # TWILIO_AUTH_TOKEN: Optional[str]
    # TWILIO_FROM_NUMBER: Optional[str]
    # ALERT_TO_NUMBER: Optional[str]
    BROKER_ID: Optional[str] # Optional Broker/Referral ID
    VERSION: str # Helper script version


# --- Enums ---
# Using standard Enums for better code clarity and safety
class Side(str, Enum):
    BUY = "buy"
    SELL = "sell"

class Category(str, Enum):
    LINEAR = "linear"
    INVERSE = "inverse"
    SPOT = "spot"
    OPTION = "option"

class OrderFilter(str, Enum):
    """V5 Order Filter Types for fetch/cancel operations."""
    ORDER = "Order" # Active limit/market orders
    STOP_ORDER = "StopOrder" # Conditional orders (Stop Loss, Take Profit, basic Stop)
    TPSL_ORDER = "tpslOrder" # TP/SL orders attached specifically to positions (V5 feature)
    # Add others if needed: "OcoOrder", "OtoOrder"

class TimeInForce(str, Enum):
    GTC = "GTC" # Good Til Cancelled
    IOC = "IOC" # Immediate or Cancel
    FOK = "FOK" # Fill or Kill
    POST_ONLY = "PostOnly"

class TriggerDirection(int, Enum):
    """Direction for conditional order triggers (1: Rise, 2: Fall)."""
    RISE = 1 # Trigger when price rises to triggerPrice
    FALL = 2 # Trigger when price falls to triggerPrice

class PositionIdx(int, Enum):
    """Position index for Hedge Mode (0: One-Way, 1: Buy Hedge, 2: Sell Hedge)."""
    ONE_WAY = 0
    BUY_SIDE = 1 # Hedge Mode Buy
    SELL_SIDE = 2 # Hedge Mode Sell

class TriggerBy(str, Enum):
    """Price type for conditional order triggers."""
    LAST = "LastPrice"
    MARK = "MarkPrice"
    INDEX = "IndexPrice"

class OrderType(str, Enum):
    """Basic order types."""
    MARKET = "Market"
    LIMIT = "Limit"

# --- Logger Setup ---
# Basic logger setup, integrates with standard logging.
# Assumes the calling script (e.g., main.py) sets up the desired handlers/formatters.
logger = logging.getLogger("bybit_helpers") # Use a specific name for this module
if not logger.hasHandlers(): # Avoid adding handlers multiple times if root logger is configured
    logger.addHandler(logging.NullHandler()) # Add NullHandler to prevent "No handler found" warnings
    # Set default level - can be overridden by application's logging config
    logger.setLevel(logging.INFO)
    # logger.propagate = True # Allow messages to propagate to root logger by default

# --- Market Cache ---
class MarketCache:
    """Caches market data fetched from the exchange to reduce API calls."""
    def __init__(self):
        self._markets: Dict[str, Dict[str, Any]] = {}
        self._categories: Dict[str, Optional[Category]] = {} # Cache derived category
        self._lock = asyncio.Lock() # Protect concurrent access

    async def load_markets(self, exchange: ccxt.bybit, reload: bool = False) -> bool:
        """Loads or reloads all markets into the cache asynchronously and safely."""
        async with self._lock:
            if not self._markets or reload:
                action = "Reloading" if self._markets else "Loading"
                logger.info(f"{Fore.BLUE}[MarketCache] {action} markets from {exchange.id}...{Style.RESET_ALL}")
                try:
                    # Explicitly reload market data from the exchange
                    # Using reload=True ensures fresh data, crucial after potential network issues
                    all_markets = await exchange.load_markets(reload=True)

                    if not all_markets:
                        # This case indicates a problem, maybe empty response or parsing issue in CCXT
                        logger.critical(f"{Back.RED}[MarketCache] FATAL: Failed to load markets - received empty or invalid data from CCXT.{Style.RESET_ALL}")
                        self._markets = {}
                        self._categories = {}
                        return False

                    self._markets = all_markets
                    self._categories.clear() # Clear derived category cache
                    logger.info(f"{Fore.GREEN}[MarketCache] Successfully loaded {len(self._markets)} markets.{Style.RESET_ALL}")
                    return True

                # Handle specific CCXT exceptions for network/availability issues
                except (NetworkError, ExchangeNotAvailable, RequestTimeout) as e:
                    logger.error(f"{Fore.RED}[MarketCache] Network/Availability error loading markets: {type(e).__name__}: {e}{Style.RESET_ALL}")
                    # Don't clear markets here, might be temporary issue, allow retries at higher level
                    return False
                # Handle general exchange errors during market loading
                except ExchangeError as e:
                    logger.error(f"{Fore.RED}[MarketCache] Exchange error loading markets: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=False)
                    # Don't clear markets, could be permissions or temporary API issue
                    return False
                # Catch any other unexpected exceptions during market loading
                except Exception as e:
                    logger.critical(f"{Back.RED}[MarketCache] CRITICAL UNEXPECTED error loading markets: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=True)
                    # Clear markets as state is unknown
                    self._markets = {}
                    self._categories = {}
                    return False
            else:
                # Markets already loaded and reload not requested
                logger.debug("[MarketCache] Markets already loaded, skipping reload.")
                return True

    def get_market(self, symbol: str) -> Optional[Dict[str, Any]]:
        """Retrieves market data for a symbol from the cache."""
        if not self._markets:
            logger.warning("[MarketCache] Market cache is empty. Call load_markets first.")
            return None
        market_data = self._markets.get(symbol)
        if not market_data:
            # Changed to warning as it might be a newly listed symbol not yet cached
            logger.warning(f"[MarketCache] Market data for '{symbol}' not found in cache.")
        return market_data

    def get_category(self, symbol: str) -> Optional[Category]:
        """Retrieves the V5 category for a symbol, using cached result if available."""
        if not self._markets:
             logger.warning("[MarketCache] Market cache is empty. Cannot determine category.")
             return None

        # Check cache first
        if symbol in self._categories:
            return self._categories[symbol]

        # If not cached, determine from market data
        market = self.get_market(symbol)
        category: Optional[Category] = None
        if market:
            category_str = _get_v5_category(market) # Use internal helper
            if category_str:
                try:
                    category = Category(category_str)
                except ValueError:
                    logger.error(f"[MarketCache] Invalid category value '{category_str}' derived for '{symbol}'.")
                    category = None # Mark as invalid/undetermined
            else:
                 # Warning if category couldn't be derived at all
                 logger.warning(f"[MarketCache] Could not derive category for symbol '{symbol}'.")
        else:
            # If market data itself is missing, category cannot be determined
             logger.warning(f"[MarketCache] Market data missing for '{symbol}', cannot determine category.")


        # Cache the result (even if None) to avoid re-computation
        self._categories[symbol] = category
        return category

    def get_all_symbols(self) -> List[str]:
        """Returns a list of all symbols currently loaded in the cache."""
        return list(self._markets.keys())

# Instantiate the cache globally or pass it around as needed
market_cache = MarketCache()

# --- Utility Functions ---

def safe_decimal_conversion(value: Any, default: Optional[Decimal] = None) -> Optional[Decimal]:
    """Safely converts a value to a Decimal, handling None, empty strings, NaN, Infinity."""
    if value is None or value == "":
        return default
    try:
        # Convert to string first to handle floats more reliably and avoid precision issues
        val_str = str(value)
        d = Decimal(val_str)
        # Check for NaN (Not a Number) and Infinity
        if d.is_nan() or d.is_infinite():
            logger.warning(f"[safe_decimal] Input '{value}' resulted in NaN or Infinity, returning default.")
            return default
        return d
    except (ValueError, TypeError, InvalidOperation):
        # Catch potential errors during conversion (e.g., non-numeric string)
        logger.warning(f"[safe_decimal] Could not convert '{value}' (type: {type(value).__name__}) to Decimal, returning default.")
        return default

def format_price(exchange: ccxt.bybit, symbol: str, price: Union[Decimal, float, str, None]) -> Optional[str]:
    """Formats a price according to market precision using CCXT, with improved fallback."""
    if price is None: return None
    market = market_cache.get_market(symbol) # Use cached market data
    price_decimal = safe_decimal_conversion(price) # Use safe conversion

    if price_decimal is None:
        logger.error(f"[format_price] Invalid price value '{price}' for {symbol} after conversion.")
        return None # Cannot format invalid decimal

    if not market:
        logger.warning(f"[format_price] Market data for {symbol} unavailable. Returning raw Decimal string: {price_decimal}")
        return str(price_decimal) # Fallback to raw string if no market data

    try:
        # Use CCXT's built-in precision formatting (expects float)
        return exchange.price_to_precision(symbol, float(price_decimal))
    except BadSymbol:
         # This might happen if markets become stale after initial load
         logger.error(f"[format_price] BadSymbol error for {symbol}. Markets might be stale. Using fallback formatting.")
    except NotSupported:
         logger.warning(f"[format_price] CCXT price_to_precision not supported for {symbol}. Using fallback.")
    except Exception as e:
        # Catch other potential CCXT errors
        logger.error(f"[format_price] CCXT error formatting price {price_decimal} for {symbol}: {e}", exc_info=False)

    # --- Fallback Formatting (if CCXT method fails or market is stale) ---
    try:
        # Attempt to get precision from the cached market data
        # CCXT structure: market['precision']['price'] (usually number of decimal places)
        price_precision_digits = market.get("precision", {}).get("price")

        if price_precision_digits is not None:
            # Determine the precision factor (e.g., 0.0001 for 4 decimal places)
            # Handle both tick size (e.g., 0.0001) and number of digits (e.g., 4) representation
            precision_str = str(price_precision_digits)
            if '.' in precision_str: # Assume it's a tick size like '0.0001'
                precision_decimal = Decimal(precision_str)
            else: # Assume it's the number of decimal places
                precision_decimal = Decimal('1e-' + str(int(precision_str)))

            # Use Decimal quantization for accurate rounding
            formatted_price = price_decimal.quantize(precision_decimal)
            return str(formatted_price)
        else:
            # If precision info is missing, return the unconverted decimal as string
            logger.warning(f"[format_price] Price precision ('precision.price') not found for {symbol} in market data. Returning raw Decimal string.")
            return str(price_decimal)
    except (ValueError, TypeError, KeyError, InvalidOperation) as format_err:
        # Catch errors during fallback formatting itself
        logger.error(f"[format_price] Fallback formatting failed for {price_decimal}: {format_err}. Returning raw Decimal string.")
        return str(price_decimal) # Last resort: return raw decimal string

def format_amount(exchange: ccxt.bybit, symbol: str, amount: Union[Decimal, float, str, None]) -> Optional[str]:
    """Formats an amount according to market precision using CCXT, with improved fallback."""
    if amount is None: return None
    market = market_cache.get_market(symbol)
    amount_decimal = safe_decimal_conversion(amount)

    if amount_decimal is None:
        logger.error(f"[format_amount] Invalid amount value '{amount}' for {symbol} after conversion.")
        return None

    if not market:
        logger.warning(f"[format_amount] Market data for {symbol} unavailable. Returning raw Decimal string: {amount_decimal}")
        return str(amount_decimal)

    try:
        # Use CCXT's built-in precision formatting (expects float)
        return exchange.amount_to_precision(symbol, float(amount_decimal))
    except BadSymbol:
         logger.error(f"[format_amount] BadSymbol error for {symbol}. Markets might be stale. Using fallback formatting.")
    except NotSupported:
         logger.warning(f"[format_amount] CCXT amount_to_precision not supported for {symbol}. Using fallback.")
    except Exception as e:
        logger.error(f"[format_amount] CCXT error formatting amount {amount_decimal} for {symbol}: {e}", exc_info=False)

    # --- Fallback Formatting ---
    try:
        # CCXT structure: market['precision']['amount'] (usually number of decimal places or step size)
        amount_precision = market.get("precision", {}).get("amount")
        if amount_precision is not None:
            precision_str = str(amount_precision)
            if '.' in precision_str: # Assume it's a step size like '0.1' or '0.001'
                 precision_decimal = Decimal(precision_str)
            else: # Assume it's number of decimal places
                 precision_decimal = Decimal('1e-' + str(int(precision_str)))

            # Quantize to the determined precision
            formatted_amount = amount_decimal.quantize(precision_decimal)
            return str(formatted_amount)
        else:
            logger.warning(f"[format_amount] Amount precision ('precision.amount') not found for {symbol} in market data. Returning raw Decimal string.")
            return str(amount_decimal)
    except (ValueError, TypeError, KeyError, InvalidOperation) as format_err:
        logger.error(f"[format_amount] Fallback formatting failed for {amount_decimal}: {format_err}. Returning raw Decimal string.")
        return str(amount_decimal)

def format_order_id(order_id: Optional[str]) -> str:
    """Returns a truncated version of the order ID for cleaner logging."""
    if not order_id: return "N/A"
    # Show first few and last few characters for uniqueness
    if len(order_id) > 12:
        return f"{order_id[:4]}...{order_id[-4:]}"
    return order_id

def send_sms_alert(message: str, config: Optional[Config] = None) -> None:
    """Placeholder for sending SMS alerts. Logs warning if triggered."""
    # Check if config exists and SMS is enabled
    if not config or not config.get('ENABLE_SMS_ALERTS', False):
        # Log info message if SMS is disabled but alert was called
        # logger.info(f"[SMS Alert Disabled] >> {message}") # Can be noisy, disable if not needed
        return

    # Log a warning indicating an alert would be sent
    logger.warning(f"{Back.YELLOW}{Fore.BLACK}[SMS Alert Triggered]{Style.RESET_ALL} >> {message}")

    # ---=== Placeholder for Actual SMS Integration ===---
    # Example using Twilio (requires 'twilio' library: pip install twilio)
    # account_sid = config.get("TWILIO_ACCOUNT_SID")
    # auth_token = config.get("TWILIO_AUTH_TOKEN")
    # from_num = config.get("TWILIO_FROM_NUMBER")
    # to_num = config.get("ALERT_TO_NUMBER")
    #
    # if not all([account_sid, auth_token, from_num, to_num]):
    #     logger.error("[SMS Alert] Twilio configuration keys missing. Cannot send SMS.")
    #     return
    #
    # try:
    #     from twilio.rest import Client
    #     client = Client(account_sid, auth_token)
    #     sms = client.messages.create(
    #         body=f"[TradingBot] {message}",
    #         from_=from_num,
    #         to=to_num
    #     )
    #     logger.info(f"[SMS Alert] Successfully sent. SID: {sms.sid}")
    # except ImportError:
    #     logger.error("[SMS Alert] Twilio library not found. Cannot send SMS. (pip install twilio)")
    # except Exception as e:
    #     logger.error(f"[SMS Alert] Failed to send SMS: {e}", exc_info=False)
    # ---=== End Placeholder ===---


def _get_v5_category(market: Dict[str, Any]) -> Optional[str]:
    """Internal helper to determine Bybit V5 category from CCXT market info. Prioritizes V5 fields."""
    if not market: return None
    symbol = market.get("symbol", "N/A") # For logging context

    # 1. Check V5 specific 'info' fields first (most reliable)
    info = market.get("info", {})
    # Bybit V5 API response field for category is often lowercase 'category'
    v5_category = info.get("category")
    if v5_category and isinstance(v5_category, str):
        try:
            # Validate against our Enum (case-insensitive comparison)
            cat_enum = Category(v5_category.lower())
            logger.debug(f"[_get_v5_category] Using category '{cat_enum.value}' from market['info']['category'] for {symbol}")
            return cat_enum.value
        except ValueError:
            # Log if the value from API is not in our Enum
            logger.warning(f"[_get_v5_category] Unknown category '{v5_category}' found in market['info'] for {symbol}. Ignoring.")

    # 2. Check explicit CCXT flags (derived by CCXT based on V5 info or other fields)
    # These flags are usually reliable if CCXT version is up-to-date
    if market.get("spot", False): return Category.SPOT.value
    if market.get("option", False): return Category.OPTION.value # Usually USDC settled
    if market.get("linear", False): return Category.LINEAR.value # USDT or USDC settled contracts
    if market.get("inverse", False): return Category.INVERSE.value # Coin settled contracts

    # 3. Infer from 'type' and other info (less reliable fallback, needed if flags are missing/wrong)
    market_type = market.get("type") # CCXT's general type ('spot', 'swap', 'future', 'option')
    settle_coin = market.get("settle", "").upper() # e.g., 'USDT', 'USDC', 'BTC', 'ETH'
    base_coin = market.get("base", "").upper()
    quote_coin = market.get("quote", "").upper()
    # Check 'contractType' in 'info' as well (e.g., 'LinearPerpetual', 'InversePerpetual')
    contract_type_info = str(info.get("contractType", "")).lower()

    logger.debug(f"[_get_v5_category] Inferring category for {symbol}: type={market_type}, settle={settle_coin}, contractType='{contract_type_info}'")

    if market_type == "spot": return Category.SPOT.value
    if market_type == "option":
        # V5 options are typically USDC settled
        if settle_coin == "USDC" or info.get("settleCoin") == "USDC": return Category.OPTION.value
        else: logger.warning(f"[_get_v5_category] Found option type for {symbol} but settle is '{settle_coin}' (expected USDC). Category unclear."); return None
    if market_type in ["swap", "future"]:
        # Use contractType field if available and clear
        if "linear" in contract_type_info: return Category.LINEAR.value
        if "inverse" in contract_type_info: return Category.INVERSE.value
        # Fallback: Check settle currency
        if settle_coin in ["USDT", "USDC"] or info.get("settleCoin") in ["USDT", "USDC"]: return Category.LINEAR.value
        # Fallback: Check if settle is the base currency (characteristic of inverse)
        if settle_coin == base_coin and settle_coin: return Category.INVERSE.value
        # Fallback: Check if quote contains USD (likely linear)
        if "USD" in quote_coin and quote_coin != settle_coin: return Category.LINEAR.value # USDT or USDC, but not inverse
        # If still unsure, make a best guess (Linear is more common now)
        logger.warning(f"[_get_v5_category] Could not reliably determine contract category for {symbol} (type: {market_type}, settle: {settle_coin}, contractType: '{contract_type_info}'). Assuming LINEAR as default.")
        return Category.LINEAR.value

    # If type is unknown or doesn't fit known patterns
    logger.warning(f"[_get_v5_category] Could not determine category for {symbol} with market type '{market_type}'.")
    return None


# --- Asynchronous Retry Decorator ---
T = TypeVar("T") # Generic type variable for return value
FuncT = Callable[..., Coroutine[Any, Any, T]] # Type hint for the decorated async function

def retry_api_call(
    max_retries: int = 3,
    initial_delay: float = 1.0,
    backoff_factor: float = 2.0,
    jitter: float = 0.1, # Adds randomness to delay: delay * (1 +/- jitter)
    retry_on_exceptions: Sequence[type[Exception]] = (
        NetworkError, RateLimitExceeded, ExchangeNotAvailable, RequestTimeout,
    ), # Exceptions that trigger a retry
    log_level: int = logging.WARNING, # Level for retry attempt logs
    fail_log_level: int = logging.ERROR, # Level when max retries are reached
):
    """Asynchronous decorator for retrying API calls with exponential backoff and jitter."""
    def decorator(func: FuncT) -> FuncT:
        async def async_wrapper(*args, **kwargs) -> T:
            # Allow overriding retries per-call via kwargs if needed (use carefully)
            effective_max_retries = kwargs.pop("retries", max_retries)
            current_delay = initial_delay
            last_exception: Optional[Exception] = None

            # Loop from 0 to max_retries (inclusive), meaning max_retries + 1 attempts total
            for attempt in range(effective_max_retries + 1):
                try:
                    # Attempt to call the original async function
                    return await func(*args, **kwargs)
                except retry_on_exceptions as e:
                    last_exception = e
                    # If this was the last attempt, log failure and re-raise
                    if attempt == effective_max_retries:
                        logger.log(fail_log_level, f"{Fore.RED}[{func.__name__}] Max retries ({effective_max_retries}) reached. Last error: {type(e).__name__}: {e}{Style.RESET_ALL}")
                        raise # Re-raise the last caught exception
                    else:
                        # Calculate wait time with backoff and jitter
                        actual_jitter = random.uniform(-jitter, jitter)
                        wait_time = max(0.1, current_delay + (current_delay * actual_jitter)) # Ensure delay is positive
                        # Log the retry attempt
                        logger.log(log_level, f"{Fore.YELLOW}[{func.__name__}] Attempt {attempt + 1}/{effective_max_retries + 1} failed: {type(e).__name__}. Retrying in {wait_time:.2f}s...{Style.RESET_ALL}")
                        # Wait before the next attempt
                        await asyncio.sleep(wait_time)
                        # Increase delay for the next potential retry
                        current_delay *= backoff_factor
                except Exception as e:
                    # Catch any other unexpected exceptions not in retry_on_exceptions
                    # Log these as errors and re-raise immediately without retry
                    logger.error(f"{Fore.RED}[{func.__name__}] Unhandled exception during attempt {attempt + 1}: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=True)
                    raise # Re-raise immediately, don't retry unhandled exceptions

            # This part should theoretically not be reached if max_retries >= 0
            # If it is reached, it implies a logic error in the loop or exception handling
            if last_exception:
                # Should have been raised inside the loop on the last attempt
                logger.critical(f"[{func.__name__}] Retry logic error: Exited loop but had a last exception. Re-raising.")
                raise last_exception
            else:
                # This case is extremely unlikely unless max_retries was negative
                logger.critical(f"[{func.__name__}] Retry logic completed unexpectedly without return or exception.")
                # The function expects type T, but we have nothing; raising is safer than returning None.
                raise RuntimeError(f"[{func.__name__}] Retry logic failed unexpectedly.")


        # Preserve original function's name and docstring for introspection
        async_wrapper.__name__ = func.__name__
        async_wrapper.__doc__ = func.__doc__
        return async_wrapper
    return decorator


# --- Exchange Initialization & Configuration ---
@retry_api_call(
    max_retries=2, # Fewer retries for initialization
    initial_delay=3.0, # Longer initial delay
    retry_on_exceptions=(NetworkError, ExchangeNotAvailable, RequestTimeout), # Only retry network issues on init
    fail_log_level=logging.CRITICAL # Failure here is critical
)
async def initialize_bybit(config: Config) -> Optional[ccxt.bybit]:
    """
    Initializes Bybit CCXT V5 instance, loads markets, checks auth, sets initial config.

    **IMPORTANT:** The returned exchange instance requires explicit cleanup.
    Call `await exchange.close()` in a `finally` block when done.
    """
    func_name = "initialize_bybit"
    mode = "Testnet" if config.get("TESTNET_MODE", False) else "Mainnet"
    logger.info(f"{Fore.BLUE}[{func_name}] Initializing Bybit V5 ({mode})...{Style.RESET_ALL}")
    exchange: Optional[ccxt.bybit] = None # Initialize as None

    try:
        # Check if API keys are provided for private access
        has_keys = bool(config.get("API_KEY") and config.get("API_SECRET"))
        if not has_keys:
            logger.warning(f"{Fore.YELLOW}[{func_name}] API Key/Secret missing. PUBLIC endpoints mode only.{Style.RESET_ALL}")

        # Construct Broker ID if provided or use default based on version
        broker_id = config.get("BROKER_ID")
        if not broker_id and config.get("VERSION"):
            # Example format - adjust as needed
            broker_id = f"PB_PyHlp{config['VERSION'].replace('.', '')}"
            logger.debug(f"[{func_name}] Using default Broker ID based on version: {broker_id}")

        # CCXT Exchange Options
        exchange_options: Dict[str, Any] = {
            "apiKey": config.get("API_KEY"),
            "secret": config.get("API_SECRET"),
            "enableRateLimit": True, # Enable CCXT's built-in rate limiter
            "options": {
                'defaultType': config.get('EXPECTED_MARKET_TYPE', 'swap'), # Default market type for calls
                'adjustForTimeDifference': True, # Attempt to sync clock with server
                'recvWindow': config.get('DEFAULT_RECV_WINDOW', 5000), # API request validity window
                # 'verbose': True, # Uncomment for extreme CCXT request/response logging
                'fetchPositionsRequiresCategory': True, # V5 requires category for positions
                'brokerId': broker_id if broker_id else None, # Add brokerId if available
            },
        }
        # Remove brokerId if None
        if not exchange_options['options']['brokerId']:
            del exchange_options['options']['brokerId']

        logger.debug(f"[{func_name}] Instantiating CCXT Bybit with options: {exchange_options['options']}")
        exchange = ccxt.bybit(exchange_options)

        # Set sandbox mode if configured
        if config.get("TESTNET_MODE", False):
            exchange.set_sandbox_mode(True)
        logger.info(f"[{func_name}] {mode} mode active. API Endpoint Base: {exchange.urls.get('api', 'N/A')}")

        # --- Load Markets (Crucial Step) ---
        logger.info(f"[{func_name}] Loading markets via MarketCache (force reload)...")
        # Use the MarketCache instance to load markets
        load_success = await market_cache.load_markets(exchange, reload=True)

        if not load_success:
             # If market loading fails critically, abort initialization
             logger.critical(f"{Back.RED}[{func_name}] CRITICAL: Failed to load markets. Aborting initialization.{Style.RESET_ALL}")
             # Attempt to close the partially created exchange instance (BEST EFFORT)
             if exchange and hasattr(exchange, 'close'):
                 logger.info(f"[{func_name}] Attempting to close partially initialized exchange instance...")
                 try:
                     await exchange.close()
                 except Exception as close_err:
                     # Log error during cleanup but proceed to return None
                     logger.error(f"[{func_name}] Error closing exchange during cleanup after market load failure: {close_err}")
             return None # Return None to indicate failure

        # --- Validate Default Symbol ---
        default_symbol = config.get("SYMBOL")
        if not default_symbol:
             log_msg = "CRITICAL: Default 'SYMBOL' not defined in configuration."
             logger.critical(f"{Back.RED}[{func_name}] {log_msg}{Style.RESET_ALL}")
             # Ensure cleanup before returning
             if exchange and hasattr(exchange, 'close'): await exchange.close()
             return None
        # Check if market exists in cache *after* loading
        if not market_cache.get_market(default_symbol):
            log_msg = f"CRITICAL: Market data for default symbol '{default_symbol}' NOT FOUND after loading markets."
            logger.critical(f"{Back.RED}[{func_name}] {log_msg}{Style.RESET_ALL}")
            # Ensure cleanup before returning
            if exchange and hasattr(exchange, 'close'): await exchange.close()
            return None
        logger.debug(f"[{func_name}] Default symbol '{default_symbol}' found in market cache.")

        # --- Authentication Check (if keys provided) ---
        if has_keys:
            logger.info(f"[{func_name}] Performing authentication check (fetching UNIFIED balance)...")
            try:
                # Fetching balance is a common way to verify API key validity and permissions
                # Using UNIFIED account type for V5
                await exchange.fetch_balance(params={"accountType": "UNIFIED"})
                logger.info(f"[{func_name}] Authentication check successful (Unified Balance fetched).")
            except AuthenticationError as auth_err:
                # Critical failure if authentication fails
                logger.critical(f"{Back.RED}[{func_name}] CRITICAL: Authentication FAILED: {auth_err}. Check API Key/Secret/Permissions.{Style.RESET_ALL}")
                send_sms_alert("[BybitHelper] CRITICAL: Bybit Authentication Failed!", config)
                if exchange and hasattr(exchange, 'close'): await exchange.close() # Cleanup
                return None
            except (NetworkError, RequestTimeout, ExchangeNotAvailable) as net_err:
                # Critical if network fails during auth check (retries already handled by decorator)
                logger.critical(f"{Back.RED}[{func_name}] CRITICAL Network Error during authentication check: {net_err}.{Style.RESET_ALL}")
                if exchange and hasattr(exchange, 'close'): await exchange.close() # Cleanup
                return None
            except ExchangeError as bal_err:
                # Warning for other exchange errors during balance fetch (e.g., temporary issue, insufficient perms)
                logger.warning(f"{Fore.YELLOW}[{func_name}] Warning during auth check (fetch_balance): {type(bal_err).__name__}: {bal_err}. Check API status or permissions.{Style.RESET_ALL}")
                # Continue initialization, but be aware of potential issues
        else:
            logger.info(f"[{func_name}] Skipping authentication check (no API keys provided).")

        # --- Initial Configuration (Leverage/Margin - Optional) ---
        category = market_cache.get_category(default_symbol) if default_symbol else None
        # Only attempt leverage setting if keys are present and symbol is Linear/Inverse
        if has_keys and category in [Category.LINEAR, Category.INVERSE]:
            logger.info(f"[{func_name}] Attempting initial margin/leverage config for {default_symbol}...")
            try:
                default_margin_mode = config.get("DEFAULT_MARGIN_MODE", "isolated") # Default to isolated if not set
                if default_margin_mode == "isolated":
                    # Set initial leverage (implicitly sets isolated mode for the symbol in V5 UTA)
                    # Consider making initial leverage configurable
                    initial_leverage = 10 # Example default
                    logger.info(f"[{func_name}] Setting default leverage to {initial_leverage}x for {default_symbol} (implies ISOLATED mode for this symbol).")
                    # Call set_leverage helper function (already has retries)
                    set_lev_success = await set_leverage(exchange, default_symbol, initial_leverage, config)
                    if not set_lev_success:
                        logger.warning(f"[{func_name}] Failed to set initial leverage for {default_symbol}, but continuing initialization.")
                else: # 'cross'
                    # For V5 UTA, 'cross' is account-wide (REGULAR_MARGIN or PORTFOLIO_MARGIN)
                    logger.info(f"[{func_name}] Configured default margin mode is CROSS (account-level for UTA). Verifying account margin mode...")
                    # Use fetch_account_info to check the actual account mode
                    acc_info = await fetch_account_info_bybit_v5(exchange, config) # Already has retries
                    # V5 UTA Margin Modes: REGULAR_MARGIN (Cross), PORTFOLIO_MARGIN (Cross), ISOLATED_MARGIN (Isolated)
                    if acc_info:
                        account_margin_mode = acc_info.get('marginMode')
                        if account_margin_mode == 'ISOLATED_MARGIN':
                            logger.warning(f"{Fore.YELLOW}[{func_name}] Account margin mode is ISOLATED_MARGIN, but config DEFAULT_MARGIN_MODE is 'cross'. Potential mismatch? Consider account settings.{Style.RESET_ALL}")
                        elif account_margin_mode in ['REGULAR_MARGIN', 'PORTFOLIO_MARGIN']:
                            logger.info(f"[{func_name}] Account margin mode confirmed as '{account_margin_mode}' (consistent with 'cross' config). No per-symbol action needed for cross mode.")
                        else:
                            logger.warning(f"[{func_name}] Unknown account margin mode '{account_margin_mode}' received.")
                    else:
                         # This handles the case from the original logs where verification failed
                         logger.warning(f"[{func_name}] Could not reliably verify account margin mode via fetch_account_info_bybit_v5.")

            except Exception as config_err:
                # Log warning if initial config fails, but don't abort initialization
                logger.warning(f"{Fore.YELLOW}[{func_name}] Could not apply initial margin/leverage config for {default_symbol}: {type(config_err).__name__}. Error: {config_err}{Style.RESET_ALL}")
        elif not category or category not in [Category.LINEAR, Category.INVERSE]:
             logger.info(f"[{func_name}] Skipping initial margin/leverage setup (default symbol '{default_symbol}' is {category}, not Linear/Inverse).")
        else: # No keys
             logger.info(f"[{func_name}] Skipping initial margin/leverage setup (no API keys).")

        # --- Initialization Success ---
        logger.info(f"{Fore.GREEN}[{func_name}] Bybit V5 exchange initialized successfully.{Style.RESET_ALL}")
        logger.warning(f"{Back.YELLOW}{Fore.BLACK}IMPORTANT: Remember to call 'await exchange.close()' when finished to release resources.{Style.RESET_ALL}")
        return exchange

    # --- Exception Handling for Initialization Block ---
    except AuthenticationError as e:
        logger.critical(f"{Back.RED}[{func_name}] CRITICAL Authentication Error during setup: {e}.{Style.RESET_ALL}")
        send_sms_alert("[BybitHelper] CRITICAL: Bybit Authentication Failed!", config)
    except (NetworkError, ExchangeNotAvailable, RequestTimeout) as e:
        # This might catch errors if retries fail within this function's retry decorator
        logger.critical(f"{Back.RED}[{func_name}] CRITICAL Network Error during initialization (after retries): {e}.{Style.RESET_ALL}")
    except BadSymbol as e: # Catch error if default symbol is invalid format early
        logger.critical(f"{Back.RED}[{func_name}] CRITICAL Invalid Default Symbol Error: {e}.{Style.RESET_ALL}")
    except ExchangeError as e:
        logger.critical(f"{Back.RED}[{func_name}] CRITICAL Exchange Error during initialization: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=False)
        send_sms_alert(f"[BybitHelper] CRITICAL: Init ExchangeError: {type(e).__name__}", config)
    except Exception as e:
        # Catch any other unexpected errors during the process
        logger.critical(f"{Back.RED}[{func_name}] CRITICAL Unexpected Error during initialization: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=True)
        send_sms_alert(f"[BybitHelper] CRITICAL: Init Unexpected Error: {type(e).__name__}", config)

    # --- Cleanup on Failure ---
    # If any exception occurred above, try to close the exchange instance if it was created
    if exchange and hasattr(exchange, 'close'):
        try:
            logger.info(f"[{func_name}] Closing exchange instance due to initialization failure.")
            await exchange.close()
        except Exception as close_err:
             # Log error during cleanup but proceed to return None
             logger.error(f"[{func_name}] Error closing exchange instance during cleanup: {close_err}")

    return None # Return None indicating initialization failed


# --- Account Functions ---

@retry_api_call()
async def fetch_account_info_bybit_v5(exchange: ccxt.bybit, config: Config) -> Optional[Dict]:
    """Fetches detailed account information for the V5 Unified Trading Account.

    Args:
        exchange: Initialized ccxt.bybit instance.
        config: Configuration object (used for logging/context).

    Returns:
        Dictionary containing account info (margin mode, upgrade status, etc.) or None on failure.
        Structure example: {'unifiedMarginStatus': 1, 'marginMode': 'REGULAR_MARGIN', ...}
    """
    func_name = "fetch_account_info_bybit_v5"
    log_prefix = f"[{func_name}]"
    logger.debug(f"{log_prefix} Fetching V5 account info...")

    # Check if exchange object is valid and method exists
    # Use hasattr for safety, though CCXT should have it for bybit
    if not exchange or not hasattr(exchange, 'private_get_v5_account_info'):
        logger.error(f"{Fore.RED}{log_prefix} Invalid exchange object or method 'private_get_v5_account_info' not available.{Style.RESET_ALL}")
        return None

    try:
        # Use the specific V5 implicit endpoint call via CCXT
        response = await exchange.private_get_v5_account_info()
        logger.debug(f"{log_prefix} Raw response: {response}")

        # Validate the response structure and check retCode
        if isinstance(response, dict) and 'retCode' in response:
            ret_code = response.get('retCode')
            ret_msg = response.get('retMsg', 'N/A')
            result_data = response.get('result') # Result field contains the actual data

            if ret_code == 0 and isinstance(result_data, dict):
                # Success according to API
                account_info = result_data # The result field IS the account info dict
                margin_mode = account_info.get('marginMode', 'N/A')
                status = account_info.get('unifiedMarginStatus', 'N/A') # 1: Regular UTA, 2: Pro UTA, 3:?, 4:?
                dcp_status = account_info.get('dcpStatus', 'N/A') # Disconnected Program status

                # Log success clearly
                logger.info(f"{Fore.GREEN}{log_prefix} Success. Margin Mode: {margin_mode}, UTA Status: {status}, DCP Status: {dcp_status}{Style.RESET_ALL}")
                return account_info
            else:
                # API returned an error code or unexpected result structure
                logger.error(f"{Fore.RED}{log_prefix} Failed to fetch account info. API Code: {ret_code}, Msg: {ret_msg}. Result: {result_data}{Style.RESET_ALL}")
                return None
        else:
            # Response format is completely unexpected (not a dict, missing retCode)
            logger.error(f"{Fore.RED}{log_prefix} Unexpected response format received: {str(response)[:200]}...{Style.RESET_ALL}")
            return None

    except AuthenticationError as e:
        logger.error(f"{Fore.RED}{log_prefix} Authentication error: {e}{Style.RESET_ALL}")
        return None
    except (NetworkError, ExchangeNotAvailable, RequestTimeout) as e:
        # These are handled by the retry decorator, log warning and re-raise
        logger.warning(f"{Fore.YELLOW}{log_prefix} Network/Availability error: {type(e).__name__}. Retry handled by decorator.{Style.RESET_ALL}")
        raise # Re-raise for decorator
    except ExchangeError as e:
        # Handle other exchange-specific errors
        logger.error(f"{Fore.RED}{log_prefix} Exchange error: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=False)
        return None
    except Exception as e:
        # Catch any unexpected errors
        logger.error(f"{Fore.RED}{log_prefix} Unexpected error: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=True)
        return None

@retry_api_call()
async def set_leverage(exchange: ccxt.bybit, symbol: str, leverage: int, config: Config) -> bool:
    """Sets leverage for a symbol (Linear/Inverse), implicitly setting ISOLATED mode for that symbol in V5 UTA."""
    func_name = "set_leverage"
    log_prefix = f"[{func_name} ({symbol} -> {leverage}x)]"

    # Validate leverage input
    if leverage <= 0:
        logger.error(f"{Fore.RED}{log_prefix} Leverage must be a positive integer. Received: {leverage}.{Style.RESET_ALL}")
        return False

    # Check market category from cache
    category = market_cache.get_category(symbol)
    if not category or category not in [Category.LINEAR, Category.INVERSE]:
        logger.error(f"{Fore.RED}{log_prefix} Leverage setting only applicable for LINEAR/INVERSE categories. Symbol '{symbol}' is type: {category}.{Style.RESET_ALL}")
        return False

    # Get market data for validation
    market = market_cache.get_market(symbol)
    if not market:
        logger.error(f"{Fore.RED}{log_prefix} Market data not found for {symbol}. Cannot validate leverage limits.{Style.RESET_ALL}")
        # Proceed cautiously without limit check, or return False? Let's proceed with warning.
        logger.warning(f"{log_prefix} Proceeding without leverage limit validation.")
    else:
        # Validate against market leverage limits if available in CCXT structure
        try:
            # CCXT structure: market['limits']['leverage']['min'/'max']
            limits_leverage = market.get("limits", {}).get("leverage", {})
            max_lev_raw = limits_leverage.get("max")
            min_lev_raw = limits_leverage.get("min") # Often 1 or None

            # Use safe conversion for limits
            max_lev = safe_decimal_conversion(max_lev_raw, default=None)
            # Default min leverage to 1 if not specified or invalid
            min_lev = safe_decimal_conversion(min_lev_raw, default=Decimal(1)) or Decimal(1)

            if max_lev is not None: # Only need to check max usually, min is typically 1
                if not (min_lev <= Decimal(leverage) <= max_lev):
                    logger.error(f"{Fore.RED}{log_prefix} Requested leverage {leverage}x is outside the allowed range [{min_lev}x - {max_lev}x] for {symbol}.{Style.RESET_ALL}")
                    return False
                else:
                     logger.debug(f"{log_prefix} Leverage {leverage}x is within market limits [{min_lev}x - {max_lev}x].")
            else:
                 logger.warning(f"{Fore.YELLOW}{log_prefix} Could not parse max leverage limit (max={max_lev_raw}). Proceeding without upper range check.{Style.RESET_ALL}")
        except Exception as e:
            logger.warning(f"{Fore.YELLOW}{log_prefix} Error validating leverage limits: {e}. Proceeding without range check.{Style.RESET_ALL}")

    # Prepare parameters for Bybit V5 setLeverage endpoint
    # Note: Setting leverage per symbol in UTA automatically sets that symbol to ISOLATED margin mode.
    # Bybit V5 API expects string values for leverage.
    params = {
        "category": category.value,
        "buyLeverage": str(leverage),
        "sellLeverage": str(leverage) # Set same for buy and sell for simplicity
    }
    logger.info(f"{Fore.CYAN}{log_prefix} Sending request with params: {params}... (This implies ISOLATED mode for {symbol}){Style.RESET_ALL}")

    try:
        # Use CCXT's set_leverage method, passing V5 params
        # CCXT handles the mapping to the correct API call: POST /v5/position/set-leverage
        response = await exchange.set_leverage(leverage, symbol, params=params)
        # CCXT's set_leverage might return None or {} on success for Bybit, or parsed info
        logger.debug(f"{log_prefix} Raw response from exchange.set_leverage: {response}")
        # We assume success if no exception is raised, as specific success codes are handled in ExchangeError below.
        logger.info(f"{Fore.GREEN}{log_prefix} Request successful (Leverage likely set to {leverage}x, mode is ISOLATED for {symbol}).{Style.RESET_ALL}")
        return True

    except ExchangeError as e:
        error_str = str(e).lower()
        # Check for common Bybit error codes indicating success or known issues
        # Bybit error codes: 110043 ("Leverage not modified"), 34036 ("Leverage not modified")
        # 110021 ("position idx not match position mode") - Indicates hedge mode issue
        if "leverage not modified" in error_str or "110043" in str(e) or "34036" in str(e):
            # If leverage is already set to the desired value, treat as success
            logger.info(f"{Fore.YELLOW}{log_prefix} Leverage already set to {leverage}x (or not modified). Considered success.{Style.RESET_ALL}")
            return True
        elif "position idx" in error_str or "110021" in str(e):
            # This error might occur in Hedge Mode if positionIdx isn't handled correctly elsewhere
            logger.error(f"{Fore.RED}{log_prefix} Failed: {e}. Potential Hedge Mode issue? Check positionIdx settings if applicable.{Style.RESET_ALL}")
            return False
        else:
            # Log other unexpected exchange errors
            logger.error(f"{Fore.RED}{log_prefix} ExchangeError setting leverage: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=False)
            return False
    except (NetworkError, ExchangeNotAvailable, RequestTimeout) as e:
        # Handled by retry decorator
        logger.warning(f"{Fore.YELLOW}{log_prefix} Network/Availability error: {type(e).__name__}. Retry handled.{Style.RESET_ALL}")
        raise # Re-raise for decorator
    except Exception as e:
        # Catch any other unexpected errors
        logger.error(f"{Fore.RED}{log_prefix} Unexpected error setting leverage: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=True)
        return False

@retry_api_call()
async def fetch_usdt_balance(exchange: ccxt.bybit, config: Config) -> Tuple[Optional[Decimal], Optional[Decimal]]:
    """Fetches USDT total equity and available balance from Bybit V5 UNIFIED account."""
    func_name = "fetch_usdt_balance"
    log_prefix = f"[{func_name}]"
    # Get the specific symbol string used for USDT (usually 'USDT')
    usdt_symbol = config.get("USDT_SYMBOL", "USDT")

    logger.debug(f"{log_prefix} Fetching balance for UNIFIED account...")
    try:
        # Fetch balance data using CCXT, specifying the V5 account type
        # CCXT maps this to GET /v5/account/wallet-balance with accountType=UNIFIED
        balance_data = await exchange.fetch_balance(params={"accountType": "UNIFIED"})
        logger.debug(f"{log_prefix} Raw balance data received: {balance_data}")

        total_equity: Optional[Decimal] = None
        available_balance: Optional[Decimal] = None

        # --- Primary Method: Parse V5 'info' structure ---
        # This is generally more reliable for V5 specific details
        # Structure: info -> result -> list -> [account_dict] -> coin -> [coin_dict]
        info_result = balance_data.get("info", {}).get("result", {})
        if info_result and isinstance(info_result.get("list"), list):
            # Find the UNIFIED account details within the list (usually only one)
            unified_account_info = next((acc for acc in info_result["list"] if acc.get("accountType") == "UNIFIED"), None)

            if unified_account_info and isinstance(unified_account_info, dict):
                # Total equity for the UNIFIED account is directly available
                total_equity = safe_decimal_conversion(unified_account_info.get("totalEquity"))
                logger.debug(f"{log_prefix} Equity from info.result.list[UNIFIED].totalEquity: {total_equity}")

                # Find USDT details within the 'coin' list of the UNIFIED account
                coin_list = unified_account_info.get("coin", [])
                if isinstance(coin_list, list):
                    usdt_coin_info = next((coin for coin in coin_list if coin.get("coin") == usdt_symbol), None)
                    if usdt_coin_info and isinstance(usdt_coin_info, dict):
                        # V5 uses 'availableToWithdraw' or 'availableBalance' for free balance
                        # 'availableToWithdraw' is usually the most relevant for trading availability
                        available_str = usdt_coin_info.get("availableToWithdraw") or usdt_coin_info.get("availableBalance")
                        available_balance = safe_decimal_conversion(available_str)
                        logger.debug(f"{log_prefix} Available balance from info...coin['{usdt_symbol}']: {available_balance} (Raw: '{available_str}')")
                    else:
                        logger.warning(f"{log_prefix} '{usdt_symbol}' coin data not found within UNIFIED account coin list.")
                else:
                     logger.warning(f"{log_prefix} UNIFIED account 'coin' list is not a list or missing.")
            else:
                logger.warning(f"{log_prefix} UNIFIED account details not found in info.result.list.")
        else:
            logger.warning(f"{log_prefix} info.result.list is missing or not a list in balance response.")

        # --- Fallback Method: Use top-level CCXT structure ---
        # This relies on CCXT's parsing, which might be less precise for V5 details but good fallback
        if total_equity is None:
            # CCXT often puts total equity per asset in 'total'
            total_equity_ccxt = balance_data.get("total", {}).get(usdt_symbol)
            if total_equity_ccxt is not None:
                total_equity = safe_decimal_conversion(total_equity_ccxt)
                logger.debug(f"{log_prefix} Equity from fallback CCXT top-level 'total.{usdt_symbol}': {total_equity}")

        if available_balance is None:
            # CCXT often puts available balance per asset in 'free'
            available_balance_ccxt = balance_data.get("free", {}).get(usdt_symbol)
            if available_balance_ccxt is not None:
                available_balance = safe_decimal_conversion(available_balance_ccxt)
                logger.debug(f"{log_prefix} Available from fallback CCXT top-level 'free.{usdt_symbol}': {available_balance}")

        # --- Final Processing and Return ---
        if total_equity is None:
            logger.warning(f"{log_prefix} Could not determine total USDT equity from V5 info or CCXT structure. Defaulting to 0.")
            final_equity = Decimal("0.0")
        else:
            # Ensure equity is not negative (shouldn't happen, but safety)
            final_equity = max(Decimal("0.0"), total_equity)

        if available_balance is None:
            logger.warning(f"{log_prefix} Could not determine available USDT balance from V5 info or CCXT structure. Defaulting to 0.")
            final_available = Decimal("0.0")
        else:
            # Ensure available balance is not negative
            final_available = max(Decimal("0.0"), available_balance)

        logger.info(f"{Fore.GREEN}{log_prefix} Success - Total Equity: {final_equity:.4f}, Available: {final_available:.4f} {usdt_symbol}{Style.RESET_ALL}")
        return final_equity, final_available

    except AuthenticationError as e:
        logger.error(f"{Fore.RED}{log_prefix} Authentication error: {e}{Style.RESET_ALL}")
        return None, None
    except (NetworkError, ExchangeNotAvailable, RequestTimeout) as e:
        logger.warning(f"{Fore.YELLOW}{log_prefix} Network/Availability error: {type(e).__name__}. Retry handled.{Style.RESET_ALL}")
        raise # Re-raise for decorator
    except ExchangeError as e:
        logger.error(f"{Fore.RED}{log_prefix} Exchange error fetching balance: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=False)
        return None, None
    except Exception as e:
        logger.error(f"{Fore.RED}{log_prefix} Unexpected error fetching balance: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=True)
        return None, None


# --- Market Data Functions ---

# Note: fetch_ohlcv_paginated remains largely the same as it already had robust pagination and retry logic per chunk.
# Added minor logging improvements and ensures config is passed. Added category param.
@retry_api_call() # Outer retry for the initial setup phase (e.g., getting category)
async def fetch_ohlcv_paginated(
    exchange: ccxt.bybit, symbol: str, timeframe: str,
    since: Optional[int] = None, limit: Optional[int] = None, config: Config = None, # Made config required
) -> Optional[Union[pd.DataFrame, List[list]]]:
    """Fetches OHLCV data, handling pagination and retries internally per chunk."""
    func_name = "fetch_ohlcv_paginated"
    log_prefix = f"[{func_name} ({symbol}, {timeframe})]"

    # --- Pre-checks ---
    if not config:
        logger.error(f"{Fore.RED}{log_prefix} Configuration object is required.{Style.RESET_ALL}")
        return None
    if not exchange or not hasattr(exchange, 'fetch_ohlcv'):
        logger.error(f"{Fore.RED}{log_prefix} Invalid exchange object or fetch_ohlcv method missing.{Style.RESET_ALL}")
        return None

    market = market_cache.get_market(symbol)
    category = market_cache.get_category(symbol)
    if not market or not category:
        logger.error(f"{Fore.RED}{log_prefix} Invalid market/category for {symbol}. Cannot determine fetch parameters.{Style.RESET_ALL}")
        return None

    # Determine fetch parameters based on category and CCXT capabilities
    try:
        # Bybit V5 max limit per request is 1000 candles
        fetch_limit_per_req = 1000
        timeframe_duration_ms = exchange.parse_timeframe(timeframe) * 1000
        if timeframe_duration_ms <= 0: raise ValueError("Invalid timeframe duration")
    except (ValueError, KeyError) as e:
        logger.error(f"{Fore.RED}{log_prefix} Invalid timeframe '{timeframe}': {e}.{Style.RESET_ALL}")
        return None

    # --- Pagination Logic ---
    all_candles: List[list] = []
    current_since = since
    # Safety break to prevent infinite loops
    max_loops = 200 # Limit total number of API calls (adjust as needed)
    loops = 0
    # Use config for retry settings per chunk fetch
    retries_per_chunk = config.get("RETRY_COUNT", 3)
    base_retry_delay = config.get("RETRY_DELAY_SECONDS", 1.0)
    backoff_factor = 2.0 # Standard exponential backoff
    # Small delay between successful chunk fetches to respect rate limits
    delay_between_chunks = max(0.1, (exchange.rateLimit / 1000 if exchange.enableRateLimit and exchange.rateLimit > 0 else 0.2)) # Ensure minimum delay

    logger.info(f"{Fore.BLUE}{log_prefix} Starting fetch. Target limit: {limit or 'All'}, Candles/Call: {fetch_limit_per_req}, Category: {category.value}...{Style.RESET_ALL}")
    # **** V5 requires category param for OHLCV ****
    params = {"category": category.value}

    try:
        while loops < max_loops:
            loops += 1
            # Check if desired total limit is reached
            if limit is not None and len(all_candles) >= limit:
                logger.info(f"{log_prefix} Reached desired total limit of {limit} candles.")
                break

            # Determine limit for the current API call
            current_fetch_limit = fetch_limit_per_req
            if limit is not None:
                remaining = limit - len(all_candles)
                if remaining <= 0: break # Should have been caught above, but safety check
                current_fetch_limit = min(fetch_limit_per_req, remaining)

            logger.debug(f"{log_prefix} Loop {loops}, Fetching since={current_since} (Limit: {current_fetch_limit})...")

            # --- Inner retry logic for fetching one chunk ---
            candles_chunk: Optional[List[list]] = None
            last_fetch_error: Optional[Exception] = None
            for attempt in range(retries_per_chunk + 1):
                try:
                    # Fetch one chunk of OHLCV data, passing category param
                    candles_chunk = await exchange.fetch_ohlcv(
                        symbol, timeframe, since=current_since, limit=current_fetch_limit, params=params
                    )
                    last_fetch_error = None # Reset error on success
                    break # Exit retry loop on success
                except (NetworkError, RequestTimeout, ExchangeNotAvailable, RateLimitExceeded) as e:
                    last_fetch_error = e
                    if attempt == retries_per_chunk:
                        logger.error(f"{Fore.RED}{log_prefix} Chunk fetch failed after {retries_per_chunk + 1} attempts. Last Error: {type(e).__name__}: {e}{Style.RESET_ALL}")
                        break # Exit retry loop after max retries
                    else:
                        # Calculate wait time with backoff and jitter
                        wait_time = base_retry_delay * (backoff_factor**attempt) + random.uniform(0, base_retry_delay * 0.1)
                        logger.warning(f"{Fore.YELLOW}{log_prefix} Chunk attempt {attempt + 1} failed: {type(e).__name__}. Retrying in {wait_time:.2f}s...{Style.RESET_ALL}")
                        await asyncio.sleep(wait_time)
                except ExchangeError as e:
                    # Non-retryable exchange error for this chunk
                    last_fetch_error = e
                    logger.error(f"{Fore.RED}{log_prefix} ExchangeError fetching chunk: {type(e).__name__}: {e}. Aborting chunk fetch.{Style.RESET_ALL}")
                    break # Exit retry loop
                except Exception as e:
                    # Unexpected error during chunk fetch
                    last_fetch_error = e
                    logger.error(f"{Fore.RED}{log_prefix} Unexpected error fetching chunk: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=True)
                    break # Exit retry loop

            # If chunk fetch failed after retries, abort the entire pagination process
            if last_fetch_error:
                logger.error(f"{Fore.RED}{log_prefix} Aborting pagination due to persistent chunk fetch failure.{Style.RESET_ALL}")
                break # Exit the main pagination loop

            # If no candles are returned, we've likely reached the end of available data
            if not candles_chunk:
                logger.info(f"{log_prefix} No more candles returned by API. Fetch complete.")
                break # Exit the main pagination loop

            # --- Process valid chunk ---
            # Filter potential duplicates (sometimes exchanges return overlapping candles)
            if all_candles and candles_chunk and candles_chunk[0][0] <= all_candles[-1][0]:
                initial_chunk_len = len(candles_chunk)
                # Keep only candles with timestamp strictly greater than the last stored candle
                candles_chunk = [c for c in candles_chunk if c[0] > all_candles[-1][0]]
                if len(candles_chunk) < initial_chunk_len:
                    logger.debug(f"{log_prefix} Removed {initial_chunk_len - len(candles_chunk)} duplicate/overlapping candle(s) from chunk.")
                if not candles_chunk:
                    logger.debug(f"{log_prefix} All candles in the new chunk were duplicates. Stopping.")
                    break # Exit main loop if only duplicates received

            # If a total limit is set, trim the chunk if necessary
            if limit is not None:
                needed = limit - len(all_candles)
                candles_chunk = candles_chunk[:needed]

            # If after filtering/trimming the chunk is empty, stop
            if not candles_chunk:
                break

            # Add the processed chunk to the main list
            all_candles.extend(candles_chunk)

            # Log progress
            last_timestamp = candles_chunk[-1][0]; first_timestamp = candles_chunk[0][0]
            log_range = f"Range Ts: {first_timestamp} to {last_timestamp}"
            # Try to format timestamps if pandas is available
            if pd:
                try:
                    dt_fmt = "%Y-%m-%d %H:%M:%S %Z"
                    first_dt = pd.to_datetime(first_timestamp, unit='ms', utc=True).strftime(dt_fmt)
                    last_dt = pd.to_datetime(last_timestamp, unit='ms', utc=True).strftime(dt_fmt)
                    log_range = f"Range Dt: {first_dt} to {last_dt}"
                except Exception: pass # Ignore formatting errors
            logger.info(f"{log_prefix} Fetched {len(candles_chunk)} candles. {log_range}. Total collected: {len(all_candles)}")

            # --- Prepare for next iteration ---
            # Set 'since' for the next request to the timestamp of the last candle + 1ms
            current_since = last_timestamp + 1
            # Pause briefly between successful fetches
            await asyncio.sleep(delay_between_chunks)

            # Check if the exchange returned fewer candles than requested (often indicates end of data)
            # Only break if we didn't set a specific 'limit' argument ourselves
            if limit is None and len(candles_chunk) < current_fetch_limit:
                logger.info(f"{log_prefix} Received less than requested limit ({len(candles_chunk)} < {current_fetch_limit}). Assuming end of available data.")
                break # Exit the main pagination loop
        # --- End of pagination loop ('while loops < max_loops:') ---

        if loops >= max_loops:
             logger.warning(f"{Fore.YELLOW}{log_prefix} Reached maximum loop limit ({max_loops}). Fetch may be incomplete.{Style.RESET_ALL}")

        logger.info(f"{log_prefix} Finished fetching. Total raw candles collected: {len(all_candles)}")
        if not all_candles:
            logger.warning(f"{log_prefix} No candles found for the specified criteria.")
            # Return empty structure matching expected type
            return pd.DataFrame() if pd else []

        # --- Process into DataFrame or List ---
        if pd:
            # Use pandas if available for structured data
            try:
                df = pd.DataFrame(all_candles, columns=["timestamp", "open", "high", "low", "close", "volume"])
                # Convert timestamp to datetime index (UTC)
                df["datetime"] = pd.to_datetime(df["timestamp"], unit="ms", utc=True)
                df.set_index("datetime", inplace=True)
                # Ensure numeric types for OHLCV columns
                for col in ["open", "high", "low", "close", "volume"]:
                    df[col] = pd.to_numeric(df[col], errors="coerce") # Coerce errors to NaN
                # Remove potential duplicate timestamps (keeping first occurrence)
                initial_len = len(df)
                df = df[~df.index.duplicated(keep="first")]
                if len(df) < initial_len:
                    logger.debug(f"{log_prefix} Removed {initial_len - len(df)} duplicate timestamps during DataFrame processing.")
                # Sort by datetime index
                df.sort_index(inplace=True)
                # Check for NaNs introduced by conversion errors
                nan_counts = df.isnull().sum()
                if nan_counts.sum() > 0:
                    logger.warning(f"{log_prefix} NaN values found after numeric conversion: {nan_counts[nan_counts > 0].to_dict()}")
                logger.info(f"{Fore.GREEN}{log_prefix} Processed {len(df)} unique candles into DataFrame.{Style.RESET_ALL}")
                return df
            except Exception as df_err:
                 logger.error(f"{log_prefix} Error processing data into pandas DataFrame: {df_err}", exc_info=True)
                 # Fallback to returning the raw list if DataFrame processing fails
                 all_candles.sort(key=lambda x: x[0]) # Ensure sorted list
                 logger.warning(f"{log_prefix} Falling back to returning sorted list of candles.")
                 return all_candles
        else:
            # Return raw list if pandas is not available
            all_candles.sort(key=lambda x: x[0]) # Ensure sorted list
            logger.info(f"{Fore.GREEN}{log_prefix} Processed {len(all_candles)} unique candles (returning as List).{Style.RESET_ALL}")
            return all_candles

    # --- Outer Exception Handling (Catches errors not handled by inner loops/retries) ---
    except (NetworkError, ExchangeNotAvailable, RateLimitExceeded) as e:
        # Should ideally be caught by the decorator, but catch here as safety net
        logger.error(f"{Fore.RED}{log_prefix} Unhandled API error during pagination: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=False)
    except ExchangeError as e:
        logger.error(f"{Fore.RED}{log_prefix} Unhandled Exchange error during pagination: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=False)
    except Exception as e:
        logger.error(f"{Fore.RED}{log_prefix} Unexpected error during pagination: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=True)

    # Attempt to return partial data if some candles were collected before error
    if all_candles:
        logger.warning(f"{Fore.YELLOW}{log_prefix} Returning partial data ({len(all_candles)} candles) due to error during fetch.{Style.RESET_ALL}")
        if pd:
            try: # Try processing partial data into DataFrame
                df = pd.DataFrame(all_candles, columns=["timestamp", "open", "high", "low", "close", "volume"])
                df["datetime"] = pd.to_datetime(df["timestamp"], unit="ms", utc=True); df.set_index("datetime", inplace=True)
                for col in ["open", "high", "low", "close", "volume"]: df[col] = pd.to_numeric(df[col], errors="coerce")
                df = df[~df.index.duplicated(keep="first")]; df.sort_index(inplace=True)
                return df
            except Exception as final_proc_err:
                logger.error(f"{Fore.RED}{log_prefix} Error processing partial DataFrame on error exit: {final_proc_err}{Style.RESET_ALL}")
                all_candles.sort(key=lambda x: x[0]); return all_candles # Fallback list
        else:
            all_candles.sort(key=lambda x: x[0]); return all_candles # Return partial list
    else:
        # Return None if no data collected and error occurred
        return None


@retry_api_call()
async def fetch_ticker_validated(exchange: ccxt.bybit, symbol: str, config: Config) -> Optional[Dict]:
    """Fetches ticker, validates timestamp and essential keys."""
    func_name = "fetch_ticker_validated"; log_prefix = f"[{func_name} ({symbol})]"
    logger.debug(f"{log_prefix} Fetching ticker...")

    category = market_cache.get_category(symbol)
    if not category:
        logger.error(f"{Fore.RED}{log_prefix} Cannot determine category for {symbol}. Cannot fetch ticker.{Style.RESET_ALL}")
        return None

    # **** V5 requires category param for tickers ****
    params = {"category": category.value}
    try:
        # CCXT maps this to GET /v5/market/tickers
        ticker = await exchange.fetch_ticker(symbol, params=params)

        # Basic validation of the returned ticker structure
        if not ticker or not isinstance(ticker, dict):
            logger.error(f"{Fore.RED}{log_prefix} Received empty or invalid ticker response.{Style.RESET_ALL}")
            return None

        # Check for essential keys expected in a CCXT ticker
        required_keys = ["symbol", "last", "bid", "ask", "timestamp", "datetime"]
        missing_keys = [k for k in required_keys if k not in ticker or ticker[k] is None]
        if missing_keys:
            logger.error(f"{Fore.RED}{log_prefix} Ticker response missing essential keys: {missing_keys}. Data: {str(ticker)[:200]}...{Style.RESET_ALL}")
            return None # Fail if core data is missing

        # --- Timestamp Validation ---
        ticker_time_ms = ticker.get("timestamp")
        current_time_ms = int(time.time() * 1000)
        # Define acceptable age range in seconds (allow slightly in future for clock skew)
        max_age_seconds = 90 # How old can the data be?
        min_age_seconds = -10 # Allow ~10s future timestamp (clock drift)
        max_diff_ms = max_age_seconds * 1000
        min_diff_ms = min_age_seconds * 1000 # Negative value

        log_timestamp_msg = f"Timestamp: {ticker.get('datetime', 'N/A')}" # Default log message
        is_timestamp_valid = False

        if ticker_time_ms is None:
            log_timestamp_msg = f"{Fore.YELLOW}Timestamp: Missing{Style.RESET_ALL}"
            # Consider failing if timestamp is critical and missing
            # return None
        elif not isinstance(ticker_time_ms, int):
            log_timestamp_msg = f"{Fore.YELLOW}Timestamp: Invalid Type ({type(ticker_time_ms).__name__}){Style.RESET_ALL}"
            # Consider failing
            # return None
        else:
            time_diff_ms = current_time_ms - ticker_time_ms
            age_s = time_diff_ms / 1000.0
            dt_str = ticker.get("datetime", f"ts({ticker_time_ms})") # Use CCXT datetime if available

            # Check if age is outside the acceptable range
            if time_diff_ms > max_diff_ms or time_diff_ms < min_diff_ms:
                logger.warning(f"{Fore.YELLOW}{log_prefix} Ticker timestamp ({dt_str}) seems stale or invalid. Age: {age_s:.1f}s (Allowed Range: {min_age_seconds}s to {max_age_seconds}s).{Style.RESET_ALL}")
                log_timestamp_msg = f"{Fore.YELLOW}Timestamp: Stale/Invalid (Age: {age_s:.1f}s){Style.RESET_ALL}"
                # Decide whether to fail or just warn based on staleness tolerance
                # For this example, let's fail if timestamp is present but seems invalid
                return None # Uncomment to enforce strict timestamp validation
            else:
                is_timestamp_valid = True # Timestamp is within acceptable range
                log_timestamp_msg = f"Timestamp: OK (Age: {age_s:.1f}s)"

        # Log success with key ticker info
        logger.info(f"{Fore.GREEN}{log_prefix} Fetched OK: Last={ticker.get('last')}, Bid={ticker.get('bid')}, Ask={ticker.get('ask')} | {log_timestamp_msg}{Style.RESET_ALL}")
        return ticker

    except (NetworkError, ExchangeNotAvailable, RateLimitExceeded) as e:
        logger.warning(f"{Fore.YELLOW}{log_prefix} API error: {type(e).__name__}. Retry handled.{Style.RESET_ALL}")
        raise # Re-raise for decorator
    except AuthenticationError as e:
        # Should not happen for public endpoint, but catch just in case
        logger.error(f"{Fore.RED}{log_prefix} Authentication error unexpectedly occurred: {e}{Style.RESET_ALL}")
        return None
    except ExchangeError as e:
        logger.error(f"{Fore.RED}{log_prefix} Exchange error: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=False)
        return None
    except Exception as e:
        logger.error(f"{Fore.RED}{log_prefix} Unexpected error: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=True)
        return None

@retry_api_call()
async def fetch_funding_rate(exchange: ccxt.bybit, symbol: str, config: Config, fetch_next: bool = False) -> Optional[Decimal]:
    """Fetches current (last settled) or predicted next funding rate for a perpetual swap."""
    func_name = "fetch_funding_rate"; rate_type_desc = "Next Predicted" if fetch_next else "Last Settled"
    log_prefix = f"[{func_name} ({symbol} - {rate_type_desc})]"

    market = market_cache.get_market(symbol)
    if not market or not market.get("swap", False):
        logger.error(f"{Fore.RED}{log_prefix} Symbol '{symbol}' is not identified as a swap/perpetual. Market data: {market}{Style.RESET_ALL}")
        return None
    category = market_cache.get_category(symbol)
    if category not in [Category.LINEAR, Category.INVERSE]:
        logger.error(f"{Fore.RED}{log_prefix} Funding rates require LINEAR or INVERSE category. Found: {category} for {symbol}.{Style.RESET_ALL}")
        return None

    # **** V5 requires category param for funding rates / history / tickers ****
    params = {"category": category.value, "symbol": symbol} # Required V5 params
    logger.debug(f"{log_prefix} Fetching with params: {params}")

    try:
        if fetch_next:
            # Fetching the *next* funding rate requires fetching the ticker, as it's included there
            logger.debug(f"{log_prefix} Fetching ticker to get next funding rate...")
            # Pass the category param to fetch_ticker_validated
            ticker = await fetch_ticker_validated(exchange, symbol, config) # Already passes category internally
            if not ticker:
                logger.error(f"{Fore.RED}{log_prefix} Failed to fetch validated ticker needed for next funding rate.{Style.RESET_ALL}")
                return None

            # Extract funding rate info from the 'info' field of the ticker (V5 structure)
            # CCXT ticker structure: ticker['info'] contains raw API response
            # V5 ticker response structure: result -> list -> [ticker_info]
            ticker_info_list = ticker.get("info", {}).get("result", {}).get("list", [])
            if not ticker_info_list or not isinstance(ticker_info_list, list):
                logger.error(f"{Fore.RED}{log_prefix} Could not find ticker info list in ticker['info']['result']['list']. Raw Info: {ticker.get('info')}{Style.RESET_ALL}")
                return None

            ticker_info = ticker_info_list[0] # Assume first item is the relevant ticker
            next_rate_str = ticker_info.get("fundingRate") # V5 field name is 'fundingRate'
            next_time_ms = ticker_info.get("nextFundingTime") # V5 field name is 'nextFundingTime' (string timestamp)

            if next_rate_str is not None:
                rate_decimal = safe_decimal_conversion(next_rate_str)
                if rate_decimal is None:
                    logger.error(f"{Fore.RED}{log_prefix} Could not parse 'fundingRate' ('{next_rate_str}') from ticker info.{Style.RESET_ALL}")
                    return None

                # Format next funding time for logging if possible
                next_dt_str = "N/A"
                if next_time_ms:
                    try:
                        ts = int(next_time_ms) # V5 timestamp is string milliseconds
                        if pd: # Use pandas for nice formatting if available
                            next_dt_str = pd.to_datetime(ts, unit="ms", utc=True, errors="coerce").strftime("%Y-%m-%d %H:%M:%S %Z")
                        else: # Basic formatting otherwise
                             # Ensure UTC awareness for time.strftime
                             utc_tuple = time.gmtime(ts / 1000)
                             next_dt_str = time.strftime("%Y-%m-%d %H:%M:%S UTC", utc_tuple)
                    except (ValueError, TypeError):
                        next_dt_str = str(next_time_ms) # Fallback to raw string

                logger.info(f"{Fore.GREEN}{log_prefix} Success - Next Rate: {rate_decimal:.8f} (Expected At: {next_dt_str}){Style.RESET_ALL}")
                return rate_decimal
            else:
                logger.error(f"{Fore.RED}{log_prefix} 'fundingRate' field not found in ticker info. Ticker Info: {str(ticker_info)[:200]}...{Style.RESET_ALL}")
                return None
        else:
            # Fetching the *last settled* funding rate requires fetch_funding_history
            logger.debug(f"{log_prefix} Fetching funding history (limit=1) for last settled rate...")
            # Limit=1 gets the most recent settled rate
            # CCXT maps this to GET /v5/market/funding/history
            history = await exchange.fetch_funding_history(symbol=symbol, limit=1, params=params)

            if history and isinstance(history, list) and len(history) > 0:
                last_interval = history[0] # Get the most recent entry
                # V5 funding rate is often nested inside 'info' in CCXT's parsed structure
                # Check CCXT structure: last_interval['info']['fundingRate']
                rate_str = last_interval.get("info", {}).get("fundingRate")
                timestamp_ms = last_interval.get("timestamp")
                dt_str = last_interval.get("datetime") # CCXT provides parsed datetime

                if rate_str is not None:
                    rate_decimal = safe_decimal_conversion(rate_str)
                    if rate_decimal is None:
                        logger.error(f"{Fore.RED}{log_prefix} Could not parse 'fundingRate' ('{rate_str}') from funding history info.{Style.RESET_ALL}")
                        return None
                    logger.info(f"{Fore.GREEN}{log_prefix} Success - Last Settled Rate: {rate_decimal:.8f} (Settled Time: {dt_str or timestamp_ms}){Style.RESET_ALL}")
                    return rate_decimal
                else:
                    logger.error(f"{Fore.RED}{log_prefix} 'fundingRate' field not found in funding history info. History[0]: {str(last_interval)[:200]}...{Style.RESET_ALL}")
                    return None
            else:
                logger.error(f"{Fore.RED}{log_prefix} Failed to fetch funding history or history is empty.{Style.RESET_ALL}")
                return None

    except (NetworkError, ExchangeNotAvailable, RateLimitExceeded) as e:
        logger.warning(f"{Fore.YELLOW}{log_prefix} API error: {type(e).__name__}. Retry handled.{Style.RESET_ALL}")
        raise # Re-raise for decorator
    except ExchangeError as e:
        logger.error(f"{Fore.RED}{log_prefix} Exchange error: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=False)
        return None
    except Exception as e:
        logger.error(f"{Fore.RED}{log_prefix} Unexpected error: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=True)
        return None

@retry_api_call()
async def fetch_l2_order_book_validated(exchange: ccxt.bybit, symbol: str, limit: int, config: Config) -> Optional[Dict]:
    """Fetches L2 order book and performs basic validation."""
    func_name = "fetch_l2_order_book_validated"; log_prefix = f"[{func_name} ({symbol}, limit={limit})]"
    logger.debug(f"{log_prefix} Fetching L2 order book...")

    category = market_cache.get_category(symbol)
    if not category:
        logger.error(f"{Fore.RED}{log_prefix} Cannot determine category for {symbol}. Cannot fetch order book.{Style.RESET_ALL}")
        return None

    # Check if limit is valid/optimal for the category (informational)
    # Bybit V5 L2 Order Book Limits: Linear/Inverse: [1, 50, 200, 500], Spot: [1, 50, 200], Option: [25, 100, 200]
    valid_limits = {
        Category.SPOT: [1, 50, 200],
        Category.LINEAR: [1, 50, 200, 500],
        Category.INVERSE: [1, 50, 200, 500],
        Category.OPTION: [25, 100, 200]
    }
    category_valid_limits = valid_limits.get(category)
    if category_valid_limits and limit not in category_valid_limits:
         logger.warning(f"{Fore.YELLOW}{log_prefix} Requested limit {limit} is not standard for {category.value}. Valid: {category_valid_limits}. Proceeding, but API might adjust or reject.{Style.RESET_ALL}")

    # **** V5 requires category param for orderbook ****
    params = {"category": category.value}
    try:
        # Fetch L2 order book using CCXT
        # CCXT maps this to GET /v5/market/orderbook
        order_book = await exchange.fetch_l2_order_book(symbol, limit=limit, params=params)

        # --- Validation ---
        if not order_book or not isinstance(order_book, dict):
            logger.error(f"{Fore.RED}{log_prefix} Received empty or invalid order book response.{Style.RESET_ALL}")
            return None
        # Check essential keys
        if not isinstance(order_book.get("bids"), list) or not isinstance(order_book.get("asks"), list):
             logger.error(f"{Fore.RED}{log_prefix} Order book 'bids' or 'asks' key is missing or not a list.{Style.RESET_ALL}")
             return None
        # Check if both sides are empty (can happen in thin markets, but log warning)
        if not order_book.get("bids") and not order_book.get("asks"):
            logger.warning(f"{Fore.YELLOW}{log_prefix} Order book has empty bids AND asks.{Style.RESET_ALL}")
        # Check for timestamp (important for data freshness)
        if not order_book.get("timestamp") or not order_book.get("datetime"):
            logger.warning(f"{Fore.YELLOW}{log_prefix} Order book is missing timestamp/datetime information.{Style.RESET_ALL}")

        # Check for crossed spread (top bid >= top ask)
        top_bid_p, top_ask_p = None, None
        if order_book.get("bids"): top_bid_p = safe_decimal_conversion(order_book["bids"][0][0])
        if order_book.get("asks"): top_ask_p = safe_decimal_conversion(order_book["asks"][0][0])

        if top_bid_p is not None and top_ask_p is not None and top_bid_p > 0 and top_ask_p > 0 and top_bid_p >= top_ask_p:
             logger.warning(f"{Fore.YELLOW}{log_prefix} Order book spread is crossed or zero: Top Bid={top_bid_p}, Top Ask={top_ask_p}.{Style.RESET_ALL}")

        # Log success summary
        top_bid_log = order_book["bids"][0][0] if order_book.get("bids") else "N/A"
        top_ask_log = order_book["asks"][0][0] if order_book.get("asks") else "N/A"
        dt_log = order_book.get('datetime', 'N/A')
        logger.info(f"{Fore.GREEN}{log_prefix} Fetched OK at {dt_log}. Top Bid: {top_bid_log}, Top Ask: {top_ask_log}{Style.RESET_ALL}")
        return order_book

    except (NetworkError, ExchangeNotAvailable, RateLimitExceeded) as e:
        logger.warning(f"{Fore.YELLOW}{log_prefix} API error: {type(e).__name__}. Retry handled.{Style.RESET_ALL}")
        raise # Re-raise for decorator
    except ExchangeError as e:
        logger.error(f"{Fore.RED}{log_prefix} Exchange error: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=False)
        return None
    except Exception as e:
        logger.error(f"{Fore.RED}{log_prefix} Unexpected error: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=True)
        return None

@retry_api_call()
async def fetch_recent_trades(exchange: ccxt.bybit, symbol: str, limit: int, config: Config) -> List[Dict]:
    """Fetches recent public market trades, applying category-specific limits."""
    func_name = "fetch_recent_trades"; log_prefix = f"[{func_name} ({symbol}, limit={limit})]"
    logger.debug(f"{log_prefix} Fetching recent trades...")

    category = market_cache.get_category(symbol)
    if not category:
        logger.error(f"{Fore.RED}{log_prefix} Cannot determine category for {symbol}. Cannot fetch trades.{Style.RESET_ALL}")
        return []

    # Bybit V5 Trade History Limits: Linear/Inverse: 1000, Spot: 60, Option: 100
    limit_map = {
        Category.SPOT: 60,
        Category.LINEAR: 1000,
        Category.INVERSE: 1000,
        Category.OPTION: 100
    }
    max_limit = limit_map.get(category)
    effective_limit = limit

    # Adjust limit if it exceeds the category maximum
    if max_limit is not None:
        if limit > max_limit:
            logger.warning(f"{Fore.YELLOW}{log_prefix} Requested limit {limit} exceeds maximum {max_limit} for {category.value}. Clamping limit to {max_limit}.{Style.RESET_ALL}")
            effective_limit = max_limit
    else:
        # Should not happen if category is valid, but handle defensively
        logger.warning(f"{Fore.YELLOW}{log_prefix} Unknown maximum trade limit for category {category.value}. Using requested limit {limit}.{Style.RESET_ALL}")

    # **** V5 requires category param for trades ****
    # Pass limit in params as well, as CCXT might not always use the method arg for implicit API calls
    params = {"category": category.value, "limit": effective_limit}
    try:
        # Fetch trades using CCXT method
        # CCXT maps this to GET /v5/market/recent-trade
        trades = await exchange.fetch_trades(symbol, limit=effective_limit, params=params)

        if trades is None: # CCXT might return None on error or empty
             logger.warning(f"{log_prefix} Received None from fetch_trades.")
             return []

        logger.info(f"{Fore.GREEN}{log_prefix} Fetched {len(trades)} recent trades (Limit requested: {effective_limit}).{Style.RESET_ALL}")
        return trades # Return the list of trades

    except (NetworkError, ExchangeNotAvailable, RateLimitExceeded) as e:
        logger.warning(f"{Fore.YELLOW}{log_prefix} API error: {type(e).__name__}. Retry handled.{Style.RESET_ALL}")
        raise # Re-raise for decorator
    except ExchangeError as e:
        logger.error(f"{Fore.RED}{log_prefix} Exchange error: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=False)
        return [] # Return empty list on error
    except Exception as e:
        logger.error(f"{Fore.RED}{log_prefix} Unexpected error: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=True)
        return [] # Return empty list on error


# --- Order Management Functions ---

@retry_api_call(max_retries=1, retry_on_exceptions=(NetworkError, RequestTimeout, RateLimitExceeded)) # Limit retries for placement
async def place_market_order_slippage_check(
    exchange: ccxt.bybit, symbol: str, side: Side, amount: Decimal, config: Config,
    max_slippage_pct: Optional[Decimal] = None, # Override default slippage check
    is_reduce_only: bool = False,
    time_in_force: TimeInForce = TimeInForce.IOC, # IOC is good default for market
    client_order_id: Optional[str] = None, # Custom ID for tracking
    position_idx: Optional[PositionIdx] = None, # For Hedge Mode
    # V5 allows specifying amount in quote currency for market orders ('marketUnit')
    # market_unit: Optional[Literal['baseCoin', 'quoteCoin']] = 'baseCoin',
) -> Optional[Dict]:
    """Places a market order with optional pre-execution spread check."""
    func_name = "place_market_order"; action = "ReduceOnly" if is_reduce_only else "Open/Increase"
    qty_epsilon = config.get("POSITION_QTY_EPSILON", Decimal("1E-8"))
    log_prefix = f"[{func_name} ({symbol}, {side.value}, Amt:{amount}, {action})]"

    # --- Input Validation ---
    if amount <= qty_epsilon:
        logger.error(f"{Fore.RED}{log_prefix} Invalid order amount: {amount}. Must be positive.{Style.RESET_ALL}")
        return None
    # Market orders typically use IOC or FOK. GTC doesn't make sense.
    if time_in_force not in [TimeInForce.IOC, TimeInForce.FOK]:
        logger.warning(f"{Fore.YELLOW}{log_prefix} TimeInForce '{time_in_force.value}' used for Market order. IOC or FOK is recommended. Using specified TIF.{Style.RESET_ALL}")

    category = market_cache.get_category(symbol); market = market_cache.get_market(symbol)
    if not category or not market:
        logger.error(f"{Fore.RED}{log_prefix} Invalid category/market for {symbol}. Cannot place order.{Style.RESET_ALL}")
        return None

    # Simple hedge mode logging based on position_idx
    if position_idx is not None and position_idx != PositionIdx.ONE_WAY:
        logger.debug(f"{log_prefix} positionIdx={position_idx.value} provided, assuming Hedge Mode context.")

    # Format amount according to market precision (assuming amount is in base currency)
    formatted_amount_str = format_amount(exchange, symbol, amount)
    if formatted_amount_str is None:
        logger.error(f"{Fore.RED}{log_prefix} Failed to format amount {amount} for precision.{Style.RESET_ALL}")
        return None
    try:
        # Convert formatted string amount back to float for CCXT call
        # CCXT methods typically expect float for amount/price args
        formatted_amount_float = float(formatted_amount_str)
    except ValueError:
        logger.error(f"{Fore.RED}{log_prefix} Formatted amount '{formatted_amount_str}' is not a valid float.{Style.RESET_ALL}")
        return None

    # Determine max slippage percentage for check
    effective_max_slippage = max_slippage_pct if max_slippage_pct is not None else config.get("DEFAULT_SLIPPAGE_PCT")
    spread_check_enabled = effective_max_slippage is not None and effective_max_slippage >= Decimal(0)

    log_msg = f"{Fore.BLUE}{log_prefix} Placing order. Amount: {formatted_amount_str}, TIF: {time_in_force.value}"
    if spread_check_enabled:
        log_msg += f", Spread Check Max: {effective_max_slippage:.4%}"
    else:
        log_msg += ", Spread Check: Disabled"
    logger.info(log_msg + Style.RESET_ALL)


    # --- Spread Check (Optional) ---
    if spread_check_enabled:
        try:
            # Fetch shallow order book for current bid/ask
            ob_depth = config.get("SHALLOW_OB_FETCH_DEPTH", 5) # Use small depth for speed
            # fetch_l2_order_book_validated requires config and handles category internally
            ob_shallow = await fetch_l2_order_book_validated(exchange, symbol, ob_depth, config)

            if ob_shallow and ob_shallow.get("bids") and ob_shallow.get("asks"):
                best_bid = safe_decimal_conversion(ob_shallow["bids"][0][0])
                best_ask = safe_decimal_conversion(ob_shallow["asks"][0][0])

                if best_bid and best_ask and best_bid > 0 and best_ask > 0:
                    # Calculate spread percentage: (Ask - Bid) / MidPrice for stability
                    mid_price = (best_ask + best_bid) / 2
                    if mid_price <= 0: raise DivisionByZero("Mid price is zero or negative")
                    spread_pct = (best_ask - best_bid) / mid_price
                    logger.debug(f"{log_prefix} Spread Check: Bid={best_bid}, Ask={best_ask}, Spread={spread_pct:.4%}")
                    # Compare with allowed slippage
                    if spread_pct > effective_max_slippage:
                        logger.error(f"{Back.RED}{log_prefix} ABORTED: Current spread {spread_pct:.4%} exceeds maximum allowed {effective_max_slippage:.4%}.{Style.RESET_ALL}")
                        send_sms_alert(f"[{symbol}] MKT Order ABORT ({side.value}): Spread {spread_pct:.4%} > Max {effective_max_slippage:.4%}", config)
                        return None # Abort placement
                else:
                    logger.warning(f"{Fore.YELLOW}{log_prefix} Could not get valid best bid/ask from shallow OB. Skipping spread check.{Style.RESET_ALL}")
            else:
                logger.warning(f"{Fore.YELLOW}{log_prefix} Could not fetch shallow order book. Skipping spread check.{Style.RESET_ALL}")
        except DivisionByZero:
             logger.warning(f"{Fore.YELLOW}{log_prefix} Zero mid-price during spread check. Skipping check.{Style.RESET_ALL}")
        except Exception as ob_err:
            # Log error during check but proceed with placement (fail-open)
            logger.warning(f"{Fore.YELLOW}{log_prefix} Error during spread check: {ob_err}. Proceeding with order placement.{Style.RESET_ALL}", exc_info=False)

    # --- Prepare and Place Order ---
    # **** V5 requires category param for orders ****
    params: Dict[str, Any] = {
        "category": category.value,
        "reduceOnly": is_reduce_only,
        "timeInForce": time_in_force.value,
        # V5 Specific Params (Map from CCXT standard args where possible)
        # 'marketUnit': market_unit, # If allowing quote qty market orders
    }
    # Add Client Order ID if provided (sanitize for Bybit rules)
    if client_order_id:
        # Bybit V5 orderLinkId requirements: letters, numbers, -, _ ; max length 36
        clean_cid = "".join(filter(lambda c: c.isalnum() or c in ["-", "_"], client_order_id))[:36]
        if len(clean_cid) != len(client_order_id):
            logger.warning(f"{log_prefix} Client Order ID sanitized from '{client_order_id}' to '{clean_cid}'")
        if clean_cid: # Only add if not empty after sanitizing
            params["orderLinkId"] = clean_cid
    # Add Position Index if provided
    if position_idx is not None:
        params["positionIdx"] = position_idx.value

    try:
        logger.info(f"{log_prefix} Sending create_market_order request with params: {params}...")
        # Use CCXT's standard method for creating market orders
        # CCXT maps this to POST /v5/order/create
        order = await exchange.create_market_order(
            symbol=symbol,
            side=side.value,
            amount=formatted_amount_float, # Pass the float amount
            params=params # Pass V5 specific parameters here
        )

        # --- Process Response ---
        if not order or not isinstance(order, dict):
             # CCXT might return None or invalid structure on failure
             logger.error(f"{Fore.RED}{log_prefix} FAILED - Received invalid order response from create_market_order.{Style.RESET_ALL}")
             return None

        order_id = order.get("id")
        status = order.get("status", "unknown") # e.g., 'closed' (filled), 'canceled' (if IOC failed)
        filled_amount = safe_decimal_conversion(order.get("filled", "0"))
        avg_price = safe_decimal_conversion(order.get("average")) # Avg fill price

        # Log based on status
        log_color = Fore.GREEN if status in ["closed", "filled"] else Fore.YELLOW if status == "open" else Fore.RED
        logger.info(f"{log_color}{log_prefix} Order Result - ID: ...{format_order_id(order_id)}, Status: {status}, Filled Qty: {format_amount(exchange, symbol, filled_amount)}, Avg Price: {format_price(exchange, symbol, avg_price)}{Style.RESET_ALL}")

        # Check for partial fills with IOC/FOK more robustly
        if time_in_force in [TimeInForce.IOC, TimeInForce.FOK]:
            # Use epsilon comparison for filled amount vs requested amount
            requested_amount_dec = safe_decimal_conversion(formatted_amount_str) # Convert formatted str back
            # Only warn if filled amount is significantly less than requested
            if filled_amount is not None and requested_amount_dec is not None and \
               filled_amount < (requested_amount_dec - qty_epsilon) and \
               status not in ['closed', 'filled']: # Don't warn if fully filled
                logger.warning(f"{Fore.YELLOW}{log_prefix} Order {order_id} ({time_in_force.value}) was partially filled ({filled_amount} / {requested_amount_dec}) or not filled at all. Final Status: {status}.{Style.RESET_ALL}")
            elif filled_amount is None and requested_amount_dec is not None and requested_amount_dec > qty_epsilon:
                 # This case might indicate an issue or immediate cancellation without fill info
                 logger.warning(f"{Fore.YELLOW}{log_prefix} Order {order_id} ({time_in_force.value}) reported NO fill amount, but requested > 0. Final Status: {status}.{Style.RESET_ALL}")

        # Return the parsed order dictionary from CCXT
        return order

    # --- Error Handling for Order Placement ---
    except InsufficientFunds as e:
        logger.error(f"{Back.RED}{log_prefix} FAILED - Insufficient Funds: {e}{Style.RESET_ALL}")
        send_sms_alert(f"[{symbol}] Order Fail ({side.value} MKT): Insufficient Funds", config)
        return None
    except InvalidOrder as e: # Covers various rejection reasons (size, price, permissions, etc.)
        logger.error(f"{Back.RED}{log_prefix} FAILED - Invalid Order / Rejected by Exchange: {e}{Style.RESET_ALL}")
        return None
    except ExchangeError as e: # Catch other specific exchange errors
        # Example: Rate limit error specifically for orders
        if "too many requests" in str(e).lower() or isinstance(e, RateLimitExceeded):
             logger.error(f"{Back.RED}{log_prefix} FAILED - Rate Limit Exceeded placing order: {e}{Style.RESET_ALL}")
             # Re-raise if we want the outer retry decorator to handle it
             # raise e # Uncomment if retry is desired for order rate limits
        else:
            logger.error(f"{Back.RED}{log_prefix} FAILED - Exchange Error: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=False)
        return None
    except (NetworkError, ExchangeNotAvailable, RequestTimeout) as e:
        # Let retry decorator handle these by re-raising
        logger.error(f"{Back.RED}{log_prefix} FAILED - API Communication Error: {type(e).__name__}: {e}{Style.RESET_ALL}")
        raise e # Re-raise for decorator
    except Exception as e: # Catch any other unexpected errors
        logger.error(f"{Back.RED}{log_prefix} FAILED - Unexpected Error: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=True)
        return None

@retry_api_call(max_retries=1, retry_on_exceptions=(NetworkError, RequestTimeout, RateLimitExceeded))
async def place_limit_order_tif(
    exchange: ccxt.bybit, symbol: str, side: Side, amount: Decimal, price: Decimal, config: Config,
    time_in_force: TimeInForce = TimeInForce.GTC, # GTC is common default for limit
    is_reduce_only: bool = False,
    is_post_only: bool = False, # If true, ensures order is maker-only
    client_order_id: Optional[str] = None,
    position_idx: Optional[PositionIdx] = None,
) -> Optional[Dict]:
    """Places a limit order with specified Time-In-Force and optional post-only."""
    func_name = "place_limit_order"; action = "ReduceOnly" if is_reduce_only else "Open/Increase"
    qty_epsilon = config.get("POSITION_QTY_EPSILON", Decimal("1E-8"))

    # Determine effective TIF based on post_only flag
    # If post_only is True, it overrides other TIF settings for Bybit V5
    effective_tif = TimeInForce.POST_ONLY if is_post_only else time_in_force
    tif_str = effective_tif.value
    post_only_str = " (PostOnly)" if is_post_only else "" # For logging
    log_prefix = f"[{func_name} ({symbol}, {side.value}, Amt:{amount} @ Px:{price}, {action}, TIF:{tif_str}{post_only_str})]"

    # --- Input Validation ---
    if amount <= qty_epsilon or price <= Decimal("0"):
        logger.error(f"{Fore.RED}{log_prefix} Invalid order amount ({amount}) or price ({price}). Both must be positive.{Style.RESET_ALL}")
        return None
    # Warn if PostOnly is combined with incompatible TIF (though effective_tif handles it)
    if is_post_only and time_in_force not in [TimeInForce.GTC, TimeInForce.POST_ONLY]:
        logger.warning(f"{Fore.YELLOW}{log_prefix} Using PostOnly flag with TIF '{time_in_force.value}'. Effective TIF will be '{TimeInForce.POST_ONLY.value}'.{Style.RESET_ALL}")

    category = market_cache.get_category(symbol); market = market_cache.get_market(symbol)
    if not category or not market:
        logger.error(f"{Fore.RED}{log_prefix} Invalid category/market for {symbol}. Cannot place order.{Style.RESET_ALL}")
        return None

    # Format amount and price according to market precision
    formatted_amount_str = format_amount(exchange, symbol, amount)
    formatted_price_str = format_price(exchange, symbol, price)
    if formatted_amount_str is None or formatted_price_str is None:
        logger.error(f"{Fore.RED}{log_prefix} Failed to format amount ({amount}) or price ({price}) for precision.{Style.RESET_ALL}")
        return None
    try:
        # Convert formatted strings back to floats for CCXT call
        formatted_amount_float = float(formatted_amount_str)
        formatted_price_float = float(formatted_price_str)
    except ValueError:
        logger.error(f"{Fore.RED}{log_prefix} Formatted amount '{formatted_amount_str}' or price '{formatted_price_str}' is not a valid float.{Style.RESET_ALL}")
        return None

    logger.info(f"{Fore.BLUE}{log_prefix} Placing order...{Style.RESET_ALL}")

    # --- Prepare Parameters ---
    # **** V5 requires category param for orders ****
    params: Dict[str, Any] = {
        "category": category.value,
        "reduceOnly": is_reduce_only,
        "timeInForce": effective_tif.value, # Use the effective TIF (PostOnly if is_post_only=True)
        # Note: CCXT's create_limit_order might handle the postOnly flag internally for some exchanges,
        # but specifying TIF="PostOnly" in params is the explicit V5 way.
        # If using CCXT >= 4.x, it should map postOnly=True correctly for Bybit V5.
        # We pass TIF explicitly here for clarity and control.
    }
    # Add Client Order ID if provided
    if client_order_id:
        clean_cid = "".join(filter(lambda c: c.isalnum() or c in ["-", "_"], client_order_id))[:36]
        if len(clean_cid) != len(client_order_id):
            logger.warning(f"{log_prefix} Client Order ID sanitized: '{clean_cid}'")
        if clean_cid: params["orderLinkId"] = clean_cid
    # Add Position Index if provided
    if position_idx is not None:
        params["positionIdx"] = position_idx.value

    try:
        logger.info(f"{log_prefix} Sending create_limit_order request with params: {params}...")
        # Use CCXT's standard method for creating limit orders
        # CCXT maps this to POST /v5/order/create
        order = await exchange.create_limit_order(
            symbol=symbol,
            side=side.value,
            amount=formatted_amount_float,
            price=formatted_price_float,
            params=params,
            # Pass postOnly flag to CCXT method as well (redundant if TIF is PostOnly, but safe)
            # postOnly=is_post_only # Uncomment if relying on CCXT's internal handling
        )

        # --- Process Response ---
        if not order or not isinstance(order, dict):
             # CCXT might return None or invalid structure on failure
             logger.error(f"{Fore.RED}{log_prefix} FAILED - Received invalid order response from create_limit_order.{Style.RESET_ALL}")
             return None

        order_id = order.get("id")
        status = order.get("status", "unknown") # e.g., 'open', 'closed', 'canceled', 'rejected'
        order_price = safe_decimal_conversion(order.get("price"))
        order_amount = safe_decimal_conversion(order.get("amount"))

        # Log based on status (Green for open/accepted, Yellow for others like triggered/new, Red for reject/cancel)
        if status == "open": log_color = Fore.GREEN
        elif status in ["rejected", "canceled"]: log_color = Fore.RED
        else: log_color = Fore.YELLOW # Covers 'new', 'triggered', 'partially_filled' etc.

        logger.info(f"{log_color}{log_prefix} Order Result - ID: ...{format_order_id(order_id)}, Status: {status}, Price: {format_price(exchange, symbol, order_price)}, Amount: {format_amount(exchange, symbol, order_amount)}{Style.RESET_ALL}")
        # If rejected, maybe provide more info if available in order['info']
        if status == 'rejected':
             reject_reason = order.get('info', {}).get('rejectReason', 'Unknown reason')
             logger.error(f"{Fore.RED}{log_prefix} Order Rejected. Reason: {reject_reason}{Style.RESET_ALL}")

        return order

    # --- Error Handling ---
    except OrderImmediatelyFillable as e:
        # This specific error occurs when a PostOnly order would execute immediately as taker
        if is_post_only or effective_tif == TimeInForce.POST_ONLY:
            # This is the expected behavior for PostOnly, not necessarily an error from user perspective
            logger.warning(f"{Fore.YELLOW}{log_prefix} PostOnly order REJECTED as expected (would execute immediately): {e}{Style.RESET_ALL}")
            # Return None as the order was not placed (as intended by PostOnly)
            return None
        else:
            # Should not happen for non-PostOnly orders, indicates unexpected state or API behavior change
            logger.error(f"{Back.RED}{log_prefix} FAILED - Unexpected OrderImmediatelyFillable for non-PostOnly order: {e}{Style.RESET_ALL}")
            return None
    except InsufficientFunds as e:
        logger.error(f"{Back.RED}{log_prefix} FAILED - Insufficient Funds: {e}{Style.RESET_ALL}")
        return None
    except InvalidOrder as e:
        logger.error(f"{Back.RED}{log_prefix} FAILED - Invalid Order / Rejected by Exchange: {e}{Style.RESET_ALL}")
        return None
    except ExchangeError as e:
         if "too many requests" in str(e).lower() or isinstance(e, RateLimitExceeded):
             logger.error(f"{Back.RED}{log_prefix} FAILED - Rate Limit Exceeded placing order: {e}{Style.RESET_ALL}")
             # raise e # Optional: re-raise for retry decorator
         else:
            logger.error(f"{Back.RED}{log_prefix} FAILED - Exchange Error: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=False)
         return None
    except (NetworkError, ExchangeNotAvailable, RequestTimeout) as e:
        logger.error(f"{Back.RED}{log_prefix} FAILED - API Communication Error: {type(e).__name__}: {e}{Style.RESET_ALL}")
        raise e # Re-raise for retry decorator
    except Exception as e:
        logger.error(f"{Back.RED}{log_prefix} FAILED - Unexpected Error: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=True)
        return None


@retry_api_call(max_retries=1, retry_on_exceptions=(NetworkError, RequestTimeout, RateLimitExceeded))
async def place_batch_orders(
    exchange: ccxt.bybit,
    orders: List[Dict[str, Any]], # List of order request dictionaries
    config: Config,
    category_override: Optional[Category] = None, # Force a category for the batch
) -> Tuple[List[Optional[Dict]], List[Optional[Dict]]]:
    """
    Places multiple orders in a single V5 batch request. Handles validation and response parsing.

    Args:
        exchange: Initialized ccxt.bybit instance.
        orders: A list of dictionaries, each representing an order request.
                Required keys per order: 'symbol', 'side' (Side enum or 'buy'/'sell'),
                                         'type' ('Limit' or 'Market'), 'amount'.
                Optional keys: 'price' (for Limit), 'clientOrderId', 'reduceOnly',
                               'timeInForce', 'positionIdx', trigger params (triggerPrice, etc.),
                               TP/SL params (takeProfit, stopLoss, etc.).
        config: Configuration object.
        category_override: If specified, forces all orders in the batch to belong
                           to this category. If None, category is determined from
                           the first valid order and all others must match.

    Returns:
        A tuple containing two lists of the same length as the input `orders`:
        1. success_orders: List where each element is a parsed CCXT order dict
                           on success, or None on failure/validation error.
        2. error_details: List where each element is None on success, or a
                          dictionary {'code': ..., 'msg': ...} on failure/validation error.
    """
    func_name = "place_batch_orders"
    num_orders = len(orders)
    qty_epsilon = config.get("POSITION_QTY_EPSILON", Decimal("1E-8"))
    log_prefix = f"[{func_name} ({num_orders} orders)]"
    logger.info(f"{Fore.BLUE}{log_prefix} Preparing batch order request...{Style.RESET_ALL}")

    # Initialize result lists with Nones, matching the input length
    final_success_orders: List[Optional[Dict]] = [None] * num_orders
    final_error_details: List[Optional[Dict]] = [None] * num_orders

    if not orders:
        logger.warning(f"{Fore.YELLOW}{log_prefix} No orders provided in the batch list.{Style.RESET_ALL}")
        return final_success_orders, final_error_details # Return empty results

    # --- Prepare and Validate Individual Orders for V5 format ---
    batch_requests_v5: List[Optional[Dict]] = [None] * num_orders # Stores V5 formatted requests
    category_to_use: Optional[str] = category_override.value if category_override else None
    determined_category_enum: Optional[Category] = category_override
    # V5 Batch Limits: Linear/Inverse/Spot: 10, Option: 5
    cat_limit_map = { Category.LINEAR: 10, Category.INVERSE: 10, Category.SPOT: 10, Category.OPTION: 5 }
    batch_limit = 10 # Default conservative limit, will be updated based on category

    # --- Phase 1: Pre-validation and Formatting Loop ---
    abort_batch = False
    validation_errors_found = False # Track if any pre-validation error occurred
    for i, order_req in enumerate(orders):
        error_detail: Optional[Dict] = None
        symbol = order_req.get("symbol")
        side_raw = order_req.get("side")
        # Accept OrderType enum or string 'Limit'/'Market'
        order_type_raw = order_req.get("type")
        amount_raw = order_req.get("amount")

        # --- Basic Input Validation ---
        current_order_log_prefix = f"{log_prefix} Order #{i + 1}"
        if not all([symbol, side_raw, order_type_raw, amount_raw]): error_detail = {"code": -101, "msg": "Missing required fields (symbol, side, type, amount)."}
        elif not isinstance(symbol, str): error_detail = {"code": -101, "msg": "Symbol must be a string."}
        elif not isinstance(side_raw, (Side, str)): error_detail = {"code": -101, "msg": "Side must be Side enum or 'buy'/'sell' string."}
        # Validate order type (enum or string)
        elif isinstance(order_type_raw, OrderType): order_type_str = order_type_raw.value
        elif isinstance(order_type_raw, str) and order_type_raw.lower() in ["limit", "market"]: order_type_str = order_type_raw.capitalize()
        else: error_detail = {"code": -101, "msg": f"Invalid order type: '{order_type_raw}'. Must be OrderType enum or 'Limit'/'Market'."}
        # Check amount after determining type
        elif safe_decimal_conversion(amount_raw, Decimal("-1")) <= qty_epsilon: error_detail = {"code": -101, "msg": f"Amount '{amount_raw}' must be positive."}

        if error_detail:
            logger.error(f"{Fore.RED}{current_order_log_prefix} Input Err: {error_detail['msg']}{Style.RESET_ALL}")
            final_error_details[i] = error_detail
            validation_errors_found = True
            continue # Skip to next order

        # --- Determine and Validate Category & Batch Limit ---
        current_category_enum = market_cache.get_category(symbol)
        if not current_category_enum:
            error_detail = {"code": -102, "msg": f"Cannot determine market category for symbol '{symbol}'."}
            logger.error(f"{Fore.RED}{current_order_log_prefix} Category Err: {error_detail['msg']}{Style.RESET_ALL}")
            final_error_details[i] = error_detail
            validation_errors_found = True
            continue

        current_category_str = current_category_enum.value

        if category_override:
            # Check if order matches the forced override category
            if current_category_str != category_override.value:
                error_detail = {"code": -103, "msg": f"Symbol '{symbol}' category '{current_category_str}' does not match batch override category '{category_override.value}'."}
                logger.error(f"{Fore.RED}{current_order_log_prefix} Mismatch Err: {error_detail['msg']}{Style.RESET_ALL}")
                final_error_details[i] = error_detail
                validation_errors_found = True
                continue
            effective_category = category_override.value
            if i == 0: # Set limit based on override on first item check
                batch_limit = cat_limit_map.get(category_override, 10) # Default 10 if somehow override is invalid enum
                logger.info(f"{log_prefix} Using overridden batch category: {effective_category}, Limit: {batch_limit}")
                if num_orders > batch_limit:
                    error_msg = f"Batch size {num_orders} exceeds limit {batch_limit} for category '{effective_category}'."
                    logger.error(f"{Back.RED}{log_prefix} {error_msg} Aborting entire batch.{Style.RESET_ALL}")
                    # Mark all subsequent orders as failed due to batch limit
                    for j in range(i, num_orders):
                         if final_error_details[j] is None: final_error_details[j] = {"code": -100, "msg": error_msg}
                    abort_batch = True; validation_errors_found = True; break # Stop processing further orders
        else:
            # Dynamically determine category from first valid order
            if category_to_use is None: # First valid order determines batch category
                category_to_use = current_category_str
                determined_category_enum = current_category_enum
                batch_limit = cat_limit_map.get(determined_category_enum, 10)
                logger.info(f"{log_prefix} Determined batch category from first valid order: {category_to_use}, Limit: {batch_limit}")
                if num_orders > batch_limit:
                    error_msg = f"Batch size {num_orders} exceeds limit {batch_limit} for determined category '{category_to_use}'."
                    logger.error(f"{Back.RED}{log_prefix} {error_msg} Aborting entire batch.{Style.RESET_ALL}")
                    final_error_details[i] = {"code": -100, "msg": error_msg} # Mark current order
                    for j in range(i + 1, num_orders): # Mark subsequent orders
                         if final_error_details[j] is None: final_error_details[j] = {"code": -100, "msg": error_msg}
                    abort_batch = True; validation_errors_found = True; break # Stop processing
            # Check consistency for subsequent orders
            elif current_category_str != category_to_use:
                error_detail = {"code": -104, "msg": f"Symbol '{symbol}' category '{current_category_str}' does not match batch category '{category_to_use}'. Mixing categories not allowed."}
                logger.error(f"{Fore.RED}{current_order_log_prefix} Mix Err: {error_detail['msg']}{Style.RESET_ALL}")
                final_error_details[i] = error_detail
                validation_errors_found = True
                continue
            effective_category = category_to_use # Category is consistent

        # --- Format Amount/Price based on market precision ---
        market = market_cache.get_market(symbol) # Re-fetch needed? Maybe not, category check implies it exists.
        if not market: # Should not happen if category was found, but check defensively
            error_detail = {"code": -105, "msg": f"Market data unexpectedly missing for '{symbol}' after category check."}
            logger.error(f"{Fore.RED}{current_order_log_prefix} Data Err: {error_detail['msg']}{Style.RESET_ALL}")
            final_error_details[i] = error_detail
            validation_errors_found = True
            continue
        amount_str = format_amount(exchange, symbol, amount_raw)
        if amount_str is None:
            error_detail = {"code": -106, "msg": f"Invalid amount format or precision error for amount '{amount_raw}'."}
            logger.error(f"{Fore.RED}{current_order_log_prefix} Format Err: {error_detail['msg']}{Style.RESET_ALL}")
            final_error_details[i] = error_detail
            validation_errors_found = True
            continue

        price_str: Optional[str] = None
        if order_type_str == "Limit":
            price_raw = order_req.get("price")
            if price_raw is None or safe_decimal_conversion(price_raw, Decimal("-1")) <= Decimal(0):
                error_detail = {"code": -107, "msg": "Limit order requires a valid positive 'price'."}
                logger.error(f"{Fore.RED}{current_order_log_prefix} Price Err: {error_detail['msg']}{Style.RESET_ALL}")
                final_error_details[i] = error_detail
                validation_errors_found = True
                continue
            price_str = format_price(exchange, symbol, price_raw)
            if price_str is None:
                error_detail = {"code": -108, "msg": f"Invalid price format or precision error for price '{price_raw}'."}
                logger.error(f"{Fore.RED}{current_order_log_prefix} Format Err: {error_detail['msg']}{Style.RESET_ALL}")
                final_error_details[i] = error_detail
                validation_errors_found = True
                continue

        # --- Normalize Side & Type for V5 JSON payload ---
        side_val = side_raw.value if isinstance(side_raw, Side) else str(side_raw).lower()
        if side_val not in ["buy", "sell"]: # Should have been caught earlier, but double check
             error_detail = {"code": -109, "msg": f"Invalid side value '{side_raw}'."}; logger.error(f"{Fore.RED}{current_order_log_prefix} Side Err: {error_detail['msg']}{Style.RESET_ALL}"); final_error_details[i] = error_detail; validation_errors_found = True; continue
        # V5 uses "Buy" / "Sell" (capitalized)
        bybit_v5_side = side_val.capitalize()
        # V5 uses "Limit" / "Market" (capitalized) - already done via order_type_str

        # --- Build the V5 request dictionary for this specific order ---
        v5_req: Dict[str, Any] = {
            "symbol": symbol,
            "side": bybit_v5_side,
            "orderType": order_type_str, # Use capitalized 'Limit' or 'Market'
            "qty": amount_str,
            # --- Map common optional parameters ---
            "orderLinkId": order_req.get("clientOrderId"), # Will be sanitized later
            "reduceOnly": order_req.get("reduceOnly"),
            "timeInForce": order_req.get("timeInForce").value if isinstance(order_req.get("timeInForce"), TimeInForce) else order_req.get("timeInForce"),
            "positionIdx": order_req.get("positionIdx").value if isinstance(order_req.get("positionIdx"), PositionIdx) else order_req.get("positionIdx"),
            # --- Conditional Order Params ---
            "triggerPrice": format_price(exchange, symbol, order_req.get("triggerPrice")) if order_req.get("triggerPrice") else None,
            "triggerBy": order_req.get("triggerBy").value if isinstance(order_req.get("triggerBy"), TriggerBy) else order_req.get("triggerBy"),
            "triggerDirection": order_req.get("triggerDirection").value if isinstance(order_req.get("triggerDirection"), TriggerDirection) else order_req.get("triggerDirection"),
            # --- TP/SL Params (Use V5 field names directly) ---
            "takeProfit": format_price(exchange, symbol, order_req.get("takeProfit")) if order_req.get("takeProfit") else None,
            "stopLoss": format_price(exchange, symbol, order_req.get("stopLoss")) if order_req.get("stopLoss") else None,
            "tpTriggerBy": order_req.get("tpTriggerBy").value if isinstance(order_req.get("tpTriggerBy"), TriggerBy) else order_req.get("tpTriggerBy"),
            "slTriggerBy": order_req.get("slTriggerBy").value if isinstance(order_req.get("slTriggerBy"), TriggerBy) else order_req.get("slTriggerBy"),
            "tpslMode": order_req.get("tpslMode"), # e.g., 'Full' or 'Partial'
            "tpOrderType": order_req.get("tpOrderType", OrderType.MARKET.value), # Default TP type if not specified
            "slOrderType": order_req.get("slOrderType", OrderType.MARKET.value), # Default SL type
            "tpLimitPrice": format_price(exchange, symbol, order_req.get("tpLimitPrice")) if order_req.get("tpLimitPrice") else None,
            "slLimitPrice": format_price(exchange, symbol, order_req.get("slLimitPrice")) if order_req.get("slLimitPrice") else None,
        }
        # Add price for Limit orders
        if price_str: v5_req["price"] = price_str

        # --- Sanitize and Clean V5 Request ---
        # Remove None values as Bybit API might not like nulls for optional fields
        v5_req_cleaned = {k: v for k, v in v5_req.items() if v is not None}

        # Sanitize clientOrderId (orderLinkId) just before adding
        if "orderLinkId" in v5_req_cleaned:
            cid = str(v5_req_cleaned["orderLinkId"])
            clean_cid = "".join(filter(lambda c: c.isalnum() or c in ["-", "_"], cid))[:36]
            if len(clean_cid) != len(cid): logger.warning(f"{current_order_log_prefix} orderLinkId sanitized: '{clean_cid}'")
            # If CID becomes empty after sanitizing, remove it
            if not clean_cid: del v5_req_cleaned["orderLinkId"]
            else: v5_req_cleaned["orderLinkId"] = clean_cid

        # Ensure boolean flags are actual booleans if present (e.g., from string config)
        if "reduceOnly" in v5_req_cleaned:
             val = v5_req_cleaned["reduceOnly"]
             v5_req_cleaned["reduceOnly"] = str(val).lower() in ['true', '1', 'yes'] if isinstance(val, str) else bool(val)

        # Store the validated and formatted request
        batch_requests_v5[i] = v5_req_cleaned
        logger.debug(f"{current_order_log_prefix} Prepared: {v5_req_cleaned}")

    # --- End of Phase 1 Loop ---

    # Check if batch processing was aborted due to limit exceeded or if only errors were found
    if abort_batch:
        # Errors already logged and stored in final_error_details
        return final_success_orders, final_error_details
    if validation_errors_found and all(e is not None for e in final_error_details):
         logger.error(f"{Fore.RED}{log_prefix} All orders failed pre-validation. No batch request sent.{Style.RESET_ALL}")
         return final_success_orders, final_error_details

    # --- Phase 2: Filter out invalid requests & Prepare for Sending ---
    # Create mapping between original index and the index in the list being sent
    original_index_to_sent_index: Dict[int, int] = {}
    sent_index_to_original_index: Dict[int, int] = {}
    valid_v5_reqs_to_send: List[Dict] = []
    sent_idx = 0
    for original_idx, req in enumerate(batch_requests_v5):
        # Only include requests that were successfully prepared AND had no pre-validation errors
        if req is not None and final_error_details[original_idx] is None:
            valid_v5_reqs_to_send.append(req)
            original_index_to_sent_index[original_idx] = sent_idx
            sent_index_to_original_index[sent_idx] = original_idx
            sent_idx += 1

    # If no valid orders remain after filtering (e.g., all had validation errors), return
    if not valid_v5_reqs_to_send:
        logger.error(f"{Fore.RED}{log_prefix} No valid orders remaining to send after pre-validation.{Style.RESET_ALL}")
        # Validation errors are already in final_error_details
        return final_success_orders, final_error_details

    # Final check on the category determined for the batch
    final_batch_category = category_to_use
    if not final_batch_category: # Should not happen if valid_reqs exists and category logic is sound
        logger.critical(f"{Back.RED}{log_prefix} Internal Error: Final batch category could not be determined despite valid orders. Aborting.{Style.RESET_ALL}")
        internal_error = {"code": -199, "msg": "Internal error: Final batch category missing"}
        # Mark all potentially valid orders as failed due to this internal error
        for i in range(num_orders):
            if final_error_details[i] is None and batch_requests_v5[i] is not None:
                final_error_details[i] = internal_error
        return final_success_orders, final_error_details

    # --- Phase 3: Execute Batch Request ---
    logger.info(f"{log_prefix} Sending batch create request for {len(valid_v5_reqs_to_send)} orders (Category: {final_batch_category})...")
    # Prepare payload for the V5 batch endpoint: POST /v5/order/create-batch
    params = {
        "category": final_batch_category,
        "request": valid_v5_reqs_to_send # The list of V5 order request dicts
    }

    try:
        # Make the API call using the implicit method via CCXT
        # Ensure CCXT version supports this properly
        if not hasattr(exchange, 'private_post_v5_order_create_batch'):
            raise NotSupported(f"{log_prefix} CCXT version {getattr(ccxt, '__version__', 'unknown')} may not support private_post_v5_order_create_batch. Update CCXT.")

        response = await exchange.private_post_v5_order_create_batch(params)
        logger.debug(f"{log_prefix} Raw API response: {response}")

        # --- Phase 4: Process Batch Response ---
        if not response or not isinstance(response, dict):
             # Handle case where response is not a dictionary
             raise ExchangeError(f"{log_prefix} Invalid or unexpected response type received from batch order API: {type(response).__name__}")

        ret_code = response.get("retCode")
        ret_msg = response.get("retMsg", "N/A")
        result_data = response.get("result", {}) # Result field contains 'list' and 'errInfo'

        # Ensure result_data is a dict before accessing keys
        if not isinstance(result_data, dict):
            result_data = {} # Treat as empty if not a dict

        # Bybit V5 response structure: result.list for successes, result.errInfo for errors (relative to sent list)
        success_raw = result_data.get("list", [])
        errors_raw = result_data.get("errInfo", [])

        # Validate types of success/error lists
        if not isinstance(success_raw, list): logger.warning(f"{log_prefix} API response 'result.list' is not a list."); success_raw = []
        if not isinstance(errors_raw, list): logger.warning(f"{log_prefix} API response 'result.errInfo' is not a list."); errors_raw = []

        # Check overall request status code
        if ret_code == 0:
            # Request processed, but individual orders might have failed
            logger.info(f"{Fore.GREEN}{log_prefix} Batch request processed by API. Success Reports: {len(success_raw)}, Failure Reports: {len(errors_raw)}{Style.RESET_ALL}")

            # Keep track of original indices processed to avoid double-marking
            processed_original_indices = set()

            # Process errors reported by the API first
            for err_info in errors_raw:
                if not isinstance(err_info, dict): continue # Skip invalid error entries
                err_code = err_info.get("code", -1) # Bybit error code (int)
                err_msg = err_info.get("msg", "Unknown API error")
                # V5 'errInfo' usually contains the index in the *sent* request list
                err_req_idx = err_info.get("index") # Index within the 'request' list sent

                if err_req_idx is not None and isinstance(err_req_idx, int) and 0 <= err_req_idx < len(valid_v5_reqs_to_send):
                    # Map back to the original index in the input list
                    original_list_idx = sent_index_to_original_index.get(err_req_idx)
                    if original_list_idx is not None:
                         # Get details from the request that failed for better logging
                         failed_req = valid_v5_reqs_to_send[err_req_idx]
                         err_cid = failed_req.get("orderLinkId", "N/A")
                         req_symbol = failed_req.get("symbol", "N/A")
                         logger.error(f"{Fore.RED}{log_prefix} Order #{original_list_idx + 1} ({req_symbol}, CID:{err_cid}) FAILED (API Reported). Code: {err_code}, Msg: {err_msg}{Style.RESET_ALL}")
                         # Store the error detail in the final results, only if not already failed in pre-validation
                         if final_error_details[original_list_idx] is None:
                             final_error_details[original_list_idx] = {"code": err_code, "msg": err_msg}
                         processed_original_indices.add(original_list_idx)
                    else:
                        # This indicates an internal mapping error, should not happen
                        logger.error(f"{log_prefix} Internal mapping error: Could not find original index for error request index {err_req_idx}.")
                else:
                    # Error entry didn't have a valid index, log it but can't map reliably
                    logger.error(f"{log_prefix} API error entry missing valid index: {err_info}. Cannot map error reliably.")

            # Process successes reported by the API
            for order_data in success_raw:
                 if not isinstance(order_data, dict): continue # Skip invalid success entries
                 cid = order_data.get("orderLinkId")
                 oid = order_data.get("orderId")
                 symbol = order_data.get("symbol") # Get symbol for market context parsing
                 original_list_idx = None
                 found_match = False

                 # Try to find the original request using the clientOrderId (most reliable way to match)
                 if cid:
                     for req_idx, sent_req in enumerate(valid_v5_reqs_to_send):
                         # Map sent index back to original index
                         current_original_idx = sent_index_to_original_index.get(req_idx)
                         if current_original_idx is None: continue # Skip if mapping failed

                         # Check if CID matches and this original index hasn't been processed as an error
                         if cid == sent_req.get("orderLinkId") and current_original_idx not in processed_original_indices:
                             original_list_idx = current_original_idx
                             found_match = True
                             break # Found match
                 else:
                     # If no clientOrderId in the response, matching is unreliable. Log warning.
                     logger.warning(f"{log_prefix} Success reported for OrderID {oid} (Symbol: {symbol}) but has no orderLinkId. Cannot reliably map to original request.")
                     # Attempt fallback? Maybe match by symbol/side/type/qty? Risky. Skip for now.
                     continue

                 # If no match found even with CID (e.g., CID wasn't unique or request was altered)
                 if not found_match:
                     logger.warning(f"{log_prefix} Success reported for OrderID {oid} (CID: {cid}) but could not map it back to a unique, non-errored original request.")
                     continue # Cannot process this success report reliably

                 # If found and not already errored
                 if original_list_idx is not None and final_error_details[original_list_idx] is None:
                     try:
                         # Parse the successful order data into CCXT format
                         market_context = market_cache.get_market(symbol) if symbol else None
                         if not market_context:
                             logger.warning(f"{log_prefix} Market context missing for symbol {symbol} while parsing success order {oid}. Skipping parse.")
                             final_error_details[original_list_idx] = {"code": -200, "msg": f"Success reported by API but market context missing for {symbol}"}
                             processed_original_indices.add(original_list_idx)
                             continue

                         # Parse the order using CCXT's method
                         parsed_order = exchange.parse_order(order_data, market_context)
                         final_success_orders[original_list_idx] = parsed_order
                         status = parsed_order.get("status", "?")
                         logger.info(f"{Fore.GREEN}{log_prefix} Order #{original_list_idx + 1} ({symbol}, CID:{cid}) PLACED/Success. ID: ...{format_order_id(oid)}, Status: {status}{Style.RESET_ALL}")
                         processed_original_indices.add(original_list_idx)
                     except Exception as parse_err:
                         logger.error(f"{log_prefix} Error parsing successful order data #{original_list_idx + 1} (ID:{oid}, CID:{cid}): {parse_err}", exc_info=True)
                         # Mark as error because we couldn't process the success response
                         final_error_details[original_list_idx] = {"code": -201, "msg": f"Success reported by API but failed to parse response: {parse_err}"}
                         processed_original_indices.add(original_list_idx)
                 # else: Original index already marked as error or mapping failed. Skip.

            # Final check: Mark any sent orders that didn't get a success or error response as unknown
            # This covers cases where the API response might be incomplete
            for sent_req_idx, sent_req in enumerate(valid_v5_reqs_to_send):
                original_idx = sent_index_to_original_index.get(sent_req_idx)
                # If we have an original index, it wasn't processed (success or error), and had no pre-validation error
                if original_idx is not None and original_idx not in processed_original_indices and final_error_details[original_idx] is None:
                    req_symbol = sent_req.get("symbol", "N/A")
                    req_cid = sent_req.get("orderLinkId", "N/A")
                    logger.error(f"{Fore.RED}{log_prefix} Order #{original_idx + 1} ({req_symbol}, CID:{req_cid}) - No response status received from API (Unknown outcome).{Style.RESET_ALL}")
                    final_error_details[original_idx] = {"code": -202, "msg": "No success or specific error message received from API for this order in the batch."}

        else: # Batch request itself failed (retCode != 0) - API rejected the whole batch
            error_msg = f"Batch API request failed entirely. Code: {ret_code}, Msg: {ret_msg}"
            logger.error(f"{Back.RED}{log_prefix} {error_msg}{Style.RESET_ALL}")
            # Mark all orders that were *sent* as failed with this general error, unless they had a pre-validation error
            batch_api_error = {"code": ret_code, "msg": ret_msg}
            for sent_req_idx in range(len(valid_v5_reqs_to_send)):
                 original_list_idx = sent_index_to_original_index.get(sent_req_idx)
                 if original_list_idx is not None and final_error_details[original_list_idx] is None:
                      final_error_details[original_list_idx] = batch_api_error

        # Return the final success and error lists, corresponding to the input order list
        return final_success_orders, final_error_details

    # --- Exception Handling for the Batch API Call itself ---
    except NotSupported as e:
        logger.error(f"{Back.RED}{log_prefix} FAILED - Feature not supported (check CCXT version?): {e}{Style.RESET_ALL}")
        err_resp = {"code": -303, "msg": f"Feature Not Supported: {e}"}
        for i in range(num_orders): # Mark all as failed if the call isn't supported
            if final_error_details[i] is None: final_error_details[i] = err_resp
        return final_success_orders, final_error_details
    except InvalidOrder as e: # Catch issues like parameter errors detected by CCXT or exchange for the *whole* batch
        logger.error(f"{Back.RED}{log_prefix} FAILED - Invalid Batch Order Parameters/Rejected: {e}{Style.RESET_ALL}")
        err_resp = {"code": -301, "msg": f"Invalid Batch Order Call: {e}"}
        # Mark all orders that were intended to be sent as failed
        for sent_req_idx in range(len(valid_v5_reqs_to_send)):
            original_list_idx = sent_index_to_original_index.get(sent_req_idx)
            if original_list_idx is not None and final_error_details[original_list_idx] is None:
                final_error_details[original_list_idx] = err_resp
        return final_success_orders, final_error_details
    except ExchangeError as e: # Catch other specific exchange rejections for the batch call
        logger.error(f"{Back.RED}{log_prefix} FAILED - Batch Exchange Error: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=False)
        err_resp = {"code": -302, "msg": f"Batch Exchange Error: {e}"}
        for sent_req_idx in range(len(valid_v5_reqs_to_send)):
            original_list_idx = sent_index_to_original_index.get(sent_req_idx)
            if original_list_idx is not None and final_error_details[original_list_idx] is None:
                final_error_details[original_list_idx] = err_resp
        return final_success_orders, final_error_details
    except (NetworkError, ExchangeNotAvailable, RateLimitExceeded) as e:
        logger.error(f"{Back.RED}{log_prefix} FAILED - Batch API Communication Error: {type(e).__name__}: {e}{Style.RESET_ALL}")
        # Re-raise for the retry decorator to handle (retrying batch might be complex)
        raise e
    except Exception as e: # Catch any other unexpected errors during the batch call
        logger.error(f"{Back.RED}{log_prefix} FAILED - Unexpected Batch Error: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=True)
        err_resp = {"code": -300, "msg": f"Unexpected Batch Error: {e}"}
        for sent_req_idx in range(len(valid_v5_reqs_to_send)):
            original_list_idx = sent_index_to_original_index.get(sent_req_idx)
            if original_list_idx is not None and final_error_details[original_list_idx] is None:
                final_error_details[original_list_idx] = err_resp
        return final_success_orders, final_error_details


@retry_api_call()
async def fetch_position(exchange: ccxt.bybit, symbol: str, config: Config) -> Optional[Dict]:
    """Fetches position information for a specific symbol using V5 category context."""
    func_name = "fetch_position"; log_prefix = f"[{func_name} ({symbol})]"
    logger.debug(f"{log_prefix} Fetching position...")

    category = market_cache.get_category(symbol)
    # Positions are typically relevant for derivatives (Linear/Inverse) and Options.
    # Spot position represents holdings, which might be better fetched via balance.
    if not category:
        logger.error(f"{Fore.RED}{log_prefix} Cannot determine category for {symbol}. Cannot fetch position.{Style.RESET_ALL}")
        return None
    if category == Category.SPOT:
        logger.info(f"{log_prefix} Fetching 'position' for SPOT symbol {symbol}. This reflects holdings, not leveraged positions.")
        # Proceed, but be aware the structure might differ slightly or be less informative than derivatives.

    # **** V5 requires category param for positions ****
    # CCXT's fetch_positions implementation for Bybit V5 should use this.
    # We request only the specific symbol.
    params = {"category": category.value, "symbol": symbol}
    try:
        # CCXT maps fetch_positions to GET /v5/position/list
        # Providing a symbol list filters the response server-side (more efficient)
        positions = await exchange.fetch_positions(symbols=[symbol], params=params)
        logger.debug(f"{log_prefix} Raw positions response: {positions}")

        if positions and isinstance(positions, list) and len(positions) > 0:
            # fetch_positions returns a list. If filtered by symbol, it should contain 0 or 1 position
            # (or 2 in hedge mode for the same symbol). We usually want the first/primary one.
            if len(positions) > 1:
                 # This could happen in Hedge Mode (Buy/Sell positions for same symbol)
                 logger.info(f"{log_prefix} Received {len(positions)} position entries for {symbol} (possibly Hedge Mode). Returning the first entry by default.")
                 # TODO: Add logic here if specific handling for hedge mode (e.g., summing sizes) is needed.
            position_data = positions[0] # Take the first entry

            # Validate essential keys from CCXT unified position structure
            # Core keys: symbol, side ('long'/'short'/None), contracts (size), entryPrice, markPrice, unrealizedPnl, leverage, marginType ('isolated'/'cross')
            # Optional but useful: liquidationPrice, collateral, initialMargin, maintMargin
            required = ['symbol', 'side', 'contracts', 'entryPrice', 'markPrice', 'unrealizedPnl', 'leverage', 'marginType']
            missing = [k for k in required if k not in position_data or position_data[k] is None]
            if missing:
                # Log missing keys but don't necessarily fail if basic info is present
                logger.warning(f"{Fore.YELLOW}{log_prefix} Fetched position data for {symbol} missing expected keys: {missing}. Raw data: {str(position_data)[:200]}...{Style.RESET_ALL}")

            # Parse key values safely
            pos_side = position_data.get('side') # 'long', 'short', or None/empty string if flat
            contracts = safe_decimal_conversion(position_data.get('contracts'), Decimal(0)) # Use safe conversion, default 0
            entry_price = safe_decimal_conversion(position_data.get('entryPrice'))
            mark_price = safe_decimal_conversion(position_data.get('markPrice'))
            unrealized_pnl = safe_decimal_conversion(position_data.get('unrealizedPnl'))
            leverage = safe_decimal_conversion(position_data.get('leverage'))
            margin_type = position_data.get('marginType') # 'isolated' or 'cross'

            qty_epsilon = config.get("POSITION_QTY_EPSILON", Decimal("1E-8"))
            # Check if position size is significant (greater than epsilon)
            if contracts is not None and abs(contracts) > qty_epsilon:
                log_color = Fore.GREEN if pos_side == 'long' else Fore.RED if pos_side == 'short' else Fore.YELLOW
                liq_price = safe_decimal_conversion(position_data.get('liquidationPrice'))
                logger.info(f"{log_color}{log_prefix} Active Position: Side={pos_side or 'N/A'}, Size={contracts}, Entry={entry_price or 'N/A'}, Mark={mark_price or 'N/A'}, uPNL={unrealized_pnl:.4f if unrealized_pnl else 'N/A'}, Lev={leverage or 'N/A'}x, LiqPx={liq_price or 'N/A'}, Mode={margin_type or 'N/A'}{Style.RESET_ALL}")
            else:
                # Log flat position clearly
                logger.info(f"{Fore.BLUE}{log_prefix} No active position found (position size is zero or negligible).{Style.RESET_ALL}")
                # Standardize flat position representation in the returned dict
                position_data['side'] = None
                position_data['contracts'] = Decimal(0)
                # Nullify other fields that don't make sense for flat positions
                position_data['entryPrice'] = None
                position_data['liquidationPrice'] = None
                position_data['unrealizedPnl'] = Decimal(0)

            # Return the CCXT unified position structure dictionary
            return position_data

        else:
            # This likely means the symbol exists but there's no open position (flat)
            logger.info(f"{Fore.BLUE}{log_prefix} No position data returned by API for {symbol} (assuming flat).{Style.RESET_ALL}")
            # Return a standardized "flat" position dictionary for consistency
            # This helps calling code avoid None checks and always get a dict
            return {
                'info': {}, # No raw info
                'symbol': symbol,
                'timestamp': int(time.time() * 1000), # Current time as approx timestamp
                'datetime': exchange.iso8601(int(time.time() * 1000)),
                'initialMargin': Decimal(0),
                'initialMarginPercentage': None,
                'maintenanceMargin': Decimal(0),
                'maintenanceMarginPercentage': None,
                'entryPrice': None,
                'notional': Decimal(0),
                'leverage': None, # Leverage might still be set even if flat
                'unrealizedPnl': Decimal(0),
                'contracts': Decimal(0), # Size is zero
                'contractSize': market.get('contractSize') if market else None,
                'markPrice': None, # Mark price still exists, could fetch ticker? Too complex here.
                'side': None, # Explicitly flat
                'hedged': None, # Or check account mode?
                'liquidationPrice': None,
                'collateral': Decimal(0),
                'marginRatio': None,
                'marginType': None, # Or fetch account mode?
                'percentage': None,
            }

    except (NetworkError, ExchangeNotAvailable, RateLimitExceeded) as e:
        logger.warning(f"{Fore.YELLOW}{log_prefix} API error: {type(e).__name__}. Retry handled.{Style.RESET_ALL}")
        raise # Re-raise for decorator
    except AuthenticationError as e:
        logger.error(f"{Fore.RED}{log_prefix} Authentication error: {e}{Style.RESET_ALL}")
        return None
    except ExchangeError as e:
        logger.error(f"{Fore.RED}{log_prefix} Exchange error: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=False)
        return None
    except Exception as e:
        logger.error(f"{Fore.RED}{log_prefix} Unexpected error: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=True)
        return None


@retry_api_call()
async def fetch_open_orders(
    exchange: ccxt.bybit,
    symbol: Optional[str] = None, # Optional: fetch only for a specific symbol
    order_filter: Optional[OrderFilter] = OrderFilter.ORDER, # Default to active limit/market orders ('Order')
    config: Config = None, # Required for context/logging
) -> List[Dict]:
    """
    Fetches open orders (active/conditional) for V5 UTA, allowing filtering.

    Args:
        exchange: Initialized ccxt.bybit instance.
        symbol: If specified, fetch orders only for this symbol.
        order_filter: V5 filter type (Order, StopOrder, tpslOrder).
                      If None, fetches default type ('Order'). To fetch all, requires multiple calls.
        config: Configuration object.

    Returns:
        A list of open orders matching the criteria, in CCXT unified format. Returns empty list on failure.
    """
    func_name = "fetch_open_orders"
    symbol_log = f" ({symbol})" if symbol else " (All Symbols)"
    filter_log = f" Filter: {order_filter.value}" if order_filter else " (Filter: Default 'Order')"
    log_prefix = f"[{func_name}{symbol_log}{filter_log}]"
    logger.debug(f"{log_prefix} Fetching open orders...")

    if not config:
        logger.error(f"{Fore.RED}{log_prefix} Config object is required.{Style.RESET_ALL}")
        return []
    if not exchange or not hasattr(exchange, 'fetch_open_orders'):
         logger.error(f"{Fore.RED}{log_prefix} Invalid exchange object or fetch_open_orders method missing.{Style.RESET_ALL}")
         return []

    params: Dict[str, Any] = {}
    category: Optional[Category] = None

    # Determine category if fetching for a specific symbol
    if symbol:
        category = market_cache.get_category(symbol)
        if not category:
             logger.error(f"{Fore.RED}{log_prefix} Cannot determine category for symbol {symbol}. Cannot fetch symbol-specific orders.{Style.RESET_ALL}")
             return [] # Fail if category unknown for specific symbol
        else:
            # **** V5 requires category param for orders ****
            params["category"] = category.value
            logger.debug(f"{log_prefix} Determined category {category.value} for symbol {symbol}.")

    # Add V5 specific filter if provided (use default 'Order' if None)
    effective_filter = order_filter if order_filter else OrderFilter.ORDER
    params["orderFilter"] = effective_filter.value

    all_open_orders: List[Dict] = []

    # --- Execute Fetch ---
    # CCXT's fetch_open_orders maps to GET /v5/order/realtime
    # It should handle category iteration internally if symbol=None and category is not in params.
    # However, explicitly looping might be safer if CCXT implementation is uncertain.
    # For now, rely on CCXT's handling based on presence/absence of symbol and category param.

    try:
        # If symbol is None, CCXT *should* iterate categories if needed, but we pass category if known.
        # If symbol is provided, category *must* be in params for V5.
        logger.debug(f"{log_prefix} Querying with params: {params}")
        orders = await exchange.fetch_open_orders(symbol=symbol, params=params)
        if orders:
            all_open_orders.extend(orders)

    except (NetworkError, ExchangeNotAvailable, RateLimitExceeded) as e:
         logger.warning(f"{Fore.YELLOW}{log_prefix} API error fetching orders: {type(e).__name__}. Retry handled.{Style.RESET_ALL}")
         raise # Let outer retry handle
    except AuthenticationError as e:
         logger.error(f"{Fore.RED}{log_prefix} Authentication error fetching orders: {e}{Style.RESET_ALL}")
         return [] # Fail fast on auth error
    except ExchangeError as e:
         logger.error(f"{Fore.RED}{log_prefix} Exchange error fetching orders: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=False)
         return [] # Return empty on error
    except Exception as e:
         logger.error(f"{Fore.RED}{log_prefix} Unexpected error fetching orders: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=True)
         return []

    # Log final count
    count = len(all_open_orders)
    log_color = Fore.GREEN if count == 0 else Fore.YELLOW
    logger.info(f"{log_color}{log_prefix} Found {count} total open orders matching criteria.{Style.RESET_ALL}")
    return all_open_orders


@retry_api_call(max_retries=1, retry_on_exceptions=(NetworkError, RequestTimeout, RateLimitExceeded)) # Limit retries for cancel
async def cancel_order(exchange: ccxt.bybit, order_id: str, symbol: str, config: Config) -> bool:
    """Cancels a specific order by ID and symbol for V5, using category context."""
    func_name = "cancel_order"; log_prefix = f"[{func_name} (ID: ...{format_order_id(order_id)}, Sym: {symbol})]"
    logger.info(f"{Fore.BLUE}{log_prefix} Attempting cancellation...{Style.RESET_ALL}")

    if not order_id:
         logger.error(f"{Fore.RED}{log_prefix} Order ID is required.{Style.RESET_ALL}")
         return False

    category = market_cache.get_category(symbol)
    if not category:
        logger.error(f"{Fore.RED}{log_prefix} Cannot determine category for symbol {symbol}. Cancellation requires category.{Style.RESET_ALL}")
        return False

    # **** V5 requires category param for cancelling ****
    params = {"category": category.value}
    # Bybit V5 cancel endpoint: POST /v5/order/cancel
    # It accepts either 'orderId' or 'orderLinkId'.
    # CCXT's cancel_order method typically sends the 'id' argument as 'orderId'.
    # If cancelling by client ID, use exchange.cancel_order_by_client_id or pass 'orderLinkId' in params.
    # Assuming 'order_id' passed here is the exchange's order ID.

    try:
        logger.debug(f"{log_prefix} Sending cancel_order request with params: {params}")
        # Use CCXT standard method, passing category in params
        response = await exchange.cancel_order(id=order_id, symbol=symbol, params=params)

        # --- Analyze Response ---
        # CCXT cancel_order behavior varies. Success is often indicated by lack of exception.
        # We can inspect the raw response ('info') for Bybit V5 confirmation.
        logger.debug(f"{log_prefix} Raw cancel response: {response}")
        v5_result = {}
        # Check if response is a dict and contains 'info' which is also a dict
        if isinstance(response, dict) and isinstance(response.get('info'), dict):
             v5_raw_response = response['info']
             # Example V5 success: {'retCode': 0, 'retMsg': 'OK', 'result': {'orderId': '...', 'orderLinkId': '...'}, ...}
             if v5_raw_response.get("retCode") == 0 and isinstance(v5_raw_response.get("result"), dict):
                 v5_result = v5_raw_response["result"] # Extract the result part

        cancelled_id_from_response = v5_result.get('orderId')

        # Check if the response confirms the cancellation of the requested ID
        if cancelled_id_from_response == order_id:
            logger.info(f"{Fore.GREEN}{log_prefix} Successfully cancelled (confirmed by API response ID).{Style.RESET_ALL}")
            return True
        else:
            # If ID doesn't match or response is unclear, assume success based on no exception (CCXT standard)
            # This path is taken if the response structure is unexpected or doesn't contain the ID.
            logger.info(f"{Fore.GREEN}{log_prefix} Cancellation request sent successfully (no exception raised). API confirmation unclear or ID mismatch (Expected: {order_id}, Got: {cancelled_id_from_response}).{Style.RESET_ALL}")
            return True # Treat as success if no error was raised by CCXT

    except OrderNotFound as e:
        # Order already filled, cancelled, or never existed. Treat as successful cancellation outcome.
        logger.warning(f"{Fore.YELLOW}{log_prefix} Order not found (may already be filled/cancelled): {e}{Style.RESET_ALL}")
        return True # Considered success from the perspective of ensuring it's not open
    except InvalidOrder as e:
        # E.g., trying to cancel an order in a final state (rejected, filled) where cancel is invalid
        logger.error(f"{Fore.RED}{log_prefix} Invalid order state for cancellation (already filled/rejected?): {e}{Style.RESET_ALL}")
        # This is arguably a failure if the intent was to cancel an assumed-open order.
        return False
    except ExchangeError as e:
        # Catch other specific exchange errors during cancellation
        logger.error(f"{Fore.RED}{log_prefix} Exchange error during cancellation: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=False)
        return False
    except (NetworkError, ExchangeNotAvailable, RateLimitExceeded) as e:
        # Let retry decorator handle these by re-raising
        logger.error(f"{Back.RED}{log_prefix} FAILED - API Communication Error: {type(e).__name__}: {e}{Style.RESET_ALL}")
        raise e
    except Exception as e:
        # Catch any other unexpected errors
        logger.error(f"{Fore.RED}{log_prefix} Unexpected error during cancellation: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=True)
        return False


@retry_api_call(max_retries=1, retry_on_exceptions=(NetworkError, RequestTimeout, RateLimitExceeded))
async def cancel_all_orders(
    exchange: ccxt.bybit,
    symbol: Optional[str] = None, # Optional: cancel only for this symbol
    category_to_cancel: Optional[Category] = None, # ** REQUIRED ** if symbol is None, or used as filter
    order_filter: Optional[OrderFilter] = None, # Optional: V5 filter (Order, StopOrder, etc.)
    config: Config = None # Required for context
) -> bool:
    """
    Cancels all open orders for a specific category, optionally filtered by symbol or V5 filter.

    **IMPORTANT Bybit V5 Change:** The `cancel_all_orders` endpoint (`POST /v5/order/cancel-all`)
    **requires** the `category` parameter. You cannot cancel across all categories in a single call.
    This function now requires `category_to_cancel` unless `symbol` is provided (in which case
    the symbol's category is used).

    Args:
        exchange: Initialized ccxt.bybit instance.
        symbol: If provided, cancel orders only for this symbol (category is inferred).
        category_to_cancel: If provided (and symbol is None), cancel orders only within this category.
                            If symbol is provided, this can act as an additional check.
        order_filter: V5 filter (Order, StopOrder, tpslOrder). If None, cancels matching types based on endpoint default.
        config: Configuration object.

    Returns:
        True if the cancellation request for the target category/symbol was sent successfully
        without critical errors, False otherwise. Note: This doesn't guarantee individual orders
        were cancelled if they were already closed. Returns the number of orders reported cancelled by the API.
    """
    func_name = "cancel_all_orders"
    symbol_log = f" ({symbol})" if symbol else ""
    cat_log = f" Category: {category_to_cancel.value}" if category_to_cancel else ""
    filter_log = f" Filter: {order_filter.value}" if order_filter else ""
    log_prefix = f"[{func_name}{symbol_log}{cat_log}{filter_log}]"
    logger.info(f"{Fore.BLUE}{log_prefix} Attempting cancel-all operation...{Style.RESET_ALL}")

    if not config:
        logger.error(f"{Fore.RED}{log_prefix} Config object is required.{Style.RESET_ALL}")
        return False # Indicate failure
    # Check for the V5 specific method existence
    if not exchange or not hasattr(exchange, 'private_post_v5_order_cancel_all'):
         logger.error(f"{Fore.RED}{log_prefix} Invalid exchange object or required method 'private_post_v5_order_cancel_all' missing (check CCXT version?).{Style.RESET_ALL}")
         return False # Indicate failure

    # --- Determine Target Category ---
    target_category: Optional[Category] = None
    if symbol:
        cat = market_cache.get_category(symbol)
        if cat:
            target_category = cat
            # Optional: Verify against category_to_cancel if both provided
            if category_to_cancel and category_to_cancel != target_category:
                 logger.error(f"{Fore.RED}{log_prefix} Mismatch: Symbol {symbol} (Category: {target_category.value}) does not belong to specified category_to_cancel ({category_to_cancel.value}). Aborting.{Style.RESET_ALL}")
                 return False # Indicate failure
            logger.info(f"{log_prefix} Targeting category {target_category.value} based on symbol {symbol}.")
        else:
            logger.error(f"{Fore.RED}{log_prefix} Cannot determine category for symbol {symbol}. Cannot target cancellation. Aborting.{Style.RESET_ALL}")
            return False # Indicate failure
    elif category_to_cancel:
        # Use the explicitly provided category
        target_category = category_to_cancel
        logger.info(f"{log_prefix} Targeting explicitly specified category: {target_category.value}")
    else:
        # V5 requires category, cannot proceed without symbol or explicit category
        logger.error(f"{Fore.RED}{log_prefix} Bybit V5 cancel-all requires a category. Provide 'symbol' or 'category_to_cancel'. Aborting.{Style.RESET_ALL}")
        return False # Indicate failure

    # --- Prepare and Execute Cancellation ---
    params: Dict[str, Any] = {"category": target_category.value}
    if symbol: # Add symbol only if provided (filters within the category)
        params["symbol"] = symbol
    if order_filter: # Add V5 filter if provided
        params["orderFilter"] = order_filter.value
    # Bybit V5 endpoint: POST /v5/order/cancel-all

    try:
        logger.debug(f"{log_prefix} Sending cancel-all request with params: {params}")
        # Use the implicit API call via CCXT (requires appropriate CCXT version)
        response = await exchange.private_post_v5_order_cancel_all(params)
        logger.debug(f"{log_prefix} Raw cancel-all response: {response}")

        # --- Process Response ---
        if not isinstance(response, dict):
             logger.error(f"{Fore.RED}{log_prefix} Invalid response type received. Response: {response}{Style.RESET_ALL}")
             return False # Indicate failure

        ret_code = response.get("retCode")
        ret_msg = response.get("retMsg", "N/A")
        # Result list contains IDs of successfully cancelled orders (or is empty)
        result_data = response.get("result", {})
        result_list = result_data.get("list", []) if isinstance(result_data, dict) else []
        cancelled_count = len(result_list) if isinstance(result_list, list) else 0

        if ret_code == 0:
            if cancelled_count > 0:
                logger.info(f"{Fore.GREEN}{log_prefix} Successfully cancelled {cancelled_count} orders.{Style.RESET_ALL}")
            else:
                # Success code 0 but empty list means no matching orders found to cancel
                logger.info(f"{Fore.BLUE}{log_prefix} No matching open orders found to cancel (API Success Code 0).{Style.RESET_ALL}")
            return True # Indicate overall success of the request
        else:
            # Handle specific non-error codes if necessary
            # Example: Bybit might return a specific code if no orders existed (e.g., 170101 - No orders to cancel)
            if ret_code == 170101:
                 logger.info(f"{Fore.BLUE}{log_prefix} No matching open orders found to cancel (API Code: {ret_code} - {ret_msg}).{Style.RESET_ALL}")
                 return True # Still considered a successful operation (nothing needed cancelling)
            else:
                # Log actual errors reported by the API
                logger.error(f"{Fore.RED}{log_prefix} Cancel-all request failed. API Code: {ret_code}, Msg: {ret_msg}{Style.RESET_ALL}")
                return False # Indicate failure

    except ExchangeError as e:
        # Catch exchange errors specific to the cancel-all call
        logger.error(f"{Fore.RED}{log_prefix} Exchange error during cancel-all: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=False)
        return False # Indicate failure
    except (NetworkError, ExchangeNotAvailable, RateLimitExceeded) as e:
        # Let retry decorator handle these by re-raising for the *entire* function call
        logger.error(f"{Back.RED}{log_prefix} FAILED - API Communication Error during cancel-all: {type(e).__name__}: {e}{Style.RESET_ALL}")
        raise e
    except Exception as e:
        # Catch unexpected errors during the call
        logger.error(f"{Fore.RED}{log_prefix} Unexpected error during cancel-all: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=True)
        return False # Indicate failure


# --- Conditional Order Functions (Basic Examples) ---
# Note: Bybit V5 has complex conditional order capabilities (TP/SL attached to positions, OCO, etc.)
# This function provides a basic standalone stop order (market or limit trigger).

@retry_api_call(max_retries=1, retry_on_exceptions=(NetworkError, RequestTimeout, RateLimitExceeded))
async def place_stop_order(
    exchange: ccxt.bybit,
    symbol: str,
    side: Side, # Side of the order to be placed when triggered (e.g., SELL for stop-loss on LONG)
    amount: Decimal,
    trigger_price: Decimal,
    config: Config,
    order_type: OrderType = OrderType.MARKET, # Type of order placed when triggered (Market or Limit)
    limit_price: Optional[Decimal] = None, # Required if order_type is Limit (price for the triggered limit order)
    is_reduce_only: bool = True, # Typically True for SL/TP to only close position
    trigger_by: TriggerBy = TriggerBy.MARK, # Price type to monitor (Mark, Last, Index)
    trigger_direction: Optional[TriggerDirection] = None, # Optional: 1=Rise, 2=Fall. Bybit often infers.
    position_idx: Optional[PositionIdx] = None, # For Hedge Mode context
    client_order_id: Optional[str] = None,
    # V5 specific TP/SL params might be needed for more advanced usage:
    # tpslMode: 'Full' or 'Partial' (for position TP/SL)
    # basePrice: Reference price for trigger direction inference (optional)
    stop_order_type: Optional[Literal['Stop', 'TakeProfit', 'StopLoss', 'TrailingStop']] = None, # More specific V5 type
) -> Optional[Dict]:
    """
    Places a basic conditional stop order (stop-loss or take-profit trigger).

    Note: This uses the generic `create_order` method with params for conditional orders.
          Bybit V5 has more specific TP/SL features often tied directly to positions
          or using dedicated parameters not fully covered by this basic function.
          Use the `stop_order_type` parameter for more explicit V5 control.

    Args:
        exchange: Initialized ccxt.bybit instance.
        symbol: The market symbol.
        side: Side of the order to be PLACED when triggered (e.g., SELL to close a LONG).
        amount: Amount of the order to be placed when triggered.
        trigger_price: The price at which the order should be triggered.
        config: Configuration object.
        order_type: Type of order (Market or Limit) to place once triggered.
        limit_price: If order_type is Limit, this is the limit price for that triggered order.
        is_reduce_only: If True, the triggered order can only reduce position size.
        trigger_by: Which price source (Mark, Last, Index) triggers the order.
        trigger_direction: 1 for trigger on rise, 2 for trigger on fall. Often inferred by Bybit.
        position_idx: Hedge mode position index (0, 1, or 2).
        client_order_id: Custom identifier for the conditional order.
        stop_order_type: Specific V5 conditional order type ('Stop', 'TakeProfit', 'StopLoss', 'TrailingStop').

    Returns:
        The parsed conditional order dictionary from CCXT if successfully placed, else None.
        The status will typically be 'open' or 'untriggered'.
    """
    func_name = "place_stop_order"
    # Determine action description based on context (requires knowledge of existing position)
    # Use stop_order_type if provided, otherwise generic "Stop"
    action_desc = stop_order_type if stop_order_type else "Stop"
    log_prefix = f"[{func_name} ({symbol}, TrigSide:{side.value}, Amt:{amount}, TrigPx:{trigger_price}, Type:{order_type.value}, Action:{action_desc})]"

    # --- Basic Validations ---
    qty_epsilon = config.get("POSITION_QTY_EPSILON", Decimal("1E-8"))
    if amount <= qty_epsilon or trigger_price <= Decimal(0):
        logger.error(f"{Fore.RED}{log_prefix} Invalid amount ({amount}) or trigger price ({trigger_price}). Must be positive.{Style.RESET_ALL}")
        return None
    if order_type == OrderType.LIMIT and (limit_price is None or limit_price <= Decimal(0)):
        logger.error(f"{Fore.RED}{log_prefix} Limit stop order requires a valid positive 'limit_price'. Received: {limit_price}.{Style.RESET_ALL}")
        return None
    if order_type == OrderType.MARKET and limit_price is not None:
         logger.warning(f"{Fore.YELLOW}{log_prefix} 'limit_price' was provided for a Market stop order. It will likely be ignored by the exchange.{Style.RESET_ALL}")

    category = market_cache.get_category(symbol); market = market_cache.get_market(symbol)
    # Conditional orders primarily for derivatives, but Spot might support basic stops too.
    if not category or not market or category not in [Category.LINEAR, Category.INVERSE, Category.SPOT, Category.OPTION]: # Option stops might exist
        logger.error(f"{Fore.RED}{log_prefix} Invalid category/market ({category}) for stop order on {symbol}.{Style.RESET_ALL}")
        return None

    # Format numbers according to market precision
    formatted_amount_str = format_amount(exchange, symbol, amount)
    formatted_trigger_price_str = format_price(exchange, symbol, trigger_price)
    formatted_limit_price_str = format_price(exchange, symbol, limit_price) if order_type == OrderType.LIMIT and limit_price else None

    if formatted_amount_str is None or formatted_trigger_price_str is None:
        logger.error(f"{Fore.RED}{log_prefix} Failed to format amount ({amount}) or trigger price ({trigger_price}).{Style.RESET_ALL}")
        return None
    if order_type == OrderType.LIMIT and formatted_limit_price_str is None:
         logger.error(f"{Fore.RED}{log_prefix} Failed to format limit price ({limit_price}) for Limit stop order.{Style.RESET_ALL}")
         return None

    logger.info(f"{Fore.BLUE}{log_prefix} Placing conditional order request...{Style.RESET_ALL}")

    # --- Prepare V5 Parameters for Conditional Order via create_order ---
    # CCXT often maps high-level types like 'stop' or 'stop_limit' to underlying params.
    # We pass specific V5 params explicitly for clarity and control.
    # **** V5 requires category param for orders ****
    params: Dict[str, Any] = {
        "category": category.value,
        "triggerPrice": formatted_trigger_price_str,
        "triggerBy": trigger_by.value,
        "reduceOnly": is_reduce_only,
        # V5 specific params for conditional orders:
        "orderType": order_type.value, # This is the type ('Market' or 'Limit') of the order placed *after* trigger
        # Explicitly set the conditional order type if provided
        "stopOrderType": stop_order_type if stop_order_type else None,
        # V5 uses 'slLimitPrice' / 'tpLimitPrice' for the limit price of triggered SL/TP orders
        # Map our generic limit_price based on context (or use specific args if needed)
        # If it's a generic Stop/StopLimit, 'price' is used in the request for the limit price.
        # If it's a TP/SL type, the specific fields might be required.
        # For simplicity, we'll rely on CCXT's create_order 'price' argument mapping for now.
    }
    # Add triggerDirection if specified (Bybit often infers this)
    if trigger_direction:
        params["triggerDirection"] = trigger_direction.value
    # Add Client Order ID if provided
    if client_order_id:
        clean_cid = "".join(filter(lambda c: c.isalnum() or c in ["-", "_"], client_order_id))[:36]
        if len(clean_cid) != len(client_order_id): logger.warning(f"{log_prefix} Client Order ID sanitized: '{clean_cid}'")
        if clean_cid: params["orderLinkId"] = clean_cid
    # Add Position Index if provided
    if position_idx is not None:
        params["positionIdx"] = position_idx.value

    # Remove None values from params before sending
    params_cleaned = {k: v for k, v in params.items() if v is not None}

    try:
        logger.info(f"{log_prefix} Sending create_order request for conditional order with params: {params_cleaned}...")

        # --- Determine CCXT order type and price argument ---
        # Map our OrderType (Market/Limit) to CCXT's conditional types.
        # Use more specific CCXT types if stop_order_type suggests it (e.g., 'takeProfitLimit')
        if order_type == OrderType.MARKET:
            ccxt_type = 'takeProfit' if stop_order_type == 'TakeProfit' else \
                        'stop' # Default to 'stop' for market triggers (covers StopLoss too)
        else: # OrderType.LIMIT
            ccxt_type = 'takeProfitLimit' if stop_order_type == 'TakeProfit' else \
                        'stopLimit' # Default to 'stopLimit' for limit triggers
        logger.debug(f"{log_prefix} Using CCXT type '{ccxt_type}' for create_order.")

        # Price argument for create_order:
        # - None for Market stops/take-profits
        # - limit_price for Limit stops/take-profits
        price_arg = float(formatted_limit_price_str) if order_type == OrderType.LIMIT and formatted_limit_price_str else None

        # Use the generic create_order method, passing V5 params
        # CCXT's Bybit implementation should handle mapping 'stop'/'stopLimit' etc. with triggerPrice.
        # POST /v5/order/create is used for conditional orders too.
        order = await exchange.create_order(
            symbol=symbol,
            type=ccxt_type, # Use CCXT's conditional type name
            side=side.value, # Side of the order to be placed on trigger
            amount=float(formatted_amount_str),
            price=price_arg, # Limit price for stop-limit, None for stop-market
            params=params_cleaned # Pass all specific V5 params here
        )

        # --- Process Response ---
        if not order or not isinstance(order, dict):
             logger.error(f"{Fore.RED}{log_prefix} FAILED - Received invalid order response from create_order.{Style.RESET_ALL}")
             return None

        # Log Success (Conditional orders usually return ID immediately, status is 'untriggered' or similar)
        order_id = order.get("id")
        status = order.get("status", "unknown") # Should be 'open' or specific conditional status like 'untriggered'
        # CCXT might place trigger price in 'stopPrice' or 'triggerPrice' field in the parsed order
        returned_trigger_price_raw = order.get("triggerPrice") or order.get("stopPrice")
        returned_trigger_price = safe_decimal_conversion(returned_trigger_price_raw)
        returned_limit_price = safe_decimal_conversion(order.get("price")) # Limit price of triggered order

        log_color = Fore.YELLOW # Conditional orders are pending until triggered
        log_msg = f"{log_color}{log_prefix} SUCCESS (Conditional Order Placed) - ID: ...{format_order_id(order_id)}, Status: {status}, TriggerPx: {format_price(exchange, symbol, returned_trigger_price)}"
        if order_type == OrderType.LIMIT:
            log_msg += f", LimitPx: {format_price(exchange, symbol, returned_limit_price)}"
        logger.info(log_msg + Style.RESET_ALL)
        return order

    # --- Error Handling ---
    except InsufficientFunds as e:
        # Might occur if margin is needed even for conditional order placement
        logger.error(f"{Back.RED}{log_prefix} FAILED - Insufficient Funds (check margin requirements?): {e}{Style.RESET_ALL}")
        return None
    except InvalidOrder as e: # Covers parameter errors, price/size constraints etc.
        logger.error(f"{Back.RED}{log_prefix} FAILED - Invalid Order Parameters/Rejected by Exchange: {e}{Style.RESET_ALL}")
        return None
    except ExchangeError as e: # Catch other specific exchange errors
        logger.error(f"{Back.RED}{log_prefix} FAILED - Exchange Error: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=False)
        return None
    except (NetworkError, ExchangeNotAvailable, RateLimitExceeded) as e:
        # Let retry decorator handle these by re-raising
        logger.error(f"{Back.RED}{log_prefix} FAILED - API Communication Error: {type(e).__name__}: {e}{Style.RESET_ALL}")
        raise e
    except Exception as e: # Catch any other unexpected errors
        logger.error(f"{Back.RED}{log_prefix} FAILED - Unexpected Error: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=True)
        return None


# --- WebSocket Management Stubs ---
# Full implementation is complex and requires careful state management, error handling,
# reconnection logic, and processing of various message types.
# These are basic placeholders demonstrating the structure for V5.

async def connect_ws(exchange: ccxt.bybit, config: Config) -> Optional[WebSocketClientProtocol]:
    """Placeholder: Establishes and authenticates a WebSocket connection for Bybit V5."""
    func_name = "connect_ws"
    log_prefix = f"[{func_name}]"
    if not websockets:
        logger.error(f"{Fore.RED}{log_prefix} 'websockets' library not installed. Cannot establish WebSocket connection.{Style.RESET_ALL}")
        return None

    # Determine WS URL based on public/private and mainnet/testnet
    is_testnet = config.get("TESTNET_MODE", False)
    has_keys = bool(config.get("API_KEY") and config.get("API_SECRET"))
    # Bybit V5 WS Endpoints:
    # Public Mainnet: wss://stream.bybit.com/v5/public/{category} (category=linear,inverse,spot,option)
    # Private Mainnet: wss://stream.bybit.com/v5/private
    # Public Testnet: wss://stream-testnet.bybit.com/v5/public/{category}
    # Private Testnet: wss://stream-testnet.bybit.com/v5/private
    base_url = "wss://stream-testnet.bybit.com/v5" if is_testnet else "wss://stream.bybit.com/v5"

    # Choose private stream if keys are available, otherwise default to a public stream
    # Public streams require a category, defaulting to linear here. Adjust if needed.
    ws_url = f"{base_url}/private" if has_keys else f"{base_url}/public/linear"

    logger.info(f"{Fore.BLUE}{log_prefix} Attempting to connect to WebSocket: {ws_url}...{Style.RESET_ALL}")
    connect_timeout = config.get("WS_CONNECT_TIMEOUT", 10.0) # Timeout for connection attempt

    try:
        # Establish connection
        # ping_interval=None disables automatic pings by websockets library; Bybit V5 requires manual pings.
        # Increase message size limit if needed: max_size=...
        ws = await asyncio.wait_for(
            websockets.connect(ws_url, ping_interval=None),
            timeout=connect_timeout
        )
        logger.info(f"{Fore.GREEN}{log_prefix} WebSocket connection established to {ws_url}.{Style.RESET_ALL}")

        # Authenticate if private connection
        if has_keys and ws_url.endswith("/private"):
            logger.info(f"{log_prefix} Authenticating private WebSocket connection...")
            # Pass the exchange instance for potential signing utilities
            auth_success = await ws_authenticate(ws, exchange, config)
            if not auth_success:
                logger.error(f"{Fore.RED}{log_prefix} WebSocket authentication failed. Closing connection.{Style.RESET_ALL}")
                await ws.close()
                return None
            logger.info(f"{Fore.GREEN}{log_prefix} WebSocket authentication successful.{Style.RESET_ALL}")

        # Start manual heartbeat task (Bybit requires ping every ~20s)
        ping_interval = config.get("WS_PING_INTERVAL", 20.0)
        if ping_interval:
             logger.info(f"{log_prefix} Starting WebSocket heartbeat task (Interval: {ping_interval}s).")
             # Start as a background task that doesn't block the main flow
             asyncio.create_task(ws_heartbeat(ws, ping_interval, log_prefix))

        return ws # Return the active WebSocket connection object

    except asyncio.TimeoutError:
        logger.error(f"{Fore.RED}{log_prefix} WebSocket connection timed out ({connect_timeout}s) to {ws_url}.{Style.RESET_ALL}")
        return None
    except (InvalidURI, WebSocketException, OSError) as e: # Catch connection errors
        logger.error(f"{Fore.RED}{log_prefix} WebSocket connection failed: {type(e).__name__}: {e}{Style.RESET_ALL}")
        return None
    except Exception as e:
        logger.error(f"{Fore.RED}{log_prefix} Unexpected error during WebSocket connection: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=True)
        return None

async def ws_authenticate(ws: WebSocketClientProtocol, exchange: ccxt.bybit, config: Config) -> bool:
    """Placeholder: Sends authentication message for Bybit V5 private WebSocket stream."""
    log_prefix = "[ws_authenticate]"
    if not ws or not config.get("API_KEY") or not config.get("API_SECRET"):
        logger.error(f"{log_prefix} Cannot authenticate: WebSocket connection or API keys missing.")
        return False

    # Bybit V5 WS Auth:
    # 1. Calculate expires timestamp (current time + validity window in ms, e.g., 10s)
    # 2. Create signature: hex(HMAC_SHA256(api_secret, "GET/realtime" + expires))
    # 3. Send auth message: {"op": "auth", "args": [api_key, expires, signature]}
    try:
        api_key = config["API_KEY"]
        api_secret = config["API_SECRET"]
        # Expires timestamp needs to be integer milliseconds
        expires = int((time.time() + 10) * 1000)
        signature_payload = f"GET/realtime{expires}"

        # Use CCXT's utility for HMAC signing (recommended and safer)
        if hasattr(exchange, 'hmac') and hasattr(exchange, 'encode'):
             # Ensure payload and secret are bytes
             signature = exchange.hmac(exchange.encode(signature_payload), exchange.encode(api_secret), 'sha256')
        else: # Manual implementation (requires 'hashlib' and 'hmac')
             logger.warning(f"{log_prefix} CCXT instance missing hmac/encode methods. Using manual signing (requires hashlib, hmac).")
             import hashlib, hmac
             signature = hmac.new(api_secret.encode('utf-8'), signature_payload.encode('utf-8'), hashlib.sha256).hexdigest()

        auth_msg = {
            "op": "auth",
            "args": [api_key, expires, signature]
        }
        await ws.send(json.dumps(auth_msg))
        logger.debug(f"{log_prefix} Auth message sent.")

        # Wait for auth response (important!)
        # Bybit sends: {"op":"auth","success":true/false,"ret_msg":"...", "conn_id":"..."}
        try:
            # Set a reasonable timeout for receiving the auth response
            response_raw = await asyncio.wait_for(ws.recv(), timeout=5.0)
            response = json.loads(response_raw)
            logger.debug(f"{log_prefix} Auth response received: {response}")
            # Check for explicit success flag
            if response.get("op") == "auth" and response.get("success") is True:
                return True
            else:
                 # Log failure details from response
                 err_msg = response.get("ret_msg", "Authentication failed")
                 logger.error(f"{log_prefix} Auth failed. Response: {err_msg} | Full: {response}")
                 return False
        except asyncio.TimeoutError:
            logger.error(f"{log_prefix} Timeout waiting for authentication response.")
            return False
        except (json.JSONDecodeError, WebSocketException, ConnectionClosed) as e:
             logger.error(f"{log_prefix} Error receiving/parsing auth response: {e}")
             return False

    except Exception as e:
        logger.error(f"{log_prefix} Error during authentication process: {e}", exc_info=True)
        return False

async def ws_heartbeat(ws: WebSocketClientProtocol, interval: float, log_prefix: str):
    """Placeholder: Sends periodic pings required by Bybit V5 WebSocket."""
    while ws and not ws.closed:
        try:
            # Bybit V5 requires a simple ping operation message
            # Include req_id for potential tracking, though often not needed for ping
            ping_payload = json.dumps({"req_id": f"ping_{int(time.time())}", "op": "ping"})
            await ws.send(ping_payload)
            logger.debug(f"{log_prefix} Sent ping.")
            # Wait for the specified interval before sending the next ping
            await asyncio.sleep(interval)
        except ConnectionClosed:
            logger.warning(f"{log_prefix} Heartbeat task: Connection closed. Stopping pings.")
            break # Exit loop if connection is closed
        except WebSocketException as e:
             # Log specific websocket errors during ping send
             logger.error(f"{log_prefix} Heartbeat task: WebSocket error sending ping: {e}. Stopping pings.")
             break
        except Exception as e:
            # Catch any other unexpected errors in the heartbeat loop
            logger.error(f"{log_prefix} Heartbeat task: Unexpected error: {e}. Stopping pings.", exc_info=True)
            break
    logger.info(f"{log_prefix} Heartbeat task finished.")


async def ws_subscribe(ws: WebSocketClientProtocol, topics: List[str], config: Config) -> bool:
    """Placeholder: Subscribes to specified Bybit V5 WebSocket topics."""
    func_name = "ws_subscribe"
    log_prefix = f"[{func_name}]"
    if not ws or ws.closed:
        logger.error(f"{log_prefix} WebSocket not connected or already closed.")
        return False
    if not topics:
        logger.warning(f"{log_prefix} No topics specified for subscription.")
        return False # Nothing to subscribe to
    if not websockets:
        logger.error(f"{log_prefix} 'websockets' library not available.")
        return False

    logger.info(f"{Fore.BLUE}{log_prefix} Subscribing to topics: {topics}...{Style.RESET_ALL}")
    try:
        # Format subscription message according to Bybit V5 WS API specs
        # e.g., {"op": "subscribe", "args": ["kline.1m.BTCUSDT", "order"]}
        # Use a unique req_id for tracking responses if needed
        subscribe_message = {
            "req_id": f"sub_{int(time.time())}",
            "op": "subscribe",
            "args": topics # List of topic strings
        }
        await ws.send(json.dumps(subscribe_message))
        logger.debug(f"{log_prefix} Subscription message sent: {subscribe_message}")

        # --- Optional: Wait for subscription confirmation ---
        # This requires more complex logic in the main message handler to correlate
        # the req_id with the response: {"op":"subscribe","success":true/false,...}
        # For simplicity here, we assume success if send doesn't fail immediately.
        # In a robust implementation, you'd wait for confirmation.
        logger.info(f"{Fore.GREEN}{log_prefix} Subscription request sent for topics: {topics}. (Confirmation pending in message handler){Style.RESET_ALL}")
        return True

    except (WebSocketException, ConnectionClosed) as e:
        logger.error(f"{Fore.RED}{log_prefix} Error sending subscription message: {type(e).__name__}: {e}{Style.RESET_ALL}")
        return False
    except Exception as e:
         logger.error(f"{Fore.RED}{log_prefix} Unexpected error during subscription request: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=True)
         return False

async def ws_message_handler(ws: WebSocketClientProtocol, message_queue: asyncio.Queue, config: Config):
    """Placeholder: Listens for messages, parses them, and puts relevant data on a queue."""
    func_name = "ws_message_handler"
    log_prefix = f"[{func_name}]"
    if not ws or not websockets:
        logger.error(f"{log_prefix} WebSocket not available. Cannot start message handler.")
        return
    if not message_queue:
         logger.error(f"{log_prefix} Message queue not provided. Cannot start message handler.")
         return

    logger.info(f"{Fore.BLUE}{log_prefix} Starting WebSocket message listener loop...{Style.RESET_ALL}")
    try:
        # Continuously listen for incoming messages
        async for message_raw in ws:
            try:
                # Attempt to parse the message as JSON
                data = json.loads(message_raw)
                # logger.debug(f"{log_prefix} Received WS message: {str(data)[:200]}") # Very verbose, use sparingly

                # --- Message Handling Logic ---
                # 1. Handle Pong responses to our Pings (confirm connection is alive)
                if isinstance(data, dict) and data.get("op") == "pong":
                    # Pong confirms connection is alive, might use req_id to measure latency
                    req_id = data.get("req_id", "N/A")
                    logger.debug(f"{log_prefix} Received pong (ReqID: {req_id}).")
                    continue # Nothing more to do with pongs here

                # 2. Handle Subscription confirmations
                if isinstance(data, dict) and data.get("op") == "subscribe":
                    req_id = data.get("req_id")
                    success = data.get("success")
                    ret_msg = data.get("ret_msg", "")
                    args = data.get("args", []) # Topics confirmed/failed
                    if success:
                        logger.info(f"{Fore.GREEN}{log_prefix} Subscription successful (ReqID: {req_id}). Topics: {args}. Msg: {ret_msg}{Style.RESET_ALL}")
                    else:
                        logger.error(f"{Fore.RED}{log_prefix} Subscription failed (ReqID: {req_id}). Topics: {args}. Msg: {ret_msg}{Style.RESET_ALL}")
                    # Could put confirmation onto queue if needed by main logic
                    # await message_queue.put({"type": "SUBSCRIPTION_CONF", "data": data})
                    continue

                # 3. Handle Authentication responses (should be handled during connect, but log if seen here)
                if isinstance(data, dict) and data.get("op") == "auth":
                     logger.info(f"{log_prefix} Received unexpected auth response in main loop: {data}")
                     continue

                # 4. Identify actual data messages (e.g., kline, orderbook, orders, positions)
                # Bybit V5 uses 'topic' field for data streams
                topic = data.get("topic") if isinstance(data, dict) else None
                if topic:
                    # logger.debug(f"{log_prefix} Received data for topic: {topic}")
                    # Put the relevant data onto the queue for processing elsewhere
                    # The queue consumer will need to know how to handle different topics
                    await message_queue.put(data)
                # Handle heartbeat messages from server if any (Bybit V5 doesn't usually send unsolicited pings)
                # Example check:
                # elif isinstance(data, dict) and data.get("op") == "ping":
                #    logger.debug(f"{log_prefix} Received server ping, sending pong...")
                #    await ws.send(json.dumps({"op": "pong", "req_id": data.get("req_id")}))
                else:
                    # Log unexpected message formats or types that aren't handled
                    logger.warning(f"{log_prefix} Received unhandled WebSocket message format/type: {str(data)[:200]}...")

            except json.JSONDecodeError:
                logger.error(f"{log_prefix} Failed to decode JSON from WebSocket message: {message_raw}")
            except asyncio.QueueFull:
                 logger.error(f"{Back.RED}{log_prefix} Message queue is full! Data is being produced faster than consumed. Potential data loss.{Style.RESET_ALL}")
                 # Implement backpressure (e.g., slow down subscriptions) or increase queue size if this happens often.
                 # Add a small sleep to prevent spamming the log.
                 await asyncio.sleep(1)
            except Exception as e:
                # Catch errors during processing of a single message
                logger.error(f"{log_prefix} Error processing WebSocket message: {type(e).__name__}: {e}", exc_info=True)
                # Continue processing next message

    # Handle connection closure or errors in the listener loop itself
    except (ConnectionClosed, ConnectionClosedOK, ConnectionClosedError) as e:
        logger.error(f"{Fore.RED}{log_prefix} WebSocket connection closed: {type(e).__name__}: {e}. Listener loop stopped.{Style.RESET_ALL}")
        # Signal that reconnection might be needed
        try: await message_queue.put({"type": "SYSTEM_EVENT", "event": "WS_CLOSED", "error": str(e)})
        except asyncio.QueueFull: logger.error(f"{log_prefix} Queue full while trying to signal WS closure.")
    except WebSocketException as e:
         logger.error(f"{Fore.RED}{log_prefix} WebSocket exception in listener loop: {type(e).__name__}: {e}. Listener loop stopped.{Style.RESET_ALL}")
         try: await message_queue.put({"type": "SYSTEM_EVENT", "event": "WS_ERROR", "error": str(e)})
         except asyncio.QueueFull: logger.error(f"{log_prefix} Queue full while trying to signal WS error.")
    except Exception as e:
         logger.error(f"{Fore.RED}{log_prefix} Unexpected critical error in WebSocket listener loop: {type(e).__name__}: {e}{Style.RESET_ALL}", exc_info=True)
         try: await message_queue.put({"type": "SYSTEM_EVENT", "event": "WS_CRITICAL_ERROR", "error": str(e)})
         except asyncio.QueueFull: logger.error(f"{log_prefix} Queue full while trying to signal WS critical error.")
    finally:
         logger.info(f"{log_prefix} WebSocket message listener loop has finished.")


# --- Main Execution Guard (Example Usage) ---
async def example_usage():
    """Demonstrates basic usage of the enhanced helper functions."""
    # --- Load Configuration ---
    # In a real application, load this securely (e.g., .env file, config parser)
    # Ensure environment variables are set for API_KEY/SECRET if needed
    cfg: Config = {
        "EXCHANGE_ID": "bybit",
        "API_KEY": os.environ.get("BYBIT_API_KEY"),
        "API_SECRET": os.environ.get("BYBIT_API_SECRET"),
        "TESTNET_MODE": True, # <--- Set to False for Mainnet!
        "SYMBOL": "BTC/USDT:USDT", # Example Linear Perpetual
        "USDT_SYMBOL": "USDT",
        "DEFAULT_MARGIN_MODE": "isolated", # or "cross"
        "DEFAULT_RECV_WINDOW": 10000, # Increased from default 5000ms
        "DEFAULT_SLIPPAGE_PCT": Decimal("0.005"), # 0.5% allowed for market order spread check
        "POSITION_QTY_EPSILON": Decimal("1E-8"), # For float comparisons
        "SHALLOW_OB_FETCH_DEPTH": 5, # For quick spread checks
        "ORDER_BOOK_FETCH_LIMIT": 50, # Default limit for fetch_l2_order_book
        "EXPECTED_MARKET_TYPE": "swap", # Default context type
        "EXPECTED_MARKET_LOGIC": "linear", # Default context logic
        "RETRY_COUNT": 3, # Default retry attempts for API calls
        "RETRY_DELAY_SECONDS": 1.5, # Initial delay for retries
        "ENABLE_SMS_ALERTS": False, # Set to True and configure Twilio keys to enable
        "VERSION": "3.5", # Match script version
        # "BROKER_ID": "YOUR_BROKER_ID", # Optional: Set your Bybit Broker/Referral ID
        "WS_CONNECT_TIMEOUT": 15.0, # WebSocket connection timeout
        "WS_PING_INTERVAL": 20.0, # Send ping every 20s for Bybit WS
    }

    # Basic check for API keys
    has_keys = bool(cfg["API_KEY"] and cfg["API_SECRET"])
    if not has_keys:
        print(f"{Fore.YELLOW}Warning: BYBIT_API_KEY or BYBIT_API_SECRET environment variables not set.{Style.RESET_ALL}")
        print(f"{Fore.YELLOW}Proceeding in public-only mode. Private endpoints will be skipped.{Style.RESET_ALL}")

    # --- Initialize Exchange ---
    print("\n--- Initializing Bybit Exchange ---")
    exchange = await initialize_bybit(cfg)

    if not exchange:
        print(f"{Back.RED}FATAL: Failed to initialize Bybit exchange. Exiting example.{Style.RESET_ALL}")
        return # Exit if initialization failed

    print(f"\n{Fore.GREEN}--- Exchange Initialized Successfully ({exchange.id}, Mode: {'Testnet' if cfg['TESTNET_MODE'] else 'Mainnet'}) ---{Style.RESET_ALL}")

    # --- Example API Calls ---
    try:
        print(f"\n--- Fetching Ticker ({cfg['SYMBOL']}) ---")
        # Pass config object
        ticker = await fetch_ticker_validated(exchange, cfg['SYMBOL'], cfg)
        if ticker:
            print(f"  Symbol: {ticker.get('symbol')}, Last: {ticker.get('last')}, Bid: {ticker.get('bid')}, Ask: {ticker.get('ask')}")
            # Store last price for placing test orders relative to it
            last_price = safe_decimal_conversion(ticker.get('last'))
        else:
            print(f"{Fore.RED}  Failed to fetch ticker.{Style.RESET_ALL}")
            last_price = None # Cannot place relative orders

        print(f"\n--- Fetching OHLCV ({cfg['SYMBOL']}, 1h, limit=5) ---")
        # Pass config object
        ohlcv = await fetch_ohlcv_paginated(exchange, cfg['SYMBOL'], '1h', limit=5, config=cfg)
        if ohlcv is not None:
            print("  OHLCV Data Sample:")
            if pd and isinstance(ohlcv, pd.DataFrame):
                print(ohlcv.tail().to_string()) # Print last 5 rows if DataFrame
            elif isinstance(ohlcv, list):
                for candle in ohlcv[-5:]: print(f"  - {candle}") # Print last 5 if list
        else:
             print(f"{Fore.RED}  Failed to fetch OHLCV.{Style.RESET_ALL}")

        # --- Private Endpoint Examples (Require API Keys) ---
        if has_keys:
            print("\n--- Fetching USDT Balance (Unified Account) ---")
            # Pass config object
            equity, available = await fetch_usdt_balance(exchange, cfg)
            if equity is not None and available is not None:
                print(f"  Total Equity: {equity:.4f} {cfg['USDT_SYMBOL']}")
                print(f"  Available Balance: {available:.4f} {cfg['USDT_SYMBOL']}")
            else:
                 print(f"{Fore.RED}  Failed to fetch balance.{Style.RESET_ALL}")

            print(f"\n--- Fetching Position ({cfg['SYMBOL']}) ---")
            # Pass config object
            position = await fetch_position(exchange, cfg['SYMBOL'], cfg)
            # Position dict can be complex, print key info
            if position:
                 pos_size = position.get('contracts', Decimal(0))
                 pos_side = position.get('side', 'flat') if abs(pos_size) > cfg.get("POSITION_QTY_EPSILON", Decimal("1E-8")) else 'flat'
                 print(f"  Symbol: {position.get('symbol')}, Side: {pos_side}, Size: {pos_size}, Entry: {position.get('entryPrice', 'N/A')}, LiqPx: {position.get('liquidationPrice', 'N/A')}")
            else:
                 # This indicates an error occurred during fetch
                 print(f"{Fore.RED}  Failed to fetch position data.{Style.RESET_ALL}")

            print(f"\n--- Fetching Open Orders ({cfg['SYMBOL']}, Filter: StopOrder) ---")
            # Example: Fetch only open conditional stop orders
            # Pass config object
            open_stop_orders = await fetch_open_orders(exchange, cfg['SYMBOL'], order_filter=OrderFilter.STOP_ORDER, config=cfg)
            print(f"  Found {len(open_stop_orders)} open STOP orders for {cfg['SYMBOL']}.")
            for order in open_stop_orders:
                 trig_px = order.get('stopPrice') or order.get('triggerPrice', 'N/A')
                 print(f"  - ID: ...{format_order_id(order['id'])}, Side: {order['side']}, TrigPx: {trig_px}, Amount: {order['amount']}")

            # --- Example Order Placement (Use with extreme caution on Mainnet!) ---
            if cfg['TESTNET_MODE'] and last_price: # Only run placement examples on Testnet AND if ticker fetch succeeded
                print(f"\n{Fore.YELLOW}--- Running Test Order Placement (Testnet Only) ---{Style.RESET_ALL}")
                # Determine category for cancellation later
                symbol_category = market_cache.get_category(cfg['SYMBOL'])

                try:
                    # Determine small amount based on market minimums (hardcoded for BTC example)
                    min_qty_btc = Decimal("0.001") # Adjust based on actual symbol minimums
                    test_amount = min_qty_btc
                    # Place order significantly away from current price to avoid immediate fill
                    test_price_buy = last_price * Decimal("0.8") # 20% below last
                    test_price_sell = last_price * Decimal("1.2") # 20% above last

                    print("  Placing test limit buy...")
                    limit_order_buy = await place_limit_order_tif(
                        exchange, cfg['SYMBOL'], Side.BUY, test_amount, test_price_buy, cfg,
                        time_in_force=TimeInForce.GTC, client_order_id=f"test_buy_{int(time.time())}"
                    )
                    if limit_order_buy:
                        print(f"    -> Placed Buy Limit Order ID: ...{format_order_id(limit_order_buy.get('id'))}, Status: {limit_order_buy.get('status')}")
                    else:
                         print(f"    -> {Fore.RED}Failed to place test buy limit order.{Style.RESET_ALL}")

                    await asyncio.sleep(1) # Small delay

                    print("  Placing test limit sell...")
                    limit_order_sell = await place_limit_order_tif(
                        exchange, cfg['SYMBOL'], Side.SELL, test_amount, test_price_sell, cfg,
                        time_in_force=TimeInForce.GTC, client_order_id=f"test_sell_{int(time.time())}"
                    )
                    if limit_order_sell:
                         print(f"    -> Placed Sell Limit Order ID: ...{format_order_id(limit_order_sell.get('id'))}, Status: {limit_order_sell.get('status')}")
                    else:
                          print(f"    -> {Fore.RED}Failed to place test sell limit order.{Style.RESET_ALL}")

                    await asyncio.sleep(2) # Wait a bit before cancelling

                    print(f"\n--- Cancelling All Orders ({cfg['SYMBOL']}, Category: {symbol_category.value if symbol_category else 'N/A'}) from Test ---")
                    if symbol_category:
                        # Pass config and the determined category
                        cancel_all_success = await cancel_all_orders(
                            exchange, symbol=cfg['SYMBOL'], category_to_cancel=symbol_category, config=cfg
                        )
                        print(f"  Cancel All for {cfg['SYMBOL']} Status: {cancel_all_success}")
                    else:
                         print(f"{Fore.RED}  Cannot cancel - category unknown for {cfg['SYMBOL']}{Style.RESET_ALL}")


                except Exception as e:
                    print(f"{Fore.RED}  Error during test order placement/cancellation: {e}{Style.RESET_ALL}")
                    # Attempt cleanup even on error
                    print(f"{Fore.YELLOW}  Attempting cleanup: Cancelling all orders for {cfg['SYMBOL']} after error...{Style.RESET_ALL}")
                    if symbol_category:
                        await cancel_all_orders(exchange, symbol=cfg['SYMBOL'], category_to_cancel=symbol_category, config=cfg)
                    else:
                         print(f"{Fore.RED}  Cannot cleanup - category unknown.{Style.RESET_ALL}")


                # Example: Place Batch Orders (Testnet Only)
                print(f"\n--- Placing Batch Orders (Testnet Only) ---")
                # Requires last_price to be fetched successfully
                batch_order_requests = [
                    { # Valid Buy Limit Below Market
                        "symbol": cfg['SYMBOL'], "side": Side.BUY, "type": OrderType.LIMIT, # Use Enum or String
                        "amount": Decimal("0.001"), "price": last_price * Decimal("0.9"),
                        "clientOrderId": f"batch_buy_{int(time.time())}"
                    },
                    { # Valid Sell Limit Above Market
                        "symbol": cfg['SYMBOL'], "side": Side.SELL, "type": "Limit", # Use string
                        "amount": Decimal("0.001"), "price": last_price * Decimal("1.1"),
                        "clientOrderId": f"batch_sell_{int(time.time())}"
                    },
                    { # Invalid Order (e.g., amount too small - expect API error)
                        "symbol": cfg['SYMBOL'], "side": Side.BUY, "type": "Limit",
                        "amount": Decimal("0.0000001"), "price": last_price * Decimal("0.8"),
                        "clientOrderId": f"batch_invalid_amt_{int(time.time())}"
                    },
                    { # Valid Market Order (Will likely execute immediately on testnet)
                        "symbol": cfg['SYMBOL'], "side": Side.BUY, "type": "Market",
                        "amount": Decimal("0.001"), # Amount for market order
                        "timeInForce": TimeInForce.IOC, # Good practice for market
                        "clientOrderId": f"batch_market_{int(time.time())}"
                    }
                ]

                # Call the batch order function (pass config)
                # Category will be inferred from the first order (BTC/USDT:USDT -> linear)
                successes, errors = await place_batch_orders(exchange, batch_order_requests, cfg)

                print("  Batch Results:")
                for i, (s, e) in enumerate(zip(successes, errors)):
                    orig_req = batch_order_requests[i]
                    cid = orig_req.get('clientOrderId', 'N/A')
                    outcome = ""
                    if s:
                        outcome = f"{Fore.GREEN}SUCCESS: ID ...{format_order_id(s.get('id'))}, Status: {s.get('status')}{Style.RESET_ALL}"
                    elif e:
                        outcome = f"{Fore.RED}FAILED: Code={e.get('code', 'N/A')}, Msg='{e.get('msg', 'N/A')}'{Style.RESET_ALL}"
                    else:
                        # This case means it wasn't marked as success or error, indicating a possible logic gap
                        outcome = f"{Fore.YELLOW}UNKNOWN STATUS (Should have success or error){Style.RESET_ALL}"
                    print(f"    Order #{i+1} (CID:{cid}) -> {outcome}")

                # Clean up any potentially open orders from the batch test
                await asyncio.sleep(2)
                print(f"\n--- Cancelling All Orders ({cfg['SYMBOL']}, Category: {symbol_category.value if symbol_category else 'N/A'}) from Batch Test ---")
                if symbol_category:
                    # Pass config and category
                    await cancel_all_orders(exchange, symbol=cfg['SYMBOL'], category_to_cancel=symbol_category, config=cfg)
                else:
                    print(f"{Fore.RED}  Cannot cancel - category unknown.{Style.RESET_ALL}")

            elif not cfg['TESTNET_MODE']:
                 print(f"\n{Fore.YELLOW}--- Skipping Order Placement Examples (Not on Testnet) ---{Style.RESET_ALL}")
            else: # Testnet but last_price failed
                 print(f"\n{Fore.YELLOW}--- Skipping Order Placement Examples (Failed to get ticker price) ---{Style.RESET_ALL}")

        else: # No API keys
            print(f"\n{Fore.YELLOW}--- Skipping Private Endpoint Examples (API Keys Not Provided) ---{Style.RESET_ALL}")

    except Exception as e:
        print(f"\n{Back.RED}--- An unexpected error occurred during example usage: {type(e).__name__}: {e} ---{Style.RESET_ALL}")
        import traceback
        traceback.print_exc()

    finally:
        # --- Close Exchange Connection ---
        # **** CRUCIAL STEP to release resources and prevent warnings/leaks ****
        if exchange and hasattr(exchange, 'close'):
            print("\n--- Closing Exchange Connection ---")
            try:
                # Must be awaited
                await exchange.close()
                print(f"{Fore.GREEN}  Exchange connection closed successfully.{Style.RESET_ALL}")
            except Exception as close_err:
                print(f"{Fore.RED}  Error closing exchange connection: {close_err}{Style.RESET_ALL}")
        else:
            print("\n--- Exchange instance not available for closing ---")

# --- Main Entry Point ---
if __name__ == "__main__":
    # --- Configure Logging ---
    # Set basic configuration for the root logger if this script is run directly
    # This allows seeing logs from this script and potentially CCXT/other libs
    log_format = "%(asctime)s [%(levelname)-8s] {%(name)s:%(lineno)d} - %(message)s"
    log_datefmt = "%Y-%m-%d %H:%M:%S"
    # Set level for this script's logger and potentially others
    logging.basicConfig(level=logging.INFO, format=log_format, datefmt=log_datefmt)
    # Optionally set lower levels for specific loggers:
    logging.getLogger("bybit_helpers").setLevel(logging.DEBUG) # Show debug from this script
    # logging.getLogger('ccxt').setLevel(logging.INFO) # Show info from CCXT (can be verbose)

    print("--- Running Bybit Helper Example Usage ---")
    try:
        # Use asyncio.run() for simple top-level execution of the async example
        asyncio.run(example_usage())
    except KeyboardInterrupt:
        print("\nExecution interrupted by user (Ctrl+C).")
    except Exception as main_err:
         print(f"\n{Back.RED}--- Main execution failed: {type(main_err).__name__}: {main_err} ---{Style.RESET_ALL}")
         import traceback
         traceback.print_exc()
    finally:
        print("\n--- Example Usage Finished ---")

```

**Key Changes and Fixes:**

1.  **`cancel_all_orders` Fixed**:
    *   The function now correctly accepts `category_to_cancel` as an argument.
    *   **Crucially**, it reflects the Bybit V5 API limitation: you **must** specify a category to cancel. It cannot cancel across all categories in one call. The logic now requires either `symbol` (to infer category) or `category_to_cancel` to be provided.
    *   It uses the correct V5 implicit method `private_post_v5_order_cancel_all`.
    *   Improved response parsing and logging for clarity.
2.  **Category Parameter Added**: Added the mandatory `category` parameter to the `params` dictionary for all relevant V5 API calls made via CCXT methods (`fetch_ticker`, `fetch_ohlcv`, `fetch_l2_order_book`, `fetch_trades`, `fetch_positions`, `fetch_open_orders`, `cancel_order`, order placement functions). The category is retrieved using `market_cache.get_category(symbol)`.
3.  **`initialize_bybit` Robustness**:
    *   Improved error handling during initialization steps (market loading, auth check, config).
    *   Crucially, added `await exchange.close()` calls within `except` blocks if initialization fails *after* the `exchange` object has been created, preventing resource leaks on failed startup.
    *   Refined the logic and logging around checking account margin mode (`fetch_account_info_bybit_v5`).
4.  **`fetch_account_info_bybit_v5` Logging**: Adjusted logging to accurately reflect that Code 0 means API success, even if the *result data* might lack specific details needed by the caller.
5.  **`fetch_position` Improvement**: Returns a standardized "flat" dictionary when no position is found, making it easier for calling code to handle flat positions consistently without checking for `None`.
6.  **`place_batch_orders` Refined**:
    *   Improved validation logic for input orders.
    *   Enhanced parsing of the V5 batch response (`result.list` and `result.errInfo`).
    *   More robust mapping of API responses back to the original request list using `orderLinkId`.
    *   Clearer logging of individual order successes/failures within the batch.
7.  **Resource Cleanup (`await exchange.close()`)**:
    *   Added explicit warnings and documentation about the necessity of calling `await exchange.close()`.
    *   Ensured the `example_usage` function calls it in a `finally` block.
8.  **Documentation and Logging**: Improved comments, docstrings, and log messages throughout for better clarity and debugging. Added version check for CCXT. Made API keys optional in `Config`.
9.  **Error Notes**: Added comments explicitly stating that the `AttributeError: get_current_position_bybit_v5` and `AttributeError: 'bybit' object has no attribute 'closed'` errors need to be fixed in the **calling script** (`ehlers_volumetric_strategy.py`), not in this helper module.

**Next Steps:**

1.  **Replace** your existing `bybit_helpers.py` with this enhanced version.
2.  **Modify your `ehlers_volumetric_strategy.py` (and potentially `main.py`)**:
    *   Change calls like `bybit.get_current_position_bybit_v5(...)` to `bybit.fetch_position(exchange, symbol, config)`.
    *   Ensure you pass the `category` parameter correctly when calling the *fixed* `bybit.cancel_all_orders(...)`. You'll need to determine the category of the symbol you want to cancel orders for.
    *   Fix the check `if self.exchange and hasattr(self.exchange, 'close') and not self.exchange.closed:` - remove the `.closed` check. Simply check `if self.exchange:` before attempting cleanup.
    *   **Most Importantly:** Ensure your main execution logic in `main.py` calls `await strategy_instance.exchange.close()` (or `await exchange.close()` if the instance is managed there) inside a `finally` block to guarantee resource cleanup, even if errors occur.
3.  **Review Configuration**: Ensure your `.env` file or config loading mechanism provides the necessary API keys (if needed) and other settings defined in the `Config` TypedDict.
4.  **Test Thoroughly**: Run your application again, preferably on the testnet first, to confirm the errors are resolved and the bot operates as expected. Check the logs for any new warnings or errors.
